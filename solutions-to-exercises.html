<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 18 Solutions to exercises | Machine Learning for Factor Investing</title>
  <meta name="description" content="Chapter 18 Solutions to exercises | Machine Learning for Factor Investing" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 18 Solutions to exercises | Machine Learning for Factor Investing" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 18 Solutions to exercises | Machine Learning for Factor Investing" />
  
  
  

<meta name="author" content="Guillaume Coqueret and Tony Guida" />


<meta name="date" content="2021-04-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-description.html"/>

<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-this-book-is-not-about"><i class="fa fa-check"></i>What this book is not about</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#the-targeted-audience"><i class="fa fa-check"></i>The targeted audience</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#how-this-book-is-structured"><i class="fa fa-check"></i>How this book is structured</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#companion-website"><i class="fa fa-check"></i>Companion website</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#why-r"><i class="fa fa-check"></i>Why R?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#coding-instructions"><i class="fa fa-check"></i>Coding instructions</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#future-developments"><i class="fa fa-check"></i>Future developments</a></li>
</ul></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="notdata.html"><a href="notdata.html"><i class="fa fa-check"></i><b>1</b> Notations and data</a>
<ul>
<li class="chapter" data-level="1.1" data-path="notdata.html"><a href="notdata.html#notations"><i class="fa fa-check"></i><b>1.1</b> Notations</a></li>
<li class="chapter" data-level="1.2" data-path="notdata.html"><a href="notdata.html#dataset"><i class="fa fa-check"></i><b>1.2</b> Dataset</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#context"><i class="fa fa-check"></i><b>2.1</b> Context</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#portfolio-construction-the-workflow"><i class="fa fa-check"></i><b>2.2</b> Portfolio construction: the workflow</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#machine-learning-is-no-magic-wand"><i class="fa fa-check"></i><b>2.3</b> Machine learning is no magic wand</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="factor.html"><a href="factor.html"><i class="fa fa-check"></i><b>3</b> Factor investing and asset pricing anomalies</a>
<ul>
<li class="chapter" data-level="3.1" data-path="factor.html"><a href="factor.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="factor.html"><a href="factor.html#detecting-anomalies"><i class="fa fa-check"></i><b>3.2</b> Detecting anomalies</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="factor.html"><a href="factor.html#challenges"><i class="fa fa-check"></i><b>3.2.1</b> Challenges</a></li>
<li class="chapter" data-level="3.2.2" data-path="factor.html"><a href="factor.html#simple-portfolio-sorts"><i class="fa fa-check"></i><b>3.2.2</b> Simple portfolio sorts  </a></li>
<li class="chapter" data-level="3.2.3" data-path="factor.html"><a href="factor.html#factors"><i class="fa fa-check"></i><b>3.2.3</b> Factors</a></li>
<li class="chapter" data-level="3.2.4" data-path="factor.html"><a href="factor.html#predictive-regressions-sorts-and-p-value-issues"><i class="fa fa-check"></i><b>3.2.4</b> Predictive regressions, sorts, and p-value issues</a></li>
<li class="chapter" data-level="3.2.5" data-path="factor.html"><a href="factor.html#fama-macbeth-regressions"><i class="fa fa-check"></i><b>3.2.5</b> Fama-Macbeth regressions</a></li>
<li class="chapter" data-level="3.2.6" data-path="factor.html"><a href="factor.html#factor-competition"><i class="fa fa-check"></i><b>3.2.6</b> Factor competition</a></li>
<li class="chapter" data-level="3.2.7" data-path="factor.html"><a href="factor.html#advanced-techniques"><i class="fa fa-check"></i><b>3.2.7</b> Advanced techniques</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="factor.html"><a href="factor.html#factors-or-characteristics"><i class="fa fa-check"></i><b>3.3</b> Factors or characteristics?</a></li>
<li class="chapter" data-level="3.4" data-path="factor.html"><a href="factor.html#hot-topics-momentum-timing-and-esg"><i class="fa fa-check"></i><b>3.4</b> Hot topics: momentum, timing and ESG</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="factor.html"><a href="factor.html#factor-momentum"><i class="fa fa-check"></i><b>3.4.1</b> Factor momentum</a></li>
<li class="chapter" data-level="3.4.2" data-path="factor.html"><a href="factor.html#factor-timing"><i class="fa fa-check"></i><b>3.4.2</b> Factor timing</a></li>
<li class="chapter" data-level="3.4.3" data-path="factor.html"><a href="factor.html#the-green-factors"><i class="fa fa-check"></i><b>3.4.3</b> The green factors</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="factor.html"><a href="factor.html#the-links-with-machine-learning"><i class="fa fa-check"></i><b>3.5</b> The links with machine learning</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="factor.html"><a href="factor.html#a-short-list-of-recent-references"><i class="fa fa-check"></i><b>3.5.1</b> A short list of recent references</a></li>
<li class="chapter" data-level="3.5.2" data-path="factor.html"><a href="factor.html#explicit-connections-with-asset-pricing-models"><i class="fa fa-check"></i><b>3.5.2</b> Explicit connections with asset pricing models</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="factor.html"><a href="factor.html#coding-exercises"><i class="fa fa-check"></i><b>3.6</b> Coding exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Data.html"><a href="Data.html"><i class="fa fa-check"></i><b>4</b> Data preprocessing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="Data.html"><a href="Data.html#know-your-data"><i class="fa fa-check"></i><b>4.1</b> Know your data</a></li>
<li class="chapter" data-level="4.2" data-path="Data.html"><a href="Data.html#missing-data"><i class="fa fa-check"></i><b>4.2</b> Missing data</a></li>
<li class="chapter" data-level="4.3" data-path="Data.html"><a href="Data.html#outlier-detection"><i class="fa fa-check"></i><b>4.3</b> Outlier detection</a></li>
<li class="chapter" data-level="4.4" data-path="Data.html"><a href="Data.html#feateng"><i class="fa fa-check"></i><b>4.4</b> Feature engineering</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="Data.html"><a href="Data.html#feature-selection"><i class="fa fa-check"></i><b>4.4.1</b> Feature selection</a></li>
<li class="chapter" data-level="4.4.2" data-path="Data.html"><a href="Data.html#scaling"><i class="fa fa-check"></i><b>4.4.2</b> Scaling the predictors</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="Data.html"><a href="Data.html#labelling"><i class="fa fa-check"></i><b>4.5</b> Labelling</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="Data.html"><a href="Data.html#simple-labels"><i class="fa fa-check"></i><b>4.5.1</b> Simple labels</a></li>
<li class="chapter" data-level="4.5.2" data-path="Data.html"><a href="Data.html#categorical-labels"><i class="fa fa-check"></i><b>4.5.2</b> Categorical labels</a></li>
<li class="chapter" data-level="4.5.3" data-path="Data.html"><a href="Data.html#the-triple-barrier-method"><i class="fa fa-check"></i><b>4.5.3</b> The triple barrier method</a></li>
<li class="chapter" data-level="4.5.4" data-path="Data.html"><a href="Data.html#filtering-the-sample"><i class="fa fa-check"></i><b>4.5.4</b> Filtering the sample</a></li>
<li class="chapter" data-level="4.5.5" data-path="Data.html"><a href="Data.html#horizons"><i class="fa fa-check"></i><b>4.5.5</b> Return horizons</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="Data.html"><a href="Data.html#pers"><i class="fa fa-check"></i><b>4.6</b> Handling persistence</a></li>
<li class="chapter" data-level="4.7" data-path="Data.html"><a href="Data.html#extensions"><i class="fa fa-check"></i><b>4.7</b> Extensions</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="Data.html"><a href="Data.html#transforming-features"><i class="fa fa-check"></i><b>4.7.1</b> Transforming features</a></li>
<li class="chapter" data-level="4.7.2" data-path="Data.html"><a href="Data.html#macrovar"><i class="fa fa-check"></i><b>4.7.2</b> Macro-economic variables</a></li>
<li class="chapter" data-level="4.7.3" data-path="Data.html"><a href="Data.html#active-learning"><i class="fa fa-check"></i><b>4.7.3</b> Active learning</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="Data.html"><a href="Data.html#additional-code-and-results"><i class="fa fa-check"></i><b>4.8</b> Additional code and results</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="Data.html"><a href="Data.html#impact-of-rescaling-graphical-representation"><i class="fa fa-check"></i><b>4.8.1</b> Impact of rescaling: graphical representation</a></li>
<li class="chapter" data-level="4.8.2" data-path="Data.html"><a href="Data.html#impact-of-rescaling-toy-example"><i class="fa fa-check"></i><b>4.8.2</b> Impact of rescaling: toy example</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="Data.html"><a href="Data.html#coding-exercises-1"><i class="fa fa-check"></i><b>4.9</b> Coding exercises</a></li>
</ul></li>
<li class="part"><span><b>II Common supervised algorithms</b></span></li>
<li class="chapter" data-level="5" data-path="lasso.html"><a href="lasso.html"><i class="fa fa-check"></i><b>5</b> Penalized regressions and sparse hedging for minimum variance portfolios</a>
<ul>
<li class="chapter" data-level="5.1" data-path="lasso.html"><a href="lasso.html#penalized-regressions"><i class="fa fa-check"></i><b>5.1</b> Penalized regressions</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="lasso.html"><a href="lasso.html#penreg"><i class="fa fa-check"></i><b>5.1.1</b> Simple regressions</a></li>
<li class="chapter" data-level="5.1.2" data-path="lasso.html"><a href="lasso.html#forms-of-penalizations"><i class="fa fa-check"></i><b>5.1.2</b> Forms of penalizations</a></li>
<li class="chapter" data-level="5.1.3" data-path="lasso.html"><a href="lasso.html#illustrations"><i class="fa fa-check"></i><b>5.1.3</b> Illustrations</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="lasso.html"><a href="lasso.html#sparse-hedging-for-minimum-variance-portfolios"><i class="fa fa-check"></i><b>5.2</b> Sparse hedging for minimum variance portfolios</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="lasso.html"><a href="lasso.html#presentation-and-derivations"><i class="fa fa-check"></i><b>5.2.1</b> Presentation and derivations</a></li>
<li class="chapter" data-level="5.2.2" data-path="lasso.html"><a href="lasso.html#sparseex"><i class="fa fa-check"></i><b>5.2.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="lasso.html"><a href="lasso.html#predictive-regressions"><i class="fa fa-check"></i><b>5.3</b> Predictive regressions</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="lasso.html"><a href="lasso.html#literature-review-and-principle"><i class="fa fa-check"></i><b>5.3.1</b> Literature review and principle</a></li>
<li class="chapter" data-level="5.3.2" data-path="lasso.html"><a href="lasso.html#code-and-results"><i class="fa fa-check"></i><b>5.3.2</b> Code and results</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="lasso.html"><a href="lasso.html#coding-exercise"><i class="fa fa-check"></i><b>5.4</b> Coding exercise</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="trees.html"><a href="trees.html"><i class="fa fa-check"></i><b>6</b> Tree-based methods</a>
<ul>
<li class="chapter" data-level="6.1" data-path="trees.html"><a href="trees.html#simple-trees"><i class="fa fa-check"></i><b>6.1</b> Simple trees</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="trees.html"><a href="trees.html#principle"><i class="fa fa-check"></i><b>6.1.1</b> Principle</a></li>
<li class="chapter" data-level="6.1.2" data-path="trees.html"><a href="trees.html#treeclass"><i class="fa fa-check"></i><b>6.1.2</b> Further details on classification</a></li>
<li class="chapter" data-level="6.1.3" data-path="trees.html"><a href="trees.html#pruning-criteria"><i class="fa fa-check"></i><b>6.1.3</b> Pruning criteria</a></li>
<li class="chapter" data-level="6.1.4" data-path="trees.html"><a href="trees.html#code-and-interpretation"><i class="fa fa-check"></i><b>6.1.4</b> Code and interpretation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="trees.html"><a href="trees.html#random-forests"><i class="fa fa-check"></i><b>6.2</b> Random forests</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="trees.html"><a href="trees.html#principle-1"><i class="fa fa-check"></i><b>6.2.1</b> Principle</a></li>
<li class="chapter" data-level="6.2.2" data-path="trees.html"><a href="trees.html#code-and-results-1"><i class="fa fa-check"></i><b>6.2.2</b> Code and results</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="trees.html"><a href="trees.html#adaboost"><i class="fa fa-check"></i><b>6.3</b> Boosted trees: Adaboost</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="trees.html"><a href="trees.html#methodology"><i class="fa fa-check"></i><b>6.3.1</b> Methodology</a></li>
<li class="chapter" data-level="6.3.2" data-path="trees.html"><a href="trees.html#illustration"><i class="fa fa-check"></i><b>6.3.2</b> Illustration</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="trees.html"><a href="trees.html#boosted-trees-extreme-gradient-boosting"><i class="fa fa-check"></i><b>6.4</b> Boosted trees: extreme gradient boosting</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="trees.html"><a href="trees.html#managing-loss"><i class="fa fa-check"></i><b>6.4.1</b> Managing loss</a></li>
<li class="chapter" data-level="6.4.2" data-path="trees.html"><a href="trees.html#penalization"><i class="fa fa-check"></i><b>6.4.2</b> Penalization</a></li>
<li class="chapter" data-level="6.4.3" data-path="trees.html"><a href="trees.html#aggregation"><i class="fa fa-check"></i><b>6.4.3</b> Aggregation</a></li>
<li class="chapter" data-level="6.4.4" data-path="trees.html"><a href="trees.html#tree-structure"><i class="fa fa-check"></i><b>6.4.4</b> Tree structure</a></li>
<li class="chapter" data-level="6.4.5" data-path="trees.html"><a href="trees.html#boostext"><i class="fa fa-check"></i><b>6.4.5</b> Extensions</a></li>
<li class="chapter" data-level="6.4.6" data-path="trees.html"><a href="trees.html#boostcode"><i class="fa fa-check"></i><b>6.4.6</b> Code and results</a></li>
<li class="chapter" data-level="6.4.7" data-path="trees.html"><a href="trees.html#instweight"><i class="fa fa-check"></i><b>6.4.7</b> Instance weighting</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="trees.html"><a href="trees.html#discussion"><i class="fa fa-check"></i><b>6.5</b> Discussion</a></li>
<li class="chapter" data-level="6.6" data-path="trees.html"><a href="trees.html#coding-exercises-2"><i class="fa fa-check"></i><b>6.6</b> Coding exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="NN.html"><a href="NN.html"><i class="fa fa-check"></i><b>7</b> Neural networks</a>
<ul>
<li class="chapter" data-level="7.1" data-path="NN.html"><a href="NN.html#the-original-perceptron"><i class="fa fa-check"></i><b>7.1</b> The original perceptron</a></li>
<li class="chapter" data-level="7.2" data-path="NN.html"><a href="NN.html#multilayer-perceptron"><i class="fa fa-check"></i><b>7.2</b> Multilayer perceptron</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="NN.html"><a href="NN.html#introduction-and-notations"><i class="fa fa-check"></i><b>7.2.1</b> Introduction and notations</a></li>
<li class="chapter" data-level="7.2.2" data-path="NN.html"><a href="NN.html#universal-approximation"><i class="fa fa-check"></i><b>7.2.2</b> Universal approximation</a></li>
<li class="chapter" data-level="7.2.3" data-path="NN.html"><a href="NN.html#backprop"><i class="fa fa-check"></i><b>7.2.3</b> Learning via back-propagation</a></li>
<li class="chapter" data-level="7.2.4" data-path="NN.html"><a href="NN.html#NNclass"><i class="fa fa-check"></i><b>7.2.4</b> Further details on classification</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="NN.html"><a href="NN.html#howdeep"><i class="fa fa-check"></i><b>7.3</b> How deep we should go and other practical issues</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="NN.html"><a href="NN.html#architectural-choices"><i class="fa fa-check"></i><b>7.3.1</b> Architectural choices</a></li>
<li class="chapter" data-level="7.3.2" data-path="NN.html"><a href="NN.html#frequency-of-weight-updates-and-learning-duration"><i class="fa fa-check"></i><b>7.3.2</b> Frequency of weight updates and learning duration</a></li>
<li class="chapter" data-level="7.3.3" data-path="NN.html"><a href="NN.html#penalizations-and-dropout"><i class="fa fa-check"></i><b>7.3.3</b> Penalizations and dropout</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="NN.html"><a href="NN.html#code-samples-and-comments-for-vanilla-mlp"><i class="fa fa-check"></i><b>7.4</b> Code samples and comments for vanilla MLP</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="NN.html"><a href="NN.html#regression-example"><i class="fa fa-check"></i><b>7.4.1</b> Regression example</a></li>
<li class="chapter" data-level="7.4.2" data-path="NN.html"><a href="NN.html#classification-example"><i class="fa fa-check"></i><b>7.4.2</b> Classification example</a></li>
<li class="chapter" data-level="7.4.3" data-path="NN.html"><a href="NN.html#custloss"><i class="fa fa-check"></i><b>7.4.3</b> Custom losses</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="NN.html"><a href="NN.html#RNN"><i class="fa fa-check"></i><b>7.5</b> Recurrent networks</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="NN.html"><a href="NN.html#presentation"><i class="fa fa-check"></i><b>7.5.1</b> Presentation</a></li>
<li class="chapter" data-level="7.5.2" data-path="NN.html"><a href="NN.html#code-and-results-2"><i class="fa fa-check"></i><b>7.5.2</b> Code and results</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="NN.html"><a href="NN.html#tabular-networks-tabnets"><i class="fa fa-check"></i><b>7.6</b> Tabular networks (TabNets)</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="NN.html"><a href="NN.html#the-zoo-of-layers"><i class="fa fa-check"></i><b>7.6.1</b> The zoo of layers</a></li>
<li class="chapter" data-level="7.6.2" data-path="NN.html"><a href="NN.html#sparsemax-activation"><i class="fa fa-check"></i><b>7.6.2</b> Sparsemax activation</a></li>
<li class="chapter" data-level="7.6.3" data-path="NN.html"><a href="NN.html#feature-selection-1"><i class="fa fa-check"></i><b>7.6.3</b> Feature selection</a></li>
<li class="chapter" data-level="7.6.4" data-path="NN.html"><a href="NN.html#the-full-architecture"><i class="fa fa-check"></i><b>7.6.4</b> The full architecture</a></li>
<li class="chapter" data-level="7.6.5" data-path="NN.html"><a href="NN.html#code-and-results-3"><i class="fa fa-check"></i><b>7.6.5</b> Code and results</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="NN.html"><a href="NN.html#other-common-architectures"><i class="fa fa-check"></i><b>7.7</b> Other common architectures</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="NN.html"><a href="NN.html#generative-aversarial-networks"><i class="fa fa-check"></i><b>7.7.1</b> Generative adversarial networks</a></li>
<li class="chapter" data-level="7.7.2" data-path="NN.html"><a href="NN.html#autoencoders"><i class="fa fa-check"></i><b>7.7.2</b> Autoencoders</a></li>
<li class="chapter" data-level="7.7.3" data-path="NN.html"><a href="NN.html#CNN"><i class="fa fa-check"></i><b>7.7.3</b> A word on convolutional networks</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="NN.html"><a href="NN.html#coding-exercises-3"><i class="fa fa-check"></i><b>7.8</b> Coding exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>8</b> Support vector machines</a>
<ul>
<li class="chapter" data-level="8.1" data-path="svm.html"><a href="svm.html#svm-for-classification"><i class="fa fa-check"></i><b>8.1</b> SVM for classification</a></li>
<li class="chapter" data-level="8.2" data-path="svm.html"><a href="svm.html#svm-for-regression"><i class="fa fa-check"></i><b>8.2</b> SVM for regression</a></li>
<li class="chapter" data-level="8.3" data-path="svm.html"><a href="svm.html#practice"><i class="fa fa-check"></i><b>8.3</b> Practice</a></li>
<li class="chapter" data-level="8.4" data-path="svm.html"><a href="svm.html#coding-exercises-4"><i class="fa fa-check"></i><b>8.4</b> Coding exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>9</b> Bayesian methods</a>
<ul>
<li class="chapter" data-level="9.1" data-path="bayes.html"><a href="bayes.html#the-bayesian-framework"><i class="fa fa-check"></i><b>9.1</b> The Bayesian framework</a></li>
<li class="chapter" data-level="9.2" data-path="bayes.html"><a href="bayes.html#bayesian-sampling"><i class="fa fa-check"></i><b>9.2</b> Bayesian sampling</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="bayes.html"><a href="bayes.html#gibbs-sampling"><i class="fa fa-check"></i><b>9.2.1</b> Gibbs sampling</a></li>
<li class="chapter" data-level="9.2.2" data-path="bayes.html"><a href="bayes.html#metropolis-hastings-sampling"><i class="fa fa-check"></i><b>9.2.2</b> Metropolis-Hastings sampling</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="bayes.html"><a href="bayes.html#bayesian-linear-regression"><i class="fa fa-check"></i><b>9.3</b> Bayesian linear regression</a></li>
<li class="chapter" data-level="9.4" data-path="bayes.html"><a href="bayes.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>9.4</b> Naive Bayes classifier</a></li>
<li class="chapter" data-level="9.5" data-path="bayes.html"><a href="bayes.html#BART"><i class="fa fa-check"></i><b>9.5</b> Bayesian additive trees</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="bayes.html"><a href="bayes.html#general-formulation"><i class="fa fa-check"></i><b>9.5.1</b> General formulation</a></li>
<li class="chapter" data-level="9.5.2" data-path="bayes.html"><a href="bayes.html#priors"><i class="fa fa-check"></i><b>9.5.2</b> Priors</a></li>
<li class="chapter" data-level="9.5.3" data-path="bayes.html"><a href="bayes.html#sampling-and-predictions"><i class="fa fa-check"></i><b>9.5.3</b> Sampling and predictions</a></li>
<li class="chapter" data-level="9.5.4" data-path="bayes.html"><a href="bayes.html#code"><i class="fa fa-check"></i><b>9.5.4</b> Code</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III From predictions to portfolios</b></span></li>
<li class="chapter" data-level="10" data-path="valtune.html"><a href="valtune.html"><i class="fa fa-check"></i><b>10</b> Validating and tuning</a>
<ul>
<li class="chapter" data-level="10.1" data-path="valtune.html"><a href="valtune.html#mlmetrics"><i class="fa fa-check"></i><b>10.1</b> Learning metrics</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="valtune.html"><a href="valtune.html#regression-analysis"><i class="fa fa-check"></i><b>10.1.1</b> Regression analysis</a></li>
<li class="chapter" data-level="10.1.2" data-path="valtune.html"><a href="valtune.html#classification-analysis"><i class="fa fa-check"></i><b>10.1.2</b> Classification analysis</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="valtune.html"><a href="valtune.html#validation"><i class="fa fa-check"></i><b>10.2</b> Validation</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="valtune.html"><a href="valtune.html#the-variance-bias-tradeoff-theory"><i class="fa fa-check"></i><b>10.2.1</b> The variance-bias tradeoff: theory</a></li>
<li class="chapter" data-level="10.2.2" data-path="valtune.html"><a href="valtune.html#the-variance-bias-tradeoff-illustration"><i class="fa fa-check"></i><b>10.2.2</b> The variance-bias tradeoff: illustration</a></li>
<li class="chapter" data-level="10.2.3" data-path="valtune.html"><a href="valtune.html#the-risk-of-overfitting-principle"><i class="fa fa-check"></i><b>10.2.3</b> The risk of overfitting: principle</a></li>
<li class="chapter" data-level="10.2.4" data-path="valtune.html"><a href="valtune.html#the-risk-of-overfitting-some-solutions"><i class="fa fa-check"></i><b>10.2.4</b> The risk of overfitting: some solutions</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="valtune.html"><a href="valtune.html#the-search-for-good-hyperparameters"><i class="fa fa-check"></i><b>10.3</b> The search for good hyperparameters</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="valtune.html"><a href="valtune.html#methods"><i class="fa fa-check"></i><b>10.3.1</b> Methods</a></li>
<li class="chapter" data-level="10.3.2" data-path="valtune.html"><a href="valtune.html#example-grid-search"><i class="fa fa-check"></i><b>10.3.2</b> Example: grid search</a></li>
<li class="chapter" data-level="10.3.3" data-path="valtune.html"><a href="valtune.html#example-bayesian-optimization"><i class="fa fa-check"></i><b>10.3.3</b> Example: Bayesian optimization</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="valtune.html"><a href="valtune.html#short-discussion-on-validation-in-backtests"><i class="fa fa-check"></i><b>10.4</b> Short discussion on validation in backtests</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ensemble.html"><a href="ensemble.html"><i class="fa fa-check"></i><b>11</b> Ensemble models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ensemble.html"><a href="ensemble.html#linear-ensembles"><i class="fa fa-check"></i><b>11.1</b> Linear ensembles</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ensemble.html"><a href="ensemble.html#principles"><i class="fa fa-check"></i><b>11.1.1</b> Principles</a></li>
<li class="chapter" data-level="11.1.2" data-path="ensemble.html"><a href="ensemble.html#example"><i class="fa fa-check"></i><b>11.1.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ensemble.html"><a href="ensemble.html#stacked-ensembles"><i class="fa fa-check"></i><b>11.2</b> Stacked ensembles</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="ensemble.html"><a href="ensemble.html#two-stage-training"><i class="fa fa-check"></i><b>11.2.1</b> Two-stage training</a></li>
<li class="chapter" data-level="11.2.2" data-path="ensemble.html"><a href="ensemble.html#code-and-results-4"><i class="fa fa-check"></i><b>11.2.2</b> Code and results</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ensemble.html"><a href="ensemble.html#extensions-1"><i class="fa fa-check"></i><b>11.3</b> Extensions</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="ensemble.html"><a href="ensemble.html#exogenous-variables"><i class="fa fa-check"></i><b>11.3.1</b> Exogenous variables</a></li>
<li class="chapter" data-level="11.3.2" data-path="ensemble.html"><a href="ensemble.html#shrinking-inter-model-correlations"><i class="fa fa-check"></i><b>11.3.2</b> Shrinking inter-model correlations</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ensemble.html"><a href="ensemble.html#exercise"><i class="fa fa-check"></i><b>11.4</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="backtest.html"><a href="backtest.html"><i class="fa fa-check"></i><b>12</b> Portfolio backtesting</a>
<ul>
<li class="chapter" data-level="12.1" data-path="backtest.html"><a href="backtest.html#protocol"><i class="fa fa-check"></i><b>12.1</b> Setting the protocol</a></li>
<li class="chapter" data-level="12.2" data-path="backtest.html"><a href="backtest.html#turning-signals-into-portfolio-weights"><i class="fa fa-check"></i><b>12.2</b> Turning signals into portfolio weights</a></li>
<li class="chapter" data-level="12.3" data-path="backtest.html"><a href="backtest.html#perfmet"><i class="fa fa-check"></i><b>12.3</b> Performance metrics</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="backtest.html"><a href="backtest.html#discussion-1"><i class="fa fa-check"></i><b>12.3.1</b> Discussion</a></li>
<li class="chapter" data-level="12.3.2" data-path="backtest.html"><a href="backtest.html#pure-performance-and-risk-indicators"><i class="fa fa-check"></i><b>12.3.2</b> Pure performance and risk indicators</a></li>
<li class="chapter" data-level="12.3.3" data-path="backtest.html"><a href="backtest.html#factor-based-evaluation"><i class="fa fa-check"></i><b>12.3.3</b> Factor-based evaluation</a></li>
<li class="chapter" data-level="12.3.4" data-path="backtest.html"><a href="backtest.html#risk-adjusted-measures"><i class="fa fa-check"></i><b>12.3.4</b> Risk-adjusted measures</a></li>
<li class="chapter" data-level="12.3.5" data-path="backtest.html"><a href="backtest.html#transaction-costs-and-turnover"><i class="fa fa-check"></i><b>12.3.5</b> Transaction costs and turnover</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="backtest.html"><a href="backtest.html#common-errors-and-issues"><i class="fa fa-check"></i><b>12.4</b> Common errors and issues</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="backtest.html"><a href="backtest.html#forward-looking-data"><i class="fa fa-check"></i><b>12.4.1</b> Forward looking data</a></li>
<li class="chapter" data-level="12.4.2" data-path="backtest.html"><a href="backtest.html#backov"><i class="fa fa-check"></i><b>12.4.2</b> Backtest overfitting</a></li>
<li class="chapter" data-level="12.4.3" data-path="backtest.html"><a href="backtest.html#simple-safeguards"><i class="fa fa-check"></i><b>12.4.3</b> Simple safeguards</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="backtest.html"><a href="backtest.html#implication-of-non-stationarity-forecasting-is-hard"><i class="fa fa-check"></i><b>12.5</b> Implication of non-stationarity: forecasting is hard</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="backtest.html"><a href="backtest.html#general-comments"><i class="fa fa-check"></i><b>12.5.1</b> General comments</a></li>
<li class="chapter" data-level="12.5.2" data-path="backtest.html"><a href="backtest.html#the-no-free-lunch-theorem"><i class="fa fa-check"></i><b>12.5.2</b> The no free lunch theorem</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="backtest.html"><a href="backtest.html#first-example-a-complete-backtest"><i class="fa fa-check"></i><b>12.6</b> First example: a complete backtest</a></li>
<li class="chapter" data-level="12.7" data-path="backtest.html"><a href="backtest.html#second-example-backtest-overfitting"><i class="fa fa-check"></i><b>12.7</b> Second example: backtest overfitting</a></li>
<li class="chapter" data-level="12.8" data-path="backtest.html"><a href="backtest.html#coding-exercises-5"><i class="fa fa-check"></i><b>12.8</b> Coding exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Further important topics</b></span></li>
<li class="chapter" data-level="13" data-path="interp.html"><a href="interp.html"><i class="fa fa-check"></i><b>13</b> Interpretability</a>
<ul>
<li class="chapter" data-level="13.1" data-path="interp.html"><a href="interp.html#global-interpretations"><i class="fa fa-check"></i><b>13.1</b> Global interpretations</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="interp.html"><a href="interp.html#surr"><i class="fa fa-check"></i><b>13.1.1</b> Simple models as surrogates</a></li>
<li class="chapter" data-level="13.1.2" data-path="interp.html"><a href="interp.html#variable-importance"><i class="fa fa-check"></i><b>13.1.2</b> Variable importance (tree-based)</a></li>
<li class="chapter" data-level="13.1.3" data-path="interp.html"><a href="interp.html#variable-importance-agnostic"><i class="fa fa-check"></i><b>13.1.3</b> Variable importance (agnostic)</a></li>
<li class="chapter" data-level="13.1.4" data-path="interp.html"><a href="interp.html#partial-dependence-plot"><i class="fa fa-check"></i><b>13.1.4</b> Partial dependence plot</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="interp.html"><a href="interp.html#local-interpretations"><i class="fa fa-check"></i><b>13.2</b> Local interpretations</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="interp.html"><a href="interp.html#lime"><i class="fa fa-check"></i><b>13.2.1</b> LIME</a></li>
<li class="chapter" data-level="13.2.2" data-path="interp.html"><a href="interp.html#shapley-values"><i class="fa fa-check"></i><b>13.2.2</b> Shapley values</a></li>
<li class="chapter" data-level="13.2.3" data-path="interp.html"><a href="interp.html#breakdown"><i class="fa fa-check"></i><b>13.2.3</b> Breakdown</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="causality.html"><a href="causality.html"><i class="fa fa-check"></i><b>14</b> Two key concepts: causality and non-stationarity</a>
<ul>
<li class="chapter" data-level="14.1" data-path="causality.html"><a href="causality.html#causality-1"><i class="fa fa-check"></i><b>14.1</b> Causality</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="causality.html"><a href="causality.html#granger"><i class="fa fa-check"></i><b>14.1.1</b> Granger causality</a></li>
<li class="chapter" data-level="14.1.2" data-path="causality.html"><a href="causality.html#causal-additive-models"><i class="fa fa-check"></i><b>14.1.2</b> Causal additive models</a></li>
<li class="chapter" data-level="14.1.3" data-path="causality.html"><a href="causality.html#structural-time-series-models"><i class="fa fa-check"></i><b>14.1.3</b> Structural time series models</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="causality.html"><a href="causality.html#nonstat"><i class="fa fa-check"></i><b>14.2</b> Dealing with changing environments</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="causality.html"><a href="causality.html#non-stationarity-yet-another-illustration"><i class="fa fa-check"></i><b>14.2.1</b> Non-stationarity: yet another illustration</a></li>
<li class="chapter" data-level="14.2.2" data-path="causality.html"><a href="causality.html#online-learning"><i class="fa fa-check"></i><b>14.2.2</b> Online learning</a></li>
<li class="chapter" data-level="14.2.3" data-path="causality.html"><a href="causality.html#homogeneous-transfer-learning"><i class="fa fa-check"></i><b>14.2.3</b> Homogeneous transfer learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="unsup.html"><a href="unsup.html"><i class="fa fa-check"></i><b>15</b> Unsupervised learning</a>
<ul>
<li class="chapter" data-level="15.1" data-path="unsup.html"><a href="unsup.html#corpred"><i class="fa fa-check"></i><b>15.1</b> The problem with correlated predictors</a></li>
<li class="chapter" data-level="15.2" data-path="unsup.html"><a href="unsup.html#principal-component-analysis-and-autoencoders"><i class="fa fa-check"></i><b>15.2</b> Principal component analysis and autoencoders</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="unsup.html"><a href="unsup.html#a-bit-of-algebra"><i class="fa fa-check"></i><b>15.2.1</b> A bit of algebra</a></li>
<li class="chapter" data-level="15.2.2" data-path="unsup.html"><a href="unsup.html#pca"><i class="fa fa-check"></i><b>15.2.2</b> PCA</a></li>
<li class="chapter" data-level="15.2.3" data-path="unsup.html"><a href="unsup.html#ae"><i class="fa fa-check"></i><b>15.2.3</b> Autoencoders</a></li>
<li class="chapter" data-level="15.2.4" data-path="unsup.html"><a href="unsup.html#application"><i class="fa fa-check"></i><b>15.2.4</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="unsup.html"><a href="unsup.html#clustering-via-k-means"><i class="fa fa-check"></i><b>15.3</b> Clustering via k-means</a></li>
<li class="chapter" data-level="15.4" data-path="unsup.html"><a href="unsup.html#nearest-neighbors"><i class="fa fa-check"></i><b>15.4</b> Nearest neighbors</a></li>
<li class="chapter" data-level="15.5" data-path="unsup.html"><a href="unsup.html#coding-exercise-1"><i class="fa fa-check"></i><b>15.5</b> Coding exercise</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="RL.html"><a href="RL.html"><i class="fa fa-check"></i><b>16</b> Reinforcement learning</a>
<ul>
<li class="chapter" data-level="16.1" data-path="RL.html"><a href="RL.html#theoretical-layout"><i class="fa fa-check"></i><b>16.1</b> Theoretical layout</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="RL.html"><a href="RL.html#general-framework"><i class="fa fa-check"></i><b>16.1.1</b> General framework</a></li>
<li class="chapter" data-level="16.1.2" data-path="RL.html"><a href="RL.html#q-learning"><i class="fa fa-check"></i><b>16.1.2</b> Q-learning</a></li>
<li class="chapter" data-level="16.1.3" data-path="RL.html"><a href="RL.html#sarsa"><i class="fa fa-check"></i><b>16.1.3</b> SARSA</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="RL.html"><a href="RL.html#the-curse-of-dimensionality"><i class="fa fa-check"></i><b>16.2</b> The curse of dimensionality</a></li>
<li class="chapter" data-level="16.3" data-path="RL.html"><a href="RL.html#policy-gradient"><i class="fa fa-check"></i><b>16.3</b> Policy gradient</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="RL.html"><a href="RL.html#principle-2"><i class="fa fa-check"></i><b>16.3.1</b> Principle</a></li>
<li class="chapter" data-level="16.3.2" data-path="RL.html"><a href="RL.html#extensions-2"><i class="fa fa-check"></i><b>16.3.2</b> Extensions</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="RL.html"><a href="RL.html#simple-examples"><i class="fa fa-check"></i><b>16.4</b> Simple examples</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="RL.html"><a href="RL.html#q-learning-with-simulations"><i class="fa fa-check"></i><b>16.4.1</b> Q-learning with simulations</a></li>
<li class="chapter" data-level="16.4.2" data-path="RL.html"><a href="RL.html#RLemp2"><i class="fa fa-check"></i><b>16.4.2</b> Q-learning with market data</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="RL.html"><a href="RL.html#concluding-remarks"><i class="fa fa-check"></i><b>16.5</b> Concluding remarks</a></li>
<li class="chapter" data-level="16.6" data-path="RL.html"><a href="RL.html#exercises"><i class="fa fa-check"></i><b>16.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Appendix</b></span></li>
<li class="chapter" data-level="17" data-path="data-description.html"><a href="data-description.html"><i class="fa fa-check"></i><b>17</b> Data description</a></li>
<li class="chapter" data-level="18" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html"><i class="fa fa-check"></i><b>18</b> Solutions to exercises</a>
<ul>
<li class="chapter" data-level="18.1" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#chapter-3"><i class="fa fa-check"></i><b>18.1</b> Chapter 3</a></li>
<li class="chapter" data-level="18.2" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#chapter-4"><i class="fa fa-check"></i><b>18.2</b> Chapter 4</a></li>
<li class="chapter" data-level="18.3" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#chapter-5"><i class="fa fa-check"></i><b>18.3</b> Chapter 5</a></li>
<li class="chapter" data-level="18.4" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#chapter-6"><i class="fa fa-check"></i><b>18.4</b> Chapter 6</a></li>
<li class="chapter" data-level="18.5" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#chapter-7-the-autoencoder-model-universal-approximation"><i class="fa fa-check"></i><b>18.5</b> Chapter 7: the autoencoder model &amp; universal approximation</a></li>
<li class="chapter" data-level="18.6" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#chapter-8"><i class="fa fa-check"></i><b>18.6</b> Chapter 8</a></li>
<li class="chapter" data-level="18.7" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#chapter-11-ensemble-neural-network"><i class="fa fa-check"></i><b>18.7</b> Chapter 11: ensemble neural network</a></li>
<li class="chapter" data-level="18.8" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#chapter-12"><i class="fa fa-check"></i><b>18.8</b> Chapter 12</a>
<ul>
<li class="chapter" data-level="18.8.1" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#ew-portfolios-with-the-tidyverse"><i class="fa fa-check"></i><b>18.8.1</b> EW portfolios with the tidyverse</a></li>
<li class="chapter" data-level="18.8.2" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#advanced-weighting-function"><i class="fa fa-check"></i><b>18.8.2</b> Advanced weighting function</a></li>
<li class="chapter" data-level="18.8.3" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#functional-programming-in-the-backtest"><i class="fa fa-check"></i><b>18.8.3</b> Functional programming in the backtest</a></li>
</ul></li>
<li class="chapter" data-level="18.9" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#chapter-15"><i class="fa fa-check"></i><b>18.9</b> Chapter 15</a></li>
<li class="chapter" data-level="18.10" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#chapter-16"><i class="fa fa-check"></i><b>18.10</b> Chapter 16</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning for Factor Investing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="solutions-to-exercises" class="section level1" number="18">
<h1><span class="header-section-number">Chapter 18</span> Solutions to exercises</h1>
<div id="chapter-3" class="section level2" number="18.1">
<h2><span class="header-section-number">18.1</span> Chapter 3</h2>
<p>For annual values, see <a href="solutions-to-exercises.html#fig:ex41b">18.1</a>:
</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="solutions-to-exercises.html#cb248-1" aria-hidden="true" tabindex="-1"></a>data_ml <span class="sc">%&gt;%</span></span>
<span id="cb248-2"><a href="solutions-to-exercises.html#cb248-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(date) <span class="sc">%&gt;%</span>                                            </span>
<span id="cb248-3"><a href="solutions-to-exercises.html#cb248-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">growth =</span> Pb <span class="sc">&gt;</span> <span class="fu">median</span>(Pb)) <span class="sc">%&gt;%</span>            <span class="co"># Creates the sort</span></span>
<span id="cb248-4"><a href="solutions-to-exercises.html#cb248-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span>                                   <span class="co"># Ungroup</span></span>
<span id="cb248-5"><a href="solutions-to-exercises.html#cb248-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">year =</span> lubridate<span class="sc">::</span><span class="fu">year</span>(date)) <span class="sc">%&gt;%</span>        <span class="co"># Creates a year variable</span></span>
<span id="cb248-6"><a href="solutions-to-exercises.html#cb248-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(year, growth) <span class="sc">%&gt;%</span>                      <span class="co"># Analyze by year &amp; sort</span></span>
<span id="cb248-7"><a href="solutions-to-exercises.html#cb248-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">ret =</span> <span class="fu">mean</span>(R1M_Usd)) <span class="sc">%&gt;%</span>              <span class="co"># Compute average return</span></span>
<span id="cb248-8"><a href="solutions-to-exercises.html#cb248-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> year, <span class="at">y =</span> ret, <span class="at">fill =</span> growth)) <span class="sc">+</span> <span class="fu">geom_col</span>(<span class="at">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="sc">+</span> <span class="co"># Plot!</span></span>
<span id="cb248-9"><a href="solutions-to-exercises.html#cb248-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="fu">c</span>(<span class="fl">0.7</span>, <span class="fl">0.8</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex41b"></span>
<img src="ML_factor_files/figure-html/ex41b-1.png" alt="The value factor: annual returns." width="400px" height="150px" />
<p class="caption">
FIGURE 18.1: The value factor: annual returns.
</p>
</div>
<p></p>
<p>For monthly values, see <a href="solutions-to-exercises.html#fig:ex41">18.2</a>:
</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="solutions-to-exercises.html#cb249-1" aria-hidden="true" tabindex="-1"></a>returns_m <span class="ot">&lt;-</span> data_ml <span class="sc">%&gt;%</span></span>
<span id="cb249-2"><a href="solutions-to-exercises.html#cb249-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(date) <span class="sc">%&gt;%</span>                                            </span>
<span id="cb249-3"><a href="solutions-to-exercises.html#cb249-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">growth =</span> Pb <span class="sc">&gt;</span> <span class="fu">median</span>(Pb)) <span class="sc">%&gt;%</span>                         <span class="co"># Creates the sort</span></span>
<span id="cb249-4"><a href="solutions-to-exercises.html#cb249-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(date, growth) <span class="sc">%&gt;%</span>                                   <span class="co"># Analyze by date &amp; sort</span></span>
<span id="cb249-5"><a href="solutions-to-exercises.html#cb249-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">ret =</span> <span class="fu">mean</span>(R1M_Usd)) <span class="sc">%&gt;%</span>                           <span class="co"># Compute average return</span></span>
<span id="cb249-6"><a href="solutions-to-exercises.html#cb249-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">spread</span>(<span class="at">key =</span> growth, <span class="at">value =</span> ret) <span class="sc">%&gt;%</span>                        <span class="co"># Pivot to wide matrix format</span></span>
<span id="cb249-7"><a href="solutions-to-exercises.html#cb249-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>()</span>
<span id="cb249-8"><a href="solutions-to-exercises.html#cb249-8" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(returns_m)[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;value&quot;</span>, <span class="st">&quot;growth&quot;</span>)                 <span class="co"># Changing column names</span></span>
<span id="cb249-9"><a href="solutions-to-exercises.html#cb249-9" aria-hidden="true" tabindex="-1"></a>returns_m <span class="sc">%&gt;%</span></span>
<span id="cb249-10"><a href="solutions-to-exercises.html#cb249-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">value =</span> <span class="fu">cumprod</span>(<span class="dv">1</span> <span class="sc">+</span> value),                           <span class="co"># From returns to portf. values</span></span>
<span id="cb249-11"><a href="solutions-to-exercises.html#cb249-11" aria-hidden="true" tabindex="-1"></a>           <span class="at">growth =</span> <span class="fu">cumprod</span>(<span class="dv">1</span> <span class="sc">+</span> growth)) <span class="sc">%&gt;%</span></span>
<span id="cb249-12"><a href="solutions-to-exercises.html#cb249-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gather</span>(<span class="at">key =</span> portfolio, <span class="at">value =</span> value, <span class="sc">-</span>date) <span class="sc">%&gt;%</span>            <span class="co"># Back in tidy format</span></span>
<span id="cb249-13"><a href="solutions-to-exercises.html#cb249-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> date, <span class="at">y =</span> value, <span class="at">color =</span> portfolio)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span>     <span class="co"># Plot!  </span></span>
<span id="cb249-14"><a href="solutions-to-exercises.html#cb249-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="fu">c</span>(<span class="fl">0.7</span>, <span class="fl">0.8</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex41"></span>
<img src="ML_factor_files/figure-html/ex41-1.png" alt="The value factor: portfolio values." width="400px" height="150px" />
<p class="caption">
FIGURE 18.2: The value factor: portfolio values.
</p>
</div>
<p></p>
<p>Portfolios based on quartiles, using the tidyverse only. We rely heavily on the fact that features are uniformized, i.e., that their distribution is uniform for each given date. Overall, small firms outperform heavily (see Figure <a href="solutions-to-exercises.html#fig:ex43">18.3</a>).</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="solutions-to-exercises.html#cb250-1" aria-hidden="true" tabindex="-1"></a>data_ml <span class="sc">%&gt;%</span></span>
<span id="cb250-2"><a href="solutions-to-exercises.html#cb250-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">small =</span> Mkt_Cap_6M_Usd <span class="sc">&lt;=</span> <span class="fl">0.25</span>,                        <span class="co"># Small firms...</span></span>
<span id="cb250-3"><a href="solutions-to-exercises.html#cb250-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">medium =</span> Mkt_Cap_6M_Usd <span class="sc">&gt;</span> <span class="fl">0.25</span> <span class="sc">&amp;</span> Mkt_Cap_6M_Usd <span class="sc">&lt;=</span> <span class="fl">0.5</span>, </span>
<span id="cb250-4"><a href="solutions-to-exercises.html#cb250-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">large =</span> Mkt_Cap_6M_Usd <span class="sc">&gt;</span> <span class="fl">0.5</span> <span class="sc">&amp;</span> Mkt_Cap_6M_Usd <span class="sc">&lt;=</span> <span class="fl">0.75</span>,</span>
<span id="cb250-5"><a href="solutions-to-exercises.html#cb250-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">xl =</span> Mkt_Cap_6M_Usd <span class="sc">&gt;</span> <span class="fl">0.75</span>,                            <span class="co"># ...Xlarge firms</span></span>
<span id="cb250-6"><a href="solutions-to-exercises.html#cb250-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">year =</span> <span class="fu">year</span>(date)) <span class="sc">%&gt;%</span>                        </span>
<span id="cb250-7"><a href="solutions-to-exercises.html#cb250-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(year) <span class="sc">%&gt;%</span></span>
<span id="cb250-8"><a href="solutions-to-exercises.html#cb250-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">small =</span> <span class="fu">mean</span>(small <span class="sc">*</span> R1M_Usd),                      <span class="co"># Compute avg returns</span></span>
<span id="cb250-9"><a href="solutions-to-exercises.html#cb250-9" aria-hidden="true" tabindex="-1"></a>              <span class="at">medium =</span> <span class="fu">mean</span>(medium <span class="sc">*</span> R1M_Usd),</span>
<span id="cb250-10"><a href="solutions-to-exercises.html#cb250-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">large =</span> <span class="fu">mean</span>(large <span class="sc">*</span> R1M_Usd),</span>
<span id="cb250-11"><a href="solutions-to-exercises.html#cb250-11" aria-hidden="true" tabindex="-1"></a>              <span class="at">xl =</span> <span class="fu">mean</span>(xl <span class="sc">*</span> R1M_Usd)) <span class="sc">%&gt;%</span></span>
<span id="cb250-12"><a href="solutions-to-exercises.html#cb250-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gather</span>(<span class="at">key =</span> size, <span class="at">value =</span> return, <span class="sc">-</span>year) <span class="sc">%&gt;%</span></span>
<span id="cb250-13"><a href="solutions-to-exercises.html#cb250-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> year, <span class="at">y =</span> return, <span class="at">fill =</span> size)) <span class="sc">+</span> <span class="fu">geom_col</span>(<span class="at">position =</span> <span class="st">&quot;dodge&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex43"></span>
<img src="ML_factor_files/figure-html/ex43-1.png" alt="The value factor: portfolio values." width="432" />
<p class="caption">
FIGURE 18.3: The value factor: portfolio values.
</p>
</div>
<p></p>
</div>
<div id="chapter-4" class="section level2" number="18.2">
<h2><span class="header-section-number">18.2</span> Chapter 4</h2>
<p>Below, we import a credit spread supplied by Bank of America. Its symbol/ticker is “BAMLC0A0CM.” We apply the data expansion on the small number of predictors to save memory space. One important trick that should not be overlooked is the uniformization step after the product <a href="Data.html#eq:macrocond">(4.3)</a> is computed. Indeed, we want the new features to have the same properties as the old ones. If we skip this step, distributions will be altered, as we show in one example below.</p>
<p>We start with the data extraction and joining. It’s important to join early so as to keep the highest data frequency (daily) in order to replace missing points with <strong>close values</strong>. Joining with monthly data before replacing creates unnecessary lags.</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="solutions-to-exercises.html#cb251-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getSymbols.FRED</span>(<span class="st">&quot;BAMLC0A0CM&quot;</span>,                                    <span class="co"># Extract data</span></span>
<span id="cb251-2"><a href="solutions-to-exercises.html#cb251-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">env =</span> <span class="st">&quot;.GlobalEnv&quot;</span>, </span>
<span id="cb251-3"><a href="solutions-to-exercises.html#cb251-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">return.class =</span> <span class="st">&quot;xts&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;BAMLC0A0CM&quot;</code></pre>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="solutions-to-exercises.html#cb253-1" aria-hidden="true" tabindex="-1"></a>cred_spread <span class="ot">&lt;-</span> <span class="fu">fortify</span>(BAMLC0A0CM)                               <span class="co"># Transform to dataframe</span></span>
<span id="cb253-2"><a href="solutions-to-exercises.html#cb253-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(cred_spread) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;date&quot;</span>, <span class="st">&quot;spread&quot;</span>)                     <span class="co"># Change column name</span></span>
<span id="cb253-3"><a href="solutions-to-exercises.html#cb253-3" aria-hidden="true" tabindex="-1"></a>cred_spread <span class="ot">&lt;-</span> cred_spread <span class="sc">%&gt;%</span>                                   <span class="co"># Take extraction and...</span></span>
<span id="cb253-4"><a href="solutions-to-exercises.html#cb253-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">full_join</span>(data_ml <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(date), <span class="at">by =</span> <span class="st">&quot;date&quot;</span>) <span class="sc">%&gt;%</span>  <span class="co"># Join!</span></span>
<span id="cb253-5"><a href="solutions-to-exercises.html#cb253-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">spread =</span> <span class="fu">na.locf</span>(spread))                             <span class="co"># Replace NA by previous</span></span>
<span id="cb253-6"><a href="solutions-to-exercises.html#cb253-6" aria-hidden="true" tabindex="-1"></a>cred_spread <span class="ot">&lt;-</span> cred_spread[<span class="sc">!</span><span class="fu">duplicated</span>(cred_spread),]            <span class="co"># Remove duplicates</span></span></code></pre></div>
<p></p>
<p>The creation of the augmented dataset requires some manipulation. Features are no longer uniform as is shown in Figure <a href="solutions-to-exercises.html#fig:ex5b">18.4</a>.</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="solutions-to-exercises.html#cb254-1" aria-hidden="true" tabindex="-1"></a>data_cond <span class="ot">&lt;-</span> data_ml <span class="sc">%&gt;%</span>                                    <span class="co"># Create new dataset</span></span>
<span id="cb254-2"><a href="solutions-to-exercises.html#cb254-2" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="fu">c</span>(<span class="st">&quot;stock_id&quot;</span>, <span class="st">&quot;date&quot;</span>, features_short))</span>
<span id="cb254-3"><a href="solutions-to-exercises.html#cb254-3" aria-hidden="true" tabindex="-1"></a>names_cred_spread <span class="ot">&lt;-</span> <span class="fu">paste0</span>(features_short, <span class="st">&quot;_cred_spread&quot;</span>) <span class="co"># New column names</span></span>
<span id="cb254-4"><a href="solutions-to-exercises.html#cb254-4" aria-hidden="true" tabindex="-1"></a>feat_cred_spread <span class="ot">&lt;-</span> data_cond <span class="sc">%&gt;%</span>                           <span class="co"># Old values</span></span>
<span id="cb254-5"><a href="solutions-to-exercises.html#cb254-5" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(features_short)</span>
<span id="cb254-6"><a href="solutions-to-exercises.html#cb254-6" aria-hidden="true" tabindex="-1"></a>cred_spread <span class="ot">&lt;-</span> data_ml <span class="sc">%&gt;%</span>                                  <span class="co"># Create vector of spreads</span></span>
<span id="cb254-7"><a href="solutions-to-exercises.html#cb254-7" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(date) <span class="sc">%&gt;%</span></span>
<span id="cb254-8"><a href="solutions-to-exercises.html#cb254-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">left_join</span>(cred_spread, <span class="at">by =</span> <span class="st">&quot;date&quot;</span>) </span>
<span id="cb254-9"><a href="solutions-to-exercises.html#cb254-9" aria-hidden="true" tabindex="-1"></a>feat_cred_spread <span class="ot">&lt;-</span> feat_cred_spread <span class="sc">*</span>                      <span class="co"># This product creates...</span></span>
<span id="cb254-10"><a href="solutions-to-exercises.html#cb254-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">matrix</span>(cred_spread<span class="sc">$</span>spread,                              <span class="co"># the new values...</span></span>
<span id="cb254-11"><a href="solutions-to-exercises.html#cb254-11" aria-hidden="true" tabindex="-1"></a>           <span class="fu">length</span>(cred_spread<span class="sc">$</span>spread),                      <span class="co"># using duplicated...</span></span>
<span id="cb254-12"><a href="solutions-to-exercises.html#cb254-12" aria-hidden="true" tabindex="-1"></a>           <span class="fu">length</span>(features_short))                          <span class="co"># columns</span></span>
<span id="cb254-13"><a href="solutions-to-exercises.html#cb254-13" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(feat_cred_spread) <span class="ot">&lt;-</span> names_cred_spread             <span class="co"># New column names</span></span>
<span id="cb254-14"><a href="solutions-to-exercises.html#cb254-14" aria-hidden="true" tabindex="-1"></a>data_cond <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(data_cond, feat_cred_spread)         <span class="co"># Aggregate old &amp; new</span></span>
<span id="cb254-15"><a href="solutions-to-exercises.html#cb254-15" aria-hidden="true" tabindex="-1"></a>data_cond <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Eps_cred_spread)) <span class="sc">+</span> <span class="fu">geom_histogram</span>() <span class="co"># Plot example</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex5b"></span>
<img src="ML_factor_files/figure-html/ex5b-1.png" alt="Distribution of Eps after conditioning." width="400px" height="150px" />
<p class="caption">
FIGURE 18.4: Distribution of Eps after conditioning.
</p>
</div>
<p></p>
<p>To prevent this issue, uniformization is required and is verified in Figure <a href="solutions-to-exercises.html#fig:ex51c">18.5</a>. </p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="solutions-to-exercises.html#cb255-1" aria-hidden="true" tabindex="-1"></a>data_cond <span class="ot">&lt;-</span> data_cond <span class="sc">%&gt;%</span>                   <span class="co"># From new dataset</span></span>
<span id="cb255-2"><a href="solutions-to-exercises.html#cb255-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(date) <span class="sc">%&gt;%</span>                       <span class="co"># Group by date and...</span></span>
<span id="cb255-3"><a href="solutions-to-exercises.html#cb255-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate_at</span>(names_cred_spread, norm_unif)  <span class="co"># Uniformize the new features</span></span>
<span id="cb255-4"><a href="solutions-to-exercises.html#cb255-4" aria-hidden="true" tabindex="-1"></a>data_cond <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Eps_cred_spread)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">100</span>) <span class="co"># Verification</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex51c"></span>
<img src="ML_factor_files/figure-html/ex51c-1.png" alt="Distribution of uniformized conditioned feature values." width="400px" height="150px" />
<p class="caption">
FIGURE 18.5: Distribution of uniformized conditioned feature values.
</p>
</div>
<p></p>
<p>The second question naturally requires the downloading of VIX series first and the joining with the original data.</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="solutions-to-exercises.html#cb256-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getSymbols.FRED</span>(<span class="st">&quot;VIXCLS&quot;</span>,                           <span class="co"># Extract data</span></span>
<span id="cb256-2"><a href="solutions-to-exercises.html#cb256-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">env =</span> <span class="st">&quot;.GlobalEnv&quot;</span>, </span>
<span id="cb256-3"><a href="solutions-to-exercises.html#cb256-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">return.class =</span> <span class="st">&quot;xts&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;VIXCLS&quot;</code></pre>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="solutions-to-exercises.html#cb258-1" aria-hidden="true" tabindex="-1"></a>vix <span class="ot">&lt;-</span> <span class="fu">fortify</span>(VIXCLS)                              <span class="co"># Transform to dataframe</span></span>
<span id="cb258-2"><a href="solutions-to-exercises.html#cb258-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(vix) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;date&quot;</span>, <span class="st">&quot;vix&quot;</span>)                   <span class="co"># Change column name</span></span>
<span id="cb258-3"><a href="solutions-to-exercises.html#cb258-3" aria-hidden="true" tabindex="-1"></a>vix <span class="ot">&lt;-</span> vix <span class="sc">%&gt;%</span>                                      <span class="co"># Take extraction and...</span></span>
<span id="cb258-4"><a href="solutions-to-exercises.html#cb258-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">full_join</span>(data_ml <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(date), <span class="at">by =</span> <span class="st">&quot;date&quot;</span>) <span class="sc">%&gt;%</span>    <span class="co"># Join! </span></span>
<span id="cb258-5"><a href="solutions-to-exercises.html#cb258-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">vix =</span> <span class="fu">na.locf</span>(vix))                      <span class="co"># Replace NA by previous</span></span>
<span id="cb258-6"><a href="solutions-to-exercises.html#cb258-6" aria-hidden="true" tabindex="-1"></a>vix <span class="ot">&lt;-</span> vix[<span class="sc">!</span><span class="fu">duplicated</span>(vix),]                       <span class="co"># Remove duplicates</span></span>
<span id="cb258-7"><a href="solutions-to-exercises.html#cb258-7" aria-hidden="true" tabindex="-1"></a>vix <span class="ot">&lt;-</span> data_ml <span class="sc">%&gt;%</span>                                  <span class="co"># Keep original data format</span></span>
<span id="cb258-8"><a href="solutions-to-exercises.html#cb258-8" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(date) <span class="sc">%&gt;%</span>                         <span class="co"># ...</span></span>
<span id="cb258-9"><a href="solutions-to-exercises.html#cb258-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">left_join</span>(vix, <span class="at">by =</span> <span class="st">&quot;date&quot;</span>)                     <span class="co"># Via left_join()</span></span></code></pre></div>
<p></p>
<p>We can then proceed with the categorization. We create the vector label in a new (smaller) dataset but not attached to the large data_ml variable. Also, we check the balance of labels and its evolution through time (see Figure <a href="solutions-to-exercises.html#fig:ex52b">18.6</a>).</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="solutions-to-exercises.html#cb259-1" aria-hidden="true" tabindex="-1"></a>delta <span class="ot">&lt;-</span> <span class="fl">0.5</span>                                       <span class="co"># Magnitude of vix correction</span></span>
<span id="cb259-2"><a href="solutions-to-exercises.html#cb259-2" aria-hidden="true" tabindex="-1"></a>vix_bar <span class="ot">&lt;-</span> <span class="fu">median</span>(vix<span class="sc">$</span>vix)                         <span class="co"># Median of vix</span></span>
<span id="cb259-3"><a href="solutions-to-exercises.html#cb259-3" aria-hidden="true" tabindex="-1"></a>data_vix <span class="ot">&lt;-</span> data_ml <span class="sc">%&gt;%</span>                            <span class="co"># Smaller dataset</span></span>
<span id="cb259-4"><a href="solutions-to-exercises.html#cb259-4" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(stock_id, date, R1M_Usd) <span class="sc">%&gt;%</span></span>
<span id="cb259-5"><a href="solutions-to-exercises.html#cb259-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">r_minus =</span> (<span class="sc">-</span><span class="fl">0.02</span>) <span class="sc">*</span> <span class="fu">exp</span>(<span class="sc">-</span>delta<span class="sc">*</span>(vix<span class="sc">$</span>vix<span class="sc">-</span>vix_bar)),  <span class="co"># r_-</span></span>
<span id="cb259-6"><a href="solutions-to-exercises.html#cb259-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">r_plus =</span> <span class="fl">0.02</span> <span class="sc">*</span> <span class="fu">exp</span>(delta<span class="sc">*</span>(vix<span class="sc">$</span>vix<span class="sc">-</span>vix_bar)))       <span class="co"># r_+</span></span>
<span id="cb259-7"><a href="solutions-to-exercises.html#cb259-7" aria-hidden="true" tabindex="-1"></a>data_vix <span class="ot">&lt;-</span> data_vix <span class="sc">%&gt;%</span> </span>
<span id="cb259-8"><a href="solutions-to-exercises.html#cb259-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">R1M_Usd_Cvix =</span> <span class="fu">if_else</span>(R1M_Usd <span class="sc">&lt;</span> r_minus, <span class="sc">-</span><span class="dv">1</span>,       <span class="co"># New label!</span></span>
<span id="cb259-9"><a href="solutions-to-exercises.html#cb259-9" aria-hidden="true" tabindex="-1"></a>                                  <span class="fu">if_else</span>(R1M_Usd <span class="sc">&gt;</span> r_plus, <span class="dv">1</span>,<span class="dv">0</span>)),</span>
<span id="cb259-10"><a href="solutions-to-exercises.html#cb259-10" aria-hidden="true" tabindex="-1"></a>           <span class="at">R1M_Usd_Cvix =</span> <span class="fu">as.factor</span>(R1M_Usd_Cvix))</span>
<span id="cb259-11"><a href="solutions-to-exercises.html#cb259-11" aria-hidden="true" tabindex="-1"></a>data_vix <span class="sc">%&gt;%</span> </span>
<span id="cb259-12"><a href="solutions-to-exercises.html#cb259-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">year =</span> <span class="fu">year</span>(date)) <span class="sc">%&gt;%</span></span>
<span id="cb259-13"><a href="solutions-to-exercises.html#cb259-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(year, R1M_Usd_Cvix) <span class="sc">%&gt;%</span></span>
<span id="cb259-14"><a href="solutions-to-exercises.html#cb259-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">nb =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb259-15"><a href="solutions-to-exercises.html#cb259-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> year, <span class="at">y =</span> nb, <span class="at">fill =</span> R1M_Usd_Cvix)) <span class="sc">+</span> <span class="fu">geom_col</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex52b"></span>
<img src="ML_factor_files/figure-html/ex52b-1.png" alt="Evolution of categories through time." width="400px" height="150px" />
<p class="caption">
FIGURE 18.6: Evolution of categories through time.
</p>
</div>
<p></p>
<p>Finally, we switch to the outliers (Figure <a href="solutions-to-exercises.html#fig:ex53a">18.7</a>). </p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="solutions-to-exercises.html#cb260-1" aria-hidden="true" tabindex="-1"></a>data_ml <span class="sc">%&gt;%</span></span>
<span id="cb260-2"><a href="solutions-to-exercises.html#cb260-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> R12M_Usd)) <span class="sc">+</span> <span class="fu">geom_histogram</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex53a"></span>
<img src="ML_factor_files/figure-html/ex53a-1.png" alt="Outliers in the dependent variable." width="400px" height="150px" />
<p class="caption">
FIGURE 18.7: Outliers in the dependent variable.
</p>
</div>
<p></p>
<p>Returns above 50 should indeed be rare.</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="solutions-to-exercises.html#cb261-1" aria-hidden="true" tabindex="-1"></a>data_ml <span class="sc">%&gt;%</span> <span class="fu">filter</span>(R12M_Usd <span class="sc">&gt;</span> <span class="dv">50</span>) <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(stock_id, date, R12M_Usd)</span></code></pre></div>
<pre><code>## [38;5;246m# A tibble: 8 x 3[39m
##   stock_id date       R12M_Usd
##      [3m[38;5;246m&lt;int&gt;[39m[23m [3m[38;5;246m&lt;date&gt;[39m[23m        [3m[38;5;246m&lt;dbl&gt;[39m[23m
## [38;5;250m1[39m      212 2000-12-31     53.0
## [38;5;250m2[39m      221 2008-12-31     53.5
## [38;5;250m3[39m      221 2009-01-31     55.2
## [38;5;250m4[39m      221 2009-02-28     54.8
## [38;5;250m5[39m      296 2002-06-30     72.2
## [38;5;250m6[39m      683 2009-02-28     96.0
## [38;5;250m7[39m      683 2009-03-31     64.8
## [38;5;250m8[39m      862 2009-02-28     58.0</code></pre>
<p></p>
<p>The largest return comes from stock #683. Let’s have a look at the stream of monthly returns in 2009.</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="solutions-to-exercises.html#cb263-1" aria-hidden="true" tabindex="-1"></a>data_ml <span class="sc">%&gt;%</span> </span>
<span id="cb263-2"><a href="solutions-to-exercises.html#cb263-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(stock_id <span class="sc">==</span> <span class="dv">683</span>, <span class="fu">year</span>(date) <span class="sc">==</span> <span class="dv">2009</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb263-3"><a href="solutions-to-exercises.html#cb263-3" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(date, R1M_Usd)</span></code></pre></div>
<pre><code>## [38;5;246m# A tibble: 12 x 2[39m
##    date       R1M_Usd
##    [3m[38;5;246m&lt;date&gt;[39m[23m       [3m[38;5;246m&lt;dbl&gt;[39m[23m
## [38;5;250m 1[39m 2009-01-31  -[31m0[39m[31m.[39m[31m625[39m
## [38;5;250m 2[39m 2009-02-28   0.472
## [38;5;250m 3[39m 2009-03-31   1.44 
## [38;5;250m 4[39m 2009-04-30   0.139
## [38;5;250m 5[39m 2009-05-31   0.086
## [38;5;250m 6[39m 2009-06-30   0.185
## [38;5;250m 7[39m 2009-07-31   0.363
## [38;5;250m 8[39m 2009-08-31   0.103
## [38;5;250m 9[39m 2009-09-30   9.91 
## [38;5;250m10[39m 2009-10-31   0.101
## [38;5;250m11[39m 2009-11-30   0.202
## [38;5;250m12[39m 2009-12-31  -[31m0[39m[31m.[39m[31m251[39m</code></pre>
<p></p>
<p>The returns are all very high. The annual value is plausible. In addition, a quick glance at the Vol1Y values shows that the stock is the most volatile of the dataset.</p>
</div>
<div id="chapter-5" class="section level2" number="18.3">
<h2><span class="header-section-number">18.3</span> Chapter 5</h2>
<p>We recycle the training and testing data variables created in the chapter (coding section notably). In addition, we create a dedicated function and resort to the <em>map2</em>() function from the <em>purrr</em> package.</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="solutions-to-exercises.html#cb265-1" aria-hidden="true" tabindex="-1"></a>alpha_seq <span class="ot">&lt;-</span> (<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>)<span class="sc">/</span><span class="dv">10</span>                     <span class="co"># Sequence of alpha values</span></span>
<span id="cb265-2"><a href="solutions-to-exercises.html#cb265-2" aria-hidden="true" tabindex="-1"></a>lambda_seq <span class="ot">&lt;-</span> <span class="fl">0.1</span><span class="sc">^</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">5</span>)                    <span class="co"># Sequence of lambda values</span></span>
<span id="cb265-3"><a href="solutions-to-exercises.html#cb265-3" aria-hidden="true" tabindex="-1"></a>pars <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(alpha_seq, lambda_seq) <span class="co"># Exploring all combinations!</span></span>
<span id="cb265-4"><a href="solutions-to-exercises.html#cb265-4" aria-hidden="true" tabindex="-1"></a>alpha_seq <span class="ot">&lt;-</span> pars[,<span class="dv">1</span>]</span>
<span id="cb265-5"><a href="solutions-to-exercises.html#cb265-5" aria-hidden="true" tabindex="-1"></a>lambda_seq <span class="ot">&lt;-</span> pars[,<span class="dv">2</span>]</span>
<span id="cb265-6"><a href="solutions-to-exercises.html#cb265-6" aria-hidden="true" tabindex="-1"></a>lasso_sens <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, lambda, x_train, y_train, x_test, y_test){ <span class="co"># Function</span></span>
<span id="cb265-7"><a href="solutions-to-exercises.html#cb265-7" aria-hidden="true" tabindex="-1"></a>    fit_temp <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x_train, y_train,                                 <span class="co"># Model</span></span>
<span id="cb265-8"><a href="solutions-to-exercises.html#cb265-8" aria-hidden="true" tabindex="-1"></a>                       <span class="at">alpha =</span> alpha, <span class="at">lambda =</span> lambda)</span>
<span id="cb265-9"><a href="solutions-to-exercises.html#cb265-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">sqrt</span>(<span class="fu">mean</span>((<span class="fu">predict</span>(fit_temp, x_test) <span class="sc">-</span> y_test)<span class="sc">^</span><span class="dv">2</span>)))           <span class="co"># Output</span></span>
<span id="cb265-10"><a href="solutions-to-exercises.html#cb265-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb265-11"><a href="solutions-to-exercises.html#cb265-11" aria-hidden="true" tabindex="-1"></a>rmse_elas <span class="ot">&lt;-</span> <span class="fu">map2</span>(alpha_seq, lambda_seq, lasso_sens,                     <span class="co"># Automation</span></span>
<span id="cb265-12"><a href="solutions-to-exercises.html#cb265-12" aria-hidden="true" tabindex="-1"></a>                  <span class="at">x_train =</span> x_penalized_train, <span class="at">y_train =</span> y_penalized_train,</span>
<span id="cb265-13"><a href="solutions-to-exercises.html#cb265-13" aria-hidden="true" tabindex="-1"></a>                  <span class="at">x_test =</span> x_penalized_test, <span class="at">y_test =</span> testing_sample<span class="sc">$</span>R1M_Usd)</span>
<span id="cb265-14"><a href="solutions-to-exercises.html#cb265-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb265-15"><a href="solutions-to-exercises.html#cb265-15" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_cols</span>(<span class="at">alpha =</span> alpha_seq, <span class="at">lambda =</span> <span class="fu">as.factor</span>(lambda_seq), <span class="at">rmse =</span> <span class="fu">unlist</span>(rmse_elas)) <span class="sc">%&gt;%</span></span>
<span id="cb265-16"><a href="solutions-to-exercises.html#cb265-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> alpha, <span class="at">y =</span> rmse, <span class="at">fill =</span> lambda)) <span class="sc">+</span> <span class="fu">geom_col</span>() <span class="sc">+</span> <span class="fu">facet_grid</span>(lambda <span class="sc">~</span>.) <span class="sc">+</span></span>
<span id="cb265-17"><a href="solutions-to-exercises.html#cb265-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.19</span>,<span class="fl">0.193</span>))</span></code></pre></div>
<div class="figure"><span id="fig:ex61"></span>
<img src="ML_factor_files/figure-html/ex61-1.png" alt="Performance of elasticnet across parameter values." width="432" />
<p class="caption">
FIGURE 18.8: Performance of elasticnet across parameter values.
</p>
</div>
<p></p>
<p>As is outlined in Figure <a href="solutions-to-exercises.html#fig:ex61">18.8</a>, the parameters have a very marginal impact. Maybe the model is not a good fit for the task.</p>
</div>
<div id="chapter-6" class="section level2" number="18.4">
<h2><span class="header-section-number">18.4</span> Chapter 6</h2>
<p>
</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="solutions-to-exercises.html#cb266-1" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">rpart</span>(formula, </span>
<span id="cb266-2"><a href="solutions-to-exercises.html#cb266-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> training_sample,     <span class="co"># Data source: full sample</span></span>
<span id="cb266-3"><a href="solutions-to-exercises.html#cb266-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">cp =</span> <span class="fl">0.001</span>)                 <span class="co"># Precision: smaller = more leaves</span></span>
<span id="cb266-4"><a href="solutions-to-exercises.html#cb266-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((<span class="fu">predict</span>(fit1, testing_sample) <span class="sc">-</span> testing_sample<span class="sc">$</span>R1M_Usd)<span class="sc">^</span><span class="dv">2</span>) </span></code></pre></div>
<pre><code>## [1] 0.04018973</code></pre>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="solutions-to-exercises.html#cb268-1" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">rpart</span>(formula,</span>
<span id="cb268-2"><a href="solutions-to-exercises.html#cb268-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> training_sample,     <span class="co"># Data source: full sample</span></span>
<span id="cb268-3"><a href="solutions-to-exercises.html#cb268-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">cp =</span> <span class="fl">0.01</span>)                  <span class="co"># Precision: smaller = more leaves</span></span>
<span id="cb268-4"><a href="solutions-to-exercises.html#cb268-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((<span class="fu">predict</span>(fit2, testing_sample) <span class="sc">-</span> testing_sample<span class="sc">$</span>R1M_Usd)<span class="sc">^</span><span class="dv">2</span>) <span class="co"># Test!</span></span></code></pre></div>
<pre><code>## [1] 0.03699696</code></pre>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="solutions-to-exercises.html#cb270-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(fit1)                         <span class="co"># Plot the first tree</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex71"></span>
<img src="ML_factor_files/figure-html/ex71-1.png" alt="Sample (complex) tree." width="480" />
<p class="caption">
FIGURE 18.9: Sample (complex) tree.
</p>
</div>
<p></p>
<p>The first model (Figure <a href="solutions-to-exercises.html#fig:ex71">18.9</a>) is <strong>too</strong> precise: going into the details of the training sample does not translate to good performance out-of-sample. The second, simpler model, yields better results.</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="solutions-to-exercises.html#cb271-1" aria-hidden="true" tabindex="-1"></a>n_trees <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">80</span>, <span class="dv">160</span>)</span>
<span id="cb271-2"><a href="solutions-to-exercises.html#cb271-2" aria-hidden="true" tabindex="-1"></a>mse_RF <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb271-3"><a href="solutions-to-exercises.html#cb271-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(n_trees)){       <span class="co"># No need for functional programming here...</span></span>
<span id="cb271-4"><a href="solutions-to-exercises.html#cb271-4" aria-hidden="true" tabindex="-1"></a>    fit_temp <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(</span>
<span id="cb271-5"><a href="solutions-to-exercises.html#cb271-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">as.formula</span>(<span class="fu">paste</span>(<span class="st">&quot;R1M_Usd ~&quot;</span>, <span class="fu">paste</span>(features_short, <span class="at">collapse =</span> <span class="st">&quot; + &quot;</span>))),  <span class="co"># New formula!</span></span>
<span id="cb271-6"><a href="solutions-to-exercises.html#cb271-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">data =</span> training_sample,    <span class="co"># Data source: training sample</span></span>
<span id="cb271-7"><a href="solutions-to-exercises.html#cb271-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">sampsize =</span> <span class="dv">30000</span>,          <span class="co"># Size of (random) sample for each tree</span></span>
<span id="cb271-8"><a href="solutions-to-exercises.html#cb271-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">replace =</span> <span class="cn">TRUE</span>,            <span class="co"># Is the sampling done with replacement?</span></span>
<span id="cb271-9"><a href="solutions-to-exercises.html#cb271-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">ntree =</span> n_trees[j],        <span class="co"># Nb of random trees</span></span>
<span id="cb271-10"><a href="solutions-to-exercises.html#cb271-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">mtry =</span> <span class="dv">5</span>)                  <span class="co"># Nb of predictors for each tree</span></span>
<span id="cb271-11"><a href="solutions-to-exercises.html#cb271-11" aria-hidden="true" tabindex="-1"></a>    mse_RF[j] <span class="ot">&lt;-</span> <span class="fu">mean</span>((<span class="fu">predict</span>(fit_temp, testing_sample) <span class="sc">-</span> testing_sample<span class="sc">$</span>R1M_Usd)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb271-12"><a href="solutions-to-exercises.html#cb271-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb271-13"><a href="solutions-to-exercises.html#cb271-13" aria-hidden="true" tabindex="-1"></a>mse_RF</span></code></pre></div>
<pre><code>## [1] 0.03967754 0.03885924 0.03766900 0.03696370 0.03699772</code></pre>
<p></p>
<p>Trees are by definition random so results can vary from test to test. Overall, large numbers of trees are preferable and the reason is that each new tree tells a new story and diversifies the risk of the whole forest. Some more technical details of why that may be the case are outlined in the original paper by <span class="citation"><a href="solutions-to-exercises.html#ref-breiman2001random" role="doc-biblioref">Breiman</a> (<a href="solutions-to-exercises.html#ref-breiman2001random" role="doc-biblioref">2001</a>)</span>.</p>
<p>For the last exercises, we recycle the <em>formula</em> used in Chapter <a href="trees.html#trees">6</a>. </p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="solutions-to-exercises.html#cb273-1" aria-hidden="true" tabindex="-1"></a>tree_2008 <span class="ot">&lt;-</span> <span class="fu">rpart</span>(formula,</span>
<span id="cb273-2"><a href="solutions-to-exercises.html#cb273-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> data_ml <span class="sc">%&gt;%</span> <span class="fu">filter</span>(<span class="fu">year</span>(date) <span class="sc">==</span> <span class="dv">2008</span>), <span class="co"># Data source: 2008</span></span>
<span id="cb273-3"><a href="solutions-to-exercises.html#cb273-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">cp =</span> <span class="fl">0.001</span>,</span>
<span id="cb273-4"><a href="solutions-to-exercises.html#cb273-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">maxdepth =</span> <span class="dv">2</span>) </span>
<span id="cb273-5"><a href="solutions-to-exercises.html#cb273-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree_2008)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex73a"></span>
<img src="ML_factor_files/figure-html/ex73a-1.png" alt="Tree for 2008." width="384" />
<p class="caption">
FIGURE 18.10: Tree for 2008.
</p>
</div>
<p></p>
<p>The first splitting criterion in Figure <a href="solutions-to-exercises.html#fig:ex73a">18.10</a> is enterprise value (EV). EV is an indicator that adjusts market capitalization by substracting debt and adding cash. It is a more faithful account of the true value of a company. In 2008, the companies that fared the least poorly were those with the highest EV (i.e., large, robust firms).</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="solutions-to-exercises.html#cb274-1" aria-hidden="true" tabindex="-1"></a>tree_2009 <span class="ot">&lt;-</span> <span class="fu">rpart</span>(formula,</span>
<span id="cb274-2"><a href="solutions-to-exercises.html#cb274-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> data_ml <span class="sc">%&gt;%</span> <span class="fu">filter</span>(<span class="fu">year</span>(date) <span class="sc">==</span> <span class="dv">2009</span>), <span class="co"># Data source: 2009</span></span>
<span id="cb274-3"><a href="solutions-to-exercises.html#cb274-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">cp =</span> <span class="fl">0.001</span>,</span>
<span id="cb274-4"><a href="solutions-to-exercises.html#cb274-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">maxdepth =</span> <span class="dv">2</span>) </span>
<span id="cb274-5"><a href="solutions-to-exercises.html#cb274-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree_2009)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex73b"></span>
<img src="ML_factor_files/figure-html/ex73b-1.png" alt="Tree for 2009." width="384" />
<p class="caption">
FIGURE 18.11: Tree for 2009.
</p>
</div>
<p></p>
<p>In 2009 (Figure <a href="solutions-to-exercises.html#fig:ex73b">18.11</a>), the firms that recovered the fastest were those that experienced high volatility in the past (likely, downwards volatility). Momentum is also very important: the firms with the lowest past returns are those that rebound the fastest. This is a typical example of the momentum crash phenomenon studied in <span class="citation"><a href="solutions-to-exercises.html#ref-barroso2015momentum" role="doc-biblioref">Barroso and Santa-Clara</a> (<a href="solutions-to-exercises.html#ref-barroso2015momentum" role="doc-biblioref">2015</a>)</span> and <span class="citation"><a href="solutions-to-exercises.html#ref-daniel2016momentum" role="doc-biblioref">K. Daniel and Moskowitz</a> (<a href="solutions-to-exercises.html#ref-daniel2016momentum" role="doc-biblioref">2016</a>)</span>. The rationale is the following: after a market downturn, the stocks with the most potential for growth are those that have suffered the largest losses. Consequently, the negative (short) leg of the momentum factor performs very well, often better than the long leg. And indeed, being long in the momentum factor in 2009 would have generated negative profits.</p>
</div>
<div id="chapter-7-the-autoencoder-model-universal-approximation" class="section level2" number="18.5">
<h2><span class="header-section-number">18.5</span> Chapter 7: the autoencoder model &amp; universal approximation</h2>
<p>
First, it is imperative to format the inputs properly. To avoid any issues, we work with perfectly rectangular data and hence restrict the investment set to the stocks with no missing points. Dimensions must also be in the correct order.</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="solutions-to-exercises.html#cb275-1" aria-hidden="true" tabindex="-1"></a>data_short <span class="ot">&lt;-</span> data_ml <span class="sc">%&gt;%</span>         <span class="co"># Shorter dataset</span></span>
<span id="cb275-2"><a href="solutions-to-exercises.html#cb275-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(stock_id <span class="sc">%in%</span> stock_ids_short) <span class="sc">%&gt;%</span></span>
<span id="cb275-3"><a href="solutions-to-exercises.html#cb275-3" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="fu">c</span>(<span class="st">&quot;stock_id&quot;</span>, <span class="st">&quot;date&quot;</span>,features_short, <span class="st">&quot;R1M_Usd&quot;</span>))</span>
<span id="cb275-4"><a href="solutions-to-exercises.html#cb275-4" aria-hidden="true" tabindex="-1"></a>dates <span class="ot">&lt;-</span> <span class="fu">unique</span>(data_short<span class="sc">$</span>date)  <span class="co"># Vector of dates</span></span>
<span id="cb275-5"><a href="solutions-to-exercises.html#cb275-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb275-6"><a href="solutions-to-exercises.html#cb275-6" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fu">length</span>(stock_ids_short)      <span class="co"># Dimension for assets</span></span>
<span id="cb275-7"><a href="solutions-to-exercises.html#cb275-7" aria-hidden="true" tabindex="-1"></a>Tt <span class="ot">&lt;-</span> <span class="fu">length</span>(dates)               <span class="co"># Dimension for dates</span></span>
<span id="cb275-8"><a href="solutions-to-exercises.html#cb275-8" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">length</span>(features_short)       <span class="co"># Dimension for features</span></span>
<span id="cb275-9"><a href="solutions-to-exercises.html#cb275-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb275-10"><a href="solutions-to-exercises.html#cb275-10" aria-hidden="true" tabindex="-1"></a>factor_data <span class="ot">&lt;-</span> data_short <span class="sc">%&gt;%</span>  <span class="co"># Factor side date</span></span>
<span id="cb275-11"><a href="solutions-to-exercises.html#cb275-11" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(date, stock_id, R1M_Usd) <span class="sc">%&gt;%</span></span>
<span id="cb275-12"><a href="solutions-to-exercises.html#cb275-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">spread</span>(<span class="at">key =</span> stock_id, <span class="at">value =</span> R1M_Usd) <span class="sc">%&gt;%</span></span>
<span id="cb275-13"><a href="solutions-to-exercises.html#cb275-13" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>date) <span class="sc">%&gt;%</span></span>
<span id="cb275-14"><a href="solutions-to-exercises.html#cb275-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>()</span>
<span id="cb275-15"><a href="solutions-to-exercises.html#cb275-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb275-16"><a href="solutions-to-exercises.html#cb275-16" aria-hidden="true" tabindex="-1"></a>beta_data <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="fu">unlist</span>(data_short <span class="sc">%&gt;%</span>  <span class="co"># Beta side data: beware the permutation below!</span></span>
<span id="cb275-17"><a href="solutions-to-exercises.html#cb275-17" aria-hidden="true" tabindex="-1"></a>                              dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>stock_id, <span class="sc">-</span>date, <span class="sc">-</span>R1M_Usd)), </span>
<span id="cb275-18"><a href="solutions-to-exercises.html#cb275-18" aria-hidden="true" tabindex="-1"></a>                   <span class="at">dim =</span> <span class="fu">c</span>(N, Tt, K))</span>
<span id="cb275-19"><a href="solutions-to-exercises.html#cb275-19" aria-hidden="true" tabindex="-1"></a>beta_data <span class="ot">&lt;-</span> <span class="fu">aperm</span>(beta_data, <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">3</span>))   <span class="co"># Permutation</span></span></code></pre></div>
<p></p>
<p>Next, we turn to the specification of the network, using a functional API form.</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="solutions-to-exercises.html#cb276-1" aria-hidden="true" tabindex="-1"></a>main_input <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> <span class="fu">c</span>(N), <span class="at">name =</span> <span class="st">&quot;main_input&quot;</span>)  <span class="co"># Main input: returns      </span></span>
<span id="cb276-2"><a href="solutions-to-exercises.html#cb276-2" aria-hidden="true" tabindex="-1"></a>factor_network <span class="ot">&lt;-</span> main_input <span class="sc">%&gt;%</span>                              <span class="co"># Def of factor side network</span></span>
<span id="cb276-3"><a href="solutions-to-exercises.html#cb276-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">8</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">name =</span> <span class="st">&quot;layer_1_r&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb276-4"><a href="solutions-to-exercises.html#cb276-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">4</span>, <span class="at">activation =</span> <span class="st">&quot;tanh&quot;</span>, <span class="at">name =</span> <span class="st">&quot;layer_2_r&quot;</span>) </span>
<span id="cb276-5"><a href="solutions-to-exercises.html#cb276-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-6"><a href="solutions-to-exercises.html#cb276-6" aria-hidden="true" tabindex="-1"></a>aux_input <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> <span class="fu">c</span>(N,K), <span class="at">name =</span> <span class="st">&quot;aux_input&quot;</span>)  <span class="co"># Aux input: characteristics</span></span>
<span id="cb276-7"><a href="solutions-to-exercises.html#cb276-7" aria-hidden="true" tabindex="-1"></a>beta_network <span class="ot">&lt;-</span> aux_input <span class="sc">%&gt;%</span>                                 <span class="co"># Def of beta side network</span></span>
<span id="cb276-8"><a href="solutions-to-exercises.html#cb276-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">8</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">name =</span> <span class="st">&quot;layer_1_l&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb276-9"><a href="solutions-to-exercises.html#cb276-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">4</span>, <span class="at">activation =</span> <span class="st">&quot;tanh&quot;</span>, <span class="at">name =</span> <span class="st">&quot;layer_2_l&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb276-10"><a href="solutions-to-exercises.html#cb276-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_permute</span>(<span class="at">dims =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="at">name =</span> <span class="st">&quot;layer_3_l&quot;</span>)          <span class="co"># Permutation!</span></span>
<span id="cb276-11"><a href="solutions-to-exercises.html#cb276-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-12"><a href="solutions-to-exercises.html#cb276-12" aria-hidden="true" tabindex="-1"></a>main_output <span class="ot">&lt;-</span> <span class="fu">layer_dot</span>(<span class="fu">c</span>(beta_network, factor_network),     <span class="co"># Product of 2 networks</span></span>
<span id="cb276-13"><a href="solutions-to-exercises.html#cb276-13" aria-hidden="true" tabindex="-1"></a>                         <span class="at">axes =</span> <span class="dv">1</span>, <span class="at">name =</span> <span class="st">&quot;main_output&quot;</span>) </span>
<span id="cb276-14"><a href="solutions-to-exercises.html#cb276-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-15"><a href="solutions-to-exercises.html#cb276-15" aria-hidden="true" tabindex="-1"></a>model_ae <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(                                      <span class="co"># AE Model specs</span></span>
<span id="cb276-16"><a href="solutions-to-exercises.html#cb276-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">inputs =</span> <span class="fu">c</span>(main_input, aux_input),</span>
<span id="cb276-17"><a href="solutions-to-exercises.html#cb276-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">outputs =</span> <span class="fu">c</span>(main_output)</span>
<span id="cb276-18"><a href="solutions-to-exercises.html#cb276-18" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p></p>
<p>Finally, we ask for the structure of the model, and train it.</p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="solutions-to-exercises.html#cb277-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_ae)                      <span class="co"># See model details / architecture</span></span></code></pre></div>
<pre><code>## Model: &quot;model_5&quot;
## __________________________________________________________________________________________
## Layer (type)                 Output Shape        Param #    Connected to                  
## ==========================================================================================
## aux_input (InputLayer)       [(None, 793, 7)]    0                                        
## __________________________________________________________________________________________
## layer_1_l (Dense)            (None, 793, 8)      64         aux_input[0][0]               
## __________________________________________________________________________________________
## main_input (InputLayer)      [(None, 793)]       0                                        
## __________________________________________________________________________________________
## layer_2_l (Dense)            (None, 793, 4)      36         layer_1_l[0][0]               
## __________________________________________________________________________________________
## layer_1_r (Dense)            (None, 8)           6352       main_input[0][0]              
## __________________________________________________________________________________________
## layer_3_l (Permute)          (None, 4, 793)      0          layer_2_l[0][0]               
## __________________________________________________________________________________________
## layer_2_r (Dense)            (None, 4)           36         layer_1_r[0][0]               
## __________________________________________________________________________________________
## main_output (Dot)            (None, 793)         0          layer_3_l[0][0]               
##                                                             layer_2_r[0][0]               
## ==========================================================================================
## Total params: 6,488
## Trainable params: 6,488
## Non-trainable params: 0
## __________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="solutions-to-exercises.html#cb279-1" aria-hidden="true" tabindex="-1"></a>model_ae <span class="sc">%&gt;%</span> <span class="fu">compile</span>(                  <span class="co"># Learning parameters</span></span>
<span id="cb279-2"><a href="solutions-to-exercises.html#cb279-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">&quot;rmsprop&quot;</span>,</span>
<span id="cb279-3"><a href="solutions-to-exercises.html#cb279-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">&quot;mse&quot;</span></span>
<span id="cb279-4"><a href="solutions-to-exercises.html#cb279-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb279-5"><a href="solutions-to-exercises.html#cb279-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-6"><a href="solutions-to-exercises.html#cb279-6" aria-hidden="true" tabindex="-1"></a>model_ae <span class="sc">%&gt;%</span> <span class="fu">fit</span>(                      <span class="co"># Learning function</span></span>
<span id="cb279-7"><a href="solutions-to-exercises.html#cb279-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">list</span>(<span class="at">main_input =</span> factor_data, <span class="at">aux_input =</span> beta_data),</span>
<span id="cb279-8"><a href="solutions-to-exercises.html#cb279-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">list</span>(<span class="at">main_output =</span> factor_data),</span>
<span id="cb279-9"><a href="solutions-to-exercises.html#cb279-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">20</span>,                      <span class="co"># Nb rounds</span></span>
<span id="cb279-10"><a href="solutions-to-exercises.html#cb279-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> <span class="dv">49</span>                   <span class="co"># Nb obs. per round</span></span>
<span id="cb279-11"><a href="solutions-to-exercises.html#cb279-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p></p>
<p>For the second exercise, we use a simple architecture. The activation function, number of epochs and batch size may matter…</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="solutions-to-exercises.html#cb280-1" aria-hidden="true" tabindex="-1"></a>model_ua <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb280-2"><a href="solutions-to-exercises.html#cb280-2" aria-hidden="true" tabindex="-1"></a>model_ua <span class="sc">%&gt;%</span>   <span class="co"># This defines the structure of the network, i.e. how layers are organized</span></span>
<span id="cb280-3"><a href="solutions-to-exercises.html#cb280-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">16</span>, <span class="at">activation =</span> <span class="st">&#39;sigmoid&#39;</span>, <span class="at">input_shape =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb280-4"><a href="solutions-to-exercises.html#cb280-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1</span>) <span class="co"># </span></span>
<span id="cb280-5"><a href="solutions-to-exercises.html#cb280-5" aria-hidden="true" tabindex="-1"></a>model_ua <span class="sc">%&gt;%</span> <span class="fu">compile</span>(                             <span class="co"># Model specification</span></span>
<span id="cb280-6"><a href="solutions-to-exercises.html#cb280-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">&#39;mean_squared_error&#39;</span>,                  <span class="co"># Loss function</span></span>
<span id="cb280-7"><a href="solutions-to-exercises.html#cb280-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_rmsprop</span>(),              <span class="co"># Optimisation method (weight updating)</span></span>
<span id="cb280-8"><a href="solutions-to-exercises.html#cb280-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">&#39;mean_absolute_error&#39;</span>)            <span class="co"># Output metric</span></span>
<span id="cb280-9"><a href="solutions-to-exercises.html#cb280-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb280-10"><a href="solutions-to-exercises.html#cb280-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_ua)                                 <span class="co"># A simple model!</span></span></code></pre></div>
<pre><code>## Model: &quot;sequential_15&quot;
## __________________________________________________________________________________________
## Layer (type)                            Output Shape                        Param #       
## ==========================================================================================
## dense_48 (Dense)                        (None, 16)                          32            
## __________________________________________________________________________________________
## dense_47 (Dense)                        (None, 1)                           17            
## ==========================================================================================
## Total params: 49
## Trainable params: 49
## Non-trainable params: 0
## __________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="solutions-to-exercises.html#cb282-1" aria-hidden="true" tabindex="-1"></a>fit_ua <span class="ot">&lt;-</span> model_ua <span class="sc">%&gt;%</span> </span>
<span id="cb282-2"><a href="solutions-to-exercises.html#cb282-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="at">by =</span> <span class="fl">0.001</span>) <span class="sc">%&gt;%</span> <span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">1</span>),              <span class="co"># Training data = x</span></span>
<span id="cb282-3"><a href="solutions-to-exercises.html#cb282-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">sin</span>(<span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="at">by =</span> <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span> <span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">1</span>),         <span class="co"># Training label = y</span></span>
<span id="cb282-4"><a href="solutions-to-exercises.html#cb282-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">epochs =</span> <span class="dv">30</span>, <span class="at">batch_size =</span> <span class="dv">64</span>                             <span class="co"># Training parameters</span></span>
<span id="cb282-5"><a href="solutions-to-exercises.html#cb282-5" aria-hidden="true" tabindex="-1"></a>) </span></code></pre></div>
<p></p>
<p>In full disclosure, to improve the fit, we also increase the sample size. We show the improvement in the figure below.</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="solutions-to-exercises.html#cb283-1" aria-hidden="true" tabindex="-1"></a>model_ua2 <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb283-2"><a href="solutions-to-exercises.html#cb283-2" aria-hidden="true" tabindex="-1"></a>model_ua2 <span class="sc">%&gt;%</span>   <span class="co"># This defines the structure of the network, i.e. how layers are organized</span></span>
<span id="cb283-3"><a href="solutions-to-exercises.html#cb283-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">128</span>, <span class="at">activation =</span> <span class="st">&#39;sigmoid&#39;</span>, <span class="at">input_shape =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb283-4"><a href="solutions-to-exercises.html#cb283-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1</span>) <span class="co"># </span></span>
<span id="cb283-5"><a href="solutions-to-exercises.html#cb283-5" aria-hidden="true" tabindex="-1"></a>model_ua2 <span class="sc">%&gt;%</span> <span class="fu">compile</span>(                             <span class="co"># Model specification</span></span>
<span id="cb283-6"><a href="solutions-to-exercises.html#cb283-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">&#39;mean_squared_error&#39;</span>,                  <span class="co"># Loss function</span></span>
<span id="cb283-7"><a href="solutions-to-exercises.html#cb283-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_rmsprop</span>(),              <span class="co"># Optimisation method (weight updating)</span></span>
<span id="cb283-8"><a href="solutions-to-exercises.html#cb283-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">&#39;mean_absolute_error&#39;</span>)            <span class="co"># Output metric</span></span>
<span id="cb283-9"><a href="solutions-to-exercises.html#cb283-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb283-10"><a href="solutions-to-exercises.html#cb283-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_ua2)                                 <span class="co"># A simple model!</span></span></code></pre></div>
<pre><code>## Model: &quot;sequential_8&quot;
## __________________________________________________________________________________________
## Layer (type)                            Output Shape                        Param #       
## ==========================================================================================
## dense_24 (Dense)                        (None, 128)                         256           
## __________________________________________________________________________________________
## dense_23 (Dense)                        (None, 1)                           129           
## ==========================================================================================
## Total params: 385
## Trainable params: 385
## Non-trainable params: 0
## __________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="solutions-to-exercises.html#cb285-1" aria-hidden="true" tabindex="-1"></a>fit_ua2 <span class="ot">&lt;-</span> model_ua2 <span class="sc">%&gt;%</span> </span>
<span id="cb285-2"><a href="solutions-to-exercises.html#cb285-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="at">by =</span> <span class="fl">0.0002</span>) <span class="sc">%&gt;%</span> <span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">1</span>),            <span class="co"># Training data = x</span></span>
<span id="cb285-3"><a href="solutions-to-exercises.html#cb285-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">sin</span>(<span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="at">by =</span> <span class="fl">0.0002</span>)) <span class="sc">%&gt;%</span> <span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">1</span>),       <span class="co"># Training label = y</span></span>
<span id="cb285-4"><a href="solutions-to-exercises.html#cb285-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">epochs =</span> <span class="dv">60</span>, <span class="at">batch_size =</span> <span class="dv">64</span>                            <span class="co"># Training parameters</span></span>
<span id="cb285-5"><a href="solutions-to-exercises.html#cb285-5" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb285-6"><a href="solutions-to-exercises.html#cb285-6" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> x) <span class="sc">%&gt;%</span></span>
<span id="cb285-7"><a href="solutions-to-exercises.html#cb285-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb285-8"><a href="solutions-to-exercises.html#cb285-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">predict</span>(model_ua, x), <span class="at">color =</span> <span class="st">&quot;Small model&quot;</span>)) <span class="sc">+</span></span>
<span id="cb285-9"><a href="solutions-to-exercises.html#cb285-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">predict</span>(model_ua2, x), <span class="at">color =</span> <span class="st">&quot;Large model&quot;</span>)) <span class="sc">+</span></span>
<span id="cb285-10"><a href="solutions-to-exercises.html#cb285-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> sin, <span class="fu">aes</span>(<span class="at">color =</span> <span class="st">&quot;sin(x) function&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb285-11"><a href="solutions-to-exercises.html#cb285-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;#9999FF&quot;</span>, <span class="st">&quot;#333399&quot;</span>, <span class="st">&quot;#000000&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex82b"></span>
<img src="ML_factor_files/figure-html/ex82b-1.png" alt="Case with 128 units. The sine function in light blue and approximation in black." width="400px" />
<p class="caption">
FIGURE 18.12: Case with 128 units. The sine function in light blue and approximation in black.
</p>
</div>
<p></p>
</div>
<div id="chapter-8" class="section level2" number="18.6">
<h2><span class="header-section-number">18.6</span> Chapter 8</h2>
<p>Since we are going to reproduce a similar analysis several times, let’s simplify the task with 2 tips. First, by using default parameter values that will be passed as common arguments to the <em>svm</em> function. Second, by creating a custom function that computes the MSE. Third, by resorting to functional calculus via the <em>map</em> function from the <em>purrr</em> package. Below, we recycle datasets created in Chapter <a href="trees.html#trees">6</a>. </p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="solutions-to-exercises.html#cb286-1" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> <span class="cf">function</span>(fit, features, label){             <span class="co"># MSE function</span></span>
<span id="cb286-2"><a href="solutions-to-exercises.html#cb286-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">mean</span>((<span class="fu">predict</span>(fit, features)<span class="sc">-</span>label)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb286-3"><a href="solutions-to-exercises.html#cb286-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb286-4"><a href="solutions-to-exercises.html#cb286-4" aria-hidden="true" tabindex="-1"></a>par_list <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">y =</span> train_label_xgb[<span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>],     <span class="co"># From Tree chapter</span></span>
<span id="cb286-5"><a href="solutions-to-exercises.html#cb286-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">x =</span> train_features_xgb[<span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>,],</span>
<span id="cb286-6"><a href="solutions-to-exercises.html#cb286-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">type =</span> <span class="st">&quot;eps-regression&quot;</span>,</span>
<span id="cb286-7"><a href="solutions-to-exercises.html#cb286-7" aria-hidden="true" tabindex="-1"></a>                 <span class="at">epsilon =</span> <span class="fl">0.1</span>,                    <span class="co"># Width of strip for errors</span></span>
<span id="cb286-8"><a href="solutions-to-exercises.html#cb286-8" aria-hidden="true" tabindex="-1"></a>                 <span class="at">gamma =</span> <span class="fl">0.5</span>,                      <span class="co"># Constant in the radial kernel </span></span>
<span id="cb286-9"><a href="solutions-to-exercises.html#cb286-9" aria-hidden="true" tabindex="-1"></a>                 <span class="at">cost =</span> <span class="fl">0.1</span>)</span>
<span id="cb286-10"><a href="solutions-to-exercises.html#cb286-10" aria-hidden="true" tabindex="-1"></a>svm_par <span class="ot">&lt;-</span> <span class="cf">function</span>(kernel, par_list){             <span class="co"># Function for SVM fit automation</span></span>
<span id="cb286-11"><a href="solutions-to-exercises.html#cb286-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">require</span>(e1071)</span>
<span id="cb286-12"><a href="solutions-to-exercises.html#cb286-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">do.call</span>(svm, <span class="fu">c</span>(<span class="at">kernel =</span> kernel, par_list))) </span>
<span id="cb286-13"><a href="solutions-to-exercises.html#cb286-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb286-14"><a href="solutions-to-exercises.html#cb286-14" aria-hidden="true" tabindex="-1"></a>kernels <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;linear&quot;</span>, <span class="st">&quot;radial&quot;</span>, <span class="st">&quot;polynomial&quot;</span>, <span class="st">&quot;sigmoid&quot;</span>) <span class="co"># Kernels</span></span>
<span id="cb286-15"><a href="solutions-to-exercises.html#cb286-15" aria-hidden="true" tabindex="-1"></a>fit_svm_par <span class="ot">&lt;-</span> <span class="fu">map</span>(kernels, svm_par, <span class="at">par_list =</span> par_list) <span class="co"># SVM models</span></span>
<span id="cb286-16"><a href="solutions-to-exercises.html#cb286-16" aria-hidden="true" tabindex="-1"></a><span class="fu">map</span>(fit_svm_par, mse,                                     <span class="co"># MSEs</span></span>
<span id="cb286-17"><a href="solutions-to-exercises.html#cb286-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">features =</span> test_feat_short,                           <span class="co"># From SVM chapter </span></span>
<span id="cb286-18"><a href="solutions-to-exercises.html#cb286-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> testing_sample<span class="sc">$</span>R1M_Usd)</span></code></pre></div>
<pre><code>## [[1]]
## [1] 0.03849786
## 
## [[2]]
## [1] 0.03924576
## 
## [[3]]
## [1] 0.03951328
## 
## [[4]]
## [1] 334.8173</code></pre>
<p></p>
<p>The first two kernels yield the best fit, while the last one should be avoided. Note that apart from the linear kernel, all other options require parameters. We have used the default ones, which may explain the poor performance of some nonlinear kernels.</p>
<p>Below, we train an SVM model on a training sample with all observations but that is limited to the 7 major predictors. Even with a smaller number of features, the training is time consuming.</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="solutions-to-exercises.html#cb288-1" aria-hidden="true" tabindex="-1"></a>svm_full <span class="ot">&lt;-</span> <span class="fu">svm</span>(<span class="at">y =</span> train_label_xgb,      <span class="co"># Train label</span></span>
<span id="cb288-2"><a href="solutions-to-exercises.html#cb288-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">x =</span> train_features_xgb,   <span class="co"># Training features</span></span>
<span id="cb288-3"><a href="solutions-to-exercises.html#cb288-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">type =</span> <span class="st">&quot;eps-regression&quot;</span>,  <span class="co"># SVM task type (see LIBSVM documentation)</span></span>
<span id="cb288-4"><a href="solutions-to-exercises.html#cb288-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">kernel =</span> <span class="st">&quot;linear&quot;</span>,        <span class="co"># SVM kernel </span></span>
<span id="cb288-5"><a href="solutions-to-exercises.html#cb288-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">epsilon =</span> <span class="fl">0.1</span>,            <span class="co"># Width of strip for errors</span></span>
<span id="cb288-6"><a href="solutions-to-exercises.html#cb288-6" aria-hidden="true" tabindex="-1"></a>                <span class="at">cost =</span> <span class="fl">0.1</span>)               <span class="co"># Slack variable penalisation</span></span>
<span id="cb288-7"><a href="solutions-to-exercises.html#cb288-7" aria-hidden="true" tabindex="-1"></a>test_feat_short <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(testing_sample,features_short)       <span class="co"># Test set</span></span>
<span id="cb288-8"><a href="solutions-to-exercises.html#cb288-8" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">predict</span>(svm_full, test_feat_short) <span class="sc">*</span> testing_sample<span class="sc">$</span>R1M_Usd <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="co"># Hit ratio</span></span></code></pre></div>
<pre><code>## [1] 0.490343</code></pre>
<p></p>
<p>This figure is very low. Below, we test a very simple form of boosted trees, for comparison purposes.</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="solutions-to-exercises.html#cb290-1" aria-hidden="true" tabindex="-1"></a>xgb_full <span class="ot">&lt;-</span> <span class="fu">xgb.train</span>(<span class="at">data =</span> train_matrix_xgb,    <span class="co"># Data source </span></span>
<span id="cb290-2"><a href="solutions-to-exercises.html#cb290-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">eta =</span> <span class="fl">0.3</span>,                          <span class="co"># Learning rate</span></span>
<span id="cb290-3"><a href="solutions-to-exercises.html#cb290-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">objective =</span> <span class="st">&quot;reg:linear&quot;</span>,           <span class="co"># Objective function</span></span>
<span id="cb290-4"><a href="solutions-to-exercises.html#cb290-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">max_depth =</span> <span class="dv">4</span>,                      <span class="co"># Maximum depth of trees</span></span>
<span id="cb290-5"><a href="solutions-to-exercises.html#cb290-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">nrounds =</span> <span class="dv">60</span>                        <span class="co"># Number of trees used (bit low here)</span></span>
<span id="cb290-6"><a href="solutions-to-exercises.html#cb290-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## [14:43:24] WARNING: amalgamation/../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.</code></pre>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="solutions-to-exercises.html#cb292-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">predict</span>(xgb_full, xgb_test) <span class="sc">*</span> testing_sample<span class="sc">$</span>R1M_Usd <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="co"># Hit ratio</span></span></code></pre></div>
<pre><code>## [1] 0.5017377</code></pre>
<p></p>
<p>The forecasts are slightly better, but the computation time is lower. Two reasons why the models perform poorly:</p>
<ol style="list-style-type: decimal">
<li>there are not enough predictors;<br />
</li>
<li>the models are static: they do not adjust dynamically to macro-conditions.</li>
</ol>
</div>
<div id="chapter-11-ensemble-neural-network" class="section level2" number="18.7">
<h2><span class="header-section-number">18.7</span> Chapter 11: ensemble neural network</h2>
<p></p>
<p>First, we create the three feature sets. The first one gets all multiples of 3 between 3 and 93. The second one gets the same indices, minus one, and the third one, the initial indices minus two.</p>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="solutions-to-exercises.html#cb294-1" aria-hidden="true" tabindex="-1"></a>feat_train_1 <span class="ot">&lt;-</span> training_sample <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(features[<span class="dv">3</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">31</span>)]) <span class="sc">%&gt;%</span>   <span class="co"># First set of feats</span></span>
<span id="cb294-2"><a href="solutions-to-exercises.html#cb294-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>() </span>
<span id="cb294-3"><a href="solutions-to-exercises.html#cb294-3" aria-hidden="true" tabindex="-1"></a>feat_train_2 <span class="ot">&lt;-</span> training_sample <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(features[<span class="dv">3</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">31</span>)<span class="sc">-</span><span class="dv">1</span>]) <span class="sc">%&gt;%</span> <span class="co"># Second set of feats</span></span>
<span id="cb294-4"><a href="solutions-to-exercises.html#cb294-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>() </span>
<span id="cb294-5"><a href="solutions-to-exercises.html#cb294-5" aria-hidden="true" tabindex="-1"></a>feat_train_3 <span class="ot">&lt;-</span> training_sample <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(features[<span class="dv">3</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">31</span>)<span class="sc">-</span><span class="dv">2</span>]) <span class="sc">%&gt;%</span> <span class="co"># Third set of feats</span></span>
<span id="cb294-6"><a href="solutions-to-exercises.html#cb294-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>() </span>
<span id="cb294-7"><a href="solutions-to-exercises.html#cb294-7" aria-hidden="true" tabindex="-1"></a>feat_test_1 <span class="ot">&lt;-</span> testing_sample <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(features[<span class="dv">3</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">31</span>)]) <span class="sc">%&gt;%</span>     <span class="co"># Test features 1</span></span>
<span id="cb294-8"><a href="solutions-to-exercises.html#cb294-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>() </span>
<span id="cb294-9"><a href="solutions-to-exercises.html#cb294-9" aria-hidden="true" tabindex="-1"></a>feat_test_2 <span class="ot">&lt;-</span> testing_sample <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(features[<span class="dv">3</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">31</span>)<span class="sc">-</span><span class="dv">1</span>]) <span class="sc">%&gt;%</span>   <span class="co"># Test features 2</span></span>
<span id="cb294-10"><a href="solutions-to-exercises.html#cb294-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>() </span>
<span id="cb294-11"><a href="solutions-to-exercises.html#cb294-11" aria-hidden="true" tabindex="-1"></a>feat_test_3 <span class="ot">&lt;-</span> testing_sample <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(features[<span class="dv">3</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">31</span>)<span class="sc">-</span><span class="dv">2</span>]) <span class="sc">%&gt;%</span>   <span class="co"># Test features 3</span></span>
<span id="cb294-12"><a href="solutions-to-exercises.html#cb294-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>() </span></code></pre></div>
<p></p>
<p>Then, we specify the network structure. First, the 3 independent networks, then the aggregation.</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="solutions-to-exercises.html#cb295-1" aria-hidden="true" tabindex="-1"></a>first_input <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">31</span>), <span class="at">name =</span> <span class="st">&quot;first_input&quot;</span>)   <span class="co"># First input      </span></span>
<span id="cb295-2"><a href="solutions-to-exercises.html#cb295-2" aria-hidden="true" tabindex="-1"></a>first_network <span class="ot">&lt;-</span> first_input <span class="sc">%&gt;%</span>                                  <span class="co"># Def of 1st network</span></span>
<span id="cb295-3"><a href="solutions-to-exercises.html#cb295-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">8</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">name =</span> <span class="st">&quot;layer_1&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb295-4"><a href="solutions-to-exercises.html#cb295-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">2</span>, <span class="at">activation =</span> <span class="st">&#39;softmax&#39;</span>)                <span class="co"># Softmax for categ. output</span></span>
<span id="cb295-5"><a href="solutions-to-exercises.html#cb295-5" aria-hidden="true" tabindex="-1"></a>second_input <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">31</span>), <span class="at">name =</span> <span class="st">&quot;second_input&quot;</span>) <span class="co"># Second input      </span></span>
<span id="cb295-6"><a href="solutions-to-exercises.html#cb295-6" aria-hidden="true" tabindex="-1"></a>second_network <span class="ot">&lt;-</span> second_input <span class="sc">%&gt;%</span>                                <span class="co"># Def of 2nd network</span></span>
<span id="cb295-7"><a href="solutions-to-exercises.html#cb295-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">8</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">name =</span> <span class="st">&quot;layer_2&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb295-8"><a href="solutions-to-exercises.html#cb295-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">2</span>, <span class="at">activation =</span> <span class="st">&#39;softmax&#39;</span>)                <span class="co"># Softmax for categ. output</span></span>
<span id="cb295-9"><a href="solutions-to-exercises.html#cb295-9" aria-hidden="true" tabindex="-1"></a>third_input <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">31</span>), <span class="at">name =</span> <span class="st">&quot;third_input&quot;</span>)  <span class="co"># Third input      </span></span>
<span id="cb295-10"><a href="solutions-to-exercises.html#cb295-10" aria-hidden="true" tabindex="-1"></a>third_network <span class="ot">&lt;-</span> third_input <span class="sc">%&gt;%</span>                                  <span class="co"># Def of 3rd network</span></span>
<span id="cb295-11"><a href="solutions-to-exercises.html#cb295-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">8</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">name =</span> <span class="st">&quot;layer_3&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb295-12"><a href="solutions-to-exercises.html#cb295-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">2</span>, <span class="at">activation =</span> <span class="st">&#39;softmax&#39;</span>)                <span class="co"># Softmax for categ. output</span></span>
<span id="cb295-13"><a href="solutions-to-exercises.html#cb295-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb295-14"><a href="solutions-to-exercises.html#cb295-14" aria-hidden="true" tabindex="-1"></a>main_output <span class="ot">&lt;-</span> <span class="fu">layer_concatenate</span>(<span class="fu">c</span>(first_network, </span>
<span id="cb295-15"><a href="solutions-to-exercises.html#cb295-15" aria-hidden="true" tabindex="-1"></a>                                   second_network,</span>
<span id="cb295-16"><a href="solutions-to-exercises.html#cb295-16" aria-hidden="true" tabindex="-1"></a>                                   third_network)) <span class="sc">%&gt;%</span>            <span class="co"># Combination</span></span>
<span id="cb295-17"><a href="solutions-to-exercises.html#cb295-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">2</span>, <span class="at">activation =</span> <span class="st">&#39;softmax&#39;</span>, <span class="at">name =</span> <span class="st">&#39;main_output&#39;</span>)</span>
<span id="cb295-18"><a href="solutions-to-exercises.html#cb295-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb295-19"><a href="solutions-to-exercises.html#cb295-19" aria-hidden="true" tabindex="-1"></a>model_ens <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(                                          <span class="co"># Agg. Model specs</span></span>
<span id="cb295-20"><a href="solutions-to-exercises.html#cb295-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">inputs =</span> <span class="fu">c</span>(first_input, second_input, third_input),</span>
<span id="cb295-21"><a href="solutions-to-exercises.html#cb295-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">outputs =</span> <span class="fu">c</span>(main_output)</span>
<span id="cb295-22"><a href="solutions-to-exercises.html#cb295-22" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p></p>
<p>Lastly, we can train and evaluate (see Figure <a href="solutions-to-exercises.html#fig:ex12c">18.13</a>).</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="solutions-to-exercises.html#cb296-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_ens)                      <span class="co"># See model details / architecture</span></span></code></pre></div>
<pre><code>## Model: &quot;model_6&quot;
## __________________________________________________________________________________________
## Layer (type)                 Output Shape        Param #    Connected to                  
## ==========================================================================================
## first_input (InputLayer)     [(None, 31)]        0                                        
## __________________________________________________________________________________________
## second_input (InputLayer)    [(None, 31)]        0                                        
## __________________________________________________________________________________________
## third_input (InputLayer)     [(None, 31)]        0                                        
## __________________________________________________________________________________________
## layer_1 (Dense)              (None, 8)           256        first_input[0][0]             
## __________________________________________________________________________________________
## layer_2 (Dense)              (None, 8)           256        second_input[0][0]            
## __________________________________________________________________________________________
## layer_3 (Dense)              (None, 8)           256        third_input[0][0]             
## __________________________________________________________________________________________
## dense_49 (Dense)             (None, 2)           18         layer_1[0][0]                 
## __________________________________________________________________________________________
## dense_50 (Dense)             (None, 2)           18         layer_2[0][0]                 
## __________________________________________________________________________________________
## dense_51 (Dense)             (None, 2)           18         layer_3[0][0]                 
## __________________________________________________________________________________________
## concatenate_1 (Concatenate)  (None, 6)           0          dense_49[0][0]                
##                                                             dense_50[0][0]                
##                                                             dense_51[0][0]                
## __________________________________________________________________________________________
## main_output (Dense)          (None, 2)           14         concatenate_1[0][0]           
## ==========================================================================================
## Total params: 836
## Trainable params: 836
## Non-trainable params: 0
## __________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="solutions-to-exercises.html#cb298-1" aria-hidden="true" tabindex="-1"></a>model_ens <span class="sc">%&gt;%</span> <span class="fu">compile</span>(                  <span class="co"># Learning parameters</span></span>
<span id="cb298-2"><a href="solutions-to-exercises.html#cb298-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(),</span>
<span id="cb298-3"><a href="solutions-to-exercises.html#cb298-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>,</span>
<span id="cb298-4"><a href="solutions-to-exercises.html#cb298-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">metrics =</span> <span class="st">&quot;categorical_accuracy&quot;</span></span>
<span id="cb298-5"><a href="solutions-to-exercises.html#cb298-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb298-6"><a href="solutions-to-exercises.html#cb298-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb298-7"><a href="solutions-to-exercises.html#cb298-7" aria-hidden="true" tabindex="-1"></a>fit_NN_ens <span class="ot">&lt;-</span> model_ens <span class="sc">%&gt;%</span> <span class="fu">fit</span>(               <span class="co"># Learning function</span></span>
<span id="cb298-8"><a href="solutions-to-exercises.html#cb298-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">list</span>(<span class="at">first_input =</span> feat_train_1, </span>
<span id="cb298-9"><a href="solutions-to-exercises.html#cb298-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">second_input =</span> feat_train_2,</span>
<span id="cb298-10"><a href="solutions-to-exercises.html#cb298-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">third_input =</span> feat_train_3),</span>
<span id="cb298-11"><a href="solutions-to-exercises.html#cb298-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">list</span>(<span class="at">main_output =</span> NN_train_labels_C), <span class="co"># Recycled from NN Chapter</span></span>
<span id="cb298-12"><a href="solutions-to-exercises.html#cb298-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">12</span>,                               <span class="co"># Nb rounds</span></span>
<span id="cb298-13"><a href="solutions-to-exercises.html#cb298-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> <span class="dv">512</span>,                          <span class="co"># Nb obs. per round</span></span>
<span id="cb298-14"><a href="solutions-to-exercises.html#cb298-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_data =</span> <span class="fu">list</span>(<span class="fu">list</span>(feat_test_1, feat_test_2, feat_test_3),</span>
<span id="cb298-15"><a href="solutions-to-exercises.html#cb298-15" aria-hidden="true" tabindex="-1"></a>                           NN_test_labels_C)</span>
<span id="cb298-16"><a href="solutions-to-exercises.html#cb298-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb298-17"><a href="solutions-to-exercises.html#cb298-17" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_NN_ens)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex12c"></span>
<img src="ML_factor_files/figure-html/ex12c-1.png" alt="Learning an integrated ensemble." width="432" />
<p class="caption">
FIGURE 18.13: Learning an integrated ensemble.
</p>
</div>
<p></p>
</div>
<div id="chapter-12" class="section level2" number="18.8">
<h2><span class="header-section-number">18.8</span> Chapter 12</h2>
<div id="ew-portfolios-with-the-tidyverse" class="section level3" number="18.8.1">
<h3><span class="header-section-number">18.8.1</span> EW portfolios with the tidyverse</h3>
<p></p>
<p>This one is incredibly easy; it’s simpler and more compact but close in spirit to the code that generates Figure <a href="factor.html#fig:factportsort">3.1</a>. The returns are plotted in Figure <a href="solutions-to-exercises.html#fig:ex130a">18.14</a>.
</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="solutions-to-exercises.html#cb299-1" aria-hidden="true" tabindex="-1"></a>data_ml <span class="sc">%&gt;%</span></span>
<span id="cb299-2"><a href="solutions-to-exercises.html#cb299-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(date) <span class="sc">%&gt;%</span>                     <span class="co"># Group by date</span></span>
<span id="cb299-3"><a href="solutions-to-exercises.html#cb299-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">return =</span> <span class="fu">mean</span>(R1M_Usd)) <span class="sc">%&gt;%</span>  <span class="co"># Compute return</span></span>
<span id="cb299-4"><a href="solutions-to-exercises.html#cb299-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> date, <span class="at">y =</span> return)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="co"># Plot</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex130a"></span>
<img src="ML_factor_files/figure-html/ex130a-1.png" alt="Time series of returns." width="384" />
<p class="caption">
FIGURE 18.14: Time series of returns.
</p>
</div>
<p></p>
</div>
<div id="advanced-weighting-function" class="section level3" number="18.8.2">
<h3><span class="header-section-number">18.8.2</span> Advanced weighting function</h3>
<p>First, we code the function with all inputs.</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="solutions-to-exercises.html#cb300-1" aria-hidden="true" tabindex="-1"></a>weights <span class="ot">&lt;-</span> <span class="cf">function</span>(Sigma, mu, Lambda, lambda, k_D, k_R, w_old){</span>
<span id="cb300-2"><a href="solutions-to-exercises.html#cb300-2" aria-hidden="true" tabindex="-1"></a>    N <span class="ot">&lt;-</span> <span class="fu">nrow</span>(Sigma)</span>
<span id="cb300-3"><a href="solutions-to-exercises.html#cb300-3" aria-hidden="true" tabindex="-1"></a>    M <span class="ot">&lt;-</span> <span class="fu">solve</span>(lambda<span class="sc">*</span>Sigma <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>k_R<span class="sc">*</span>Lambda <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>k_D<span class="sc">*</span><span class="fu">diag</span>(N)) <span class="co"># Inverse matrix</span></span>
<span id="cb300-4"><a href="solutions-to-exercises.html#cb300-4" aria-hidden="true" tabindex="-1"></a>    num <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(M <span class="sc">%*%</span> (mu <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>k_R<span class="sc">*</span>Lambda <span class="sc">%*%</span> w_old))       <span class="co"># eta numerator</span></span>
<span id="cb300-5"><a href="solutions-to-exercises.html#cb300-5" aria-hidden="true" tabindex="-1"></a>    den <span class="ot">&lt;-</span> <span class="fu">sum</span>(M <span class="sc">%*%</span> <span class="fu">rep</span>(<span class="dv">1</span>,N))                              <span class="co"># eta denominator</span></span>
<span id="cb300-6"><a href="solutions-to-exercises.html#cb300-6" aria-hidden="true" tabindex="-1"></a>    eta <span class="ot">&lt;-</span> num <span class="sc">/</span> den                                        <span class="co"># eta</span></span>
<span id="cb300-7"><a href="solutions-to-exercises.html#cb300-7" aria-hidden="true" tabindex="-1"></a>    vec <span class="ot">&lt;-</span> mu <span class="sc">+</span> eta <span class="sc">*</span> <span class="fu">rep</span>(<span class="dv">1</span>,N) <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>k_R<span class="sc">*</span>Lambda <span class="sc">%*%</span> w_old     <span class="co"># Vector in weight</span></span>
<span id="cb300-8"><a href="solutions-to-exercises.html#cb300-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(M <span class="sc">%*%</span> vec)</span>
<span id="cb300-9"><a href="solutions-to-exercises.html#cb300-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p></p>
<p>Second, we test it on some random dataset. We use the returns created at the end of Chapter <a href="notdata.html#notdata">1</a> and used for the Lasso allocation in Section <a href="lasso.html#sparseex">5.2.2</a>. For <span class="math inline">\(\boldsymbol{\mu}\)</span>, we use the sample average, which is rarely a good idea in practice. It serves as illustration only.</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="solutions-to-exercises.html#cb301-1" aria-hidden="true" tabindex="-1"></a>Sigma <span class="ot">&lt;-</span> returns <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>date) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>() <span class="sc">%&gt;%</span> <span class="fu">cov</span>()  <span class="co"># Covariance matrix</span></span>
<span id="cb301-2"><a href="solutions-to-exercises.html#cb301-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> returns <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>date) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">2</span>,mean)             <span class="co"># Vector of exp. returns</span></span>
<span id="cb301-3"><a href="solutions-to-exercises.html#cb301-3" aria-hidden="true" tabindex="-1"></a>Lambda <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="fu">nrow</span>(Sigma))                                          <span class="co"># Trans. Cost matrix</span></span>
<span id="cb301-4"><a href="solutions-to-exercises.html#cb301-4" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="dv">1</span>                                                          <span class="co"># Risk aversion</span></span>
<span id="cb301-5"><a href="solutions-to-exercises.html#cb301-5" aria-hidden="true" tabindex="-1"></a>k_D <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb301-6"><a href="solutions-to-exercises.html#cb301-6" aria-hidden="true" tabindex="-1"></a>k_R <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb301-7"><a href="solutions-to-exercises.html#cb301-7" aria-hidden="true" tabindex="-1"></a>w_old <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">nrow</span>(Sigma)) <span class="sc">/</span> <span class="fu">nrow</span>(Sigma)                           <span class="co"># Prev. weights: EW</span></span>
<span id="cb301-8"><a href="solutions-to-exercises.html#cb301-8" aria-hidden="true" tabindex="-1"></a><span class="fu">weights</span>(Sigma, mu, Lambda, lambda, k_D, k_R, w_old) <span class="sc">%&gt;%</span> <span class="fu">head</span>()       <span class="co"># First weights</span></span></code></pre></div>
<pre><code>##             [,1]
## 1   0.0031339308
## 3  -0.0003243527
## 4   0.0011944677
## 7   0.0014194215
## 9   0.0015086240
## 11 -0.0005015207</code></pre>
<p></p>
<p>Some weights can of course be negative. Finally, we use the map2() function to test some sensitivity. We examine 3 key indicators:<br />
- <strong>diversification</strong>, which we measure via the inverse of the sum of squared weights (inverse Hirschman-Herfindhal index);<br />
- <strong>leverage</strong>, which we assess via the absolute sum of negative weights;<br />
- <strong>in-sample volatility</strong>, which we compute as <span class="math inline">\(\textbf{w}&#39; \boldsymbol{\Sigma} \textbf{x}\)</span></p>
<p>To do so, we create a dedicated function below.</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="solutions-to-exercises.html#cb303-1" aria-hidden="true" tabindex="-1"></a>sensi <span class="ot">&lt;-</span> <span class="cf">function</span>(lambda, k_D, Sigma, mu, Lambda, k_R, w_old){</span>
<span id="cb303-2"><a href="solutions-to-exercises.html#cb303-2" aria-hidden="true" tabindex="-1"></a>    w <span class="ot">&lt;-</span> <span class="fu">weights</span>(Sigma, mu, Lambda, lambda, k_D, k_R, w_old)</span>
<span id="cb303-3"><a href="solutions-to-exercises.html#cb303-3" aria-hidden="true" tabindex="-1"></a>    out <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb303-4"><a href="solutions-to-exercises.html#cb303-4" aria-hidden="true" tabindex="-1"></a>    out<span class="sc">$</span>div <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">sum</span>(w<span class="sc">^</span><span class="dv">2</span>)             <span class="co"># Diversification</span></span>
<span id="cb303-5"><a href="solutions-to-exercises.html#cb303-5" aria-hidden="true" tabindex="-1"></a>    out<span class="sc">$</span>lev <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">abs</span>(w[w<span class="sc">&lt;</span><span class="dv">0</span>]))       <span class="co"># Leverage</span></span>
<span id="cb303-6"><a href="solutions-to-exercises.html#cb303-6" aria-hidden="true" tabindex="-1"></a>    out<span class="sc">$</span>vol <span class="ot">&lt;-</span> <span class="fu">t</span>(w) <span class="sc">%*%</span> Sigma <span class="sc">%*%</span> w   <span class="co"># In-sample vol</span></span>
<span id="cb303-7"><a href="solutions-to-exercises.html#cb303-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(out)</span>
<span id="cb303-8"><a href="solutions-to-exercises.html#cb303-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p></p>
<p>Instead of using the baseline <em>map2</em> function, we rely on a version thereof that concatenates results into a dataframe directly.</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="solutions-to-exercises.html#cb304-1" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span>(<span class="sc">-</span><span class="dv">3</span><span class="sc">:</span><span class="dv">2</span>)              <span class="co"># parameter values</span></span>
<span id="cb304-2"><a href="solutions-to-exercises.html#cb304-2" aria-hidden="true" tabindex="-1"></a>k_D <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span><span class="dv">10</span><span class="sc">^</span>(<span class="sc">-</span><span class="dv">3</span><span class="sc">:</span><span class="dv">2</span>)               <span class="co"># parameter values</span></span>
<span id="cb304-3"><a href="solutions-to-exercises.html#cb304-3" aria-hidden="true" tabindex="-1"></a>pars <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(lambda, k_D) <span class="co"># parameter grid</span></span>
<span id="cb304-4"><a href="solutions-to-exercises.html#cb304-4" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> pars<span class="sc">$</span>lambda</span>
<span id="cb304-5"><a href="solutions-to-exercises.html#cb304-5" aria-hidden="true" tabindex="-1"></a>k_D <span class="ot">&lt;-</span> pars<span class="sc">$</span>k_D</span>
<span id="cb304-6"><a href="solutions-to-exercises.html#cb304-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb304-7"><a href="solutions-to-exercises.html#cb304-7" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">map2_dfr</span>(lambda, k_D, sensi, </span>
<span id="cb304-8"><a href="solutions-to-exercises.html#cb304-8" aria-hidden="true" tabindex="-1"></a>                <span class="at">Sigma =</span> Sigma, <span class="at">mu =</span> mu, <span class="at">Lambda =</span> Lambda, <span class="at">k_R =</span> k_R, <span class="at">w_old =</span> w_old)</span>
<span id="cb304-9"><a href="solutions-to-exercises.html#cb304-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb304-10"><a href="solutions-to-exercises.html#cb304-10" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_cols</span>(<span class="at">lambda =</span> <span class="fu">as.factor</span>(lambda), <span class="at">k_D =</span> <span class="fu">as.factor</span>(k_D), res) <span class="sc">%&gt;%</span></span>
<span id="cb304-11"><a href="solutions-to-exercises.html#cb304-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gather</span>(<span class="at">key =</span> indicator, <span class="at">value =</span> value, <span class="sc">-</span>lambda, <span class="sc">-</span>k_D) <span class="sc">%&gt;%</span></span>
<span id="cb304-12"><a href="solutions-to-exercises.html#cb304-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> lambda, <span class="at">y =</span> value, <span class="at">fill =</span> k_D)) <span class="sc">+</span> <span class="fu">geom_col</span>(<span class="at">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="sc">+</span></span>
<span id="cb304-13"><a href="solutions-to-exercises.html#cb304-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_grid</span>(indicator <span class="sc">~</span>. , <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex131d"></span>
<img src="ML_factor_files/figure-html/ex131d-1.png" alt="Indicators related to portfolio weights." width="432" />
<p class="caption">
FIGURE 18.15: Indicators related to portfolio weights.
</p>
</div>
<p></p>
<p>In Figure <a href="solutions-to-exercises.html#fig:ex131d">18.15</a>, each panel displays an indicator. In the first panel, we see that diversification increases with <span class="math inline">\(k_D\)</span>: indeed, as this number increases, the portfolio converges to uniform (EW) values. The parameter <span class="math inline">\(\lambda\)</span> has a minor impact. The second panel naturally shows the inverse effect for leverage: as diversification increases with <span class="math inline">\(k_D\)</span>, leverage (i.e., total negative positions - shortsales) decreases. Finally, the last panel shows that in-sample volatility is however largely driven by the risk aversion parameter. As <span class="math inline">\(\lambda\)</span> increases, volatility logically decreases. For small values of <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(k_D\)</span> is negatively related to volatility but the pattern reverses for large values of <span class="math inline">\(\lambda\)</span>. This is because the equally weighted portfolio is less risky than very leveraged mean-variance policies, but more risky than the minimum-variance portfolio.</p>
</div>
<div id="functional-programming-in-the-backtest" class="section level3" number="18.8.3">
<h3><span class="header-section-number">18.8.3</span> Functional programming in the backtest</h3>
<p>
Often, programmers prefer to avoid loops. In order to avoid a loop in the backtest, we need to code what happens for one given date. This is encapsulated in the following function. For simplicity, we code it for only one strategy. Also, the function will assume the structure of the data is known, but the columns (features &amp; labels) could also be passed as arguments. We recycle the function <strong>weights_xgb</strong> from Chapter <a href="backtest.html#backtest">12</a>.</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="solutions-to-exercises.html#cb305-1" aria-hidden="true" tabindex="-1"></a>portf_map <span class="ot">&lt;-</span> <span class="cf">function</span>(t, data_ml, ticks, t_oos, m_offset, train_size, weight_func){</span>
<span id="cb305-2"><a href="solutions-to-exercises.html#cb305-2" aria-hidden="true" tabindex="-1"></a>    train_data <span class="ot">&lt;-</span> data_ml <span class="sc">%&gt;%</span> <span class="fu">filter</span>(date <span class="sc">&lt;</span> t_oos[t] <span class="sc">-</span> m_offset <span class="sc">*</span> <span class="dv">30</span>,   <span class="co"># Roll. window w. buffer</span></span>
<span id="cb305-3"><a href="solutions-to-exercises.html#cb305-3" aria-hidden="true" tabindex="-1"></a>                                     date <span class="sc">&gt;</span> t_oos[t] <span class="sc">-</span> m_offset <span class="sc">*</span> <span class="dv">30</span> <span class="sc">-</span> <span class="dv">365</span> <span class="sc">*</span> train_size)</span>
<span id="cb305-4"><a href="solutions-to-exercises.html#cb305-4" aria-hidden="true" tabindex="-1"></a>    test_data <span class="ot">&lt;-</span> data_ml <span class="sc">%&gt;%</span> <span class="fu">filter</span>(date <span class="sc">==</span> t_oos[t])                   <span class="co"># Test set  </span></span>
<span id="cb305-5"><a href="solutions-to-exercises.html#cb305-5" aria-hidden="true" tabindex="-1"></a>    realized_returns <span class="ot">&lt;-</span> test_data <span class="sc">%&gt;%</span>                                   <span class="co"># Computing returns via:</span></span>
<span id="cb305-6"><a href="solutions-to-exercises.html#cb305-6" aria-hidden="true" tabindex="-1"></a>        dplyr<span class="sc">::</span><span class="fu">select</span>(R1M_Usd)                                          <span class="co"># 1M holding period!</span></span>
<span id="cb305-7"><a href="solutions-to-exercises.html#cb305-7" aria-hidden="true" tabindex="-1"></a>    temp_weights <span class="ot">&lt;-</span> <span class="fu">weight_func</span>(train_data, test_data, features)        <span class="co"># Weights = &gt; recycled!</span></span>
<span id="cb305-8"><a href="solutions-to-exercises.html#cb305-8" aria-hidden="true" tabindex="-1"></a>    ind <span class="ot">&lt;-</span> <span class="fu">match</span>(temp_weights<span class="sc">$</span>names, ticks) <span class="sc">%&gt;%</span> <span class="fu">na.omit</span>()               <span class="co"># Index of test assets</span></span>
<span id="cb305-9"><a href="solutions-to-exercises.html#cb305-9" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">c</span>() </span>
<span id="cb305-10"><a href="solutions-to-exercises.html#cb305-10" aria-hidden="true" tabindex="-1"></a>    x<span class="sc">$</span>weights <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">length</span>(ticks))                           <span class="co"># Empty weights</span></span>
<span id="cb305-11"><a href="solutions-to-exercises.html#cb305-11" aria-hidden="true" tabindex="-1"></a>    x<span class="sc">$</span>weights[ind] <span class="ot">&lt;-</span> temp_weights<span class="sc">$</span>weights                       <span class="co"># Locate weights correctly</span></span>
<span id="cb305-12"><a href="solutions-to-exercises.html#cb305-12" aria-hidden="true" tabindex="-1"></a>    x<span class="sc">$</span>returns <span class="ot">&lt;-</span> <span class="fu">sum</span>(temp_weights<span class="sc">$</span>weights <span class="sc">*</span> realized_returns)    <span class="co"># Compute returns</span></span>
<span id="cb305-13"><a href="solutions-to-exercises.html#cb305-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(x)</span>
<span id="cb305-14"><a href="solutions-to-exercises.html#cb305-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p></p>
<p>Next, we combine this function to <strong>map</strong>(). We only test the first 6 dates: this reduces the computation times.</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="solutions-to-exercises.html#cb306-1" aria-hidden="true" tabindex="-1"></a>back_test <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span> <span class="sc">%&gt;%</span>             <span class="co"># Test on the first 100 out-of-sample dates</span></span>
<span id="cb306-2"><a href="solutions-to-exercises.html#cb306-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(portf_map, <span class="at">data_ml =</span> data_ml, <span class="at">ticks =</span> ticks, <span class="at">t_oos =</span> t_oos,</span>
<span id="cb306-3"><a href="solutions-to-exercises.html#cb306-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">m_offset =</span> <span class="dv">1</span>, <span class="at">train_size =</span> <span class="dv">5</span>, <span class="at">weight_func =</span> weights_xgb)</span></code></pre></div>
<pre><code>## [14:43:55] WARNING: amalgamation/../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.
## [14:44:04] WARNING: amalgamation/../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.
## [14:44:14] WARNING: amalgamation/../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.</code></pre>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="solutions-to-exercises.html#cb308-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(back_test[[<span class="dv">1</span>]]<span class="sc">$</span>weights)     <span class="co"># Sample weights</span></span></code></pre></div>
<pre><code>## [1] 0.001675042 0.000000000 0.000000000 0.001675042 0.000000000 0.001675042</code></pre>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="solutions-to-exercises.html#cb310-1" aria-hidden="true" tabindex="-1"></a>back_test[[<span class="dv">1</span>]]<span class="sc">$</span>returns           <span class="co"># Return of first period</span></span></code></pre></div>
<pre><code>## [1] 0.0189129</code></pre>
<p></p>
<p>Each element of backtest is a list with two components: the portfolio weights and the returns. To access the data easily, functions like <em>melt</em> from the package <em>reshape2</em> are useful.</p>
</div>
</div>
<div id="chapter-15" class="section level2" number="18.9">
<h2><span class="header-section-number">18.9</span> Chapter 15</h2>
<p>We recycle the AE model trained in Chapter <a href="unsup.html#unsup">15</a>. Strangely, building smaller models (encoder) from larger ones (AE) requires to save and then reload the weights. This creates an external file, which we call “ae_weights.” We can check that the output does have 4 columns (compressed) instead of 7 (original data).
</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="solutions-to-exercises.html#cb312-1" aria-hidden="true" tabindex="-1"></a><span class="fu">save_model_weights_hdf5</span>(<span class="at">object =</span> ae_model,<span class="at">filepath =</span><span class="st">&quot;ae_weights.hdf5&quot;</span>, <span class="at">overwrite =</span> <span class="cn">TRUE</span>)</span>
<span id="cb312-2"><a href="solutions-to-exercises.html#cb312-2" aria-hidden="true" tabindex="-1"></a>encoder_model <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(<span class="at">inputs =</span> input_layer, <span class="at">outputs =</span> encoder)</span>
<span id="cb312-3"><a href="solutions-to-exercises.html#cb312-3" aria-hidden="true" tabindex="-1"></a>encoder_model <span class="sc">%&gt;%</span> </span>
<span id="cb312-4"><a href="solutions-to-exercises.html#cb312-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">load_model_weights_hdf5</span>(<span class="at">filepath =</span> <span class="st">&quot;ae_weights.hdf5&quot;</span>,<span class="at">skip_mismatch =</span> <span class="cn">TRUE</span>,<span class="at">by_name =</span> <span class="cn">TRUE</span>)</span>
<span id="cb312-5"><a href="solutions-to-exercises.html#cb312-5" aria-hidden="true" tabindex="-1"></a>encoder_model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb312-6"><a href="solutions-to-exercises.html#cb312-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">&#39;mean_squared_error&#39;</span>,</span>
<span id="cb312-7"><a href="solutions-to-exercises.html#cb312-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">&#39;adam&#39;</span>,</span>
<span id="cb312-8"><a href="solutions-to-exercises.html#cb312-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">&#39;mean_absolute_error&#39;</span>)</span>
<span id="cb312-9"><a href="solutions-to-exercises.html#cb312-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb312-10"><a href="solutions-to-exercises.html#cb312-10" aria-hidden="true" tabindex="-1"></a>encoder_model <span class="sc">%&gt;%</span> </span>
<span id="cb312-11"><a href="solutions-to-exercises.html#cb312-11" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">predict_on_batch</span>(<span class="at">x =</span> training_sample <span class="sc">%&gt;%</span> </span>
<span id="cb312-12"><a href="solutions-to-exercises.html#cb312-12" aria-hidden="true" tabindex="-1"></a>                              dplyr<span class="sc">::</span><span class="fu">select</span>(features_short) <span class="sc">%&gt;%</span> </span>
<span id="cb312-13"><a href="solutions-to-exercises.html#cb312-13" aria-hidden="true" tabindex="-1"></a>                              <span class="fu">as.matrix</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb312-14"><a href="solutions-to-exercises.html#cb312-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">head</span>(<span class="dv">5</span>)</span></code></pre></div>
<pre><code>##           [,1]      [,2]      [,3]      [,4]
## [1,] -1.676068 0.2152901 0.1490787 0.8586778
## [2,] -1.684428 0.1919250 0.1985757 0.8494947
## [3,] -1.686019 0.1909507 0.1556696 0.8760668
## [4,] -1.689391 0.1893837 0.1492719 0.8799014
## [5,] -1.694696 0.1924362 0.1314638 0.8783331</code></pre>
<p></p>
<p></p>
</div>
<div id="chapter-16" class="section level2" number="18.10">
<h2><span class="header-section-number">18.10</span> Chapter 16</h2>
<p>All we need to do is change the rho coefficient in the code of Chapter <a href="RL.html#RL">16</a>. </p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="solutions-to-exercises.html#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)                                                 <span class="co"># Fixing the random seed</span></span>
<span id="cb314-2"><a href="solutions-to-exercises.html#cb314-2" aria-hidden="true" tabindex="-1"></a>n_sample <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">5</span>                                             <span class="co"># Number of samples generated</span></span>
<span id="cb314-3"><a href="solutions-to-exercises.html#cb314-3" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> (<span class="sc">-</span><span class="fl">0.8</span>)                                                <span class="co"># Autoregressive parameter</span></span>
<span id="cb314-4"><a href="solutions-to-exercises.html#cb314-4" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="fl">0.4</span>                                                    <span class="co"># Std. dev. of noise</span></span>
<span id="cb314-5"><a href="solutions-to-exercises.html#cb314-5" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fl">0.06</span> <span class="sc">*</span> rho                                              <span class="co"># Scaled mean of returns</span></span>
<span id="cb314-6"><a href="solutions-to-exercises.html#cb314-6" aria-hidden="true" tabindex="-1"></a>data_RL3 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">returns =</span> a<span class="sc">/</span>rho <span class="sc">+</span> <span class="fu">arima.sim</span>(<span class="at">n =</span> n_sample, <span class="co"># Returns via AR(1) simulation</span></span>
<span id="cb314-7"><a href="solutions-to-exercises.html#cb314-7" aria-hidden="true" tabindex="-1"></a>                                               <span class="fu">list</span>(<span class="at">ar =</span> rho),       </span>
<span id="cb314-8"><a href="solutions-to-exercises.html#cb314-8" aria-hidden="true" tabindex="-1"></a>                                               <span class="at">sd =</span> sd),</span>
<span id="cb314-9"><a href="solutions-to-exercises.html#cb314-9" aria-hidden="true" tabindex="-1"></a>                   <span class="at">action =</span> <span class="fu">round</span>(<span class="fu">runif</span>(n_sample)<span class="sc">*</span><span class="dv">4</span>)<span class="sc">/</span><span class="dv">4</span>) <span class="sc">%&gt;%</span>   <span class="co"># Random action (portfolio)</span></span>
<span id="cb314-10"><a href="solutions-to-exercises.html#cb314-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">new_state =</span> <span class="fu">if_else</span>(returns <span class="sc">&lt;</span> <span class="dv">0</span>, <span class="st">&quot;neg&quot;</span>, <span class="st">&quot;pos&quot;</span>),   <span class="co"># Coding of state</span></span>
<span id="cb314-11"><a href="solutions-to-exercises.html#cb314-11" aria-hidden="true" tabindex="-1"></a>           <span class="at">reward =</span> returns <span class="sc">*</span> action,                        <span class="co"># Reward = portfolio return</span></span>
<span id="cb314-12"><a href="solutions-to-exercises.html#cb314-12" aria-hidden="true" tabindex="-1"></a>           <span class="at">state =</span> <span class="fu">lag</span>(new_state),                           <span class="co"># Next state</span></span>
<span id="cb314-13"><a href="solutions-to-exercises.html#cb314-13" aria-hidden="true" tabindex="-1"></a>           <span class="at">action =</span> <span class="fu">as.character</span>(action)) <span class="sc">%&gt;%</span> </span>
<span id="cb314-14"><a href="solutions-to-exercises.html#cb314-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">na.omit</span>()                                                <span class="co"># Remove one missing state</span></span></code></pre></div>
<p></p>
<p>The learning can then proceed.</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="solutions-to-exercises.html#cb315-1" aria-hidden="true" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">alpha =</span> <span class="fl">0.1</span>,                        <span class="co"># Learning rate</span></span>
<span id="cb315-2"><a href="solutions-to-exercises.html#cb315-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">gamma =</span> <span class="fl">0.7</span>,                        <span class="co"># Discount factor for rewards</span></span>
<span id="cb315-3"><a href="solutions-to-exercises.html#cb315-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">epsilon =</span> <span class="fl">0.1</span>)                      <span class="co"># Exploration rate</span></span>
<span id="cb315-4"><a href="solutions-to-exercises.html#cb315-4" aria-hidden="true" tabindex="-1"></a>fit_RL3 <span class="ot">&lt;-</span> <span class="fu">ReinforcementLearning</span>(data_RL3,          <span class="co"># Main RL function</span></span>
<span id="cb315-5"><a href="solutions-to-exercises.html#cb315-5" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">s =</span> <span class="st">&quot;state&quot;</span>, </span>
<span id="cb315-6"><a href="solutions-to-exercises.html#cb315-6" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">a =</span> <span class="st">&quot;action&quot;</span>, </span>
<span id="cb315-7"><a href="solutions-to-exercises.html#cb315-7" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">r =</span> <span class="st">&quot;reward&quot;</span>, </span>
<span id="cb315-8"><a href="solutions-to-exercises.html#cb315-8" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">s_new =</span> <span class="st">&quot;new_state&quot;</span>, </span>
<span id="cb315-9"><a href="solutions-to-exercises.html#cb315-9" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">control =</span> control)</span>
<span id="cb315-10"><a href="solutions-to-exercises.html#cb315-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit_RL3)   <span class="co"># Show the output</span></span></code></pre></div>
<pre><code>## State-Action function Q
##          0.25         0         1      0.75       0.5
## neg 0.7107268 0.5971710 1.4662416 0.9535698 0.8069591
## pos 0.7730842 0.7869229 0.4734467 0.4258593 0.6257039
## 
## Policy
## neg pos 
## &quot;1&quot; &quot;0&quot; 
## 
## Reward (last iteration)
## [1] 3013.162</code></pre>
<p></p>
<p>In this case, the constantly switching feature of the return process changes the outcome. The negative state is associated with large profits when the portfolio is fully invested, while the positive state has the best average reward when the agent refrains from investing.</p>
<p>For the second exercise, the trick is to define all possible actions, that is all combinations (+1,0-1) for the two assets on all dates. We recycle the data from Chapter <a href="RL.html#RL">16</a>.</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="solutions-to-exercises.html#cb317-1" aria-hidden="true" tabindex="-1"></a>pos_3 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>)                              <span class="co"># Possible alloc. to asset 1</span></span>
<span id="cb317-2"><a href="solutions-to-exercises.html#cb317-2" aria-hidden="true" tabindex="-1"></a>pos_4 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>)                              <span class="co"># Possible alloc. to asset 3</span></span>
<span id="cb317-3"><a href="solutions-to-exercises.html#cb317-3" aria-hidden="true" tabindex="-1"></a>pos <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(pos_3, pos_4)                <span class="co"># All combinations</span></span>
<span id="cb317-4"><a href="solutions-to-exercises.html#cb317-4" aria-hidden="true" tabindex="-1"></a>pos <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(pos, <span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(pos))         <span class="co"># Adding combination id</span></span>
<span id="cb317-5"><a href="solutions-to-exercises.html#cb317-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb317-6"><a href="solutions-to-exercises.html#cb317-6" aria-hidden="true" tabindex="-1"></a>ret_pb_RL <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(<span class="at">r3 =</span> return_3, <span class="at">r4 =</span> return_4, <span class="co"># Returns &amp; P/B dataframe</span></span>
<span id="cb317-7"><a href="solutions-to-exercises.html#cb317-7" aria-hidden="true" tabindex="-1"></a>                       <span class="at">pb3 =</span> pb_3, <span class="at">pb4 =</span> pb_4) </span>
<span id="cb317-8"><a href="solutions-to-exercises.html#cb317-8" aria-hidden="true" tabindex="-1"></a>data_RL4 <span class="ot">&lt;-</span> <span class="fu">sapply</span>(ret_pb_RL,                        <span class="co"># Combining return &amp; positions</span></span>
<span id="cb317-9"><a href="solutions-to-exercises.html#cb317-9" aria-hidden="true" tabindex="-1"></a>                   rep.int, </span>
<span id="cb317-10"><a href="solutions-to-exercises.html#cb317-10" aria-hidden="true" tabindex="-1"></a>                   <span class="at">times =</span> <span class="fu">nrow</span>(pos)) <span class="sc">%&gt;%</span></span>
<span id="cb317-11"><a href="solutions-to-exercises.html#cb317-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb317-12"><a href="solutions-to-exercises.html#cb317-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(<span class="at">id =</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(pos), <span class="dv">1</span>, <span class="at">each =</span> <span class="fu">length</span>(return_3))) <span class="sc">%&gt;%</span></span>
<span id="cb317-13"><a href="solutions-to-exercises.html#cb317-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">left_join</span>(pos) <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>id) <span class="sc">%&gt;%</span></span>
<span id="cb317-14"><a href="solutions-to-exercises.html#cb317-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">action =</span> <span class="fu">paste</span>(pos_3, pos_4),            <span class="co"># Uniting actions</span></span>
<span id="cb317-15"><a href="solutions-to-exercises.html#cb317-15" aria-hidden="true" tabindex="-1"></a>           <span class="at">pb3 =</span> <span class="fu">round</span>(<span class="dv">5</span> <span class="sc">*</span> pb3),                    <span class="co"># Simplifying states</span></span>
<span id="cb317-16"><a href="solutions-to-exercises.html#cb317-16" aria-hidden="true" tabindex="-1"></a>           <span class="at">pb4 =</span> <span class="fu">round</span>(<span class="dv">5</span> <span class="sc">*</span> pb4),                    <span class="co"># Simplifying states</span></span>
<span id="cb317-17"><a href="solutions-to-exercises.html#cb317-17" aria-hidden="true" tabindex="-1"></a>           <span class="at">state =</span> <span class="fu">paste</span>(pb3, pb4),                 <span class="co"># Uniting states</span></span>
<span id="cb317-18"><a href="solutions-to-exercises.html#cb317-18" aria-hidden="true" tabindex="-1"></a>           <span class="at">reward =</span> pos_3<span class="sc">*</span>r3 <span class="sc">+</span> pos_4<span class="sc">*</span>r4,            <span class="co"># Computing rewards</span></span>
<span id="cb317-19"><a href="solutions-to-exercises.html#cb317-19" aria-hidden="true" tabindex="-1"></a>           <span class="at">new_state =</span> <span class="fu">lead</span>(state)) <span class="sc">%&gt;%</span>             <span class="co"># Infer new state</span></span>
<span id="cb317-20"><a href="solutions-to-exercises.html#cb317-20" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>pb3, <span class="sc">-</span>pb4, <span class="sc">-</span>pos_3,          <span class="co"># Remove superfluous vars.</span></span>
<span id="cb317-21"><a href="solutions-to-exercises.html#cb317-21" aria-hidden="true" tabindex="-1"></a>                  <span class="sc">-</span>pos_4, <span class="sc">-</span>r3, <span class="sc">-</span>r4) </span></code></pre></div>
<p></p>
<p>We can the plug this data into the RL function.</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="solutions-to-exercises.html#cb318-1" aria-hidden="true" tabindex="-1"></a>fit_RL4 <span class="ot">&lt;-</span> <span class="fu">ReinforcementLearning</span>(data_RL4,           <span class="co"># Main RL function</span></span>
<span id="cb318-2"><a href="solutions-to-exercises.html#cb318-2" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">s =</span> <span class="st">&quot;state&quot;</span>, </span>
<span id="cb318-3"><a href="solutions-to-exercises.html#cb318-3" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">a =</span> <span class="st">&quot;action&quot;</span>, </span>
<span id="cb318-4"><a href="solutions-to-exercises.html#cb318-4" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">r =</span> <span class="st">&quot;reward&quot;</span>, </span>
<span id="cb318-5"><a href="solutions-to-exercises.html#cb318-5" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">s_new =</span> <span class="st">&quot;new_state&quot;</span>, </span>
<span id="cb318-6"><a href="solutions-to-exercises.html#cb318-6" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">control =</span> control)</span>
<span id="cb318-7"><a href="solutions-to-exercises.html#cb318-7" aria-hidden="true" tabindex="-1"></a>fit_RL4<span class="sc">$</span>Q <span class="ot">&lt;-</span> <span class="fu">round</span>(fit_RL4<span class="sc">$</span>Q, <span class="dv">3</span>) <span class="co"># Round the Q-matrix</span></span>
<span id="cb318-8"><a href="solutions-to-exercises.html#cb318-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit_RL4)                   <span class="co"># Show the output </span></span></code></pre></div>
<pre><code>## State-Action function Q
##       0 0    0 1  0 -1  -1 -1   -1 0   -1 1   1 -1    1 0    1 1
## 0 2 0.000  0.000 0.002 -0.017 -0.018 -0.020  0.023  0.025  0.024
## 0 3 0.001 -0.005 0.007 -0.013 -0.019 -0.026  0.031  0.027  0.021
## 3 1 0.003  0.003 0.003  0.002  0.002  0.003  0.002  0.002  0.003
## 2 1 0.027  0.038 0.020  0.004  0.015  0.039  0.013  0.021  0.041
## 2 2 0.021  0.014 0.027  0.038  0.047  0.045 -0.004 -0.011 -0.016
## 2 3 0.007  0.006 0.008  0.054  0.057  0.056 -0.041 -0.041 -0.041
## 1 1 0.027  0.054 0.005 -0.031 -0.005  0.041  0.025  0.046  0.072
## 1 2 0.019  0.020 0.020  0.015  0.023  0.029  0.012  0.014  0.023
## 1 3 0.008  0.019 0.000 -0.036 -0.027 -0.016  0.042  0.053  0.060
## 
## Policy
##    0 2    0 3    3 1    2 1    2 2    2 3    1 1    1 2    1 3 
##  &quot;1 0&quot; &quot;1 -1&quot; &quot;0 -1&quot;  &quot;1 1&quot; &quot;-1 0&quot; &quot;-1 0&quot;  &quot;1 1&quot; &quot;-1 1&quot;  &quot;1 1&quot; 
## 
## Reward (last iteration)
## [1] 0</code></pre>
<p></p>
<p>The matrix is less sparse compared to the one of Chapter <a href="RL.html#RL">16</a>; we have covered much more ground! Some policy recommendations have not changed compared to the smaller sample, but some have! The change occurs for the states for which only a few points were available in the first trial. With more data, the decision is altered.</p>

<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-abbasi2012metafraud" class="csl-entry">
Abbasi, Ahmed, Conan Albrecht, Anthony Vance, and James Hansen. 2012. <span>“Metafraud: A Meta-Learning Framework for Detecting Financial Fraud.”</span> <em><span>MIS</span> Quarterly</em>, 1293–1327.
</div>
<div id="ref-aboussalah2020continuous" class="csl-entry">
Aboussalah, Amine Mohamed, and Chi-Guhn Lee. 2020. <span>“Continuous Control with Stacked Deep Dynamic Recurrent Reinforcement Learning for Portfolio Optimization.”</span> <em>Expert Systems with Applications</em> 140: 112891.
</div>
<div id="ref-adler2008cost" class="csl-entry">
Adler, Timothy, and Mark Kritzman. 2008. <span>“The Cost of Socially Responsible Investing.”</span> <em>Journal of Portfolio Management</em> 35 (1): 52–56.
</div>
<div id="ref-agarwal2006algorithms" class="csl-entry">
Agarwal, Amit, Elad Hazan, Satyen Kale, and Robert E Schapire. 2006. <span>“Algorithms for Portfolio Management Based on the Newton Method.”</span> In <em>Proceedings of the 23rd International Conference on Machine Learning</em>, 9–16. ACM.
</div>
<div id="ref-aggarwal2013outlier" class="csl-entry">
Aggarwal, Charu C. 2013. <em>Outlier Analysis</em>. Springer.
</div>
<div id="ref-aldridge2019neural" class="csl-entry">
Aldridge, Irene, and Marco Avellaneda. 2019. <span>“Neural Networks in Finance: Design and Performance.”</span> <em>Journal of Financial Data Science</em> 1 (4): 39–62.
</div>
<div id="ref-alessandrini2020optimal" class="csl-entry">
Alessandrini, Fabio, and Eric Jondeau. 2020. <span>“Optimal Strategies for <span>ESG</span> Portfolios.”</span> <em>SSRN Working Paper</em> 3578830.
</div>
<div id="ref-allison2001missing" class="csl-entry">
Allison, Paul D. 2001. <em>Missing Data</em>. Vol. 136. Sage publications.
</div>
<div id="ref-almahdi2017adaptive" class="csl-entry">
Almahdi, Saud, and Steve Y Yang. 2017. <span>“An Adaptive Portfolio Trading System: A Risk-Return Portfolio Optimization Using Recurrent Reinforcement Learning with Expected Maximum Drawdown.”</span> <em>Expert Systems with Applications</em> 87: 267–79.
</div>
<div id="ref-almahdi2019constrained" class="csl-entry">
———. 2019. <span>“A Constrained Portfolio Trading System Using Particle Swarm Algorithm and Recurrent Reinforcement Learning.”</span> <em>Expert Systems with Applications</em> 130: 145–56.
</div>
<div id="ref-alti2019dynamic" class="csl-entry">
Alti, Aydoğan, and Sheridan Titman. 2019. <span>“A Dynamic Model of Characteristic-Based Return Predictability.”</span> <em>Journal of Finance</em> 74 (6): 3187–3216.
</div>
<div id="ref-ammann2016characteristics" class="csl-entry">
Ammann, Manuel, Guillaume Coqueret, and Jan-Philip Schade. 2016. <span>“Characteristics-Based Portfolio Choice with Leverage Constraints.”</span> <em>Journal of Banking &amp; Finance</em> 70: 23–37.
</div>
<div id="ref-amrhein2019scientists" class="csl-entry">
Amrhein, Valentin, Sander Greenland, and Blake McShane. 2019. <span>“Scientists Rise up Against Statistical Significance.”</span> <em>Nature</em> 567: 305–7.
</div>
<div id="ref-anderson2000talking" class="csl-entry">
Anderson, James A, and Edward Rosenfeld. 2000. <em>Talking Nets: An Oral History of Neural Networks</em>. MIT Press.
</div>
<div id="ref-andersson2020deep" class="csl-entry">
Andersson, Kristoffer, and Cornelis Oosterlee. 2020. <span>“A Deep Learning Approach for Computations of Exposure Profiles for High-Dimensional Bermudan Options.”</span> <em>arXiv Preprint</em>, no. 2003.01977.
</div>
<div id="ref-andre2020dirichlet" class="csl-entry">
André, Eric, and Guillaume Coqueret. 2020. <span>“Dirichlet Policies for Reinforced Factor Portfolios.”</span> <em>SSRN Working Paper</em> 3726714.
</div>
<div id="ref-ang2014asset" class="csl-entry">
Ang, Andrew. 2014. <em>Asset Management: A Systematic Approach to Factor Investing</em>. Oxford University Press.
</div>
<div id="ref-ang2006cross" class="csl-entry">
Ang, Andrew, Robert J Hodrick, Yuhang Xing, and Xiaoyan Zhang. 2006. <span>“The Cross-Section of Volatility and Expected Returns.”</span> <em>Journal of Finance</em> 61 (1): 259–99.
</div>
<div id="ref-ang2012testing" class="csl-entry">
Ang, Andrew, and Dennis Kristensen. 2012. <span>“Testing Conditional Factor Models.”</span> <em>Journal of Financial Economics</em> 106 (1): 132–56.
</div>
<div id="ref-ang2018using" class="csl-entry">
Ang, Andrew, Jun Liu, and Krista Schwarz. 2018. <span>“Using Individual Stocks or Portfolios in Tests of Factor Models.”</span> <em>SSRN Working Paper</em> 1106463.
</div>
<div id="ref-arik2019tabnet" class="csl-entry">
Arik, Sercan O, and Tomas Pfister. 2020. <span>“TabNet: Attentive Interpretable Tabular Learning.”</span> <em>arXiv Preprint</em>, no. 1908.07442.
</div>
<div id="ref-arjovsky2019invariant" class="csl-entry">
Arjovsky, Martin, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. 2019. <span>“Invariant Risk Minimization.”</span> <em>arXiv Preprint</em>, no. 1907.02893.
</div>
<div id="ref-arnott2019factor" class="csl-entry">
Arnott, Robert D, Mark Clements, Vitali Kalesnik, and Juhani T Linnainmaa. 2020. <span>“Factor Momentum.”</span> <em>Journal of the American Statistical Association</em> 3116974.
</div>
<div id="ref-arnott2014can" class="csl-entry">
Arnott, Robert D, Jason C Hsu, Jun Liu, and Harry Markowitz. 2014. <span>“Can Noise Create the Size and Value Effects?”</span> <em>Management Science</em> 61 (11): 2569–79.
</div>
<div id="ref-arnott2019alice" class="csl-entry">
Arnott, Rob, Campbell R Harvey, Vitali Kalesnik, and Juhani Linnainmaa. 2019. <span>“Alice’s Adventures in Factorland: Three Blunders That Plague Factor Investing.”</span> <em>Journal of Portfolio Management</em> 45 (4): 18–36.
</div>
<div id="ref-arnott2019backtesting" class="csl-entry">
Arnott, Rob, Campbell R Harvey, and Harry Markowitz. 2019. <span>“A Backtesting Protocol in the Era of Machine Learning.”</span> <em>Journal of Financial Data Science</em> 1 (1): 64–74.
</div>
<div id="ref-aronow2020book" class="csl-entry">
Aronow, Peter M., and Fredrik Sävje. 2019. <span>“Book Review. <span>T</span>he Book of <span>W</span>hy: The New Science of Cause and Effect.”</span> <em>Journal of the American Statistical Association</em> 115 (529): 482–85.
</div>
<div id="ref-asness2020betting" class="csl-entry">
Asness, Cliff, Andrea Frazzini, Niels Joachim Gormsen, and Lasse Heje Pedersen. 2020. <span>“Betting Against Correlation: Testing Theories of the Low-Risk Effect.”</span> <em>Journal of Financial Economics</em> 135 (3): 629–52.
</div>
<div id="ref-asness2013value" class="csl-entry">
Asness, Clifford S, Tobias J Moskowitz, and Lasse Heje Pedersen. 2013. <span>“Value and Momentum Everywhere.”</span> <em>Journal of Finance</em> 68 (3): 929–85.
</div>
<div id="ref-asness2017contrarian" class="csl-entry">
Asness, Clifford, Swati Chandra, Antti Ilmanen, and Ronen Israel. 2017. <span>“Contrarian Factor Timing Is Deceptively Difficult.”</span> <em>Journal of Portfolio Management</em> 43 (5): 72–87.
</div>
<div id="ref-asness2013devil" class="csl-entry">
Asness, Clifford, and Andrea Frazzini. 2013. <span>“The Devil in HML’s Details.”</span> <em>Journal of Portfolio Management</em> 39 (4): 49–68.
</div>
<div id="ref-asness2018size" class="csl-entry">
Asness, Clifford, Andrea Frazzini, Ronen Israel, Tobias J Moskowitz, and Lasse H Pedersen. 2018. <span>“Size Matters, If You Control Your Junk.”</span> <em>Journal of Financial Economics</em> 129 (3): 479–509.
</div>
<div id="ref-asness2015investing" class="csl-entry">
Asness, Clifford, Antti Ilmanen, Ronen Israel, and Tobias Moskowitz. 2015. <span>“Investing with Style.”</span> <em>Journal of Investment Management</em> 13 (1): 27–63.
</div>
<div id="ref-astakhov2019firm" class="csl-entry">
Astakhov, Anton, Tomas Havranek, and Jiri Novak. 2019. <span>“Firm Size and Stock Returns: A Quantitative Survey.”</span> <em>Journal of Economic Surveys</em> 33 (5): 1463–92.
</div>
<div id="ref-atta2020strategies" class="csl-entry">
Atta-Darkua, Vaska, David Chambers, Elroy Dimson, Zhenkai Ran, and Ting Yu. 2020. <span>“Strategies for Responsible Investing: Emerging Academic Evidence.”</span> <em>Journal of Portfolio Management</em> 46 (3): 26–35.
</div>
<div id="ref-babiak2020deep" class="csl-entry">
Babiak, Mykola, and Jozef Barunik. 2020. <span>“Deep Learning, Predictability, and Optimal Portfolio Returns.”</span> <em>arXiv Preprint</em>, no. 2009.03394.
</div>
<div id="ref-bache2014magrittr" class="csl-entry">
Bache, Stefan Milton, and Hadley Wickham. 2014. <span>“Magrittr: A Forward-Pipe Operator for r.”</span> <em>R Package Version</em> 1 (1).
</div>
<div id="ref-back2010asset" class="csl-entry">
Back, Kerry. 2010. <em>Asset Pricing and Portfolio Choice Theory</em>. Oxford University Press.
</div>
<div id="ref-baesens2015fraud" class="csl-entry">
Baesens, Bart, Veronique Van Vlasselaer, and Wouter Verbeke. 2015. <em>Fraud Analytics Using Descriptive, Predictive, and Social Network Techniques: A Guide to Data Science for Fraud Detection</em>. John Wiley &amp; Sons.
</div>
<div id="ref-bai2002determining" class="csl-entry">
Bai, Jushan, and Serena Ng. 2002. <span>“Determining the Number of Factors in Approximate Factor Models.”</span> <em>Econometrica</em> 70 (1): 191–221.
</div>
<div id="ref-bailey2014deflated" class="csl-entry">
Bailey, David H, and Marcos López de Prado. 2014. <span>“The Deflated Sharpe Ratio: Correcting for Selection Bias, Backtest Overfitting, and Non-Normality.”</span> <em>Journal of Portfolio Management</em> 40 (5): 39–59.
</div>
<div id="ref-bailey1978note" class="csl-entry">
Bailey, T, and A. K. Jain. 1978. <span>“A Note on Distance-Weighted k-Nearest Neighbor Rules.”</span> <em>IEEE Trans. On Systems, Man, Cybernetics</em> 8 (4): 311–13.
</div>
<div id="ref-bajgrowicz2012technical" class="csl-entry">
Bajgrowicz, Pierre, and Olivier Scaillet. 2012. <span>“Technical Trading Revisited: <span>F</span>alse Discoveries, Persistence Tests, and Transaction Costs.”</span> <em>Journal of Financial Economics</em> 106 (3): 473–91.
</div>
<div id="ref-baker2011benchmarks" class="csl-entry">
Baker, Malcolm, Brendan Bradley, and Jeffrey Wurgler. 2011. <span>“Benchmarks as Limits to Arbitrage: Understanding the Low-Volatility Anomaly.”</span> <em>Financial Analysts Journal</em> 67 (1): 40–54.
</div>
<div id="ref-baker2019leverage" class="csl-entry">
Baker, Malcolm, Mathias F Hoeyer, and Jeffrey Wurgler. 2020. <span>“Leverage and the Beta Anomaly.”</span> <em>Journal of Financial and Quantitative Analysis</em> Forthcoming: 1–24.
</div>
<div id="ref-baker2017detecting" class="csl-entry">
Baker, Malcolm, Patrick Luo, and Ryan Taliaferro. 2017. <span>“Detecting Anomalies: The Relevance and Power of Standard Asset Pricing Tests.”</span>
</div>
<div id="ref-bali2016empirical" class="csl-entry">
Bali, Turan G, Robert F Engle, and Scott Murray. 2016. <em>Empirical Asset Pricing: The Cross Section of Stock Returns</em>. John Wiley &amp; Sons.
</div>
<div id="ref-ballings2015evaluating" class="csl-entry">
Ballings, Michel, Dirk Van den Poel, Nathalie Hespeels, and Ruben Gryp. 2015. <span>“Evaluating Multiple Classifiers for Stock Price Direction Prediction.”</span> <em>Expert Systems with Applications</em> 42 (20): 7046–56.
</div>
<div id="ref-ban2016machine" class="csl-entry">
Ban, Gah-Yi, Noureddine El Karoui, and Andrew EB Lim. 2016. <span>“Machine Learning and Portfolio Optimization.”</span> <em>Management Science</em> 64 (3): 1136–54.
</div>
<div id="ref-bansal1993new" class="csl-entry">
Bansal, Ravi, David A Hsieh, and S Viswanathan. 1993. <span>“A New Approach to International Arbitrage Pricing.”</span> <em>Journal of Finance</em> 48 (5): 1719–47.
</div>
<div id="ref-bansal1993no" class="csl-entry">
Bansal, Ravi, and Salim Viswanathan. 1993. <span>“No Arbitrage and Arbitrage Pricing: A New Approach.”</span> <em>Journal of Finance</em> 48 (4): 1231–62.
</div>
<div id="ref-banz1981relationship" class="csl-entry">
Banz, Rolf W. 1981. <span>“The Relationship Between Return and Market Value of Common Stocks.”</span> <em>Journal of Financial Economics</em> 9 (1): 3–18.
</div>
<div id="ref-barberis2018psychology" class="csl-entry">
Barberis, Nicholas. 2018. <span>“Psychology-Based Models of Asset Prices and Trading Volume.”</span> In <em>Handbook of Behavioral Economics-Foundations and Applications</em>.
</div>
<div id="ref-barberis2015x" class="csl-entry">
Barberis, Nicholas, Robin Greenwood, Lawrence Jin, and Andrei Shleifer. 2015. <span>“<span>X</span>-<span>CAPM</span>: An Extrapolative Capital Asset Pricing Model.”</span> <em>Journal of Financial Economics</em> 115 (1): 1–24.
</div>
<div id="ref-barberis2019prospect" class="csl-entry">
Barberis, Nicholas, Lawrence J Jin, and Baolian Wang. 2020. <span>“Prospect Theory and Stock Market Anomalies.”</span> <em>SSRN Working Paper</em> 3477463.
</div>
<div id="ref-barberis2016prospect" class="csl-entry">
Barberis, Nicholas, Abhiroop Mukherjee, and Baolian Wang. 2016. <span>“Prospect Theory and Stock Returns: An Empirical Test.”</span> <em>Review of Financial Studies</em> 29 (11): 3068–3107.
</div>
<div id="ref-barberis2003style" class="csl-entry">
Barberis, Nicholas, and Andrei Shleifer. 2003. <span>“Style Investing.”</span> <em>Journal of Financial Economics</em> 68 (2): 161–99.
</div>
<div id="ref-barillas2018comparing" class="csl-entry">
Barillas, Francisco, and Jay Shanken. 2018. <span>“Comparing Asset Pricing Models.”</span> <em>Journal of Finance</em> 73 (2): 715–54.
</div>
<div id="ref-barron1993universal" class="csl-entry">
Barron, Andrew R. 1993. <span>“Universal Approximation Bounds for Superpositions of a Sigmoidal Function.”</span> <em>IEEE Transactions on Information Theory</em> 39 (3): 930–45.
</div>
<div id="ref-barron1994approximation" class="csl-entry">
———. 1994. <span>“Approximation and Estimation Bounds for Artificial Neural Networks.”</span> <em>Machine Learning</em> 14 (1): 115–33.
</div>
<div id="ref-barroso2015momentum" class="csl-entry">
Barroso, Pedro, and Pedro Santa-Clara. 2015. <span>“Momentum Has Its Moments.”</span> <em>Journal of Financial Economics</em> 116 (1): 111–20.
</div>
<div id="ref-basak2004online" class="csl-entry">
Basak, Jayanta. 2004. <span>“Online Adaptive Decision Trees.”</span> <em>Neural Computation</em> 16 (9): 1959–81.
</div>
<div id="ref-bates1969combination" class="csl-entry">
Bates, John M, and Clive WJ Granger. 1969. <span>“The Combination of Forecasts.”</span> <em>Journal of the Operational Research Society</em> 20 (4): 451–68.
</div>
<div id="ref-bauder2020bayesian" class="csl-entry">
Bauder, David, Taras Bodnar, Nestor Parolya, and Wolfgang Schmid. 2020. <span>“Bayesian Inference of the Multi-Period Optimal Portfolio for an Exponential Utility.”</span> <em>Journal of Multivariate Analysis</em> 175: 104544.
</div>
<div id="ref-baz2015dissecting" class="csl-entry">
Baz, Jamil, Nicolas Granger, Campbell R Harvey, Nicolas Le Roux, and Sandy Rattray. 2015. <span>“Dissecting Investment Strategies in the Cross Section and Time Series.”</span> <em>SSRN Working Paper</em> 2695101.
</div>
<div id="ref-beery2018recognition" class="csl-entry">
Beery, Sara, Grant Van Horn, and Pietro Perona. 2018. <span>“Recognition in Terra Incognita.”</span> In <em>Proceedings of the European Conference on Computer Vision (ECCV)</em>, 456–73.
</div>
<div id="ref-belle2020principles" class="csl-entry">
Belle, Vaishak, and Ioannis Papantonis. 2020. <span>“Principles and Practice of Explainable Machine Learning.”</span> <em>arXiv Preprint</em>, no. 2009.11698.
</div>
<div id="ref-bellone2020equity" class="csl-entry">
Bellone, Benoit, Thomas Heckel, François Soupé, and Raul Leote de Carvalho. 2020. <span>“Equity Factor Investing: Historical Perspective of Recent Performance.”</span> <em>SSRN Working Paper</em> 3732113.
</div>
<div id="ref-belsley2005regression" class="csl-entry">
Belsley, David A, Edwin Kuh, and Roy E Welsch. 2005. <em>Regression Diagnostics: Identifying Influential Data and Sources of Collinearity</em>. Vol. 571. John Wiley &amp; Sons.
</div>
<div id="ref-ben2010theory" class="csl-entry">
Ben-David, Shai, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. 2010. <span>“A Theory of Learning from Different Domains.”</span> <em>Machine Learning</em> 79 (1-2): 151–75.
</div>
<div id="ref-bengio2012practical" class="csl-entry">
Bengio, Yoshua. 2012. <span>“Practical Recommendations for Gradient-Based Training of Deep Architectures.”</span> In <em>Neural Networks: Tricks of the Trade</em>, 437–78. Springer.
</div>
<div id="ref-berg2019aggregate" class="csl-entry">
Berg, Florian, Julian F Koelbel, and Roberto Rigobon. 2020. <span>“Aggregate Confusion: The Divergence of <span>ESG</span> Ratings.”</span> <em>SSRN Working Paper</em> 3438533.
</div>
<div id="ref-bergstra2012random" class="csl-entry">
Bergstra, James, and Yoshua Bengio. 2012. <span>“Random Search for Hyper-Parameter Optimization.”</span> <em>Journal of Machine Learning Research</em> 13 (Feb): 281–305.
</div>
<div id="ref-berk1999optimal" class="csl-entry">
Berk, Jonathan B, Richard C Green, and Vasant Naik. 1999. <span>“Optimal Investment, Growth Options, and Security Returns.”</span> <em>Journal of Finance</em> 54 (5): 1553–1607.
</div>
<div id="ref-bernstein2019disaster" class="csl-entry">
Bernstein, Asaf, Matthew T Gustafson, and Ryan Lewis. 2019. <span>“Disaster on the Horizon: The Price Effect of Sea Level Rise.”</span> <em>Journal of Financial Economics</em> 134 (2): 253–72.
</div>
<div id="ref-bertoluzzo2012testing" class="csl-entry">
Bertoluzzo, Francesco, and Marco Corazza. 2012. <span>“Testing Different Reinforcement Learning Configurations for Financial Trading: Introduction and Applications.”</span> <em>Procedia Economics and Finance</em> 3: 68–77.
</div>
<div id="ref-bertsekas2017dynamic" class="csl-entry">
Bertsekas, Dimitri P. 2017. <em>Dynamic Programming and Optimal Control - Volume II, Fourth Edition</em>. Athena Scientific.
</div>
<div id="ref-betermier2019supply" class="csl-entry">
Betermier, Sebastien, Laurent E Calvet, and Evan Jo. 2019. <span>“A Supply and Demand Approach to Equity Pricing.”</span> <em>SSRN Working Paper</em> 3440147.
</div>
<div id="ref-betermier2017value" class="csl-entry">
Betermier, Sebastien, Laurent E Calvet, and Paolo Sodini. 2017. <span>“Who Are the Value and Growth Investors?”</span> <em>Journal of Finance</em> 72 (1): 5–46.
</div>
<div id="ref-bhamra2019does" class="csl-entry">
Bhamra, Harjoat S, and Raman Uppal. 2019. <span>“Does Household Finance Matter? Small Financial Errors with Large Social Costs.”</span> <em>American Economic Review</em> 109 (3): 1116–54.
</div>
<div id="ref-bhatia2010survey" class="csl-entry">
Bhatia, Nitin, and others. 2010. <span>“Survey of Nearest Neighbor Techniques.”</span> <em>arXiv Preprint</em>, no. 1007.0085.
</div>
<div id="ref-bhattacharyya2011data" class="csl-entry">
Bhattacharyya, Siddhartha, Sanjeev Jha, Kurian Tharakunnel, and J Christopher Westland. 2011. <span>“Data Mining for Credit Card Fraud: A Comparative Study.”</span> <em>Decision Support Systems</em> 50 (3): 602–13.
</div>
<div id="ref-biau2012analysis" class="csl-entry">
Biau, Gérard. 2012. <span>“Analysis of a Random Forests Model.”</span> <em>Journal of Machine Learning Research</em> 13 (Apr): 1063–95.
</div>
<div id="ref-biau2008consistency" class="csl-entry">
Biau, Gérard, Luc Devroye, and GAbor Lugosi. 2008. <span>“Consistency of Random Forests and Other Averaging Classifiers.”</span> <em>Journal of Machine Learning Research</em> 9 (Sep): 2015–33.
</div>
<div id="ref-biecek2021explanatory" class="csl-entry">
Biecek, Przemyslaw, and Tomasz Burzykowski. 2021. <em>Explanatory Model Analysis: Explore, Explain, and Examine Predictive Models</em>. CRC Press.
</div>
<div id="ref-binz2020can" class="csl-entry">
Binz, Oliver, Katherine Schipper, and Kevin Standridge. 2020. <span>“What Can Analysts Learn from Artificial Intelligence about Fundamental Analysis?”</span> <em>SSRN Working Paper</em> 3745078.
</div>
<div id="ref-black1992global" class="csl-entry">
Black, Fischer, and Robert Litterman. 1992. <span>“Global Portfolio Optimization.”</span> <em>Financial Analysts Journal</em> 48 (5): 28–43.
</div>
<div id="ref-blank2019using" class="csl-entry">
Blank, Herbert, Richard Davis, and Shannon Greene. 2019. <span>“Using Alternative Research Data in Real-World Portfolios.”</span> <em>Journal of Investing</em> 28 (4): 95–103.
</div>
<div id="ref-blitz2020exclusion" class="csl-entry">
Blitz, David, and Laurens Swinkels. 2020. <span>“Is Exclusion Effective?”</span> <em>Journal of Portfolio Management</em> 46 (3): 42–48.
</div>
<div id="ref-blum1999universal" class="csl-entry">
Blum, Avrim, and Adam Kalai. 1999. <span>“Universal Portfolios with and Without Transaction Costs.”</span> <em>Machine Learning</em> 35 (3): 193–205.
</div>
<div id="ref-bodnar2013equivalence" class="csl-entry">
Bodnar, Taras, Nestor Parolya, and Wolfgang Schmid. 2013. <span>“On the Equivalence of Quadratic Optimization Problems Commonly Used in Portfolio Theory.”</span> <em>European Journal of Operational Research</em> 229 (3): 637–44.
</div>
<div id="ref-boehmke2019hands" class="csl-entry">
Boehmke, Brad, and Brandon Greenwell. 2019. <em>Hands-on Machine Learning with r</em>. Chapman &amp; Hall / CRC.
</div>
<div id="ref-boloorforoosh2019beta" class="csl-entry">
Boloorforoosh, Ali, Peter Christoffersen, Christian Gourieroux, and Mathieu Fournier. 2020. <span>“Beta Risk in the Cross-Section of Equities.”</span> <em>Review of Financial Studies</em> Forthcoming.
</div>
<div id="ref-bonaccolto2019developing" class="csl-entry">
Bonaccolto, Giovanni, and Sandra Paterlini. 2019. <span>“Developing New Portfolio Strategies by Aggregation.”</span> <em>Annals of Operations Research</em>, 1–39.
</div>
<div id="ref-boriah2008similarity" class="csl-entry">
Boriah, Shyam, Varun Chandola, and Vipin Kumar. 2008. <span>“Similarity Measures for Categorical Data: A Comparative Evaluation.”</span> In <em>Proceedings of the 2008 SIAM International Conference on Data Mining</em>, 243–54.
</div>
<div id="ref-boser1992training" class="csl-entry">
Boser, Bernhard E, Isabelle M Guyon, and Vladimir N Vapnik. 1992. <span>“A Training Algorithm for Optimal Margin Classifiers.”</span> In <em>Proceedings of the Fifth Annual Workshop on Computational Learning Theory</em>, 144–52. ACM.
</div>
<div id="ref-bouchaud2019sticky" class="csl-entry">
Bouchaud, Jean-philippe, Philipp Krueger, Augustin Landier, and David Thesmar. 2019. <span>“Sticky Expectations and the Profitability Anomaly.”</span> <em>Journal of Finance</em> 74 (2): 639–74.
</div>
<div id="ref-bouthillier2020survey" class="csl-entry">
Bouthillier, Xavier, and Gaël Varoquaux. 2020. <span>“Survey of Machine-Learning Experimental Methods at NeurIPS2019 and Iclr2020.”</span> Research Report. Inria Saclay Ile de France.
</div>
<div id="ref-boyd2004convex" class="csl-entry">
Boyd, Stephen, and Lieven Vandenberghe. 2004. <em>Convex Optimization</em>. Cambridge University Press.
</div>
<div id="ref-branch2012socially" class="csl-entry">
Branch, Ben, and Li Cai. 2012. <span>“Do Socially Responsible Index Investors Incur an Opportunity Cost?”</span> <em>Financial Review</em> 47 (3): 617–30.
</div>
<div id="ref-brandt2009parametric" class="csl-entry">
Brandt, Michael W, Pedro Santa-Clara, and Rossen Valkanov. 2009. <span>“Parametric Portfolio Policies: Exploiting Characteristics in the Cross-Section of Equity Returns.”</span> <em>Review of Financial Studies</em> 22 (9): 3411–47.
</div>
<div id="ref-braun1987predicting" class="csl-entry">
Braun, Helmut, and John S Chandler. 1987. <span>“Predicting Stock Market Behavior Through Rule Induction: An Application of the Learning-from-Example Approach.”</span> <em>Decision Sciences</em> 18 (3): 415–29.
</div>
<div id="ref-breiman1996stacked" class="csl-entry">
Breiman, Leo. 1996. <span>“Stacked Regressions.”</span> <em>Machine Learning</em> 24 (1): 49–64.
</div>
<div id="ref-breiman2001random" class="csl-entry">
———. 2001. <span>“Random Forests.”</span> <em>Machine Learning</em> 45 (1): 5–32.
</div>
<div id="ref-breiman1984classification" class="csl-entry">
Breiman, Leo, Jerome Friedman, Charles J. Stone, and R. A. Olshen. 1984. <em>Classification and Regression Trees</em>. Chapman &amp; Hall.
</div>
<div id="ref-breiman2004population" class="csl-entry">
Breiman, Leo, and others. 2004. <span>“Population Theory for Boosting Ensembles.”</span> <em>Annals of Statistics</em> 32 (1): 1–11.
</div>
<div id="ref-briere2021rains" class="csl-entry">
Briere, Marie, and Ariane Szafarz. 2021. <span>“When It Rains, It Pours: <span>M</span>ultifactor Asset Management in Good and Bad Times.”</span> <em>Journal of Financial Research</em> Forthcoming.
</div>
<div id="ref-brodersen2015inferring" class="csl-entry">
Brodersen, Kay H, Fabian Gallusser, Jim Koehler, Nicolas Remy, Steven L Scott, and others. 2015. <span>“Inferring Causal Impact Using Bayesian Structural Time-Series Models.”</span> <em>Annals of Applied Statistics</em> 9 (1): 247–74.
</div>
<div id="ref-brodie2009sparse" class="csl-entry">
Brodie, Joshua, Ingrid Daubechies, Christine De Mol, Domenico Giannone, and Ignace Loris. 2009. <span>“Sparse and Stable Markowitz Portfolios.”</span> <em>Proceedings of the National Academy of Sciences</em> 106 (30): 12267–72.
</div>
<div id="ref-brown2012experimental" class="csl-entry">
Brown, Iain, and Christophe Mues. 2012. <span>“An Experimental Comparison of Classification Algorithms for Imbalanced Credit Scoring Data Sets.”</span> <em>Expert Systems with Applications</em> 39 (3): 3446–53.
</div>
<div id="ref-bruder2019integration" class="csl-entry">
Bruder, Benjamin, Yazid Cheikh, Florent Deixonne, and Ban Zheng. 2019. <span>“Integration of <span>ESG</span> in Asset Allocation.”</span> <em>SSRN Working Paper</em> 3473874.
</div>
<div id="ref-bryzgalova2019spurious" class="csl-entry">
Bryzgalova, Svetlana. 2019. <span>“Spurious Factors in Linear Asset Pricing Models.”</span>
</div>
<div id="ref-bryzgalova2019bayesian" class="csl-entry">
Bryzgalova, Svetlana, Jiantao Huang, and Christian Julliard. 2019. <span>“Bayesian Solutions for the Factor Zoo: We Just Ran Two Quadrillion Models.”</span> <em>SSRN Working Paper</em> 3481736.
</div>
<div id="ref-bryzgalova2019forest" class="csl-entry">
Bryzgalova, Svetlana, Markus Pelger, and Jason Zhu. 2019. <span>“Forest Through the Trees: Building Cross-Sections of Stock Returns.”</span> <em>SSRN Working Paper</em> 3493458.
</div>
<div id="ref-buehler2019deep" class="csl-entry">
Buehler, Hans, Lukas Gonon, Josef Teichmann, and Ben Wood. 2019. <span>“Deep Hedging.”</span> <em>Quantitative Finance</em> 19 (8): 1271–91.
</div>
<div id="ref-buehler2020generating" class="csl-entry">
Buehler, Hans, Blanka Horvath, Terry Lyons, Imanol Perez Arribas, and Ben Wood. 2020. <span>“Generating Financial Markets with Signatures.”</span> <em>SSRN Working Paper</em> 3657366.
</div>
<div id="ref-burrell1997impact" class="csl-entry">
Burrell, Phillip R., and Bukola Otulayo Folarin. 1997. <span>“The Impact of Neural Networks in Finance.”</span> <em>Neural Computing &amp; Applications</em> 6 (4): 193–200.
</div>
<div id="ref-bustos2020stock" class="csl-entry">
Bustos, O, and A Pomares-Quimbaya. 2020. <span>“Stock Market Movement Forecast: A Systematic Review.”</span> <em>Expert Systems with Applications</em> Forthcoming.
</div>
<div id="ref-buhlmann2014cam" class="csl-entry">
Bühlmann, Peter, Jonas Peters, Jan Ernest, and others. 2014. <span>“CAM: Causal Additive Models, High-Dimensional Order Search and Penalized Regression.”</span> <em>Annals of Statistics</em> 42 (6): 2526–56.
</div>
<div id="ref-cakici2021size" class="csl-entry">
Cakici, Nusret, and Adam Zaremba. 2021. <span>“Size, Value, Profitability, and Investment Effects in International Stock Returns: <span>A</span>re They Really There?”</span> <em>Journal of Investing</em> Forthcoming.
</div>
<div id="ref-camilleri2020market" class="csl-entry">
Camilleri, Mark Anthony. 2020. <span>“The Market for Socially Responsible Investing: A Review of the Developments.”</span> <em>Social Responsibility Journal</em> Forthcoming.
</div>
<div id="ref-campbell2006efficient" class="csl-entry">
Campbell, John Y, and Motohiro Yogo. 2006. <span>“Efficient Tests of Stock Return Predictability.”</span> <em>Journal of Financial Economics</em> 81 (1): 27–60.
</div>
<div id="ref-cao2020fundamental" class="csl-entry">
Cao, Kai, and Haifeng You. 2020. <span>“Fundamental Analysis via Machine Learning.”</span> <em>SSRN Working Paper</em> 3706532.
</div>
<div id="ref-cao2003support" class="csl-entry">
Cao, Li-Juan, and Francis Eng Hock Tay. 2003. <span>“Support Vector Machine with Adaptive Parameters in Financial Time Series Forecasting.”</span> <em>IEEE Transactions on Neural Networks</em> 14 (6): 1506–18.
</div>
<div id="ref-carhart1997persistence" class="csl-entry">
Carhart, Mark M. 1997. <span>“On Persistence in Mutual Fund Performance.”</span> <em>Journal of Finance</em> 52 (1): 57–82.
</div>
<div id="ref-carlson2004corporate" class="csl-entry">
Carlson, Murray, Adlai Fisher, and Ron Giammarino. 2004. <span>“Corporate Investment and Asset Price Dynamics: Implications for the Cross-Section of Returns.”</span> <em>Journal of Finance</em> 59 (6): 2577–2603.
</div>
<div id="ref-castaneda2019microfounding" class="csl-entry">
Castaneda, Pablo, and Jorge Sabat. 2019. <span>“Microfounding the Fama-MacBeth Regression.”</span> <em>SSRN Working Paper</em> 3435141.
</div>
<div id="ref-cattaneo2019characteristic" class="csl-entry">
Cattaneo, Matias D, Richard K Crump, Max Farrell, and Ernst Schaumburg. 2020. <span>“Characteristic-Sorted Portfolios: Estimation and Inference”</span> Forthcoming: 1–47.
</div>
<div id="ref-cazalet2014facts" class="csl-entry">
Cazalet, Zélia, and Thierry Roncalli. 2014. <span>“Facts and Fantasies about Factor Investing.”</span> <em>SSRN Working Paper</em> 2524547.
</div>
<div id="ref-chakrabarti2020time" class="csl-entry">
Chakrabarti, Gagari, and Chitrakalpa Sen. 2020. <span>“Time Series Momentum Trading in Green Stocks.”</span> <em>Studies in Economics and Finance</em>.
</div>
<div id="ref-chandola2009anomaly" class="csl-entry">
Chandola, Varun, Arindam Banerjee, and Vipin Kumar. 2009. <span>“Anomaly Detection: A Survey.”</span> <em>ACM Computing Surveys (CSUR)</em> 41 (3): 15.
</div>
<div id="ref-chang2011libsvm" class="csl-entry">
Chang, Chih-Chung, and Chih-Jen Lin. 2011. <span>“<span>LIBSVM</span>: <span>A</span> Library for Support Vector Machines.”</span> <em>ACM Transactions on Intelligent Systems and Technology (TIST)</em> 2 (3): 27.
</div>
<div id="ref-chaouki2020deep" class="csl-entry">
Chaouki, Ayman, Stephen Hardiman, Christian Schmidt, Joachim de Lataillade, and others. 2020. <span>“Deep Deterministic Portfolio Optimization.”</span> <em>arXiv Preprint</em>, no. 2003.06497.
</div>
<div id="ref-charpentier2020reinforcement" class="csl-entry">
Charpentier, Arthur, Romuald Elie, and Carl Remlinger. 2020. <span>“Reinforcement Learning in Economics and Finance.”</span> <em>arXiv Preprint</em>, no. 2003.10014.
</div>
<div id="ref-che2018recurrent" class="csl-entry">
Che, Zhengping, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. 2018. <span>“Recurrent Neural Networks for Multivariate Time Series with Missing Values.”</span> <em>Scientific Reports</em> 8 (1): 6085.
</div>
<div id="ref-cheema2020decarbonization" class="csl-entry">
Cheema-Fox, Alexander, Bridget Realmuto LaPerla, George Serafeim, David Turkington, and Hui Stacie Wang. 2020. <span>“Decarbonization Factors.”</span> <em>SSRN Working Paper</em> 3448637.
</div>
<div id="ref-chen2019limits" class="csl-entry">
Chen, Andrew Y. 2019. <span>“The Limits of p-Hacking: A Thought Experiment.”</span> <em>SSRN Working Paper</em> 3272572.
</div>
<div id="ref-chen2020t" class="csl-entry">
———. 2020a. <span>“Do t-Stat Hurdles Need to Be Raised?”</span> <em>SSRN Working Paper</em> 3254995.
</div>
<div id="ref-chen2020limits" class="csl-entry">
———. 2020b. <span>“The Limits of p-Hacking: Some Thought Experiments.”</span> <em>Journal of Finance</em> Forthcoming.
</div>
<div id="ref-chen2020zeroing" class="csl-entry">
Chen, Andrew Y, and Mihail Velikov. 2020. <span>“Zeroing in on the Expected Returns of Anomalies.”</span> <em>SSRN Working Paper</em> 3073681.
</div>
<div id="ref-chen2020publication" class="csl-entry">
Chen, Andrew Y, and Tom Zimmermann. 2020. <span>“Publication Bias and the Cross-Section of Stock Returns.”</span> <em>Review of Asset Pricing Studies</em> Forthcoming.
</div>
<div id="ref-chen2001initialization" class="csl-entry">
Chen, Huifen. 2001. <span>“Initialization for <span>NORTA</span>: <span>G</span>eneration of Random Vectors with Specified Marginals and Correlations.”</span> <em>INFORMS Journal on Computing</em> 13 (4): 312–31.
</div>
<div id="ref-chen2018shapley" class="csl-entry">
Chen, Jianbo, Le Song, Martin J Wainwright, and Michael I Jordan. 2018. <span>“L-Shapley and c-Shapley: Efficient Model Interpretation for Structured Data.”</span> <em>arXiv Preprint</em>, no. 1808.02610.
</div>
<div id="ref-chen2016financial" class="csl-entry">
Chen, Jou-Fan, Wei-Lun Chen, Chun-Ping Huang, Szu-Hao Huang, and An-Pin Chen. 2016. <span>“Financial Time-Series Data Analysis Using Deep Convolutional Neural Networks.”</span> In <em>2016 7th International Conference on Cloud Computing and Big Data (CCBD)</em>, 87–92. IEEE.
</div>
<div id="ref-chen2012dividend" class="csl-entry">
Chen, Long, Zhi Da, and Richard Priestley. 2012. <span>“Dividend Smoothing and Predictability.”</span> <em>Management Science</em> 58 (10): 1834–53.
</div>
<div id="ref-chen2019deep" class="csl-entry">
Chen, Luyang, Markus Pelger, and Jason Zhu. 2020. <span>“Deep Learning in Asset Pricing.”</span> <em>SSRN Working Paper</em> 3350138.
</div>
<div id="ref-chen2016xgboost" class="csl-entry">
Chen, Tianqi, and Carlos Guestrin. 2016. <span>“Xgboost: A Scalable Tree Boosting System.”</span> In <em>Proceedings of the 22nd <span>ACM</span> <span>SIGKDD</span> <span>I</span>nternational Conference on Knowledge Discovery and Data Mining</em>, 785–94. ACM.
</div>
<div id="ref-chen2017feature" class="csl-entry">
Chen, Yingjun, and Yongtao Hao. 2017. <span>“A Feature Weighted Support Vector Machine and k-Nearest Neighbor Algorithm for Stock Market Indices Prediction.”</span> <em>Expert Systems with Applications</em> 80: 340–55.
</div>
<div id="ref-chiang2021modeling" class="csl-entry">
Chiang, I-Hsuan Ethan, Yin Liao, and Qing Zhou. 2021. <span>“Modeling the Cross-Section of Stock Returns Using Sensible Models in a Model Pool.”</span> <em>Journal of Empirical Finance</em> 60: 56–73.
</div>
<div id="ref-chib2021winners" class="csl-entry">
Chib, Siddhartha, Dashan Huang, Lingxiao Zhao, and Guofu Zhou. 2020. <span>“Winners from Winners: <span>A</span> Tale of Risk Factors.”</span> <em>SSRN Working Paper</em> 3478223.
</div>
<div id="ref-chib2020factors" class="csl-entry">
Chib, Siddhartha, and Xiaming Zeng. 2020. <span>“Which Factors Are Risk Factors in Asset Pricing? <span>A</span> Model Scan Framework.”</span> <em>Journal of Business &amp; Economic Statistics</em> 38 (4): 771–83.
</div>
<div id="ref-chib2019comparing" class="csl-entry">
Chib, Siddhartha, Xiaming Zeng, and Lingxiao Zhao. 2020. <span>“On Comparing Asset Pricing Models.”</span> <em>Journal of Finance</em> 75 (1): 551–77.
</div>
<div id="ref-chinco2019sparse" class="csl-entry">
Chinco, Alexander, Adam D Clark-Joseph, and Mao Ye. 2019. <span>“Sparse Signals in the Cross-Section of Returns.”</span> <em>Journal of Finance</em> 74 (1): 449–92.
</div>
<div id="ref-chinco2019estimating" class="csl-entry">
Chinco, Alexander, Andreas Neuhierl, and Michael Weber. 2020. <span>“Estimating the Anomaly Baserate.”</span> <em>Journal of Financial Economics</em> Forthcoming.
</div>
<div id="ref-chinco2019risk" class="csl-entry">
Chinco, Alex, Samuel M Hartzmark, and Abigail B Sussman. 2019. <span>“Necessary Evidence for a Risk Factor’s Relevance.”</span> <em>SSRN Working Paper</em> 3487624.
</div>
<div id="ref-chipman2010bart" class="csl-entry">
Chipman, Hugh A, Edward I George, and Robert E McCulloch. 2010. <span>“<span>BART</span>: <span>B</span>ayesian Additive Regression Trees.”</span> <em>Annals of Applied Statistics</em> 4 (1): 266–98.
</div>
<div id="ref-choi2014momentum" class="csl-entry">
Choi, Seung Mo, and Hwagyun Kim. 2014. <span>“Momentum Effect as Part of a Market Equilibrium.”</span> <em>Journal of Financial and Quantitative Analysis</em> 49 (1): 107–30.
</div>
<div id="ref-chollet2017deep" class="csl-entry">
Chollet, François. 2017. <em>Deep Learning with Python</em>. Manning Publications Company.
</div>
<div id="ref-chordia2020anomalies" class="csl-entry">
Chordia, Tarun, Amit Goyal, and Alessio Saretto. 2020. <span>“Anomalies and False Rejections.”</span> <em>Review of Financial Studies</em> 33 (5): 2134–79.
</div>
<div id="ref-chordia2015cross" class="csl-entry">
Chordia, Tarun, Amit Goyal, and Jay Shanken. 2019. <span>“Cross-Sectional Asset Pricing with Individual Stocks: Betas Versus Characteristics.”</span> <em>SSRN Working Paper</em> 2549578.
</div>
<div id="ref-chow2002multivariate" class="csl-entry">
Chow, Ying-Foon, John A Cotsomitis, and Andy CC Kwan. 2002. <span>“Multivariate Cointegration and Causality Tests of Wagner’s Hypothesis: Evidence from the <span>UK</span>.”</span> <em>Applied Economics</em> 34 (13): 1671–77.
</div>
<div id="ref-chung2015gated" class="csl-entry">
Chung, Junyoung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. 2015. <span>“Gated Feedback Recurrent Neural Networks.”</span> In <em>International Conference on Machine Learning</em>, 2067–75.
</div>
<div id="ref-claeskens2008model" class="csl-entry">
Claeskens, Gerda, and Nils Lid Hjort. 2008. <em>Model Selection and Model Averaging</em>. Cambridge University Press.
</div>
<div id="ref-clark2009improving" class="csl-entry">
Clark, Todd E, and Michael W McCracken. 2009. <span>“Improving Forecast Accuracy by Combining Recursive and Rolling Forecasts.”</span> <em>International Economic Review</em> 50 (2): 363–95.
</div>
<div id="ref-cocco2019evidence" class="csl-entry">
Cocco, Joao F, Francisco Gomes, and Paula Lopes. 2020. <span>“Evidence on Expectations of Household Finances.”</span> <em>SSRN Working Paper</em> 3362495.
</div>
<div id="ref-cochrane2009asset" class="csl-entry">
Cochrane, John H. 2009. <em>Asset Pricing: Revised Edition</em>. Princeton University Press.
</div>
<div id="ref-cochrane2011presidential" class="csl-entry">
———. 2011. <span>“Presidential Address: Discount Rates.”</span> <em>Journal of Finance</em> 66 (4): 1047–1108.
</div>
<div id="ref-cong2019analyzing" class="csl-entry">
Cong, Lin William, Tengyuan Liang, and Xiao Zhang. 2019a. <span>“Analyzing Textual Information at Scale.”</span> <em>SSRN Working Paper</em> 3449822.
</div>
<div id="ref-cong2019textual" class="csl-entry">
———. 2019b. <span>“Textual Factors: A Scalable, Interpretable, and Data-Driven Approach to Analyzing Unstructured Information.”</span> <em>SSRN Working Paper</em> 3307057.
</div>
<div id="ref-cong2019rise" class="csl-entry">
Cong, Lin William, and Douglas Xu. 2019. <span>“Rise of Factor Investing: Asset Prices, Informational Efficiency, and Security Design.”</span> <em>SSRN Working Paper</em> 2800590.
</div>
<div id="ref-connor1988risk" class="csl-entry">
Connor, Gregory, and Robert A Korajczyk. 1988. <span>“Risk and Return in an Equilibrium APT: Application of a New Test Methodology.”</span> <em>Journal of Financial Economics</em> 21 (2): 255–89.
</div>
<div id="ref-connor1993test" class="csl-entry">
———. 1993. <span>“A Test for the Number of Factors in an Approximate Factor Model.”</span> <em>The Journal of Finance</em> 48 (4): 1263–91.
</div>
<div id="ref-cont2007volatility" class="csl-entry">
Cont, Rama. 2007. <span>“Volatility Clustering in Financial Markets: Empirical Facts and Agent-Based Models.”</span> In <em>Long Memory in Economics</em>, 289–309. Springer.
</div>
<div id="ref-cooper2018new" class="csl-entry">
Cooper, Ilan, and Paulo F Maio. 2019. <span>“New Evidence on Conditional Factor Models.”</span> <em>Journal of Financial and Quantitative Analysis</em> 54 (5): 1975–2016.
</div>
<div id="ref-coqueret2015diversified" class="csl-entry">
Coqueret, Guillaume. 2015. <span>“Diversified Minimum-Variance Portfolios.”</span> <em>Annals of Finance</em> 11 (2): 221–41.
</div>
<div id="ref-coqueret2017approximate" class="csl-entry">
———. 2017. <span>“Approximate<span> NORTA</span> Simulations for Virtual Sample Generation.”</span> <em>Expert Systems with Applications</em> 73: 69–81.
</div>
<div id="ref-coqueret2018economic" class="csl-entry">
———. 2020. <span>“Stock Specific Sentiment and Return Predictability.”</span> <em>Quantitative Finance</em> Forthcoming.
</div>
<div id="ref-coqueret2019training" class="csl-entry">
Coqueret, Guillaume, and Tony Guida. 2020. <span>“Training Trees on Tails with Applications to Portfolio Choice.”</span> <em>Annals of Operations Research</em> 288: 181–221.
</div>
<div id="ref-cornell2020stock" class="csl-entry">
Cornell, Bradford. 2020. <span>“Stock Characteristics and Stock Returns: A Skeptic’s Look at the Cross Section of Expected Returns.”</span> <em>Journal of Portfolio Management</em>.
</div>
<div id="ref-cornell2021value" class="csl-entry">
Cornell, Bradford, and Aswath Damodaran. 2021. <span>“Value Investing: Requiem, Rebirth or Reincarnation?”</span> <em>SSRN Working Paper</em> 3779481.
</div>
<div id="ref-cornuejols2011apprentissage" class="csl-entry">
Cornuejols, Antoine, Laurent Miclet, and Vincent Barra. 2018. <em>Apprentissage Artificiel: Deep Learning, Concepts Et Algorithmes</em>. Eyrolles.
</div>
<div id="ref-cortes1995support" class="csl-entry">
Cortes, Corinna, and Vladimir Vapnik. 1995. <span>“Support-Vector Networks.”</span> <em>Machine Learning</em> 20 (3): 273–97.
</div>
<div id="ref-costarelli2016survey" class="csl-entry">
Costarelli, Danilo, Renato Spigler, and Gianluca Vinti. 2016. <span>“A Survey on Approximation by Means of Neural Network Operators.”</span> <em>Journal of NeuroTechnology</em> 1 (1).
</div>
<div id="ref-cover1991universal" class="csl-entry">
Cover, Thomas M. 1991. <span>“Universal Portfolios.”</span> <em>Mathematical Finance</em> 1 (1): 1–29.
</div>
<div id="ref-cover1996universal" class="csl-entry">
Cover, Thomas M, and Erik Ordentlich. 1996. <span>“Universal Portfolios with Side Information.”</span> <em>IEEE Transactions on Information Theory</em> 42 (2): 348–63.
</div>
<div id="ref-crammer2006online" class="csl-entry">
Crammer, Koby, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. <span>“Online Passive-Aggressive Algorithms.”</span> <em>Journal of Machine Learning Research</em> 7 (Mar): 551–85.
</div>
<div id="ref-cronqvist2015fetal" class="csl-entry">
Cronqvist, Henrik, Alessandro Previtero, Stephan Siegel, and Roderick E White. 2015. <span>“The Fetal Origins Hypothesis in Finance: Prenatal Environment, the Gender Gap, and Investor Behavior.”</span> <em>Review of Financial Studies</em> 29 (3): 739–86.
</div>
<div id="ref-cronqvist2015value" class="csl-entry">
Cronqvist, Henrik, Stephan Siegel, and Frank Yu. 2015. <span>“Value Versus Growth Investing: Why Do Different Investors Have Different Styles?”</span> <em>Journal of Financial Economics</em> 117 (2): 333–49.
</div>
<div id="ref-cuchiero2016new" class="csl-entry">
Cuchiero, Christa, Irene Klein, and Josef Teichmann. 2016. <span>“A New Perspective on the Fundamental Theorem of Asset Pricing for Large Financial Markets.”</span> <em>Theory of Probability &amp; Its Applications</em> 60 (4): 561–79.
</div>
<div id="ref-cybenko1989approximation" class="csl-entry">
Cybenko, George. 1989. <span>“Approximation by Superpositions of a Sigmoidal Function.”</span> <em>Mathematics of Control, Signals and Systems</em> 2 (4): 303–14.
</div>
<div id="ref-d2011identifying" class="csl-entry">
d’Aspremont, Alexandre. 2011. <span>“Identifying Small Mean-Reverting Portfolios.”</span> <em>Quantitative Finance</em> 11 (3): 351–64.
</div>
<div id="ref-dangl2012predictive" class="csl-entry">
Dangl, Thomas, and Michael Halling. 2012. <span>“Predictive Regressions with Time-Varying Coefficients.”</span> <em>Journal of Financial Economics</em> 106 (1): 157–81.
</div>
<div id="ref-dangl2020optimal" class="csl-entry">
Dangl, Thomas, and Alex Weissensteiner. 2020. <span>“Optimal Portfolios Under Time-Varying Investment Opportunities, Parameter Uncertainty, and Ambiguity Aversion.”</span> <em>Journal of Financial and Quantitative Analysis</em> 55 (4): 1163–98.
</div>
<div id="ref-daniel2001overconfidence" class="csl-entry">
Daniel, Kent D, David Hirshleifer, and Avanidhar Subrahmanyam. 2001. <span>“Overconfidence, Arbitrage, and Equilibrium Asset Pricing.”</span> <em>Journal of Finance</em> 56 (3): 921–65.
</div>
<div id="ref-daniel2019short" class="csl-entry">
Daniel, Kent, David Hirshleifer, and Lin Sun. 2020. <span>“Short and Long Horizon Behavioral Factors.”</span> <em>Review of Financial Studies</em> 33 (4): 1673–1736.
</div>
<div id="ref-daniel2016momentum" class="csl-entry">
Daniel, Kent, and Tobias J Moskowitz. 2016. <span>“Momentum Crashes.”</span> <em>Journal of Financial Economics</em> 122 (2): 221–47.
</div>
<div id="ref-daniel2020cross" class="csl-entry">
Daniel, Kent, Lira Mota, Simon Rottke, and Tano Santos. 2020. <span>“The Cross-Section of Risk and Return.”</span> <em>Review of Financial Studies</em> 33 (5): 1927–79.
</div>
<div id="ref-daniel1997evidence" class="csl-entry">
Daniel, Kent, and Sheridan Titman. 1997. <span>“Evidence on the Characteristics of Cross Sectional Variation in Stock Returns.”</span> <em>Journal of Finance</em> 52 (1): 1–33.
</div>
<div id="ref-daniel2012testing" class="csl-entry">
———. 2012. <span>“Testing Factor-Model Explanations of Market Anomalies.”</span> <em>Critical Finance Review</em> 1 (1): 103–39.
</div>
<div id="ref-daniel2001explaining" class="csl-entry">
Daniel, Kent, Sheridan Titman, and KC John Wei. 2001. <span>“Explaining the Cross-Section of Stock Returns in <span>J</span>apan: Factors or Characteristics?”</span> <em>Journal of Finance</em> 56 (2): 743–66.
</div>
<div id="ref-de2015comparing" class="csl-entry">
De Moor, Lieven, Geert Dhaene, and Piet Sercu. 2015. <span>“On Comparing Zero-Alpha Tests Across Multifactor Asset Pricing Models.”</span> <em>Journal of Banking &amp; Finance</em> 61: S235–40.
</div>
<div id="ref-de2020subsampled" class="csl-entry">
De Nard, Gianluca, Simon Hediger, and Markus Leippold. 2020. <span>“Subsampled Factor Models for Asset Pricing: The Rise of <span>V</span>asa.”</span> <em>SSRN Working Paper</em> 3557957.
</div>
<div id="ref-de2018advances" class="csl-entry">
De Prado, Marcos Lopez. 2018. <em>Advances in Financial Machine Learning</em>. John Wiley &amp; Sons.
</div>
<div id="ref-delbaen1994general" class="csl-entry">
Delbaen, Freddy, and Walter Schachermayer. 1994. <span>“A General Version of the Fundamental Theorem of Asset Pricing.”</span> <em>Mathematische Annalen</em> 300 (1): 463–520.
</div>
<div id="ref-demetrescu2020testing" class="csl-entry">
Demetrescu, Matei, Iliyan Georgiev, Paulo MM Rodrigues, and AM Taylor. 2020. <span>“Testing for Episodic Predictability in Stock Returns.”</span> <em>Journal of Econometrics</em> Forthcoming.
</div>
<div id="ref-demiguel2009generalized" class="csl-entry">
DeMiguel, Victor, Lorenzo Garlappi, Francisco J Nogales, and Raman Uppal. 2009. <span>“A Generalized Approach to Portfolio Optimization: Improving Performance by Constraining Portfolio Norms.”</span> <em>Management Science</em> 55 (5): 798–812.
</div>
<div id="ref-demiguel2007optimal" class="csl-entry">
DeMiguel, Victor, Lorenzo Garlappi, and Raman Uppal. 2009. <span>“Optimal Versus Naive Diversification: <span>H</span>ow Inefficient Is the 1/<span>N</span> Portfolio Strategy?”</span> <em>Review of Financial Studies</em> 22 (5): 1915–53.
</div>
<div id="ref-demiguel2019crowding" class="csl-entry">
DeMiguel, Victor, Alberto Martin Utrera, and Raman Uppal. 2019. <span>“What Alleviates Crowding in Factor Investing?”</span> <em>SSRN Working Paper</em> 3392875.
</div>
<div id="ref-martin2018transaction" class="csl-entry">
DeMiguel, Victor, Alberto Martin Utrera, Raman Uppal, and Francisco J Nogales. 2020. <span>“A Transaction-Cost Perspective on the Multitude of Firm Characteristics.”</span> <em>Review of Financial Studies</em> 33 (5): 2180–2222.
</div>
<div id="ref-demiguel2015parameter" class="csl-entry">
DeMiguel, Victor, Alberto Martı́n-Utrera, and Francisco J Nogales. 2015. <span>“Parameter Uncertainty in Multiperiod Portfolio Optimization with Transaction Costs.”</span> <em>Journal of Financial and Quantitative Analysis</em> 50 (6): 1443–71.
</div>
<div id="ref-denil2014narrowing" class="csl-entry">
Denil, Misha, David Matheson, and Nando De Freitas. 2014. <span>“Narrowing the Gap: Random Forests in Theory and in Practice.”</span> In <em>International Conference on Machine Learning</em>, 665–73.
</div>
<div id="ref-dichtl2019optimal" class="csl-entry">
Dichtl, Hubert, Wolfgang Drobetz, Harald Lohre, Carsten Rother, and Patrick Vosskamp. 2019. <span>“Optimal Timing and Tilting of Equity Factors.”</span> <em>Financial Analysts Journal</em> 75 (4): 84–102.
</div>
<div id="ref-dichtl2019data" class="csl-entry">
Dichtl, Hubert, Wolfgang Drobetz, Andreas Neuhierl, and Viktoria-Sophie Wendt. 2020. <span>“Data Snooping in Equity Premium Prediction.”</span> <em>Journal of Forecasting</em> Forthcoming.
</div>
<div id="ref-dichtl2020build" class="csl-entry">
Dichtl, Hubert, Wolfgang Drobetz, and Viktoria-Sophie Wendt. 2020. <span>“How to Build a Factor Portfolio: Does the Allocation Strategy Matter?”</span> <em>European Financial Management</em> Forthcoming.
</div>
<div id="ref-dingli2017financial" class="csl-entry">
Dingli, Alexiei, and Karl Sant Fournier. 2017. <span>“Financial Time Series Forecasting–a Deep Learning Approach.”</span> <em>International Journal of Machine Learning and Computing</em> 7 (5): 118–22.
</div>
<div id="ref-dixon2020industrial" class="csl-entry">
Dixon, Matthew F. 2020. <span>“Industrial Forecasting with Exponentially Smoothed Recurrent Neural Networks.”</span> <em>SSRN Working Paper</em>, no. 3572181.
</div>
<div id="ref-dixon2020machine" class="csl-entry">
Dixon, Matthew F., Igor Halperin, and Paul Bilokon. 2020. <em>Machine Learning in Finance: From Theory to Practice</em>. Springer.
</div>
<div id="ref-donaldson1996forecast" class="csl-entry">
Donaldson, R Glen, and Mark Kamstra. 1996. <span>“Forecast Combining with Neural Networks.”</span> <em>Journal of Forecasting</em> 15 (1): 49–61.
</div>
<div id="ref-drucker1997improving" class="csl-entry">
Drucker, Harris. 1997. <span>“Improving Regressors Using Boosting Techniques.”</span> In <em>International Conference on Machine Learning</em>, 97:107–15.
</div>
<div id="ref-drucker1997support" class="csl-entry">
Drucker, Harris, Christopher JC Burges, Linda Kaufman, Alex J Smola, and Vladimir Vapnik. 1997. <span>“Support Vector Regression Machines.”</span> In <em>Advances in Neural Information Processing Systems</em>, 155–61.
</div>
<div id="ref-du2020deep" class="csl-entry">
Du, Jiayi, Muyang Jin, Petter N Kolm, Gordon Ritter, Yixuan Wang, and Bofei Zhang. 2020. <span>“Deep Reinforcement Learning for Option Replication and Hedging.”</span> <em>Journal of Financial Data Science</em> Forthcoming.
</div>
<div id="ref-du2013neural" class="csl-entry">
Du, Ke-Lin, and Madisetti NS Swamy. 2013. <em>Neural Networks and Statistical Learning</em>. Springer Science &amp; Business Media.
</div>
<div id="ref-duchi2011adaptive" class="csl-entry">
Duchi, John, Elad Hazan, and Yoram Singer. 2011. <span>“Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.”</span> <em>Journal of Machine Learning Research</em> 12 (Jul): 2121–59.
</div>
<div id="ref-dunis2013hybrid" class="csl-entry">
Dunis, Christian L, Spiros D Likothanassis, Andreas S Karathanasopoulos, Georgios S Sermpinis, and Konstantinos A Theofilatos. 2013. <span>“A Hybrid Genetic Algorithm–Support Vector Machine Approach in the Task of Forecasting and Trading.”</span> <em>Journal of Asset Management</em> 14 (1): 52–71.
</div>
<div id="ref-eakins1998analyzing" class="csl-entry">
Eakins, Stanley G, Stanley R Stansell, and James F Buck. 1998. <span>“Analyzing the Nature of Institutional Demand for Common Stocks.”</span> <em>Quarterly Journal of Business and Economics</em>, 33–48.
</div>
<div id="ref-efimov2019using" class="csl-entry">
Efimov, Dmitry, and Di Xu. 2019. <span>“Using Generative Adversarial Networks to Synthesize Artificial Financial Datasets.”</span> <em>Proceedings of the Conference on Neural Information Processing Systems</em>.
</div>
<div id="ref-ehsani2019factor" class="csl-entry">
Ehsani, Sina, and Juhani T Linnainmaa. 2019. <span>“Factor Momentum and the Momentum Factor.”</span> <em>SSRN Working Paper</em> 3014521.
</div>
<div id="ref-elliott2019detecting" class="csl-entry">
Elliott, Graham, Nikolay Kudrin, and Kaspar Wuthrich. 2019. <span>“Detecting p-Hacking.”</span> <em>arXiv Preprint</em>, no. 1906.06711.
</div>
<div id="ref-elman1990finding" class="csl-entry">
Elman, Jeffrey L. 1990. <span>“Finding Structure in Time.”</span> <em>Cognitive Science</em> 14 (2): 179–211.
</div>
<div id="ref-enders2001primer" class="csl-entry">
Enders, Craig K. 2001. <span>“A Primer on Maximum Likelihood Algorithms Available for Use with Missing Data.”</span> <em>Structural Equation Modeling</em> 8 (1): 128–41.
</div>
<div id="ref-enders2010applied" class="csl-entry">
———. 2010. <em>Applied Missing Data Analysis</em>. Guilford Press.
</div>
<div id="ref-engelberg2018anomalies" class="csl-entry">
Engelberg, Joseph, R David McLean, and Jeffrey Pontiff. 2018. <span>“Anomalies and News.”</span> <em>Journal of Finance</em> 73 (5): 1971–2001.
</div>
<div id="ref-engilberge2019sodeep" class="csl-entry">
Engilberge, Martin, Louis Chevallier, Patrick Pérez, and Matthieu Cord. 2019. <span>“SoDeep: A Sorting Deep Net to Learn Ranking Loss Surrogates.”</span> In <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 10792–801.
</div>
<div id="ref-engle1982autoregressive" class="csl-entry">
Engle, Robert F. 1982. <span>“Autoregressive Conditional Heteroscedasticity with Estimates of the Variance of United Kingdom Inflation.”</span> <em>Econometrica</em>, 987–1007.
</div>
<div id="ref-enke2005use" class="csl-entry">
Enke, David, and Suraphan Thawornwong. 2005. <span>“The Use of Data Mining and Neural Networks for Forecasting Stock Market Returns.”</span> <em>Expert Systems with Applications</em> 29 (4): 927–40.
</div>
<div id="ref-fabozzi2020introduction" class="csl-entry">
Fabozzi, Frank J. 2020. <span>“Introduction: Special Issue on Ethical Investing.”</span> <em>Journal of Portfolio Management</em> 46 (3): 1–4.
</div>
<div id="ref-fabozzi2018being" class="csl-entry">
Fabozzi, Frank J, and Marcos López de Prado. 2018. <span>“Being Honest in Backtest Reporting: A Template for Disclosing Multiple Tests.”</span> <em>Journal of Portfolio Management</em> 45 (1): 141–47.
</div>
<div id="ref-falck2020factor" class="csl-entry">
Falck, Antoine, Adam Rej, and David Thesmar. 2020. <span>“Is Factor Momentum More Than Stock Momentum?”</span> <em>arXiv Preprint</em>, no. 2009.04824.
</div>
<div id="ref-fama1992cross" class="csl-entry">
Fama, Eugene F, and Kenneth R French. 1992. <span>“The Cross-Section of Expected Stock Returns.”</span> <em>Journal of Finance</em> 47 (2): 427–65.
</div>
<div id="ref-fama1993common" class="csl-entry">
———. 1993. <span>“Common Risk Factors in the Returns on Stocks and Bonds.”</span> <em>Journal of Financial Economics</em> 33 (1): 3–56.
</div>
<div id="ref-fama2015five" class="csl-entry">
———. 2015. <span>“A Five-Factor Asset Pricing Model.”</span> <em>Journal of Financial Economics</em> 116 (1): 1–22.
</div>
<div id="ref-fama2018choosing" class="csl-entry">
———. 2018. <span>“Choosing Factors.”</span> <em>Journal of Financial Economics</em> 128 (2): 234–52.
</div>
<div id="ref-fama1973risk" class="csl-entry">
Fama, Eugene F, and James D MacBeth. 1973. <span>“Risk, Return, and Equilibrium: Empirical Tests.”</span> <em>Journal of Political Economy</em> 81 (3): 607–36.
</div>
<div id="ref-farmer2019pockets" class="csl-entry">
Farmer, Leland, Lawrence Schmidt, and Allan Timmermann. 2019. <span>“Pockets of Predictability.”</span> <em>SSRN Working Paper</em> 3152386.
</div>
<div id="ref-fastrich2015constructing" class="csl-entry">
Fastrich, Björn, Sandra Paterlini, and Peter Winker. 2015. <span>“Constructing Optimal Sparse Portfolios Using Regularization Methods.”</span> <em>Computational Management Science</em> 12 (3): 417–34.
</div>
<div id="ref-feng2019taming" class="csl-entry">
Feng, Guanhao, Stefano Giglio, and Dacheng Xiu. 2020. <span>“Taming the Factor Zoo: A Test of New Factors.”</span> <em>Journal of Finance</em> 75 (3): 1327–70.
</div>
<div id="ref-feng2019deep" class="csl-entry">
Feng, Guanhao, Nicholas G Polson, and Jianeng Xu. 2019. <span>“Deep Learning in Characteristics-Sorted Factor Models.”</span> <em>SSRN Working Paper</em> 3243683.
</div>
<div id="ref-ferreira2020reinforced" class="csl-entry">
Ferreira, Tadeu A. 2020. <span>“Reinforced Deep Markov Models with Applications in Automatic Trading.”</span> <em>arXiv Preprint</em>, no. 2011.04391.
</div>
<div id="ref-fischer2018deep" class="csl-entry">
Fischer, Thomas, and Christopher Krauss. 2018. <span>“Deep Learning with Long Short-Term Memory Networks for Financial Market Predictions.”</span> <em>European Journal of Operational Research</em> 270 (2): 654–69.
</div>
<div id="ref-fisher2018all" class="csl-entry">
Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. 2019. <span>“All Models Are Wrong, but Many Are Useful: Learning a Variable’s Importance by Studying an Entire Class of Prediction Models Simultaneously.”</span> <em>Journal of Machine Learning Research</em> 20 (177): 1–81.
</div>
<div id="ref-fister2021two" class="csl-entry">
Fister, Dušan, Matjaž Perc, and Timotej Jagrič. 2021. <span>“Two Robust Long Short-Term Memory Frameworks for Trading Stocks.”</span> <em>Applied Intelligence</em>, 1–19.
</div>
<div id="ref-de2020esg" class="csl-entry">
Franco, Carmine de, Christophe Geissler, Vincent Margot, and Bruno Monnier. 2020. <span>“<span>ESG</span> Investments: Filtering Versus Machine Learning Approaches.”</span> <em>arXiv Preprint</em>, no. 2002.07477.
</div>
<div id="ref-frazier2018tutorial" class="csl-entry">
Frazier, Peter I. 2018. <span>“A Tutorial on <span>B</span>ayesian Optimization.”</span> <em>arXiv Preprint</em>, no. 1807.02811.
</div>
<div id="ref-frazzini2014betting" class="csl-entry">
Frazzini, Andrea, and Lasse Heje Pedersen. 2014. <span>“Betting Against Beta.”</span> <em>Journal of Financial Economics</em> 111 (1): 1–25.
</div>
<div id="ref-freeman1992nonlinear" class="csl-entry">
Freeman, Robert N, and Senyo Y Tse. 1992. <span>“A Nonlinear Model of Security Price Responses to Unexpected Earnings.”</span> <em>Journal of Accounting Research</em>, 185–209.
</div>
<div id="ref-freund1996experiments" class="csl-entry">
Freund, Yoav, and Robert E Schapire. 1996. <span>“Experiments with a New Boosting Algorithm.”</span> In <em>Machine Learning: Proceedings of the Thirteenth International Conference</em>, 96:148–56.
</div>
<div id="ref-freund1997decision" class="csl-entry">
———. 1997. <span>“A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting.”</span> <em>Journal of Computer and System Sciences</em> 55 (1): 119–39.
</div>
<div id="ref-freyberger2020dissecting" class="csl-entry">
Freyberger, Joachim, Andreas Neuhierl, and Michael Weber. 2020. <span>“Dissecting Characteristics Nonparametrically.”</span> <em>Review of Financial Studies</em> 33 (5): 2326–77.
</div>
<div id="ref-friede2015esg" class="csl-entry">
Friede, Gunnar, Timo Busch, and Alexander Bassen. 2015. <span>“<span>ESG</span> and Financial Performance: Aggregated Evidence from More Than 2000 Empirical Studies.”</span> <em>Journal of Sustainable Finance &amp; Investment</em> 5 (4): 210–33.
</div>
<div id="ref-friedman2001greedy" class="csl-entry">
Friedman, Jerome H. 2001. <span>“Greedy Function Approximation: A Gradient Boosting Machine.”</span> <em>Annals of Statistics</em>, 1189–1232.
</div>
<div id="ref-friedman2002stochastic" class="csl-entry">
———. 2002. <span>“Stochastic Gradient Boosting.”</span> <em>Computational Statistics &amp; Data Analysis</em> 38 (4): 367–78.
</div>
<div id="ref-friedman2008sparse" class="csl-entry">
Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2008. <span>“Sparse Inverse Covariance Estimation with the Graphical Lasso.”</span> <em>Biostatistics</em> 9 (3): 432–41.
</div>
<div id="ref-friedman2000additive" class="csl-entry">
Friedman, Jerome, Trevor Hastie, Robert Tibshirani, and others. 2000. <span>“Additive Logistic Regression: A Statistical View of Boosting (with Discussion and a Rejoinder by the Authors).”</span> <em>Annals of Statistics</em> 28 (2): 337–407.
</div>
<div id="ref-friedman1997bayesian" class="csl-entry">
Friedman, Nir, Dan Geiger, and Moises Goldszmidt. 1997. <span>“Bayesian Network Classifiers.”</span> <em>Machine Learning</em> 29 (2-3): 131–63.
</div>
<div id="ref-frost1986empirical" class="csl-entry">
Frost, Peter A, and James E Savarino. 1986. <span>“An Empirical Bayes Approach to Efficient Portfolio Selection.”</span> <em>Journal of Financial and Quantitative Analysis</em> 21 (3): 293–305.
</div>
<div id="ref-fu2018machine" class="csl-entry">
Fu, XingYu, JinHong Du, YiFeng Guo, MingWen Liu, Tao Dong, and XiuWen Duan. 2018. <span>“A Machine Learning Framework for Stock Selection.”</span> <em>arXiv Preprint</em>, no. 1806.01743.
</div>
<div id="ref-gaba2017combining" class="csl-entry">
Gaba, Anil, Ilia Tsetlin, and Robert L Winkler. 2017. <span>“Combining Interval Forecasts.”</span> <em>Decision Analysis</em> 14 (1): 1–20.
</div>
<div id="ref-gagliardini2016time" class="csl-entry">
Gagliardini, Patrick, Elisa Ossola, and Olivier Scaillet. 2016. <span>“Time-Varying Risk Premium in Large Cross-Sectional Equity Data Sets.”</span> <em>Econometrica</em> 84 (3): 985–1046.
</div>
<div id="ref-gagliardini2019estimation" class="csl-entry">
———. 2019. <span>“Estimation of Large Dimensional Conditional Factor Models in Finance.”</span> <em>SSRN Working Paper</em> 3443426.
</div>
<div id="ref-galema2008stocks" class="csl-entry">
Galema, Rients, Auke Plantinga, and Bert Scholtens. 2008. <span>“The Stocks at Stake: Return and Risk in Socially Responsible Investment.”</span> <em>Journal of Banking &amp; Finance</em> 32 (12): 2646–54.
</div>
<div id="ref-galili2016splitting" class="csl-entry">
Galili, Tal, and Isaac Meilijson. 2016. <span>“Splitting Matters: How Monotone Transformation of Predictor Variables May Improve the Predictions of Decision Tree Models.”</span> <em>arXiv Preprint</em>, no. 1611.04561.
</div>
<div id="ref-garcia2019continuous" class="csl-entry">
Garcı́a-Galicia, Mauricio, Alin A Carsteanu, and Julio B Clempner. 2019. <span>“Continuous-Time Reinforcement Learning Approach for Portfolio Management with Time Penalization.”</span> <em>Expert Systems with Applications</em> 129: 27–36.
</div>
<div id="ref-garcia2009k" class="csl-entry">
Garcı́a-Laencina, Pedro J, José-Luis Sancho-Gómez, Anı́bal R Figueiras-Vidal, and Michel Verleysen. 2009. <span>“K Nearest Neighbours with Mutual Information for Simultaneous Classification and Missing Data Imputation.”</span> <em>Neurocomputing</em> 72 (7-9): 1483–93.
</div>
<div id="ref-geertsema2020cross" class="csl-entry">
Geertsema, Paul, and Helen Lu. 2020. <span>“The Cross-Section of Long-Run Expected Stock Returns.”</span> <em>SSRN Working Paper</em> 3774548.
</div>
<div id="ref-gelman2013bayesian" class="csl-entry">
Gelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. <em>Bayesian Data Analysis, 3rd Edition</em>. Chapman &amp; Hall / CRC.
</div>
<div id="ref-geman1992neural" class="csl-entry">
Geman, Stuart, Elie Bienenstock, and René Doursat. 1992. <span>“Neural Networks and the Bias/Variance Dilemma.”</span> <em>Neural Computation</em> 4 (1): 1–58.
</div>
<div id="ref-genre2013combining" class="csl-entry">
Genre, Véronique, Geoff Kenny, Aidan Meyler, and Allan Timmermann. 2013. <span>“Combining Expert Forecasts: Can Anything Beat the Simple Average?”</span> <em>International Journal of Forecasting</em> 29 (1): 108–21.
</div>
<div id="ref-gentzkow2019text" class="csl-entry">
Gentzkow, Matthew, Bryan Kelly, and Matt Taddy. 2019. <span>“Text as Data.”</span> <em>Journal of Economic Literature</em> 57 (3): 535–74.
</div>
<div id="ref-ghosh2006optimum" class="csl-entry">
Ghosh, Anil K. 2006. <span>“On Optimum Choice of k in Nearest Neighbor Classification.”</span> <em>Computational Statistics &amp; Data Analysis</em> 50 (11): 3113–23.
</div>
<div id="ref-gibson2020responsible" class="csl-entry">
Gibson, Rajna, Simon Glossner, Philipp Krueger, Pedro Matos, and Tom Steffen. 2020. <span>“Responsible Institutional Investing Around the World.”</span> <em>SSRN Working Paper</em> 3525530.
</div>
<div id="ref-giglio2018asset" class="csl-entry">
Giglio, Stefano, and Dacheng Xiu. 2019. <span>“Asset Pricing with Omitted Factors.”</span> <em>SSRN Working Paper</em> 2865922.
</div>
<div id="ref-gomes2003equilibrium" class="csl-entry">
Gomes, Joao, Leonid Kogan, and Lu Zhang. 2003. <span>“Equilibrium Cross Section of Returns.”</span> <em>Journal of Political Economy</em> 111 (4): 693–732.
</div>
<div id="ref-gong2015momentum" class="csl-entry">
Gong, Qiang, Ming Liu, and Qianqiu Liu. 2015. <span>“Momentum Is Really Short-Term Momentum.”</span> <em>Journal of Banking &amp; Finance</em> 50: 169–82.
</div>
<div id="ref-gonzalo2018predictive" class="csl-entry">
Gonzalo, Jesús, and Jean-Yves Pitarakis. 2018. <span>“Predictive Regressions.”</span> In <em>Oxford Research Encyclopedia of Economics and Finance</em>.
</div>
<div id="ref-goodfellow2016deep" class="csl-entry">
Goodfellow, Ian, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. 2016. <em>Deep Learning</em>. MIT Press Cambridge.
</div>
<div id="ref-goodfellow2014generative" class="csl-entry">
Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. <span>“Generative Adversarial Nets.”</span> In <em>Advances in Neural Information Processing Systems</em>, 2672–80.
</div>
<div id="ref-gospodinov2019too" class="csl-entry">
Gospodinov, Nikolay, Raymond Kan, and Cesare Robotti. 2019. <span>“Too Good to Be True? <span>F</span>allacies in Evaluating Risk Factor Models.”</span> <em>Journal of Financial Economics</em> 132 (2): 451–71.
</div>
<div id="ref-gospodinov2020generalized" class="csl-entry">
Gospodinov, Nikolay, and Esfandiar Maasoumi. 2020. <span>“Generalized Aggregation of Misspecified Models: With an Application to Asset Pricing.”</span> <em>Journal of Econometrics</em> Forthcoming.
</div>
<div id="ref-goto2015improving" class="csl-entry">
Goto, Shingo, and Yan Xu. 2015. <span>“Improving Mean Variance Optimization Through Sparse Hedging Restrictions.”</span> <em>Journal of Financial and Quantitative Analysis</em> 50 (6): 1415–41.
</div>
<div id="ref-gougler2020factor" class="csl-entry">
Gougler, Arnaud, and Sebastian Utz. 2020. <span>“Factor Exposures and Diversification: Are Sustainably-Screened Portfolios Any Different?”</span> <em>Financial Markets and Portfolio Management</em> Forthcoming.
</div>
<div id="ref-gower1971general" class="csl-entry">
Gower, John C. 1971. <span>“A General Coefficient of Similarity and Some of Its Properties.”</span> <em>Biometrics</em>, 857–71.
</div>
<div id="ref-goyal2012empirical" class="csl-entry">
Goyal, Amit. 2012. <span>“Empirical Cross-Sectional Asset Pricing: A Survey.”</span> <em>Financial Markets and Portfolio Management</em> 26 (1): 3–38.
</div>
<div id="ref-goyal2015momentum" class="csl-entry">
Goyal, Amit, and Sunil Wahal. 2015. <span>“Is Momentum an Echo?”</span> <em>Journal of Financial and Quantitative Analysis</em> 50 (6): 1237–67.
</div>
<div id="ref-granger1969investigating" class="csl-entry">
Granger, Clive WJ. 1969. <span>“Investigating Causal Relations by Econometric Models and Cross-Spectral Methods.”</span> <em>Econometrica</em>, 424–38.
</div>
<div id="ref-green2013supraview" class="csl-entry">
Green, Jeremiah, John RM Hand, and X Frank Zhang. 2013. <span>“The Supraview of Return Predictive Signals.”</span> <em>Review of Accounting Studies</em> 18 (3): 692–730.
</div>
<div id="ref-green2017characteristics" class="csl-entry">
———. 2017. <span>“The Characteristics That Provide Independent Information about Average Us Monthly Stock Returns.”</span> <em>Review of Financial Studies</em> 30 (12): 4389–4436.
</div>
<div id="ref-greene2018econometric" class="csl-entry">
Greene, William H. 2018. <em>Econometric Analysis, Eighth Edition</em>. Pearson Education.
</div>
<div id="ref-greenwell2017pdp" class="csl-entry">
Greenwell, Brandon M. 2017. <span>“Pdp: An r Package for Constructing Partial Dependence Plots.”</span> <em>R Journal</em> 9 (1): 421–36.
</div>
<div id="ref-greenwell2020variable" class="csl-entry">
Greenwell, Brandon M, and Bradley C Boehmke. Forthcoming. <span>“Variable Importance Plots: <span>A</span>n Introduction to the Vip Package.”</span> <em>R Journal</em>.
</div>
<div id="ref-greenwood2012share" class="csl-entry">
Greenwood, Robin, and Samuel G Hanson. 2012. <span>“Share Issuance and Factor Timing.”</span> <em>Journal of Finance</em> 67 (2): 761–98.
</div>
<div id="ref-grinblatt2005prospect" class="csl-entry">
Grinblatt, Mark, and Bing Han. 2005. <span>“Prospect Theory, Mental Accounting, and Momentum.”</span> <em>Journal of Financial Economics</em> 78 (2): 311–39.
</div>
<div id="ref-grushka2016ensembles" class="csl-entry">
Grushka-Cockayne, Yael, Victor Richmond R Jose, and Kenneth C Lichtendahl Jr. 2016. <span>“Ensembles of Overfit and Overconfident Forecasts.”</span> <em>Management Science</em> 63 (4): 1110–30.
</div>
<div id="ref-gu2019autoencoder" class="csl-entry">
Gu, Shihao, Bryan T Kelly, and Dacheng Xiu. 2020a. <span>“Autoencoder Asset Pricing Models.”</span> <em>Journal of Econometrics</em> Forthcoming.
</div>
<div id="ref-gu2018empirical" class="csl-entry">
———. 2020b. <span>“Empirical Asset Pricing via Machine Learning.”</span> <em>Review of Financial Studies</em> 33 (5): 2223–73.
</div>
<div id="ref-guida2019big" class="csl-entry">
Guida, Tony, and Guillaume Coqueret. 2018a. <span>“Ensemble Learning Applied to Quant Equity: Gradient Boosting in a Multifactor Framework.”</span> In <em>Big Data and Machine Learning in Quantitative Investment</em>, 129–48. Wiley.
</div>
<div id="ref-guida2018machine" class="csl-entry">
———. 2018b. <span>“Machine Learning in Systematic Equity Allocation: A Model Comparison.”</span> <em>Wilmott</em> 2018 (98): 24–33.
</div>
<div id="ref-guidolin2016ambiguity" class="csl-entry">
Guidolin, Massimo, and Hening Liu. 2016. <span>“Ambiguity Aversion and Underdiversification.”</span> <em>Journal of Financial and Quantitative Analysis</em> 51 (4): 1297–1323.
</div>
<div id="ref-guliyev2018approximation" class="csl-entry">
Guliyev, Namig J, and Vugar E Ismailov. 2018. <span>“On the Approximation by Single Hidden Layer Feedforward Neural Networks with Fixed Weights.”</span> <em>Neural Networks</em> 98: 296–304.
</div>
<div id="ref-guo2020sparse" class="csl-entry">
Guo, Li. 2020. <span>“Sparse Signals in Market Anomalies.”</span> <em>SSRN Working Paper</em> 3683288.
</div>
<div id="ref-gupta2014outlier" class="csl-entry">
Gupta, Manish, Jing Gao, Charu Aggarwal, and Jiawei Han. 2014. <span>“Outlier Detection for Temporal Data.”</span> <em>IEEE Transactions on Knowledge and Data Engineering</em> 26 (9): 2250–67.
</div>
<div id="ref-gupta2019factor" class="csl-entry">
Gupta, Tarun, and Bryan Kelly. 2019. <span>“Factor Momentum Everywhere.”</span> <em>Journal of Portfolio Management</em> 45 (3): 13–36.
</div>
<div id="ref-guresen2011using" class="csl-entry">
Guresen, Erkam, Gulgun Kayakutlu, and Tugrul U Daim. 2011. <span>“Using Artificial Neural Network Models in Stock Market Index Prediction.”</span> <em>Expert Systems with Applications</em> 38 (8): 10389–97.
</div>
<div id="ref-guyon2003introduction" class="csl-entry">
Guyon, Isabelle, and André Elisseeff. 2003. <span>“An Introduction to Variable and Feature Selection.”</span> <em>Journal of Lachine Learning Research</em> 3 (Mar): 1157–82.
</div>
<div id="ref-haddad2020economics" class="csl-entry">
Haddad, Valentin, Serhiy Kozak, and Shrihari Santosh. 2020. <span>“Factor Timing.”</span> <em>Review of Financial Studies</em> 33 (5): 1980–2018.
</div>
<div id="ref-hahn2019bayesian" class="csl-entry">
Hahn, P Richard, Jared S Murray, and Carlos Carvalho. 2019. <span>“Bayesian Regression Tree Models for Causal Inference: Regularization, Confounding, and Heterogeneous Effects.”</span> <em>arXiv Preprint</em>, no. 1706.09523.
</div>
<div id="ref-hall2019introduction" class="csl-entry">
Hall, Patrick, and Navdeep Gill. 2019. <em>An Introduction to Machine Learning Interpretability - Second Edition</em>. O’Reilly.
</div>
<div id="ref-hall2008choice" class="csl-entry">
Hall, Peter, Byeong U Park, Richard J Samworth, and others. 2008. <span>“Choice of Neighbor Order in Nearest-Neighbor Classification.”</span> <em>Annals of Statistics</em> 36 (5): 2135–52.
</div>
<div id="ref-halperin2018market" class="csl-entry">
Halperin, Igor, and Ilya Feldshteyn. 2018. <span>“Market Self-Learning of Signals, Impact and Optimal Trading: Invisible Hand Inference with Free Energy.”</span> <em>arXiv Preprint</em>, no. 1805.06126.
</div>
<div id="ref-han2018firm" class="csl-entry">
Han, Yufeng, Ai He, D Rapach, and Guofu Zhou. 2019. <span>“Firm Characteristics and Expected Stock Returns.”</span> <em>SSRN Working Paper</em> 3185335.
</div>
<div id="ref-hanin2018start" class="csl-entry">
Hanin, Boris, and David Rolnick. 2018. <span>“How to Start Training: <span>T</span>he Effect of Initialization and Architecture.”</span> In <em>Advances in Neural Information Processing Systems</em>, 571–81.
</div>
<div id="ref-hansen1982large" class="csl-entry">
Hansen, Lars Peter. 1982. <span>“Large Sample Properties of Generalized Method of Moments Estimators.”</span> <em>Econometrica</em>, 1029–54.
</div>
<div id="ref-harrald1997evolving" class="csl-entry">
Harrald, Paul G, and Mark Kamstra. 1997. <span>“Evolving Artificial Neural Networks to Combine Financial Forecasts.”</span> <em>IEEE Transactions on Evolutionary Computation</em> 1 (1): 40–52.
</div>
<div id="ref-hartzmark2019dividend" class="csl-entry">
Hartzmark, Samuel M, and David H Solomon. 2019. <span>“The Dividend Disconnect.”</span> <em>Journal of Finance</em> 74 (5): 2153–99.
</div>
<div id="ref-harvey2017presidential" class="csl-entry">
Harvey, Campbell R. 2017. <span>“Presidential Address: The Scientific Outlook in Financial Economics.”</span> <em>Journal of Finance</em> 72 (4): 1399–1440.
</div>
<div id="ref-harvey2020replication" class="csl-entry">
———. 2020. <span>“Replication in Financial Economics.”</span> <em>Critical Finance Review</em>, 1–9.
</div>
<div id="ref-harvey2010portfolio" class="csl-entry">
Harvey, Campbell R, John C Liechty, Merrill W Liechty, and Peter Müller. 2010. <span>“Portfolio Selection with Higher Moments.”</span> <em>Quantitative Finance</em> 10 (5): 469–85.
</div>
<div id="ref-harvey2015backtesting" class="csl-entry">
Harvey, Campbell R, and Yan Liu. 2015. <span>“Backtesting.”</span> <em>Journal of Portfolio Management</em> 42 (1): 13–28.
</div>
<div id="ref-harvey2019census" class="csl-entry">
———. 2019. <span>“A Census of the Factor Zoo.”</span> <em>SSRN Working Paper</em> 3341728.
</div>
<div id="ref-harvey2019false" class="csl-entry">
———. 2020. <span>“False (and Missed) Discoveries in Financial Economics.”</span> <em>Journal of Finance</em> Forthcoming.
</div>
<div id="ref-harvey2019evaluation" class="csl-entry">
Harvey, Campbell R, Yan Liu, and Alessio Saretto. 2020. <span>“An Evaluation of Alternative Multiple Testing Methods for Finance Applications.”</span> <em>Review of Asset Pricing Studies</em> 10 (2): 199–248.
</div>
<div id="ref-harvey2016and" class="csl-entry">
Harvey, Campbell R, Yan Liu, and Heqing Zhu. 2016. <span>“… and the Cross-Section of Expected Returns.”</span> <em>Review of Financial Studies</em> 29 (1): 5–68.
</div>
<div id="ref-harvey2017lucky" class="csl-entry">
Harvey, Campbell, and Yan Liu. 2019. <span>“Lucky Factors.”</span> <em>SSRN Working Paper</em> 2528780.
</div>
<div id="ref-hasler2019should" class="csl-entry">
Hasler, Michael, Mariana Khapko, and Roberto Marfe. 2019. <span>“Should Investors Learn about the Timing of Equity Risk?”</span> <em>Journal of Financial Economics</em> 132 (3): 182–204.
</div>
<div id="ref-hassan2007fusion" class="csl-entry">
Hassan, Md Rafiul, Baikunth Nath, and Michael Kirley. 2007. <span>“A Fusion Model of HMM, ANN and GA for Stock Market Forecasting.”</span> <em>Expert Systems with Applications</em> 33 (1): 171–80.
</div>
<div id="ref-hastie2020ridge" class="csl-entry">
Hastie, Trevor. 2020. <span>“Ridge Regression: An Essential Concept in Data Science.”</span> <em>arXiv Preprint</em>, no. 2006.00371.
</div>
<div id="ref-friedman2009elements" class="csl-entry">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em>The Elements of Statistical Learning</em>. Springer.
</div>
<div id="ref-haugen1996commonality" class="csl-entry">
Haugen, Robert A, and Nardin L Baker. 1996. <span>“Commonality in the Determinants of Expected Stock Returns.”</span> <em>Journal of Financial Economics</em> 41 (3): 401–39.
</div>
<div id="ref-haykin2009neural" class="csl-entry">
Haykin, Simon S. 2009. <em>Neural Networks and Learning Machines</em>. Prentice Hall.
</div>
<div id="ref-hazan2007logarithmic" class="csl-entry">
Hazan, Elad, Amit Agarwal, and Satyen Kale. 2007. <span>“Logarithmic Regret Algorithms for Online Convex Optimization.”</span> <em>Machine Learning</em> 69 (2-3): 169–92.
</div>
<div id="ref-hazan2016introduction" class="csl-entry">
Hazan, Elad, and others. 2016. <span>“Introduction to Online Convex Optimization.”</span> <em>Foundations and Trends<span><span></span></span> in Optimization</em> 2 (3-4): 157–325.
</div>
<div id="ref-he2019factors" class="csl-entry">
He, Ai, Dashan Huang, and Guofu Zhou. 2020. <span>“New Factors Wanted: Evidence from a Simple Specification Test.”</span> <em>SSRN Working Paper</em> 3143752.
</div>
<div id="ref-head2015extent" class="csl-entry">
Head, Megan L, Luke Holman, Rob Lanfear, Andrew T Kahn, and Michael D Jennions. 2015. <span>“The Extent and Consequences of p-Hacking in Science.”</span> <em>PLoS Biology</em> 13 (3): e1002106.
</div>
<div id="ref-heinze2018invariant" class="csl-entry">
Heinze-Deml, Christina, Jonas Peters, and Nicolai Meinshausen. 2018. <span>“Invariant Causal Prediction for Nonlinear Models.”</span> <em>Journal of Causal Inference</em> 6 (2).
</div>
<div id="ref-henkel2011time" class="csl-entry">
Henkel, Sam James, J Spencer Martin, and Federico Nardari. 2011. <span>“Time-Varying Short-Horizon Predictability.”</span> <em>Journal of Financial Economics</em> 99 (3): 560–80.
</div>
<div id="ref-henrique2019literature" class="csl-entry">
Henrique, Bruno Miranda, Vinicius Amorim Sobreiro, and Herbert Kimura. 2019. <span>“Literature Review: Machine Learning Techniques Applied to Financial Market Prediction.”</span> <em>Expert Systems with Applications</em> 124: 226–51.
</div>
<div id="ref-hiemstra1994testing" class="csl-entry">
Hiemstra, Craig, and Jonathan D Jones. 1994. <span>“Testing for Linear and Nonlinear Granger Causality in the Stock Price-Volume Relation.”</span> <em>Journal of Finance</em> 49 (5): 1639–64.
</div>
<div id="ref-hill2007corporate" class="csl-entry">
Hill, Ronald Paul, Thomas Ainscough, Todd Shank, and Daryl Manullang. 2007. <span>“Corporate Social Responsibility and Socially Responsible Investing: A Global Perspective.”</span> <em>Journal of Business Ethics</em> 70 (2): 165–74.
</div>
<div id="ref-hjalmarsson2011new" class="csl-entry">
Hjalmarsson, Erik. 2011. <span>“New Methods for Inference in Long-Horizon Regressions.”</span> <em>Journal of Financial and Quantitative Analysis</em> 46 (3): 815–39.
</div>
<div id="ref-hjalmarsson2012characteristic" class="csl-entry">
Hjalmarsson, Erik, and Petar Manchev. 2012. <span>“Characteristic-Based Mean-Variance Portfolio Choice.”</span> <em>Journal of Banking &amp; Finance</em> 36 (5): 1392–1401.
</div>
<div id="ref-ho1995random" class="csl-entry">
Ho, Tin Kam. 1995. <span>“Random Decision Forests.”</span> In <em>Proceedings of 3rd International Conference on Document Analysis and Recognition</em>, 1:278–82. IEEE.
</div>
<div id="ref-ho2002simple" class="csl-entry">
Ho, Yu-Chi, and David L Pepyne. 2002. <span>“Simple Explanation of the No-Free-Lunch Theorem and Its Implications.”</span> <em>Journal of Optimization Theory and Applications</em> 115 (3): 549–70.
</div>
<div id="ref-hochreiter1997long" class="csl-entry">
Hochreiter, Sepp, and Jürgen Schmidhuber. 1997. <span>“Long Short-Term Memory.”</span> <em>Neural Computation</em> 9 (8): 1735–80.
</div>
<div id="ref-hodge2004survey" class="csl-entry">
Hodge, Victoria, and Jim Austin. 2004. <span>“A Survey of Outlier Detection Methodologies.”</span> <em>Artificial Intelligence Review</em> 22 (2): 85–126.
</div>
<div id="ref-hodges2017factor" class="csl-entry">
Hodges, Philip, Ked Hogan, Justin R Peterson, and Andrew Ang. 2017. <span>“Factor Timing with Cross-Sectional and Time-Series Predictors.”</span> <em>Journal of Portfolio Management</em> 44 (1): 30–43.
</div>
<div id="ref-hoechle2018correcting" class="csl-entry">
Hoechle, Daniel, Markus Schmid, and Heinz Zimmermann. 2018. <span>“Correcting Alpha Misattribution in Portfolio Sorts.”</span> <em>SSRN Working Paper</em> 3190310.
</div>
<div id="ref-hoi2018online" class="csl-entry">
Hoi, Steven CH, Doyen Sahoo, Jing Lu, and Peilin Zhao. 2018. <span>“Online Learning: A Comprehensive Survey.”</span> <em>arXiv Preprint</em>, no. 1802.02871.
</div>
<div id="ref-honaker2010missing" class="csl-entry">
Honaker, James, and Gary King. 2010. <span>“What to Do about Missing Values in Time-Series Cross-Section Data.”</span> <em>American Journal of Political Science</em> 54 (2): 561–81.
</div>
<div id="ref-hong2020climate" class="csl-entry">
Hong, Harrison, G Andrew Karolyi, and José A Scheinkman. 2020. <span>“Climate Finance.”</span> <em>Review of Financial Studies</em> 33 (3): 1011–23.
</div>
<div id="ref-hong2019climate" class="csl-entry">
Hong, Harrison, Frank Weikai Li, and Jiangmin Xu. 2019. <span>“Climate Risks and Market Efficiency.”</span> <em>Journal of Econometrics</em> 208 (1): 265–81.
</div>
<div id="ref-horel2019towards" class="csl-entry">
Horel, Enguerrand, and Kay Giesecke. 2019. <span>“Towards Explainable <span>AI</span>: <span>S</span>ignificance Tests for Neural Networks.”</span> <em>arXiv Preprint</em>, no. 1902.06021.
</div>
<div id="ref-horenstein2020unintended" class="csl-entry">
Horenstein, Alex R. 2020. <span>“The Unintended Impact of Academic Research on Asset Returns: <span>T</span>he Capital Asset Pricing Model Alpha.”</span> <em>Management Science</em>.
</div>
<div id="ref-hoseinzade2019cnnpred" class="csl-entry">
Hoseinzade, Ehsan, and Saman Haratizadeh. 2019. <span>“CNNpred: <span>CNN</span>-Based Stock Market Prediction Using a Diverse Set of Variables.”</span> <em>Expert Systems with Applications</em> 129: 273–85.
</div>
<div id="ref-hou2015digesting" class="csl-entry">
Hou, Kewei, Chen Xue, and Lu Zhang. 2015. <span>“Digesting Anomalies: An Investment Approach.”</span> <em>Review of Financial Studies</em> 28 (3): 650–705.
</div>
<div id="ref-hou2019replicating" class="csl-entry">
———. 2020. <span>“Replicating Anomalies.”</span> <em>Review of Financial Studies</em> 33 (5): 2019–2133.
</div>
<div id="ref-hsu2018asset" class="csl-entry">
Hsu, Po-Hsuan, Qiheng Han, Wensheng Wu, and Zhiguang Cao. 2018. <span>“Asset Allocation Strategies, Data Snooping, and the 1/n Rule.”</span> <em>Journal of Banking &amp; Finance</em> 97: 257–69.
</div>
<div id="ref-huang2020fundamental" class="csl-entry">
Huang, Dashan, Huacheng Zhang, Guofu Zhou, and Yingzi Zhu. 2020. <span>“Fundamental Extrapolation and Stock Returns.”</span> <em>SSRN Working Paper</em> 3678363.
</div>
<div id="ref-huang2020smart" class="csl-entry">
Huang, Shiyang, Yang Song, and Hong Xiang. 2020. <span>“The Smart Beta Mirage.”</span> <em>SSRN Working Paper</em> 3622753.
</div>
<div id="ref-huang2005forecasting" class="csl-entry">
Huang, Wei, Yoshiteru Nakamori, and Shou-Yang Wang. 2005. <span>“Forecasting Stock Market Movement Direction with Support Vector Machine.”</span> <em>Computers &amp; Operations Research</em> 32 (10): 2513–22.
</div>
<div id="ref-huck2019large" class="csl-entry">
Huck, Nicolas. 2019. <span>“Large Data Sets and Machine Learning: <span>A</span>pplications to Statistical Arbitrage.”</span> <em>European Journal of Operational Research</em> 278 (1): 330–42.
</div>
<div id="ref-hubner2005generalized" class="csl-entry">
Hübner, Georges. 2005. <span>“The Generalized Treynor Ratio.”</span> <em>Review of Finance</em> 9 (3): 415–35.
</div>
<div id="ref-hunermund2019causal" class="csl-entry">
Hünermund, Paul, and Elias Bareinboim. 2019. <span>“Causal Inference and Data-Fusion in Econometrics.”</span> <em>arXiv Preprint</em>, no. 1912.09104.
</div>
<div id="ref-ilmanen2011expected" class="csl-entry">
Ilmanen, Antti. 2011. <em>Expected Returns: An Investor’s Guide to Harvesting Market Rewards</em>. John Wiley &amp; Sons.
</div>
<div id="ref-ilmanen2019factor" class="csl-entry">
Ilmanen, Antti, Ronen Israel, Tobias J Moskowitz, Ashwin K Thapar, and Franklin Wang. 2019. <span>“Factor Premia and Factor Timing: A Century of Evidence.”</span> <em>SSRN Working Paper</em> 3400998.
</div>
<div id="ref-jacobs2019anomalies" class="csl-entry">
Jacobs, Heiko, and Sebastian Müller. 2020. <span>“Anomalies Across the Globe: Once Public, No Longer Existent?”</span> <em>Journal of Financial Economics</em> 135 (1): 213–30.
</div>
<div id="ref-jacobs1991adaptive" class="csl-entry">
Jacobs, Robert A, Michael I Jordan, Steven J Nowlan, Geoffrey E Hinton, and others. 1991. <span>“Adaptive Mixtures of Local Experts.”</span> <em>Neural Computation</em> 3 (1): 79–87.
</div>
<div id="ref-jagannathan2003risk" class="csl-entry">
Jagannathan, Ravi, and Tongshu Ma. 2003. <span>“Risk Reduction in Large Portfolios: Why Imposing the Wrong Constraints Helps.”</span> <em>Journal of Finance</em> 58 (4): 1651–83.
</div>
<div id="ref-jagannathan1998asymptotic" class="csl-entry">
Jagannathan, Ravi, and Zhenyu Wang. 1998. <span>“An Asymptotic Theory for Estimating Beta-Pricing Models Using Cross-Sectional Regression.”</span> <em>Journal of Finance</em> 53 (4): 1285–1309.
</div>
<div id="ref-james2013introduction" class="csl-entry">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 112. Springer.
</div>
<div id="ref-jegadeesh2019empirical" class="csl-entry">
Jegadeesh, Narasimhan, Joonki Noh, Kuntara Pukthuanthong, Richard Roll, and Junbo L Wang. 2019. <span>“Empirical Tests of Asset Pricing Models with Individual Assets: Resolving the Errors-in-Variables Bias in Risk Premium Estimation.”</span> <em>Journal of Financial Economics</em> 133 (2): 273–98.
</div>
<div id="ref-jegadeesh1993returns" class="csl-entry">
Jegadeesh, Narasimhan, and Sheridan Titman. 1993. <span>“Returns to Buying Winners and Selling Losers: Implications for Stock Market Efficiency.”</span> <em>Journal of Finance</em> 48 (1): 65–91.
</div>
<div id="ref-jensen1968performance" class="csl-entry">
Jensen, Michael C. 1968. <span>“The Performance of Mutual Funds in the Period 1945–1964.”</span> <em>Journal of Finance</em> 23 (2): 389–416.
</div>
<div id="ref-jha2019implementing" class="csl-entry">
Jha, Vinesh. 2019. <span>“Implementing Alternative Data in an Investment Process.”</span> In <em>Big Data and Machine Learning in Quantitative Investment</em>, 51–74. Wiley.
</div>
<div id="ref-jiang2020re" class="csl-entry">
Jiang, Jingwen, Bryan Kelly, and Dacheng Xiu. 2020. <span>“(Re-)Imag(in)ing Price Trends.”</span> <em>SSRN Working Paper</em> 3756587.
</div>
<div id="ref-jiang2020applications" class="csl-entry">
Jiang, Weiwei. 2020. <span>“Applications of Deep Learning in Stock Market Prediction: Recent Progress.”</span> <em>arXiv Preprint</em>, no. 2003.01859.
</div>
<div id="ref-jiang2017deep" class="csl-entry">
Jiang, Zhengyao, Dixing Xu, and Jinjun Liang. 2017. <span>“A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem.”</span> <em>arXiv Preprint</em>, no. 1706.10059.
</div>
<div id="ref-jin2019drivers" class="csl-entry">
Jin, Dunhong. 2019. <span>“The Drivers and Inhibitors of Factor Investing.”</span> <em>SSRN Working Paper</em>, no. 3492142.
</div>
<div id="ref-johannesson2020explanatory" class="csl-entry">
Johannesson, Erik, James A Ohlson, and Weihuan Zhai. 2020. <span>“The Explanatory Power of Explanatory Variables.”</span> <em>SSRN Working Paper</em> 3622743.
</div>
<div id="ref-johnson2002rational" class="csl-entry">
Johnson, Timothy C. 2002. <span>“Rational Momentum Effects.”</span> <em>Journal of Finance</em> 57 (2): 585–608.
</div>
<div id="ref-johnson2019fresh" class="csl-entry">
Johnson, Travis L. 2019. <span>“A Fresh Look at Return Predictability Using a More Efficient Estimator.”</span> <em>Review of Asset Pricing Studies</em> 9 (1): 1–46.
</div>
<div id="ref-jordan1997serial" class="csl-entry">
Jordan, Michael I. 1997. <span>“Serial Order: A Parallel Distributed Processing Approach.”</span> In <em>Advances in Psychology</em>, 121:471–95.
</div>
<div id="ref-jorion1985international" class="csl-entry">
Jorion, Philippe. 1985. <span>“International Portfolio Diversification with Estimation Risk.”</span> <em>Journal of Business</em>, 259–78.
</div>
<div id="ref-jurczenko2017factor" class="csl-entry">
Jurczenko, Emmanuel. 2017. <em>Factor Investing: From Traditional to Alternative Risk Premia</em>. Elsevier.
</div>
<div id="ref-kalisch2012causal" class="csl-entry">
Kalisch, Markus, Martin Mächler, Diego Colombo, Marloes H Maathuis, Peter Bühlmann, and others. 2012. <span>“Causal Inference Using Graphical Models with the r Package Pcalg.”</span> <em>Journal of Statistical Software</em> 47 (11): 1–26.
</div>
<div id="ref-kan2007optimal" class="csl-entry">
Kan, Raymond, and Guofu Zhou. 2007. <span>“Optimal Portfolio Choice with Parameter Uncertainty.”</span> <em>Journal of Financial and Quantitative Analysis</em> 42 (3): 621–56.
</div>
<div id="ref-kang2021crowding" class="csl-entry">
Kang, Wenjin, K Geert Rouwenhorst, and Ke Tang. 2021. <span>“Crowding and Factor Returns.”</span> <em>SSRN Working Paper</em> 3803954.
</div>
<div id="ref-karpe2020multi" class="csl-entry">
Karpe, Michaël, Jin Fang, Zhongyao Ma, and Chen Wang. 2020. <span>“Multi-Agent Reinforcement Learning in a Realistic Limit Order Book Market Simulation.”</span> <em>arXiv Preprint</em>, no. 2006.05574.
</div>
<div id="ref-ke2017lightgbm" class="csl-entry">
Ke, Guolin, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. <span>“Lightgbm: A Highly Efficient Gradient Boosting Decision Tree.”</span> In <em>Advances in Neural Information Processing Systems</em>, 3146–54.
</div>
<div id="ref-ke2019predicting" class="csl-entry">
Ke, Zheng Tracy, Bryan T Kelly, and Dacheng Xiu. 2019. <span>“Predicting Returns with Text Data.”</span> <em>SSRN Working Paper</em> 3388293.
</div>
<div id="ref-kearns2013machine" class="csl-entry">
Kearns, Michael, and Yuriy Nevmyvaka. 2013. <span>“Machine Learning for Market Microstructure and High Frequency Trading.”</span> <em>High Frequency Trading: New Realities for Traders, Markets, and Regulators</em>.
</div>
<div id="ref-kelly2019characteristics" class="csl-entry">
Kelly, Bryan T, Seth Pruitt, and Yinan Su. 2019. <span>“Characteristics Are Covariances: A Unified Model of Risk and Return.”</span> <em>Journal of Financial Economics</em> 134 (3): 501–24.
</div>
<div id="ref-kempf2007effect" class="csl-entry">
Kempf, Alexander, and Peer Osthoff. 2007. <span>“The Effect of Socially Responsible Investing on Portfolio Performance.”</span> <em>European Financial Management</em> 13 (5): 908–22.
</div>
<div id="ref-khedmati2020online" class="csl-entry">
Khedmati, Majid, and Pejman Azin. 2020. <span>“An Online Portfolio Selection Algorithm Using Clustering Approaches and Considering Transaction Costs.”</span> <em>Expert Systems with Applications</em> Forthcoming: 113546.
</div>
<div id="ref-kim2003financial" class="csl-entry">
Kim, Kyoung-jae. 2003. <span>“Financial Time Series Forecasting Using Support Vector Machines.”</span> <em>Neurocomputing</em> 55 (1-2): 307–19.
</div>
<div id="ref-kim2019arbitrage" class="csl-entry">
Kim, Soohun, Robert A Korajczyk, and Andreas Neuhierl. 2019. <span>“Arbitrage Portfolios.”</span> <em>SSRN Working Paper</em> 3263001.
</div>
<div id="ref-kim2014deciphering" class="csl-entry">
Kim, Woo Chang, Jang Ho Kim, and Frank J Fabozzi. 2014. <span>“Deciphering Robust Portfolios.”</span> <em>Journal of Banking &amp; Finance</em> 45: 1–8.
</div>
<div id="ref-kimoto1990stock" class="csl-entry">
Kimoto, Takashi, Kazuo Asakawa, Morio Yoda, and Masakazu Takeoka. 1990. <span>“Stock Market Prediction System with Modular Neural Networks.”</span> In <em>1990 IJCNN International Joint Conference on Neural Networks</em>, 1–6. IEEE.
</div>
<div id="ref-kingma2014adam" class="csl-entry">
Kingma, Diederik P, and Jimmy Ba. 2014. <span>“Adam: A Method for Stochastic Optimization.”</span> <em>arXiv Preprint</em>, no. 1412.6980.
</div>
<div id="ref-kirby2020firm" class="csl-entry">
Kirby, Chris. 2020. <span>“Firm Characteristics, Stock Market Regimes, and the Cross-Section of Expected Returns.”</span> <em>SSRN Working Paper</em> 3520131.
</div>
<div id="ref-koijen2019demand" class="csl-entry">
Koijen, Ralph S. J., and Motohiro Yogo. 2019. <span>“A Demand System Approach to Asset Pricing.”</span> <em>Journal of Political Economy</em> 127 (4): 1475–515.
</div>
<div id="ref-koijen2019investors" class="csl-entry">
Koijen, Ralph SJ, Robert J Richmond, and Motohiro Yogo. 2019. <span>“Which Investors Matter for Global Equity Valuations and Expected Returns?”</span> <em>SSRN Working Paper</em> 3378340.
</div>
<div id="ref-kolm2019dynamic" class="csl-entry">
Kolm, Petter N, and Gordon Ritter. 2019a. <span>“Dynamic Replication and Hedging: A Reinforcement Learning Approach.”</span> <em>Journal of Financial Data Science</em> 1 (1): 159–71.
</div>
<div id="ref-kolm2019modern" class="csl-entry">
———. 2019b. <span>“Modern Perspectives on Reinforcement Learning in Finance.”</span> <em>Journal of Machine Learning in Finance</em> 1 (1).
</div>
<div id="ref-kong2019new" class="csl-entry">
Kong, Weiwei, Christopher Liaw, Aranyak Mehta, and D Sivakumar. 2019. <span>“A New Dog Learns Old Tricks: RL Finds Classic Optimization Algorithms.”</span> <em>Proceedings of the ICLR Conference</em>, 1–25.
</div>
<div id="ref-koshiyama2020quantnet" class="csl-entry">
Koshiyama, Adriano, Sebastian Flennerhag, Stefano B Blumberg, Nick Firoozye, and Philip Treleaven. 2020. <span>“QuantNet: Transferring Learning Across Systematic Trading Strategies.”</span> <em>arXiv Preprint</em>, no. 2004.03445.
</div>
<div id="ref-kozak2018interpreting" class="csl-entry">
Kozak, Serhiy, Stefan Nagel, and Shrihari Santosh. 2018. <span>“Interpreting Factor Models.”</span> <em>Journal of Finance</em> 73 (3): 1183–223.
</div>
<div id="ref-kozak2019shrinking" class="csl-entry">
———. 2019. <span>“Shrinking the Cross-Section.”</span> <em>Journal of Financial Economics</em> 135: 271–92.
</div>
<div id="ref-krauss2017deep" class="csl-entry">
Krauss, Christopher, Xuan Anh Do, and Nicolas Huck. 2017. <span>“Deep Neural Networks, Gradient-Boosted Trees, Random Forests: Statistical Arbitrage on the s&amp;p 500.”</span> <em>European Journal of Operational Research</em> 259 (2): 689–702.
</div>
<div id="ref-kremer2019sparse" class="csl-entry">
Kremer, Philipp J, Sangkyun Lee, Małgorzata Bogdan, and Sandra Paterlini. 2019. <span>“Sparse Portfolio Selection via the Sorted L1-Norm.”</span> <em>Journal of Banking &amp; Finance</em>, 105687.
</div>
<div id="ref-krkoska2019herding" class="csl-entry">
Krkoska, Eduard, and Klaus Reiner Schenk-Hoppé. 2019. <span>“Herding in Smart-Beta Investment Products.”</span> <em>Journal of Risk and Financial Management</em> 12 (1): 47.
</div>
<div id="ref-kruschke2014doing" class="csl-entry">
Kruschke, John. 2014. <em>Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan (2nd Ed.)</em>. Academic Press.
</div>
<div id="ref-kuhn2019feature" class="csl-entry">
Kuhn, Max, and Kjell Johnson. 2019. <em>Feature Engineering and Selection: A Practical Approach for Predictive Models</em>. CRC Press.
</div>
<div id="ref-kurtz2020three" class="csl-entry">
Kurtz, Lloyd. 2020. <span>“Three Pillars of Modern Responsible Investment.”</span> <em>Journal of Investing</em> 29 (2): 21–32.
</div>
<div id="ref-lai2011mean" class="csl-entry">
Lai, Tze Leung, Haipeng Xing, Zehao Chen, and others. 2011. <span>“Mean–Variance Portfolio Optimization When Means and Covariances Are Unknown.”</span> <em>Annals of Applied Statistics</em> 5 (2A): 798–823.
</div>
<div id="ref-lakonishok1994contrarian" class="csl-entry">
Lakonishok, Josef, Andrei Shleifer, and Robert W Vishny. 1994. <span>“Contrarian Investment, Extrapolation, and Risk.”</span> <em>Journal of Finance</em> 49 (5): 1541–78.
</div>
<div id="ref-leary2011determinants" class="csl-entry">
Leary, Mark T, and Roni Michaely. 2011. <span>“Determinants of Dividend Smoothing: Empirical Evidence.”</span> <em>Review of Financial Studies</em> 24 (10): 3197–3249.
</div>
<div id="ref-ledoit2008robust" class="csl-entry">
Ledoit, Oliver, and Michael Wolf. 2008. <span>“Robust Performance Hypothesis Testing with the Sharpe Ratio.”</span> <em>Journal of Empirical Finance</em> 15 (5): 850–59.
</div>
<div id="ref-ledoit2004well" class="csl-entry">
Ledoit, Olivier, and Michael Wolf. 2004. <span>“A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices.”</span> <em>Journal of Multivariate Analysis</em> 88 (2): 365–411.
</div>
<div id="ref-ledoit2017nonlinear" class="csl-entry">
———. 2017. <span>“Nonlinear Shrinkage of the Covariance Matrix for Portfolio Selection: Markowitz Meets Goldilocks.”</span> <em>Review of Financial Studies</em> 30 (12): 4349–88.
</div>
<div id="ref-ledoit2018efficient" class="csl-entry">
Ledoit, Olivier, Michael Wolf, and Zhao Zhao. 2020. <span>“Efficient Sorting: A More Powerful Test for Cross-Sectional Anomalies.”</span> <em>Journal of Financial Econometrics</em> 17 (4): 645–86.
</div>
<div id="ref-lee2020hyperparameter" class="csl-entry">
Lee, Sang Il. 2020. <span>“Hyperparameter Optimization for Forecasting Stock Returns.”</span> <em>arXiv Preprint</em>, no. 2001.10278.
</div>
<div id="ref-legendre1805nouvelles" class="csl-entry">
Legendre, Adrien Marie. 1805. <em>Nouvelles m<span>é</span>thodes Pour La d<span>é</span>termination Des Orbites Des Com<span>è</span>tes</em>. F. Didot.
</div>
<div id="ref-leippold2020fama" class="csl-entry">
Leippold, Markus, and Roger Rüegg. 2020. <span>“Fama–French Factor Timing: The Long-Only Integrated Approach.”</span> <em>SSRN Working Paper</em> 3410972.
</div>
<div id="ref-leippold2021anatomy" class="csl-entry">
Leippold, Markus, and Hanlin Yang. 2021. <span>“The Anatomy of Factor Momentum.”</span> <em>SSRN Working Paper</em>.
</div>
<div id="ref-lemperiere2014two" class="csl-entry">
Lempérière, Yves, Cyril Deremble, Philip Seager, Marc Potters, and Jean-Philippe Bouchaud. 2014. <span>“Two Centuries of Trend Following.”</span> <em>arXiv Preprint</em>, no. 1404.3274.
</div>
<div id="ref-lettau2018estimating" class="csl-entry">
Lettau, Martin, and Markus Pelger. 2020a. <span>“Estimating Latent Asset-Pricing Factors.”</span> <em>Journal of Econometrics</em> Forthcoming.
</div>
<div id="ref-lettau2018factors" class="csl-entry">
———. 2020b. <span>“Factors That Fit the Time Series and Cross-Section of Stock Returns.”</span> <em>Review of Financial Studies</em> 33 (5): 2274–2325.
</div>
<div id="ref-leung2001using" class="csl-entry">
Leung, Mark T, Hazem Daouk, and An-Sing Chen. 2001. <span>“Using Investment Portfolio Return to Combine Forecasts: A Multiobjective Approach.”</span> <em>European Journal of Operational Research</em> 134 (1): 84–102.
</div>
<div id="ref-li2014online" class="csl-entry">
Li, Bin, and Steven CH Hoi. 2014. <span>“Online Portfolio Selection: A Survey.”</span> <em>ACM Computing Surveys (CSUR)</em> 46 (3): 35.
</div>
<div id="ref-li2018online" class="csl-entry">
Li, Bin, and Steven Chu Hong Hoi. 2018. <em>Online Portfolio Selection: Principles and Algorithms</em>. CRC Press.
</div>
<div id="ref-li2020conditional" class="csl-entry">
Li, Jia, Zhipeng Liao, and Rogier Quaedvlieg. 2020. <span>“Conditional Superior Predictive Ability.”</span> <em>SSRN Working Paper</em> 3536461.
</div>
<div id="ref-li2020factors" class="csl-entry">
Li, Sicong Allen, Victor DeMiguel, and Alberto Martin-Utrera. 2020. <span>“Which Factors with Price-Impact Costs?”</span> <em>SSRN Working Paper</em> 3688484.
</div>
<div id="ref-lim2020time" class="csl-entry">
Lim, Bryan, and Stefan Zohren. 2021. <span>“Time Series Forecasting with Deep Learning: A Survey.”</span> <em>Philosophical Transactions of the Royal Society A</em> 379 (2194): 20200209.
</div>
<div id="ref-linnainmaa2018history" class="csl-entry">
Linnainmaa, Juhani T, and Michael R Roberts. 2018. <span>“The History of the Cross-Section of Stock Returns.”</span> <em>Review of Financial Studies</em> 31 (7): 2606–49.
</div>
<div id="ref-lintner1965valuation" class="csl-entry">
Lintner, John. 1965. <span>“The Valuation of Risk Assets and the Selection of Risky Investments in Stock Portfolios and Capital Budgets.”</span> <em>Review of Economics and Statistics</em> 47 (1): 13–37.
</div>
<div id="ref-lioui2018esg" class="csl-entry">
Lioui, Abraham. 2018. <span>“<span>ESG</span> Factor Investing: Myth or Reality?”</span> <em>SSRN Working Paper</em> 3272090.
</div>
<div id="ref-lioui2020factor" class="csl-entry">
Lioui, Abraham, and Andrea Tarelli. 2020. <span>“Factor Investing for the Long Run.”</span> <em>SSRN Working Paper</em> 3531946.
</div>
<div id="ref-little2014statistical" class="csl-entry">
Little, Roderick JA, and Donald B Rubin. 2014. <em>Statistical Analysis with Missing Data</em>. Vol. 333. John Wiley &amp; Sons.
</div>
<div id="ref-liu2020can" class="csl-entry">
Liu, Li, Zhiyuan Pan, and Yudong Wang. 2020. <span>“What Can We Learn from the Return Predictability over Business Cycle?”</span> <em>Journal of Forecasting</em> Forthcoming.
</div>
<div id="ref-lo1990contrarian" class="csl-entry">
Lo, Andrew W, and A Craig MacKinlay. 1990. <span>“When Are Contrarian Profits Due to Stock Market Overreaction?”</span> <em>Review of Financial Studies</em> 3 (2): 175–205.
</div>
<div id="ref-lopez2020false" class="csl-entry">
Lopez de Prado, Marcos, and David H Bailey. 2020. <span>“The False Strategy Theorem: <span>A</span> Financial Application of Experimental Mathematics.”</span> <em>American Mathematical Monthly</em> Forthcoming.
</div>
<div id="ref-loreggia2016deep" class="csl-entry">
Loreggia, Andrea, Yuri Malitsky, Horst Samulowitz, and Vijay Saraswat. 2016. <span>“Deep Learning for Algorithm Portfolios.”</span> In <em>Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</em>, 1280–86. AAAI Press.
</div>
<div id="ref-loughran2016textual" class="csl-entry">
Loughran, Tim, and Bill McDonald. 2016. <span>“Textual Analysis in Accounting and Finance: A Survey.”</span> <em>Journal of Accounting Research</em> 54 (4): 1187–1230.
</div>
<div id="ref-lundberg2017unified" class="csl-entry">
Lundberg, Scott M, and Su-In Lee. 2017. <span>“A Unified Approach to Interpreting Model Predictions.”</span> In <em>Advances in Neural Information Processing Systems</em>, 4765–74.
</div>
<div id="ref-luo2020momentum" class="csl-entry">
Luo, Jiang, Avanidhar Subrahmanyam, and Sheridan Titman. 2020. <span>“Momentum and Reversals When Overconfident Investors Underestimate Their Competition.”</span> <em>Review of Financial Studies</em> Forthcoming.
</div>
<div id="ref-ma2018testing" class="csl-entry">
Ma, Shujie, Wei Lan, Liangjun Su, and Chih-Ling Tsai. 2020. <span>“Testing Alphas in Conditional Time-Varying Factor Models with High Dimensional Assets.”</span> <em>Journal of Business &amp; Economic Statistics</em> 38 (1): 214–27.
</div>
<div id="ref-ma2020portfolio" class="csl-entry">
Ma, Yilin, Ruizhu Han, and Weizhong Wang. 2020. <span>“Portfolio Optimization with Return Prediction Using Deep Learning and Machine Learning.”</span> <em>Expert Systems with Applications</em> Forthcoming: 113973.
</div>
<div id="ref-maathuis2018handbook" class="csl-entry">
Maathuis, Marloes, Mathias Drton, Steffen Lauritzen, and Martin Wainwright. 2018. <em>Handbook of Graphical Models</em>. CRC Press.
</div>
<div id="ref-maclaurin2015gradient" class="csl-entry">
Maclaurin, Dougal, David Duvenaud, and Ryan Adams. 2015. <span>“Gradient-Based Hyperparameter Optimization Through Reversible Learning.”</span> In <em>International Conference on Machine Learning</em>, 2113–22.
</div>
<div id="ref-maillard2010properties" class="csl-entry">
Maillard, Sébastien, Thierry Roncalli, and Jérôme Teiletche. 2010. <span>“The Properties of Equally Weighted Risk Contribution Portfolios.”</span> <em>Journal of Portfolio Management</em> 36 (4): 60–70.
</div>
<div id="ref-maillet2015global" class="csl-entry">
Maillet, Bertrand, Sessi Tokpavi, and Benoit Vaucher. 2015. <span>“Global Minimum Variance Portfolio Optimisation Under Some Model Risk: A Robust Regression-Based Approach.”</span> <em>European Journal of Operational Research</em> 244 (1): 289–99.
</div>
<div id="ref-mailund2019pipelines" class="csl-entry">
Mailund, Thomas. 2019. <span>“Pipelines: Magrittr.”</span> In <em>R Data Science Quick Reference</em>, 71–81. Springer.
</div>
<div id="ref-markowitz1952portfolio" class="csl-entry">
Markowitz, Harry. 1952. <span>“Portfolio Selection.”</span> <em>Journal of Finance</em> 7 (1): 77–91.
</div>
<div id="ref-marti2019corrgan" class="csl-entry">
Marti, Gautier. 2019. <span>“CorrGAN: Sampling Realistic Financial Correlation Matrices Using Generative Adversarial Networks.”</span> <em>arXiv Preprint</em>, no. 1910.09504.
</div>
<div id="ref-martin2019bayesian" class="csl-entry">
Martin, Evan A, and Audrey Qiuyan Fu. 2019. <span>“A Bayesian Approach to Directed Acyclic Graphs with a Candidate Graph.”</span> <em>arXiv Preprint</em>, no. 1909.10678.
</div>
<div id="ref-martin2019market" class="csl-entry">
Martin, Ian, and Stefan Nagel. 2019. <span>“Market Efficiency in the Age of Big Data.”</span> <em>SSRN Working Paper</em> 3511296.
</div>
<div id="ref-martins2016softmax" class="csl-entry">
Martins, Andre, and Ramon Astudillo. 2016. <span>“From Softmax to Sparsemax: <span>A</span> Sparse Model of Attention and Multi-Label Classification.”</span> In <em>International Conference on Machine Learning</em>, 1614–23.
</div>
<div id="ref-mascio2020market" class="csl-entry">
Mascio, David A, Frank J Fabozzi, and J Kenton Zumwalt. 2020. <span>“Market Timing Using Combined Forecasts and Machine Learning.”</span> <em>Journal of Forecasting</em> Forthcoming.
</div>
<div id="ref-mason2000boosting" class="csl-entry">
Mason, Llew, Jonathan Baxter, Peter L Bartlett, and Marcus R Frean. 2000. <span>“Boosting Algorithms as Gradient Descent.”</span> In <em>Advances in Neural Information Processing Systems</em>, 512–18.
</div>
<div id="ref-masters1993practical" class="csl-entry">
Masters, Timothy. 1993. <em>Practical Neural Network Recipes in <span>C</span>++</em>. Morgan Kaufmann.
</div>
<div id="ref-matias2012forecasting" class="csl-entry">
Matı́as, José M, and Juan C Reboredo. 2012. <span>“Forecasting Performance of Nonlinear Models for Intraday Stock Returns.”</span> <em>Journal of Forecasting</em> 31 (2): 172–88.
</div>
<div id="ref-mcgee2020optimal" class="csl-entry">
McGee, Richard, and Jose Olmo. 2020. <span>“Optimal Characteristic Portfolios.”</span> <em>SSRN Working Paper</em> 3638177.
</div>
<div id="ref-mclean2016does" class="csl-entry">
McLean, R David, and Jeffrey Pontiff. 2016. <span>“Does Academic Research Destroy Stock Return Predictability?”</span> <em>Journal of Finance</em> 71 (1): 5–32.
</div>
<div id="ref-meng2019reinforcement" class="csl-entry">
Meng, Terry Lingze, and Matloob Khushi. 2019. <span>“Reinforcement Learning in Financial Markets.”</span> <em>Data</em> 4 (3): 110.
</div>
<div id="ref-metropolis1949monte" class="csl-entry">
Metropolis, Nicholas, and Stanislaw Ulam. 1949. <span>“The <span>M</span>onte <span>C</span>arlo Method.”</span> <em>Journal of the American Statistical Association</em> 44 (247): 335–41.
</div>
<div id="ref-meyer2000matrix" class="csl-entry">
Meyer, Carl D. 2000. <em>Matrix Analysis and Applied Linear Algebra</em>. Vol. 71. SIAM.
</div>
<div id="ref-michaelides2020large" class="csl-entry">
Michaelides, Michael. 2020. <span>“Large Sample Size Bias in Empirical Finance.”</span> <em>Finance Research Letters</em> Forthcoming.
</div>
<div id="ref-moehle2021portfolio" class="csl-entry">
Moehle, Nicholas, Stephen Boyd, and Andrew Ang. 2021. <span>“Portfolio Performance Attribution via <span>S</span>hapley Value.”</span> <em>arXiv Preprint</em>, no. 2102.05799.
</div>
<div id="ref-mohri2018foundations" class="csl-entry">
Mohri, Mehryar, Afshin Rostamizadeh, and Ameet Talwalkar. 2018. <em>Foundations of Machine Learning</em>. MIT Press.
</div>
<div id="ref-molnar2019interpretable" class="csl-entry">
Molnar, Christoph. 2019. <em>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable</em>. LeanPub / Lulu.
</div>
<div id="ref-molnar2018iml" class="csl-entry">
Molnar, Christoph, Giuseppe Casalicchio, and Bernd Bischl. 2018. <span>“Iml: An r Package for Interpretable Machine Learning.”</span> <em>Journal of Open Source Software</em> 3 (27): 786.
</div>
<div id="ref-moody1997optimization" class="csl-entry">
Moody, John, and Lizhong Wu. 1997. <span>“Optimization of Trading Systems and Portfolios.”</span> In <em>Proceedings of the IEEE/IAFE 1997 Computational Intelligence for Financial Engineering (CIFEr)</em>, 300–307. IEEE.
</div>
<div id="ref-moody1998performance" class="csl-entry">
Moody, John, Lizhong Wu, Yuansong Liao, and Matthew Saffell. 1998. <span>“Performance Functions and Reinforcement Learning for Trading Systems and Portfolios.”</span> <em>Journal of Forecasting</em> 17 (5-6): 441–70.
</div>
<div id="ref-moritz2016tree" class="csl-entry">
Moritz, Benjamin, and Tom Zimmermann. 2016. <span>“Tree-Based Conditional Portfolio Sorts: The Relation Between Past and Future Stock Returns.”</span> <em>SSRN Working Paper</em> 2740751.
</div>
<div id="ref-mosavi2020comprehensive" class="csl-entry">
Mosavi, Amir, Pedram Ghamisi, Yaser Faghan, Puhong Duan, and Shahab Shamshirband. 2020. <span>“Comprehensive Review of Deep Reinforcement Learning Methods and Applications in Economics.”</span> <em>arXiv Preprint</em>, no. 2004.01509.
</div>
<div id="ref-moskowitz1999industries" class="csl-entry">
Moskowitz, Tobias J, and Mark Grinblatt. 1999. <span>“Do Industries Explain Momentum?”</span> <em>Journal of Finance</em> 54 (4): 1249–90.
</div>
<div id="ref-moskowitz2012time" class="csl-entry">
Moskowitz, Tobias J, Yao Hua Ooi, and Lasse Heje Pedersen. 2012. <span>“Time Series Momentum.”</span> <em>Journal of Financial Economics</em> 104 (2): 228–50.
</div>
<div id="ref-mossin1966equilibrium" class="csl-entry">
Mossin, Jan. 1966. <span>“Equilibrium in a Capital Asset Market.”</span> <em>Econometrica: <span>J</span>ournal of the Econometric Society</em> 34 (4): 768–83.
</div>
<div id="ref-nagy2016can" class="csl-entry">
Nagy, Zoltán, Altaf Kassam, and Linda-Eling Lee. 2016. <span>“Can <span>ESG</span> Add Alpha? <span>A</span>n Analysis of <span>ESG</span> Tilt and Momentum Strategies.”</span> <em>The Journal of Investing</em> 25 (2): 113–24.
</div>
<div id="ref-nesterov1983method" class="csl-entry">
Nesterov, Yurii. 1983. <span>“A Method for Unconstrained Convex Minimization Problem with the Rate of Convergence o (1/k^ 2).”</span> In <em>Doklady AN USSR</em>, 269:543–47.
</div>
<div id="ref-neuneier1996optimal" class="csl-entry">
Neuneier, Ralph. 1996. <span>“Optimal Asset Allocation Using Adaptive Dynamic Programming.”</span> In <em>Advances in Neural Information Processing Systems</em>, 952–58.
</div>
<div id="ref-neuneier1998enhancing" class="csl-entry">
———. 1998. <span>“Enhancing q-Learning for Optimal Asset Allocation.”</span> In <em>Advances in Neural Information Processing Systems</em>, 936–42.
</div>
<div id="ref-ngai2011application" class="csl-entry">
Ngai, Eric WT, Yong Hu, YH Wong, Yijun Chen, and Xin Sun. 2011. <span>“The Application of Data Mining Techniques in Financial Fraud Detection: A Classification Framework and an Academic Review of Literature.”</span> <em>Decision Support Systems</em> 50 (3): 559–69.
</div>
<div id="ref-ni2020conditional" class="csl-entry">
Ni, Hao, Lukasz Szpruch, Magnus Wiese, Shujian Liao, and Baoren Xiao. 2020. <span>“Conditional Sig-Wasserstein <span>GAN</span>s for Time Series Generation.”</span> <em>arXiv Preprint</em>, no. 2006.05421.
</div>
<div id="ref-novy2012momentum" class="csl-entry">
Novy-Marx, Robert. 2012. <span>“Is Momentum Really Momentum?”</span> <em>Journal of Financial Economics</em> 103 (3): 429–53.
</div>
<div id="ref-novy2015taxonomy" class="csl-entry">
Novy-Marx, Robert, and Mihail Velikov. 2015. <span>“A Taxonomy of Anomalies and Their Trading Costs.”</span> <em>Review of Financial Studies</em> 29 (1): 104–47.
</div>
<div id="ref-nuti2019adaptive" class="csl-entry">
Nuti, Giuseppe, Lluı́s Antoni Jiménez Rugama, and Kaspar Thommen. 2019. <span>“Adaptive Reticulum.”</span> <em>arXiv Preprint</em>, no. 1912.05901.
</div>
<div id="ref-nystrup2020hyperparameter" class="csl-entry">
Nystrup, Peter, Erik Lindstrom, and Henrik Madsen. 2020. <span>“Hyperparameter Optimization for Portfolio Selection.”</span> <em>Journal of Financial Data Science</em> Forthcoming.
</div>
<div id="ref-okun2011ensembles" class="csl-entry">
Okun, Oleg, Giorgio Valentini, and Matteo Re. 2011. <em>Ensembles in Machine Learning Applications</em>. Vol. 373. Springer Science &amp; Business Media.
</div>
<div id="ref-olazaran1996sociological" class="csl-entry">
Olazaran, Mikel. 1996. <span>“A Sociological Study of the Official History of the Perceptrons Controversy.”</span> <em>Social Studies of Science</em> 26 (3): 611–59.
</div>
<div id="ref-olson2018data" class="csl-entry">
Olson, Randal S, William La Cava, Zairah Mustahsan, Akshay Varik, and Jason H Moore. 2018. <span>“Data-Driven Advice for Applying Machine Learning to Bioinformatics Problems.”</span> <em>arXiv Preprint</em>, no. 1708.05070.
</div>
<div id="ref-orimoloye2019comparing" class="csl-entry">
Orimoloye, Larry Olanrewaju, Ming-Chien Sung, Tiejun Ma, and Johnnie EV Johnson. 2019. <span>“Comparing the Effectiveness of Deep Feedforward Neural Networks and Shallow Architectures for Predicting Stock Price Indices.”</span> <em>Expert Systems with Applications</em>, 112828.
</div>
<div id="ref-pan2009survey" class="csl-entry">
Pan, Sinno Jialin, and Qiang Yang. 2009. <span>“A Survey on Transfer Learning.”</span> <em>IEEE Transactions on Knowledge and Data Engineering</em> 22 (10): 1345–59.
</div>
<div id="ref-patel2015predicting" class="csl-entry">
Patel, Jigar, Sahil Shah, Priyank Thakkar, and K Kotecha. 2015a. <span>“Predicting Stock and Stock Price Index Movement Using Trend Deterministic Data Preparation and Machine Learning Techniques.”</span> <em>Expert Systems with Applications</em> 42 (1): 259–68.
</div>
<div id="ref-patel2015bpredicting" class="csl-entry">
Patel, Jigar, Sahil Shah, Priyank Thakkar, and Ketan Kotecha. 2015b. <span>“Predicting Stock Market Index Using Fusion of Machine Learning Techniques.”</span> <em>Expert Systems with Applications</em> 42 (4): 2162–72.
</div>
<div id="ref-patton2010monotonicity" class="csl-entry">
Patton, Andrew J, and Allan Timmermann. 2010. <span>“Monotonicity in Asset Returns: <span>N</span>ew Tests with Applications to the Term Structure, the <span>CAPM</span>, and Portfolio Sorts.”</span> <em>Journal of Financial Economics</em> 98 (3): 605–25.
</div>
<div id="ref-patton2020you" class="csl-entry">
Patton, Andrew J, and Brian M Weller. 2020. <span>“What You See Is Not What You Get: <span>T</span>he Costs of Trading Market Anomalies.”</span> <em>Journal of Financial Economics</em> Forthcoming.
</div>
<div id="ref-pearl2009causality" class="csl-entry">
Pearl, Judea. 2009. <em>Causality: Models, Reasoning and Inference. Second Edition</em>. Vol. 29. Cambridge University Press.
</div>
<div id="ref-pedersen2020enhanced" class="csl-entry">
Pedersen, Lasse Heje, Abhilash Babu, and Ari Levine. 2020. <span>“Enhanced Portfolio Optimization.”</span> <em>SSRN Working Paper</em> 3530390.
</div>
<div id="ref-penasse2018understanding" class="csl-entry">
Penasse, Julien. 2019. <span>“Understanding Alpha Decay.”</span> <em>SSRN Working Paper</em> 2953614.
</div>
<div id="ref-pendharkar2018trading" class="csl-entry">
Pendharkar, Parag C, and Patrick Cusatis. 2018. <span>“Trading Financial Indices with Reinforcement Learning Agents.”</span> <em>Expert Systems with Applications</em> 103: 1–13.
</div>
<div id="ref-pengimprovability" class="csl-entry">
Peng, Jingfu, and Yuhong Yang. 2021. <span>“On Improvability of Model Selection by Model Averaging.”</span> <em>Journal of Econometrics</em> Forthcoming.
</div>
<div id="ref-perrin2019machine" class="csl-entry">
Perrin, Sarah, and Thierry Roncalli. 2019. <span>“Machine Learning Optimization Algorithms &amp; Portfolio Allocation.”</span> <em>SSRN Working Paper</em> 3425827.
</div>
<div id="ref-pesaran2011forecast" class="csl-entry">
Pesaran, M Hashem, and Andreas Pick. 2011. <span>“Forecast Combination Across Estimation Windows.”</span> <em>Journal of Business &amp; Economic Statistics</em> 29 (2): 307–18.
</div>
<div id="ref-peters2017elements" class="csl-entry">
Peters, Jonas, Dominik Janzing, and Bernhard Schölkopf. 2017. <em>Elements of Causal Inference: Foundations and Learning Algorithms</em>. MIT Press.
</div>
<div id="ref-petersen2009estimating" class="csl-entry">
Petersen, Mitchell A. 2009. <span>“Estimating Standard Errors in Finance Panel Data Sets: Comparing Approaches.”</span> <em>Review of Financial Studies</em> 22 (1): 435–80.
</div>
<div id="ref-pflug20121" class="csl-entry">
Pflug, Georg Ch, Alois Pichler, and David Wozabal. 2012. <span>“The 1/n Investment Strategy Is Optimal Under High Model Ambiguity.”</span> <em>Journal of Banking &amp; Finance</em> 36 (2): 410–17.
</div>
<div id="ref-pike2020combining" class="csl-entry">
Pike, Tyler, and Francisco Vazquez-Grande. 2020. <span>“Combining Forecasts: Can Machines Beat the Average?”</span> <em>SSRN Working Paper</em> 3691117.
</div>
<div id="ref-plyakha2014equal" class="csl-entry">
Plyakha, Yuliya, Raman Uppal, and Grigory Vilkov. 2016. <span>“Equal or Value Weighting? Implications for Asset-Pricing Tests.”</span> <em>SSRN Working Paper</em> 1787045.
</div>
<div id="ref-polyak1964some" class="csl-entry">
Polyak, Boris T. 1964. <span>“Some Methods of Speeding up the Convergence of Iteration Methods.”</span> <em>USSR Computational Mathematics and Mathematical Physics</em> 4 (5): 1–17.
</div>
<div id="ref-popov2019neural" class="csl-entry">
Popov, Sergei, Stanislav Morozov, and Artem Babenko. 2019. <span>“Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data.”</span> <em>arXiv Preprint</em>, no. 1909.06312.
</div>
<div id="ref-powell2011review" class="csl-entry">
Powell, Warren B, and Jun Ma. 2011. <span>“A Review of Stochastic Algorithms with Continuous Value Function Approximation and Some New Approximate Policy Iteration Algorithms for Multidimensional Continuous Applications.”</span> <em>Journal of Control Theory and Applications</em> 9 (3): 336–52.
</div>
<div id="ref-de2020crowdsourced" class="csl-entry">
Prado, Marcos López de, and Frank J Fabozzi. 2020. <span>“Crowdsourced Investment Research Through Tournaments.”</span> <em>Journal of Financial Data Science</em> 2 (1): 86–93.
</div>
<div id="ref-probst2018tunability" class="csl-entry">
Probst, Philipp, Bernd Bischl, and Anne-Laure Boulesteix. 2018. <span>“Tunability: Importance of Hyperparameters of Machine Learning Algorithms.”</span> <em>arXiv Preprint</em>, no. 1802.09596.
</div>
<div id="ref-pukthuanthong2018protocol" class="csl-entry">
Pukthuanthong, Kuntara, Richard Roll, and Avanidhar Subrahmanyam. 2018. <span>“A Protocol for Factor Identification.”</span> <em>Review of Financial Studies</em> 32 (4): 1573–1607.
</div>
<div id="ref-quionero2009dataset" class="csl-entry">
Quionero-Candela, Joaquin, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. 2009. <em>Dataset Shift in Machine Learning</em>. MIT Press.
</div>
<div id="ref-rapach2013international" class="csl-entry">
Rapach, David E, Jack K Strauss, and Guofu Zhou. 2013. <span>“International Stock Return Predictability: What Is the Role of the <span>U</span>nited <span>S</span>tates?”</span> <em>Journal of Finance</em> 68 (4): 1633–62.
</div>
<div id="ref-rapach2019time" class="csl-entry">
Rapach, David, and Guofu Zhou. 2019. <span>“Time-Series and Cross-Sectional Stock Return Forecasting: New Machine Learning Methods.”</span> <em>SSRN Working Paper</em> 3428095.
</div>
<div id="ref-rashmi2015dart" class="csl-entry">
Rashmi, Korlakai Vinayak, and Ran Gilad-Bachrach. 2015. <span>“DART: Dropouts Meet Multiple Additive Regression Trees.”</span> In <em>AISTATS</em>, 489–97.
</div>
<div id="ref-ravisankar2011detection" class="csl-entry">
Ravisankar, Pediredla, Vadlamani Ravi, G Raghava Rao, and Indranil Bose. 2011. <span>“Detection of Financial Statement Fraud and Feature Selection Using Data Mining Techniques.”</span> <em>Decision Support Systems</em> 50 (2): 491–500.
</div>
<div id="ref-razin2020drowning" class="csl-entry">
Razin, Ronny, and Gilat Levy. 2020. <span>“A Maximum Likelihood Approach to Combining Forecasts.”</span> <em>Theoretical Economics</em> Forthcoming.
</div>
<div id="ref-reboredo2012nonlinearity" class="csl-entry">
Reboredo, Juan C, José M Matı́as, and Raquel Garcia-Rubio. 2012. <span>“Nonlinearity in Forecasting of High-Frequency Stock Returns.”</span> <em>Computational Economics</em> 40 (3): 245–64.
</div>
<div id="ref-regenstein2018reproducible" class="csl-entry">
Regenstein, Jonathan K. 2018. <em>Reproducible Finance with r: Code Flows and Shiny Apps for Portfolio Analysis</em>. Chapman &amp; Hall / CRC.
</div>
<div id="ref-ribeiro2016should" class="csl-entry">
Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. <span>“Why Should <span>I</span> Trust You?: <span>E</span>xplaining the Predictions of Any Classifier.”</span> In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, 1135–44. ACM.
</div>
<div id="ref-ridgeway1999boosting" class="csl-entry">
Ridgeway, Greg, David Madigan, and Thomas Richardson. 1999. <span>“Boosting Methodology for Regression Problems.”</span> In <em>AISTATS</em>.
</div>
<div id="ref-ripley2007pattern" class="csl-entry">
Ripley, Brian D. 2007. <em>Pattern Recognition and Neural Networks</em>. Cambridge University Press.
</div>
<div id="ref-roberts1994simple" class="csl-entry">
Roberts, Gareth O, and Adrian FM Smith. 1994. <span>“Simple Conditions for the Convergence of the Gibbs Sampler and Metropolis-Hastings Algorithms.”</span> <em>Stochastic Processes and Their Applications</em> 49 (2): 207–16.
</div>
<div id="ref-romano2005stepwise" class="csl-entry">
Romano, Joseph P, and Michael Wolf. 2005. <span>“Stepwise Multiple Testing as Formalized Data Snooping.”</span> <em>Econometrica</em> 73 (4): 1237–82.
</div>
<div id="ref-romano2013testing" class="csl-entry">
———. 2013. <span>“Testing for Monotonicity in Expected Asset Returns.”</span> <em>Journal of Empirical Finance</em> 23: 93–116.
</div>
<div id="ref-rosenblatt1958perceptron" class="csl-entry">
Rosenblatt, Frank. 1958. <span>“The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.”</span> <em>Psychological Review</em> 65 (6): 386.
</div>
<div id="ref-ross1976arbitrage" class="csl-entry">
Ross, Stephen A. 1976. <span>“The Arbitrage Theory of Capital Asset Pricing.”</span> <em>Journal of Economic Theory</em> 13 (3): 341–60.
</div>
<div id="ref-rousseeuw2005robust" class="csl-entry">
Rousseeuw, Peter J, and Annick M Leroy. 2005. <em>Robust Regression and Outlier Detection</em>. Vol. 589. Wiley.
</div>
<div id="ref-ruf2019neural" class="csl-entry">
Ruf, Johannes, and Weiguan Wang. 2019. <span>“Neural Networks for Option Pricing and Hedging: A Literature Review.”</span> <em>arXiv Preprint</em>, no. 1911.05620.
</div>
<div id="ref-sangadiev2020deepfolio" class="csl-entry">
Sangadiev, Aiusha, Rodrigo Rivera-Castro, Kirill Stepanov, Andrey Poddubny, Kirill Bubenchikov, Nikita Bekezin, Polina Pilyugina, and Evgeny Burnaev. 2020. <span>“Deep<span>F</span>olio: <span>C</span>onvolutional Neural Networks for Portfolios with Limit Order Book Data.”</span> <em>arXiv Preprint</em>, no. 2008.12152.
</div>
<div id="ref-santi2018exploring" class="csl-entry">
Santi, Caterina, and Remco CJ Zwinkels. 2018. <span>“Exploring Style Herding by Mutual Funds.”</span> <em>SSRN Working Paper</em> 2986059.
</div>
<div id="ref-sato2019model" class="csl-entry">
Sato, Yoshiharu. 2019. <span>“Model-Free Reinforcement Learning for Financial Portfolios: A Brief Survey.”</span> <em>arXiv Preprint</em>, no. 1904.04973.
</div>
<div id="ref-schafer1999multiple" class="csl-entry">
Schafer, Joseph L. 1999. <span>“Multiple Imputation: A Primer.”</span> <em>Statistical Methods in Medical Research</em> 8 (1): 3–15.
</div>
<div id="ref-schapire1990strength" class="csl-entry">
Schapire, Robert E. 1990. <span>“The Strength of Weak Learnability.”</span> <em>Machine Learning</em> 5 (2): 197–227.
</div>
<div id="ref-schapire2003boosting" class="csl-entry">
———. 2003. <span>“The Boosting Approach to Machine Learning: An Overview.”</span> In <em>Nonlinear Estimation and Classification</em>, 149–71. Springer.
</div>
<div id="ref-schapire2012boosting" class="csl-entry">
Schapire, Robert E, and Yoav Freund. 2012. <em>Boosting: Foundations and Algorithms</em>. MIT Press.
</div>
<div id="ref-schnaubelt2019comparison" class="csl-entry">
Schnaubelt, Matthias. 2019. <span>“A Comparison of Machine Learning Model Validation Schemes for Non-Stationary Time Series Data.”</span> FAU Discussion Papers in Economics.
</div>
<div id="ref-schueth2003socially" class="csl-entry">
Schueth, Steve. 2003. <span>“Socially Responsible Investing in the United States.”</span> <em>Journal of Business Ethics</em> 43 (3): 189–94.
</div>
<div id="ref-scornet2015consistency" class="csl-entry">
Scornet, Erwan, Gérard Biau, Jean-Philippe Vert, and others. 2015. <span>“Consistency of Random Forests.”</span> <em>Annals of Statistics</em> 43 (4): 1716–41.
</div>
<div id="ref-seni2010ensemble" class="csl-entry">
Seni, Giovanni, and John F Elder. 2010. <span>“Ensemble Methods in Data Mining: Improving Accuracy Through Combining Predictions.”</span> <em>Synthesis Lectures on Data Mining and Knowledge Discovery</em> 2 (1): 1–126.
</div>
<div id="ref-settles2009active" class="csl-entry">
Settles, Burr. 2009. <span>“Active Learning Literature Survey.”</span> University of Wisconsin-Madison Department of Computer Sciences.
</div>
<div id="ref-settles2012active" class="csl-entry">
———. 2012. <span>“Active Learning.”</span> <em>Synthesis Lectures on Artificial Intelligence and Machine Learning</em> 6 (1): 1–114.
</div>
<div id="ref-sezer2019financial" class="csl-entry">
Sezer, Omer Berat, Mehmet Ugur Gudelek, and Ahmet Murat Ozbayoglu. 2019. <span>“Financial Time Series Forecasting with Deep Learning: A Systematic Literature Review: 2005-2019.”</span> <em>arXiv Preprint</em>, no. 1911.13288.
</div>
<div id="ref-shah2014comparison" class="csl-entry">
Shah, Anoop D, Jonathan W Bartlett, James Carpenter, Owen Nicholas, and Harry Hemingway. 2014. <span>“Comparison of Random Forest and Parametric Imputation Models for Imputing Missing Data Using MICE: A CALIBER Study.”</span> <em>American Journal of Epidemiology</em> 179 (6): 764–74.
</div>
<div id="ref-shalit2020shapley" class="csl-entry">
Shalit, Haim. 2020. <span>“The Shapley Value of Regression Portfolios.”</span> <em>Journal of Asset Management</em> 21 (6): 506–12.
</div>
<div id="ref-shanaev2020efficient" class="csl-entry">
Shanaev, Savva, and Binam Ghimire. 2020. <span>“Efficient Scholars: Academic Attention and the Disappearance of Anomalies.”</span> <em>European Journal of Finance</em> Forthcoming: 1–27.
</div>
<div id="ref-shanken1992estimation" class="csl-entry">
Shanken, Jay. 1992. <span>“On the Estimation of Beta-Pricing Models.”</span> <em>Review of Financial Studies</em> 5 (1): 1–33.
</div>
<div id="ref-shapley1953value" class="csl-entry">
Shapley, Lloyd S. 1953. <span>“A Value for n-Person Games.”</span> <em>Contributions to the Theory of Games</em> 2 (28): 307–17.
</div>
<div id="ref-sharpe1964capital" class="csl-entry">
Sharpe, William F. 1964. <span>“Capital Asset Prices: A Theory of Market Equilibrium Under Conditions of Risk.”</span> <em>Journal of Finance</em> 19 (3): 425–42.
</div>
<div id="ref-sharpe1966mutual" class="csl-entry">
———. 1966. <span>“Mutual Fund Performance.”</span> <em>Journal of Business</em> 39 (1): 119–38.
</div>
<div id="ref-shea2020searching" class="csl-entry">
Shea, Yifei, and Erhard Radatz. 2020. <span>“Searching for Inner Peace with Value Factors.”</span> <em>Risk &amp; Reward</em>, 14–19.
</div>
<div id="ref-silver2016mastering" class="csl-entry">
Silver, David, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, and Marc Lanctot. 2016. <span>“Mastering the Game of Go with Deep Neural Networks and Tree Search.”</span> <em>Nature</em> 529: 484–89.
</div>
<div id="ref-simonian2019machine" class="csl-entry">
Simonian, Joseph, Chenwei Wu, Daniel Itano, and Vyshaal Narayanam. 2019. <span>“A Machine Learning Approach to Risk Factors: <span>A</span> Case Study Using the <span>F</span>ama-<span>F</span>rench-<span>C</span>arhart Model.”</span> <em>Journal of Financial Data Science</em> 1 (1): 32–44.
</div>
<div id="ref-simonsohn2014p" class="csl-entry">
Simonsohn, Uri, Leif D Nelson, and Joseph P Simmons. 2014. <span>“P-Curve: A Key to the File-Drawer.”</span> <em>Journal of Experimental Psychology: General</em> 143 (2): 534.
</div>
<div id="ref-sirignano2019universal" class="csl-entry">
Sirignano, Justin, and Rama Cont. 2019. <span>“Universal Features of Price Formation in Financial Markets: Perspectives from Deep Learning.”</span> <em>Quantitative Finance</em> 19 (9): 1449–59.
</div>
<div id="ref-smith2018disciplined" class="csl-entry">
Smith, Leslie N. 2018. <span>“A Disciplined Approach to Neural Network Hyper-Parameters: Part 1–Learning Rate, Batch Size, Momentum, and Weight Decay.”</span> <em>arXiv Preprint</em>, no. 1803.09820.
</div>
<div id="ref-smith2020instability" class="csl-entry">
Smith, Simon, and Allan Timmermann. 2020. <span>“Instability in Risk Premia.”</span> <em>SSRN Working Paper</em> 3728192.
</div>
<div id="ref-snoek2012practical" class="csl-entry">
Snoek, Jasper, Hugo Larochelle, and Ryan P Adams. 2012. <span>“Practical Bayesian Optimization of Machine Learning Algorithms.”</span> In <em>Advances in Neural Information Processing Systems</em>, 2951–59.
</div>
<div id="ref-snow2020machine" class="csl-entry">
Snow, Derek. 2020. <span>“Machine Learning in Asset Management: Part 2: Portfolio Construction—Weight Optimization.”</span> <em>Journal of Financial Data Science</em> Forthcoming.
</div>
<div id="ref-soleymani2020financial" class="csl-entry">
Soleymani, Farzan, and Eric Paquet. 2020. <span>“Financial Portfolio Optimization with Online Deep Reinforcement Learning and Restricted Stacked Autoencoder-DeepBreath.”</span> <em>Expert Systems with Applications</em> Forthcoming: 113456.
</div>
<div id="ref-sparapani2019r" class="csl-entry">
Sparapani, Rodney, Charles Spanbauer, and Robert McCulloch. 2019. <span>“The <span>BART</span> <span>R</span> Package.”</span> Comprehensive R Archive Network. <a href="https://cran.r-project.org/web/packages/BART/vignettes/the-BART-R-package.pdf">https://cran.r-project.org/web/packages/BART/vignettes/the-BART-R-package.pdf</a>.
</div>
<div id="ref-spirtes2000causation" class="csl-entry">
Spirtes, Peter, Clark N Glymour, Richard Scheines, and David Heckerman. 2000. <em>Causation, Prediction, and Search</em>. MIT Press.
</div>
<div id="ref-srivastava2014dropout" class="csl-entry">
Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. <span>“Dropout: A Simple Way to Prevent Neural Networks from Overfitting.”</span> <em>Journal of Machine Learning Research</em> 15 (1): 1929–58.
</div>
<div id="ref-stagnol2021understanding" class="csl-entry">
Stagnol, Lauren, Christian Lopez, Thierry Roncalli, Bruno Taillardat, and Smart Beta Team. 2021. <span>“Understanding the Performance of the Equity Value Factor.”</span> <em>Amundi Working Paper</em>.
</div>
<div id="ref-stambaugh1999predictive" class="csl-entry">
Stambaugh, Robert F. 1999. <span>“Predictive Regressions.”</span> <em>Journal of Financial Economics</em> 54 (3): 375–421.
</div>
<div id="ref-staniak2018explanations" class="csl-entry">
Staniak, Mateusz, and Przemyslaw Biecek. 2018. <span>“Explanations of Model Predictions with Live and breakDown Packages.”</span> <em>arXiv Preprint</em>, no. 1804.01955.
</div>
<div id="ref-stekhoven2011missforest" class="csl-entry">
Stekhoven, Daniel J, and Peter Bühlmann. 2011. <span>“MissForest—Non-Parametric Missing Value Imputation for Mixed-Type Data.”</span> <em>Bioinformatics</em> 28 (1): 112–18.
</div>
<div id="ref-stevens1998inverse" class="csl-entry">
Stevens, Guy VG. 1998. <span>“On the Inverse of the Covariance Matrix in Portfolio Analysis.”</span> <em>Journal of Finance</em> 53 (5): 1821–27.
</div>
<div id="ref-suhonen2017quantifying" class="csl-entry">
Suhonen, Antti, Matthias Lennkh, and Fabrice Perez. 2017. <span>“Quantifying Backtest Overfitting in Alternative Beta Strategies.”</span> <em>Journal of Portfolio Management</em> 43 (2): 90–104.
</div>
<div id="ref-sun2020time" class="csl-entry">
Sun, Yuying, YM Hong, T Lee, Shouyang Wang, and Xinyu Zhang. 2020. <span>“Time-Varying Model Averaging.”</span> <em>Journal of Econometrics</em> Forthcoming.
</div>
<div id="ref-sutton2018reinforcement" class="csl-entry">
Sutton, Richard S, and Andrew G Barto. 2018. <em>Reinforcement Learning: <span>A</span>n Introduction (2nd Edition)</em>. MIT Press.
</div>
<div id="ref-taghian2020learning" class="csl-entry">
Taghian, Mehran, Ahmad Asadi, and Reza Safabakhsh. 2020. <span>“Learning Financial Asset-Specific Trading Rules via Deep Reinforcement Learning.”</span> <em>arXiv Preprint</em>, no. 2010.14194.
</div>
<div id="ref-textor2016robust" class="csl-entry">
Textor, Johannes, Benito van der Zander, Mark S Gilthorpe, Maciej Liśkiewicz, and George TH Ellison. 2016. <span>“Robust Causal Inference Using Directed Acyclic Graphs: The r Package <span>‘Dagitty’</span>.”</span> <em>International Journal of Epidemiology</em> 45 (6): 1887–94.
</div>
<div id="ref-theate2020application" class="csl-entry">
Théate, Thibaut, and Damien Ernst. 2020. <span>“An Application of Deep Reinforcement Learning to Algorithmic Trading.”</span> <em>arXiv Preprint</em>, no. 2004.06627.
</div>
<div id="ref-tibshirani1996regression" class="csl-entry">
Tibshirani, Robert. 1996. <span>“Regression Shrinkage and Selection via the Lasso.”</span> <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, 267–88.
</div>
<div id="ref-tierney1994markov" class="csl-entry">
Tierney, Luke. 1994. <span>“Markov Chains for Exploring Posterior Distributions.”</span> <em>Annals of Statistics</em>, 1701–28.
</div>
<div id="ref-tikka2017identifying" class="csl-entry">
Tikka, Santtu, and Juha Karvanen. 2017. <span>“Identifying Causal Effects with the <span>R</span> Package Causaleffect.”</span> <em>Journal of Statistical Software</em> 76 (1): 1–30.
</div>
<div id="ref-timmermann2018forecasting" class="csl-entry">
Timmermann, Allan. 2018. <span>“Forecasting Methods in Finance.”</span> <em>Annual Review of Financial Economics</em> 10: 449–79.
</div>
<div id="ref-ting2002instance" class="csl-entry">
Ting, Kai Ming. 2002. <span>“An Instance-Weighting Method to Induce Cost-Sensitive Trees.”</span> <em>IEEE Transactions on Knowledge &amp; Data Engineering</em>, no. 3: 659–65.
</div>
<div id="ref-tobek2021does" class="csl-entry">
Tobek, Ondrej, and Martin Hronec. 2021. <span>“Does It Pay to Follow Anomalies Research? <span>M</span>achine Learning Approach with International Evidence.”</span> <em>Journal of Financial Markets</em> Forthcoming: 100588.
</div>
<div id="ref-treynor1965rate" class="csl-entry">
Treynor, Jack L. 1965. <span>“How to Rate Management of Investment Funds.”</span> <em>Harvard Business Review</em> 43 (1): 63–75.
</div>
<div id="ref-tsantekidis2017forecasting" class="csl-entry">
Tsantekidis, Avraam, Nikolaos Passalis, Anastasios Tefas, Juho Kanniainen, Moncef Gabbouj, and Alexandros Iosifidis. 2017. <span>“Forecasting Stock Prices from the Limit Order Book Using Convolutional Neural Networks.”</span> In <em>2017 IEEE 19th Conference on Business Informatics (CBI)</em>, 1:7–12.
</div>
<div id="ref-tsiakas2020equity" class="csl-entry">
Tsiakas, Ilias, Jiahan Li, and Haibin Zhang. 2020. <span>“Equity Premium Prediction and the State of the Economy.”</span> <em>Journal of Empirical Finance</em> Forthcoming.
</div>
<div id="ref-tu2010incorporating" class="csl-entry">
Tu, Jun, and Guofu Zhou. 2010. <span>“Incorporating Economic Objectives into Bayesian Priors: Portfolio Choice Under Parameter Uncertainty.”</span> <em>Journal of Financial and Quantitative Analysis</em> 45 (4): 959–86.
</div>
<div id="ref-uematsu2019high" class="csl-entry">
Uematsu, Yoshimasa, and Shinya Tanaka. 2019. <span>“High-Dimensional Macroeconomic Forecasting and Variable Selection via Penalized Regression.”</span> <em>Econometrics Journal</em> 22 (1): 34–56.
</div>
<div id="ref-van2018flexible" class="csl-entry">
Van Buuren, Stef. 2018. <em>Flexible Imputation of Missing Data</em>. Chapman &amp; Hall / CRC.
</div>
<div id="ref-van2011size" class="csl-entry">
Van Dijk, Mathijs A. 2011. <span>“Is Size Dead? <span>A</span> Review of the Size Effect in Equity Returns.”</span> <em>Journal of Banking &amp; Finance</em> 35 (12): 3263–74.
</div>
<div id="ref-vapnik1963pattern" class="csl-entry">
Vapnik, Vladimir, and A. Lerner. 1963. <span>“Pattern Recognition Using Generalized Portrait Method.”</span> <em>Automation and Remote Control</em> 24: 774–80.
</div>
<div id="ref-vayanos2013institutional" class="csl-entry">
Vayanos, Dimitri, and Paul Woolley. 2013. <span>“An Institutional Theory of Momentum and Reversal.”</span> <em>Review of Financial Studies</em> 26 (5): 1087–1145.
</div>
<div id="ref-vidal2020born" class="csl-entry">
Vidal, Thibaut, Toni Pacheco, and Maximilian Schiffer. 2020. <span>“Born-Again Tree Ensembles.”</span> <em>arXiv Preprint</em>, no. 2003.11132.
</div>
<div id="ref-vincent2020investment" class="csl-entry">
Vincent, Kendro, Yu-Chin Hsu, and Hsiou-Wei Lin. 2020. <span>“Investment Styles and the Multiple Testing of Cross-Sectional Stock Return Predictability.”</span> <em>Journal of Financial Markets</em> Forthcoming: 100598.
</div>
<div id="ref-virtanen1987forecasting" class="csl-entry">
Virtanen, Ilkka, and Paavo Yli-Olli. 1987. <span>“Forecasting Stock Market Prices in a Thin Security Market.”</span> <em>Omega</em> 15 (2): 145–55.
</div>
<div id="ref-volpati2020zooming" class="csl-entry">
Volpati, Valerio, Michael Benzaquen, Zoltan Eisler, Iacopo Mastromatteo, Bence Toth, and Jean-Philippe Bouchaud. 2020. <span>“Zooming in on Equity Factor Crowding.”</span> <em>arXiv Preprint</em>, no. 2001.04185.
</div>
<div id="ref-von1972probabilistic" class="csl-entry">
Von Holstein, Carl-Axel S Staël. 1972. <span>“Probabilistic Forecasting: An Experiment Related to the Stock Market.”</span> <em>Organizational Behavior and Human Performance</em> 8 (1): 139–58.
</div>
<div id="ref-wallbridge2020transformers" class="csl-entry">
Wallbridge, James. 2020. <span>“Transformers for Limit Order Books.”</span> <em>arXiv Preprint</em>, no. 2003.00130.
</div>
<div id="ref-wang2011comparative" class="csl-entry">
Wang, Gang, Jinxing Hao, Jian Ma, and Hongbing Jiang. 2011. <span>“A Comparative Assessment of Ensemble Learning for Credit Scoring.”</span> <em>Expert Systems with Applications</em> 38 (1): 223–30.
</div>
<div id="ref-wang2019continuous" class="csl-entry">
Wang, Haoran, and Xun Yu Zhou. 2019. <span>“Continuous-Time Mean-Variance Portfolio Selection: A Reinforcement Learning Framework.”</span> <em>SSRN Working Paper</em> 3382932.
</div>
<div id="ref-wang2012stock" class="csl-entry">
Wang, Ju-Jie, Jian-Zhou Wang, Zhe-George Zhang, and Shu-Po Guo. 2012. <span>“Stock Index Forecasting Based on a Hybrid Model.”</span> <em>Omega</em> 40 (6): 758–66.
</div>
<div id="ref-wang2019portfolio" class="csl-entry">
Wang, Wuyu, Weizi Li, Ning Zhang, and Kecheng Liu. 2020. <span>“Portfolio Formation with Preselection Using Deep Learning from Long-Term Financial Data.”</span> <em>Expert Systems with Applications</em> 143: 113042.
</div>
<div id="ref-watkins1992q" class="csl-entry">
Watkins, Christopher JCH, and Peter Dayan. 1992. <span>“Q-Learning.”</span> <em>Machine Learning</em> 8 (3-4): 279–92.
</div>
<div id="ref-wei2019model" class="csl-entry">
Wei, Haoran, Yuanbo Wang, Lidia Mangu, and Keith Decker. 2019. <span>“Model-Based Reinforcement Learning for Predictions and Control for Limit Order Books.”</span> <em>arXiv Preprint</em>, no. 1910.03743.
</div>
<div id="ref-weiss2016survey" class="csl-entry">
Weiss, Karl, Taghi M Khoshgoftaar, and DingDing Wang. 2016. <span>“A Survey of Transfer Learning.”</span> <em>Journal of Big Data</em> 3 (1): 9.
</div>
<div id="ref-white1988economic" class="csl-entry">
White, Halbert. 1988. <span>“Economic Prediction Using Neural Networks: The Case of IBM Daily Stock Returns.”</span>
</div>
<div id="ref-white2000reality" class="csl-entry">
———. 2000. <span>“A Reality Check for Data Snooping.”</span> <em>Econometrica</em> 68 (5): 1097–1126.
</div>
<div id="ref-wickham2019welcome" class="csl-entry">
Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, L McGowan, Romain François, Garrett Grolemund, et al. 2019. <span>“Welcome to the Tidyverse.”</span> <em>Journal of Open Source Software</em> 4 (43): 1686.
</div>
<div id="ref-widrow1960adaptive" class="csl-entry">
Widrow, Bernard, and Marcian E Hoff. 1960. <span>“Adaptive Switching Circuits.”</span> In <em>IRE WESCON Convention Record</em>, 4:96–104.
</div>
<div id="ref-wiese2019quant" class="csl-entry">
Wiese, Magnus, Robert Knobloch, Ralf Korn, and Peter Kretschmer. 2020. <span>“Quant GANs: Deep Generation of Financial Time Series.”</span> <em>Quantitative Finance</em> Forthcoming.
</div>
<div id="ref-wolpert1992connection" class="csl-entry">
Wolpert, David H. 1992a. <span>“On the Connection Between in-Sample Testing and Generalization Error.”</span> <em>Complex Systems</em> 6 (1): 47.
</div>
<div id="ref-wolpert1992stacked" class="csl-entry">
———. 1992b. <span>“Stacked Generalization.”</span> <em>Neural Networks</em> 5 (2): 241–59.
</div>
<div id="ref-wolpert1997no" class="csl-entry">
Wolpert, David H, and William G Macready. 1997. <span>“No Free Lunch Theorems for Optimization.”</span> <em>IEEE Transactions on Evolutionary Computation</em> 1 (1): 67–82.
</div>
<div id="ref-wong2020non" class="csl-entry">
Wong, Steven YK, Jennifer Chan, Lamiae Azizi, and Richard YD Xu. 2020. <span>“Time-Varying Neural Network for Stock Return Prediction.”</span> <em>arXiv Preprint</em>, no. 2003.02515.
</div>
<div id="ref-wu2020cross" class="csl-entry">
Wu, Wenbo, Jiaqi Chen, Zhibin Yang, and Michael L Tindall. 2020. <span>“A Cross-Sectional Machine Learning Approach for Hedge Fund Return Prediction and Selection.”</span> <em>Management Science</em> Forthcoming.
</div>
<div id="ref-xiong2018practical" class="csl-entry">
Xiong, Zhuoran, Xiao-Yang Liu, Shan Zhong, Hongyang Yang, and Anwar Walid. 2018. <span>“Practical Deep Reinforcement Learning Approach for Stock Trading.”</span> <em>arXiv Preprint</em>, no. 1811.07522.
</div>
<div id="ref-xu2020testing" class="csl-entry">
Xu, Ke-Li. 2020. <span>“Testing for Multiple-Horizon Predictability: Direct Regression Based Versus Implication Based.”</span> <em>Review of Financial Studies</em> Forthcoming.
</div>
<div id="ref-yang2020weighted" class="csl-entry">
Yang, Hanlin. 2020a. <span>“A Weighted Least Squares Estimator of Factor Momentum.”</span> <em>SSRN Working Paper</em> 3443998.
</div>
<div id="ref-yang2020decomposing" class="csl-entry">
———. 2020b. <span>“Decomposing Factor Momentum.”</span> <em>SSRN Working Paper</em> 3517888.
</div>
<div id="ref-yang2018investor" class="csl-entry">
Yang, Steve Y, Yangyang Yu, and Saud Almahdi. 2018. <span>“An Investor Sentiment Reward-Based Trading System Using Gaussian Inverse Reinforcement Learning Algorithm.”</span> <em>Expert Systems with Applications</em> 114: 388–401.
</div>
<div id="ref-yin2020equity" class="csl-entry">
Yin, Anwen. 2020. <span>“Equity Premium Prediction and Optimal Portfolio Decision with Bagging.”</span> <em>North American Journal of Economics and Finance</em>, 101274.
</div>
<div id="ref-yu2019model" class="csl-entry">
Yu, Pengqian, Joon Sern Lee, Ilya Kulyatin, Zekun Shi, and Sakyasingha Dasgupta. 2019. <span>“Model-Based Deep Reinforcement Learning for Dynamic Portfolio Optimization.”</span> <em>arXiv Preprint</em>, no. 1901.08740.
</div>
<div id="ref-zaremba2020have" class="csl-entry">
Zaremba, Adam, Mehmet Umutlu, and Alina Maydubura. 2020. <span>“Where Have the Profits Gone? <span>M</span>arket Efficiency and the Disappearing Equity Anomalies in Country and Industry Returns.”</span> <em>Journal of Banking &amp; Finance</em> Forthcoming: 105966.
</div>
<div id="ref-zeiler2012adadelta" class="csl-entry">
Zeiler, Matthew D. 2012. <span>“ADADELTA: An Adaptive Learning Rate Method.”</span> <em>arXiv Preprint</em>, no. 1212.5701.
</div>
<div id="ref-zhang2012ensemble" class="csl-entry">
Zhang, Cha, and Yunqian Ma. 2012. <em>Ensemble Machine Learning: Methods and Applications</em>. Springer.
</div>
<div id="ref-zhang2009stock" class="csl-entry">
Zhang, Yudong, and Lenan Wu. 2009. <span>“Stock Market Prediction of s&amp;p 500 via Combination of Improved BCO Approach and BP Neural Network.”</span> <em>Expert Systems with Applications</em> 36 (5): 8849–54.
</div>
<div id="ref-zhang2020deep" class="csl-entry">
Zhang, Zihao, Stefan Zohren, and Stephen Roberts. 2020. <span>“Deep Reinforcement Learning for Trading.”</span> <em>Journal of Financial Data Science</em> 2 (2): 25–40.
</div>
<div id="ref-zhao2019causal" class="csl-entry">
Zhao, Qingyuan, and Trevor Hastie. 2020. <span>“Causal Interpretations of Black-Box Models.”</span> <em>Journal of Business &amp; Economic Statistics</em> Forthcoming.
</div>
<div id="ref-zhou2012ensemble" class="csl-entry">
Zhou, Zhi-Hua. 2012. <em>Ensemble Methods: Foundations and Algorithms</em>. Chapman &amp; Hall / CRC.
</div>
<div id="ref-zou2005regularization" class="csl-entry">
Zou, Hui, and Trevor Hastie. 2005. <span>“Regularization and Variable Selection via the Elastic Net.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 67 (2): 301–20.
</div>
<div id="ref-zuckerman2019man" class="csl-entry">
Zuckerman, Gregory. 2019. <em>The Man Who Solved the Market: How Jim Simons Launched the Quant Revolution</em>. Penguin Random House.
</div>
</div>
</div>
</div>










































            </section>

          </div>
        </div>
      </div>
<a href="data-description.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed",
"download": false
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
