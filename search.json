[{"path":"index.html","id":"preface","chapter":"Preface\n\n\n\n\n\n\n\n\n\n\n\n\n","heading":"Preface\n\n\n\n\n\n\n\n\n\n\n\n\n","text":"book intended cover advanced modelling techniques applied equity investment strategies built firm characteristics. content threefold. First, try simply explain ideas behind mainstream machine learning algorithms used equity asset allocation. Second, mention wide range academic references readers wish push little . Finally, provide hands-R code samples show apply concepts tools realistic dataset share encourage reproducibility.","code":""},{"path":"index.html","id":"what-this-book-is-not-about","chapter":"Preface\n\n\n\n\n\n\n\n\n\n\n\n\n","heading":"What this book is not about\n\n\n\n\n\n\n\n\n\n\n\n\n","text":"book deals machine learning (ML) tools applications factor investing. Factor investing subfield large discipline encompasses asset allocation, quantitative trading wealth management. premise differences returns firms can explained characteristics firms. Thus, departs traditional analyses rely price volume data , like classical portfolio theory à la Markowitz (1952), high frequency trading. general broad treatment Machine Learning Finance, refer Matthew F. Dixon, Halperin, Bilokon (2020).topics discuss related themes covered monograph. themes include:Applications ML financial fields, fraud detection credit scoring. refer Ngai et al. (2011) Baesens, Van Vlasselaer, Verbeke (2015) general purpose fraud detection, Bhattacharyya et al. (2011) focus credit cards Ravisankar et al. (2011) Abbasi et al. (2012) studies fraudulent financial reporting. topic credit scoring, G. Wang et al. (2011) Brown Mues (2012) provide overviews methods empirical results. Also, cover ML algorithms data sampled higher (daily intraday) frequencies (microstructure models, limit order book). chapter Kearns Nevmyvaka (2013) recent paper Sirignano Cont (2019) good introductions topic.\nUse cases alternative datasets show leverage textual data social media, satellite imagery, credit card logs predict sales, earning reports, , ultimately, future returns. literature topic still emerging (see, e.g., Blank, Davis, Greene (2019), Jha (2019) Z. T. Ke, Kelly, Xiu (2019)) likely blossom near future.\nTechnical details machine learning tools. provide insights specificities approaches (believe important), purpose book serve reference manual statistical learning. refer Hastie, Tibshirani, Friedman (2009), Cornuejols, Miclet, Barra (2018) (written French), James et al. (2013) (coded R!) Mohri, Rostamizadeh, Talwalkar (2018) general treatment subject.1 Moreover, K.-L. Du Swamy (2013) Goodfellow et al. (2016) solid monographs neural networks particularly Sutton Barto (2018) provide self-contained comprehensive tour reinforcement learning.Finally, book cover methods natural language processing (NLP) can used evaluate sentiment can turn translated investment decisions. topic nonetheless trending lately refer Loughran McDonald (2016), Cong, Liang, Zhang (2019a), Cong, Liang, Zhang (2019b) Gentzkow, Kelly, Taddy (2019) recent advances matter.","code":""},{"path":"index.html","id":"the-targeted-audience","chapter":"Preface\n\n\n\n\n\n\n\n\n\n\n\n\n","heading":"The targeted audience\n\n\n\n\n\n\n\n\n\n\n\n\n","text":"read book? book intended two types audiences. First, postgraduate students wish pursue studies quantitative finance view towards investment asset management. second target groups professionals money management industry either seek pivot towards allocation methods based machine learning simply interested new tools want upgrade set competences. lesser extent, book can serve scholars researchers need manual broad spectrum references recent asset pricing issues machine learning algorithms applied money management. book covers mostly common methods, also shows implement exotic models, like causal graphs (Chapter 14), Bayesian additive trees (Chapter 9), hybrid autoencoders (Chapter 7).book assumes basic knowledge algebra (matrix manipulation), analysis (function differentiation, gradients), optimization (first second order conditions, dual forms), statistics (distributions, moments, tests, simple estimation method like maximum likelihood). minimal financial culture also required: simple notions like stocks, accounting quantities (e.g., book value) defined book. Lastly, examples illustrations coded R. minimal culture language sufficient understand code snippets rely heavily common functions tidyverse (Wickham et al. (2019), www.tidyverse.org), piping (Bache Wickham (2014), Mailund (2019)).","code":""},{"path":"index.html","id":"how-this-book-is-structured","chapter":"Preface\n\n\n\n\n\n\n\n\n\n\n\n\n","heading":"How this book is structured\n\n\n\n\n\n\n\n\n\n\n\n\n","text":"book divided four parts.Part gathers preparatory material starts notations data presentation (Chapter 1), followed introductory remarks (Chapter 2). Chapter 3 outlines economic foundations (theoretical empirical) factor investing briefly sums dedicated recent literature. Chapter 4 deals data preparation. rapidly recalls basic tips warns major issues.Part II book dedicated predictive algorithms supervised learning. common tools used forecast financial quantities (returns, volatilities, Sharpe ratios, etc.). range penalized regressions (Chapter 5), tree methods (Chapter 6), encompassing neural networks (Chapter 7), support vector machines (Chapter 8) Bayesian approaches (Chapter 9).next portion book bridges gap tools applications finance. Chapter 10 details assess improve ML engines defined beforehand. Chapter 11 explains models can combined often may good idea. Finally, one important chapters (Chapter 12) reviews critical steps portfolio backtesting mentions frequent mistakes often encountered stage.end book covers range advanced topics connected machine learning specifically. first one interpretability. ML models often considered black boxes raises trust issues: one trust ML-based predictions? Chapter 13 intended present methods help understand happening hood. Chapter 14 focused causality, much powerful concept correlation also heart many recent discussions Artificial Intelligence (AI). ML tools rely correlation-like patterns important underline benefits techniques related causality. Finally, Chapters 15 16 dedicated non-supervised methods. latter can useful, financial applications wisely cautiously motivated. ","code":""},{"path":"index.html","id":"companion-website","chapter":"Preface\n\n\n\n\n\n\n\n\n\n\n\n\n","heading":"Companion website\n\n\n\n\n\n\n\n\n\n\n\n\n","text":"book entirely available http://www.mlfactor.com. important content book accessible, also data code used throughout chapters. can found https://github.com/shokru/mlfactor.github.io/tree/master/material. online version book updated beyond publication printed version.","code":""},{"path":"index.html","id":"why-r","chapter":"Preface\n\n\n\n\n\n\n\n\n\n\n\n\n","heading":"Why R?\n\n\n\n\n\n\n\n\n\n\n\n\n","text":"supremacy Python dominant ML programming language widespread belief. almost applications deep learning (2020 one fashionable branches ML) coded Python via Tensorflow Pytorch.\nfact R lot offer well. First , let us forget one influencial textbooks ML (Hastie, Tibshirani, Friedman (2009)) written statisticians code R. Moreover, many statistics-orientated algorithms (e.g., BARTs Section 9.5) primarily coded R always Python. R offering Bayesian packages general (https://cran.r-project.org/web/views/Bayesian.html) Bayesian learning particular probably unmatched.currently several ML frameworks available R.\ncaret: https://topepo.github.io/caret/index.html, compilation 200 ML models;\ntidymodels: https://github.com/tidymodels, recent collection packages ML workflow (developed Max Kuhn RStudio, token high quality material!);\nrtemis: https://rtemis.netlify.com, general purpose package ML visualization;\nmlr3: https://mlr3.mlr-org.com/index.html, also simple framework ML models;\nh2o: https://github.com/h2oai/h2o-3/tree/master/h2o-r, large set tools provided h2o (coded Java);\nOpen ML: https://github.com/openml/openml-r, R version OpenML (www.openml.org) community.Moreover, via reticulate package, possible (always easy) benefit Python tools well. prominent example adaptation tensorflow keras libraries R. Thus, advanced Python material readily available R users. also true resources, like Stanford’s CoreNLP library (Java) adapted R package coreNLP (use book).","code":""},{"path":"index.html","id":"coding-instructions","chapter":"Preface\n\n\n\n\n\n\n\n\n\n\n\n\n","heading":"Coding instructions\n\n\n\n\n\n\n\n\n\n\n\n\n","text":"One purposes book propose large-scale tutorial ML applications financial predictions portfolio selection. Thus, one keyword REPRODUCIBILITY! order duplicate results (possible randomness learning algorithms), need running versions R RStudio computer. best books learn R also often freely available online. short list can found https://rstudio.com/resources/books/. monograph R Data Science probably crucial.terms coding requirements, rely heavily tidyverse, collection packages (libraries). three packages use dplyr implements simple data manipulations (filter, select, arrange), tidyr formats data tidy fashion, ggplot, graphical outputs.list packages use can found Table 0.1 . Packages star \\(*\\) need installed via bioconductor.2 Packages plus \\(^+\\) need installed manually.3\nTABLE 0.1:  List packages used book.packages (collections thereof), tidyverse lubridate compulsory almost sections book. install new package R, just typeinstall.packages(“name_of_the_package”)console. Sometimes, function name conflicts (especially select() function), use syntax package::function() make sure function call right source. exact version packages used compile book listed “renv.lock” file available book’s GitHub web page https://github.com/shokru/mlfactor.github.io. One minor comment following: functions gather() spread() dplyr package superseded pivot_longer() pivot_wider(), still use much compact syntax.much , created short code chunks commented line whenever felt useful. Comments displayed end row preceded single hastag #.book constructed big notebook, thus results often presented code chunks. can graphs tables. Sometimes, simple numbers preceded two hashtags ##. example illustrates formatting.book can viewed big tutorial. Therefore, chunks depend previously defined variables. replicating parts code (via online code), please make sure environment includes relevant variables. One best practice always start running code chunks Chapter 1. exercises, often resort variables created corresponding chapters.","code":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n1+2 # Example## [1] 3"},{"path":"index.html","id":"acknowledgments","chapter":"Preface\n\n\n\n\n\n\n\n\n\n\n\n\n","heading":"Acknowledgments\n\n\n\n\n\n\n\n\n\n\n\n\n","text":"core book prepared series lectures given one authors students master’s degrees finance EMLYON Business School Imperial College Business School Spring 2019. grateful students asked fruitful questions thereby contributed improve content book.grateful Bertrand Tavin Gautier Marti thorough screening book. also thank Eric André, Aurélie Brossard, Alban Cousin, Frédérique Girod, Philippe Huber, Jean-Michel Maeso, Javier Nogales friendly reviews; Christophe Dervieux help bookdown; Mislav Sagovac Vu Tran early feedback; John Kimmel making happen Jonathan Regenstein availability, matter topic. Lastly, grateful anonymous reviews collected John.","code":""},{"path":"index.html","id":"future-developments","chapter":"Preface\n\n\n\n\n\n\n\n\n\n\n\n\n","heading":"Future developments\n\n\n\n\n\n\n\n\n\n\n\n\n","text":"Machine learning factor investing two immense research domains overlap two also quite substantial developing fast pace. content book always constitute solid background, naturally destined obsolescence. Moreover, construction, subtopics many references escaped scrutiny. intent progressively improve content book update latest ongoing research. grateful comment helps correct update monograph. Thank sending feedback directly (via pull requests) book’s website hosted https://github.com/shokru/mlfactor.github.io.","code":""},{"path":"notdata.html","id":"notdata","chapter":"1 Notations and data","heading":"1 Notations and data","text":"","code":""},{"path":"notdata.html","id":"notations","chapter":"1 Notations and data","heading":"1.1 Notations","text":"section aims providing formal mathematical conventions used throughout book.Bold notations indicate vectors matrices. use capital letters matrices lower case letters vectors.\n\\(\\mathbf{v}'\\) \\(\\mathbf{M}'\\) denote transposes \\(\\mathbf{v}\\) \\(\\mathbf{M}\\). \\(\\mathbf{M}=[m]_{,j}\\), \\(\\) row index \\(j\\) column index.work two notations parallel. first one pure machine learning notation labels (also called output, dependent variables predicted variables) \\(\\mathbf{y}=y_i\\) approximated functions features \\(\\mathbf{X}_i=(x_{,1},\\dots,x_{,K})\\). dimension feature matrix \\(\\mathbf{X}\\) \\(\\times K\\): \\(\\) instances, records, observations one \\(K\\) attributes, features, inputs, predictors serve independent explanatory variables (terms used interchangeably). Sometimes, ease notations, write \\(\\textbf{x}_i\\) one instance (one row) \\(\\textbf{X}\\) \\(\\textbf{x}_k\\) one (feature) column vector \\(\\textbf{X}\\).second notation type pertains finance directly relate first. often work discrete returns \\(r_{t,n}=p_{t,n}/p_{t-1,n}-1\\) computed price data. \\(t\\) time index \\(n\\) asset index. Unless specified otherwise, return always computed one period, though period can sometimes one month one year. Whenever confusion might occur, specify notations returns.line previous conventions, number return dates \\(T\\) number assets, \\(N\\). features characteristics assets denoted \\(x_{t,n}^{(k)}\\): time-\\(t\\) value \\(k^{th}\\) attribute firm asset \\(n\\). stacked notation, \\(\\mathbf{x}_{t,n}\\) stand vector characteristics asset \\(n\\) time \\(t\\). Moreover, \\(\\mathbf{r}_t\\) stands returns time \\(t\\) \\(\\mathbf{r}_n\\) stands returns asset \\(n\\). Often, returns play role dependent variable, label (ML terms). riskless asset, use notation \\(r_{t,f}\\).link two notations time following. One instance (observation)   \\(\\) consist one couple (\\(t,n\\)) one particular date one particular firm (data perfectly rectangular missing field, \\(=T\\times N\\)). label usually performance measure firm computed future period, features consist firm attributes time \\(t\\). Hence, purpose machine learning engine factor investing determine model maps time-\\(t\\) characteristics firms future performance.terms canonical matrices: \\(\\mathbf{}_N\\) denote \\((N\\times N)\\) identity matrix.probabilistic literature, employ expectation operator \\(\\mathbb{E}[\\cdot]\\) conditional expectation \\(\\mathbb{E}_t[\\cdot]\\), corresponding filtration \\(\\mathcal{F}_t\\) corresponds information available time \\(t\\). precisely, \\(\\mathbb{E}_t[\\cdot]=\\mathbb{E}[\\cdot | \\mathcal{F}_t]\\). \\(\\mathbb{V}[\\cdot]\\) denote variance operator. Depending context, probabilities written simply \\(P\\), sometimes use heavier notation \\(\\mathbb{P}\\). Probability density functions (pdfs) denoted lowercase letters (\\(f\\)) cumulative distribution functions (cdfs) uppercase letters (\\(F\\)). write equality distribution \\(X \\overset{d}{=}Y\\), equivalent \\(F_X(z)=F_Y(z)\\) \\(z\\) support variables. random process \\(X_t\\), say stationary law \\(X_t\\) constant time, .e., \\(X_t\\overset{d}{=}X_s\\), \\(\\overset{d}{=}\\) means equality distribution.Sometimes, asymptotic behaviors characterized usual Landau notation \\(o(\\cdot)\\) \\(O(\\cdot)\\). symbol \\(\\propto\\) refers proportionality: \\(x\\propto y\\) means \\(x\\) proportional \\(y\\). respect derivatives, use standard notation \\(\\frac{\\partial}{\\partial x}\\) differentiating respect \\(x\\). resort compact symbol \\(\\nabla\\) derivatives computed (gradient vector).equations, left-hand side right-hand side can written compactly: l.h.s. r.h.s., respectively.Finally, turn functions. list :\n- \\(1_{\\{x \\}}\\): indicator function condition \\(x\\), equal one \\(x\\) true zero otherwise.\n- \\(\\phi(\\cdot)\\) \\(\\Phi(\\cdot)\\) standard Gaussian pdf cdf.\n- card\\((\\cdot)=\\#(\\cdot)\\) two notations cardinal function evaluates number elements given set (provided argument function).\n- \\(\\lfloor \\cdot \\rfloor\\) integer part function.\n- real number \\(x\\), \\([x]^+\\) positive part \\(x\\), \\(\\max(0,x)\\).\n- tanh\\((\\cdot)\\) hyperbolic tangent: tanh\\((x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}\\).\n- ReLu\\((\\cdot)\\) rectified linear unit: ReLu\\((x)=\\max(0,x)\\).\n- s\\((\\cdot)\\) softmax function: \\(s(\\textbf{x})_i=\\frac{e^{x_i}}{\\sum_{j=1}^Je^{x_j}}\\), subscript \\(\\) refers \\(^{th}\\) element vector.","code":""},{"path":"notdata.html","id":"dataset","chapter":"1 Notations and data","heading":"1.2 Dataset","text":"Throughout book, sake reproducibility, illustrate concepts present examples implementation based single financial dataset available https://github.com/shokru/mlfactor.github.io/tree/master/material. dataset comprises information 1,207 stocks listed US (possibly originating Canada Mexico). time range starts November 1998 ends March 2019. point time, 93 characteristics describe firms sample. attributes cover wide range topics:valuation (earning yields, accounting ratios);profitability quality (return equity);momentum technical analysis (past returns, relative strength index);risk (volatilities);estimates (earnings-per-share);volume liquidity (share turnover).sample perfectly rectangular: missing points, number firms attributes constant time. makes computations backtest tricky, also realistic.data 99 columns 268336 rows. first two columns indicate stock identifier date. next 93 columns features (see Table 17.1 Appendix details). last four columns labels. points sampled monthly frequency. always case practice, number assets changes time, shown Figure 1.1.\nFIGURE 1.1: Number assets time.\nfour immediate labels dataset: R1M_Usd, R3M_Usd, R6M_Usd R12M_Usd, correspond 1-month, 3-month, 6-month 12-month future/forward returns stocks. returns total returns, , incorporate potential dividend payments considered periods. better proxy financial gain compared price returns . refer analysis Hartzmark Solomon (2019) study impact decoupling price returns dividends. labels located last 4 columns dataset. provide descriptive statistics .anticipation future models, keep name predictors memory. addition, also keep much shorter list predictors.predictors uniformized, , given feature time point, distribution uniform. Given 1,207 stocks, graph display perfect rectangle.\nFIGURE 1.2: Distribution dividend yield feature date 2000-02-29.\noriginal labels (future returns) numerical used regression exercises, , objective predict scalar real number. Sometimes, exercises can different purpose may forecast categories (also called classes), like “buy,” “hold” “sell.” order able perform type classification analysis, create additional labels categorical.new labels binary: equal 1 (true) original return median return considered period 0 (false) . Hence, point time, half sample label equal zero half one: stocks overperform others underperform.machine learning, models estimated one portion data (training set) tested another portion data (testing set) assess quality. split sample accordingly.also keep memory key variables, like list asset identifiers rectangular version returns. simplicity, computation latter, shrink investment universe keep stocks maximum number points.","code":"\nlibrary(tidyverse)                      # Activate the data science package\nlibrary(lubridate)                      # Activate the date management package\nload(\"data_ml.RData\")                   # Load the data\ndata_ml <- data_ml %>% \n    filter(date > \"1999-12-31\",         # Keep the date with sufficient data points\n           date < \"2019-01-01\") %>%\n    arrange(stock_id, date)             # Order the data\ndata_ml[1:6, 1:6]                       # Sample values## # A tibble: 6 × 6\n##   stock_id date       Advt_12M_Usd Advt_3M_Usd Advt_6M_Usd Asset_Turnover\n##      <int> <date>            <dbl>       <dbl>       <dbl>          <dbl>\n## 1        1 2000-01-31         0.41        0.39        0.42           0.19\n## 2        1 2000-02-29         0.41        0.39        0.4            0.19\n## 3        1 2000-03-31         0.4         0.37        0.37           0.2 \n## 4        1 2000-04-30         0.39        0.36        0.37           0.2 \n## 5        1 2000-05-31         0.4         0.42        0.4            0.2 \n## 6        1 2000-06-30         0.41        0.47        0.42           0.21\ndata_ml  %>% \n    group_by(date) %>%                                   # Group by date\n    summarize(nb_assets = stock_id %>%                   # Count nb assets\n                  as.factor() %>% nlevels()) %>%\n    ggplot(aes(x = date, y = nb_assets)) + geom_col() +  # Plot\n    theme_light() + coord_fixed(3)## # A tibble: 4 × 5\n##   Label      mean    sd    min   max\n##   <chr>     <dbl> <dbl>  <dbl> <dbl>\n## 1 R12M_Usd 0.137  0.738 -0.991  96.0\n## 2 R1M_Usd  0.0127 0.176 -0.922  30.2\n## 3 R3M_Usd  0.0369 0.328 -0.929  39.4\n## 4 R6M_Usd  0.0723 0.527 -0.98  107.\nfeatures <- colnames(data_ml[3:95]) # Keep the feature's column names (hard-coded, beware!)\nfeatures_short <- c(\"Div_Yld\", \"Eps\", \"Mkt_Cap_12M_Usd\", \"Mom_11M_Usd\", \n                    \"Ocf\", \"Pb\", \"Vol1Y_Usd\")\ndata_ml %>%\n    filter(date == \"2000-02-29\") %>%\n    ggplot(aes(x = Div_Yld)) + geom_histogram(bins = 100) + \n    theme_light() + coord_fixed(0.03)\ndata_ml <- data_ml %>% \n    group_by(date) %>%                                   # Group by date\n    mutate(R1M_Usd_C = R1M_Usd > median(R1M_Usd),        # Create the categorical labels\n           R12M_Usd_C = R12M_Usd > median(R12M_Usd)) %>%\n    ungroup() %>%\n    mutate_if(is.logical, as.factor)\nseparation_date <- as.Date(\"2014-01-15\")\ntraining_sample <- filter(data_ml, date < separation_date)\ntesting_sample <- filter(data_ml, date >= separation_date)\nstock_ids <- levels(as.factor(data_ml$stock_id)) # A list of all stock_ids\nstock_days <- data_ml %>%                        # Compute the number of data points per stock\n    group_by(stock_id) %>% summarize(nb = n()) \nstock_ids_short <- stock_ids[which(stock_days$nb == max(stock_days$nb))] # Stocks with full data\nreturns <- data_ml %>%                           # Compute returns, in matrix format, in 3 steps:\n    filter(stock_id %in% stock_ids_short) %>%    # 1. Filtering the data\n    dplyr::select(date, stock_id, R1M_Usd) %>%   # 2. Keep returns along with dates & firm names\n    pivot_wider(names_from = \"stock_id\", \n                values_from = \"R1M_Usd\")         # 3. Put in matrix shape "},{"path":"intro.html","id":"intro","chapter":"2 Introduction","heading":"2 Introduction","text":"Conclusions often echo introductions. chapter completed end writing book. outlines principles ideas probably relevant sum technical details covered subsequently. stuck disappointing results, advise reader take step away algorithm come back section get broader perspective issues predictive modelling.","code":""},{"path":"intro.html","id":"context","chapter":"2 Introduction","heading":"2.1 Context","text":"blossoming machine learning factor investing source confluence three favorable developments: data availability, computational capacity, economic groundings.First, data. Nowadays, classical providers, Bloomberg Reuters seen playing field invaded niche players aggregation platforms.4 addition, high-frequency data derivative quotes become mainstream. Hence, firm-specific attributes easy often cheap compile. means size \\(\\mathbf{X}\\) (2.1) now sufficiently large plugged ML algorithms. order magnitude (2019) can reached following: hundred monthly observations several thousand stocks (US listed least) covering hundred attributes. makes dataset dozens millions points. reasonably high figure, highlight chronological depth probably weak point remain decades come accounting figures released quarterly basis. Needless say drawback hold high-frequency strategies.Second, computational power, hardware software. Storage processing speed technical hurdles anymore models can even run cloud thanks services hosted major actors (Amazon, Microsoft, IBM Google) smaller players (Rackspace, Techila). software side, open source become norm, funded corporations (TensorFlow & Keras Google, Pytorch Facebook, h2o, etc.), universities (Scikit-Learn INRIA, NLPCore Stanford, NLTK UPenn) small groups researchers (caret, xgboost, tidymodels list pair frameworks). Consequently, ML longer private turf handful expert computer scientists, contrary accessible anyone willing learn code.Finally, economic framing. Machine learning applications finance initially introduced computer scientists information system experts (e.g., Braun Chandler (1987), White (1988)) exploited shortly academics financial economics (Bansal Viswanathan (1993)), hedge funds (see, e.g., Zuckerman (2019)). Nonlinear relationships became mainstream asset pricing (Freeman Tse (1992), Bansal, Hsieh, Viswanathan (1993)). contributions started pave way brute-force approaches blossomed since 2010 decade mentioned throughout book.synthetic proposal R. Arnott, Harvey, Markowitz (2019), first piece advice rely model makes sense economically. agree stance, assumption make book future returns depend firm characteristics. relationship features performance largely unknown probably time-varying. ML can useful: detect hidden patterns beyond documented asset pricing anomalies. Moreover, dynamic training allows adapt changing market conditions.","code":""},{"path":"intro.html","id":"portfolio-construction-the-workflow","chapter":"2 Introduction","heading":"2.2 Portfolio construction: the workflow","text":"Building successful portfolio strategies requires many steps. book covers many focuses predominantly prediction part. Indeed, allocating assets time requires make bets thus presage foresee ones well ones . book, mostly resort supervised learning forecast returns cross-section. baseline equation supervised learning,\\[\\begin{equation}\n\\mathbf{y}=f(\\mathbf{X})+\\mathbf{\\epsilon},\n\\tag{2.1}\n\\end{equation}\\]translated financial terms \\[\\begin{equation}\n\\mathbf{r}_{t+1,n}=f(\\mathbf{x}_{t,n})+\\mathbf{\\epsilon}_{t+1,n},\n\\tag{2.2}\n\\end{equation}\\]\n\\(f(\\mathbf{x}_{t,n})\\) can viewed expected return time \\(t+1\\) computed time \\(t\\), , \\(\\mathbb{E}_t[r_{t+1,n}]\\). Note model common assets (\\(f\\) indexed \\(n\\)), thus shares similarity panel approaches.Building accurate predictions requires pay attention terms equation. Chronologically, first step gather data process (see Chapter 4). best knowledge, consensus , \\(\\textbf{x}\\) side, features include classical predictors reported literature: market capitalization, accounting ratios, risk measures, momentum proxies (see Chapter 3). dependent variable, many researchers practitioners work monthly returns, maturities may perform better --sample.tempting believe crucial part choice \\(f\\) (sophisticated, mathematically), believe choice engineering inputs, , variables, least important. usual modelling families \\(f\\) covered Chapters 5 9. Finally, errors \\(\\mathbf{\\epsilon}_{t+1,n}\\) often overlooked. People consider vanilla quadratic programming best way go (common sure!), thus mainstream objective minimize squared errors. fact, options may wiser choices (see instance Section 7.4.3).Even overall process, depicted Figure 2.1, seems sequential, judicious conceive integrated. steps intertwined part dealt independently others.5 global framing problem essential, choice predictors, family algorithms, mention portfolio weighting schemes (see Chapter 12 latter).\nFIGURE 2.1: Simplified workflow ML-based portfolio construction.\n","code":""},{"path":"intro.html","id":"machine-learning-is-no-magic-wand","chapter":"2 Introduction","heading":"2.3 Machine learning is no magic wand","text":"definition, curse predictions rely past data infer patterns subsequent fluctuations. less explicit hope forecaster past turn good approximation future. Needless say, pious wish; general, predictions fare badly. Surprisingly, depend much sophistication econometric tool. fact, heuristic guesses often hard beat.illustrate sad truth, baseline algorithms detail Chapters 5 7 yield best mediocre results. done purpose. forces reader understand blindly feeding data parameters coded function seldom suffice reach satisfactory --sample accuracy., sum key points learned exploratory journey financial ML.first point causality key. one able identify \\(X \\rightarrow y\\), \\(y\\) expected returns, problem solved. Unfortunately, causality incredibly hard uncover.Thus, researchers time make simple correlation patterns, far less informative robust.Relatedly, financial datasets extremely noisy. daunting task extract signals . -arbitrage reasonings imply simple pattern yielded durable profits, mechanically rapidly vanish.-free lunch theorem Wolpert (1992a) imposes analyst formulates views model. economic econometric framing key. assumptions choices made regarding dependent variables explanatory features decisive. corollary, data key. inputs given models probably much important choice model .maximize --sample efficiency, right question probably paraphrase Jeff Bezos: ’s going change? Persistent series likely unveil enduring patterns.Everybody makes mistakes. Errors loops variable indexing part journey. matters learn lapses.conclude, remind reader obvious truth: nothing ever replace practice. Gathering cleaning data, coding backtests, tuning ML models, testing weighting schemes, debugging, starting : absolutely indispensable steps tasks must repeated indefinitely. substitute experience.","code":""},{"path":"factor.html","id":"factor","chapter":"3 Factor investing and asset pricing anomalies","heading":"3 Factor investing and asset pricing anomalies","text":"Asset pricing anomalies foundations factor investing. chapter aim twofold:present simple ideas concepts: basic factor models common empirical facts (time-varying nature returns risk premia);provide reader lists articles go much deeper stimulate satisfy curiosity.purpose chapter provide full treatment many topics related factor investing. Rather, intended give broad overview cover essential themes reader guided towards relevant references. , can serve short, non-exhaustive, review literature. subject factor modelling finance incredibly vast number papers dedicated substantial still rapidly increasing.universe peer-reviewed financial journals can split two. first kind academic journals. articles mostly written professors, audience consists mostly scholars. articles long often technical. Prominent examples Journal Finance, Review Financial Studies Journal Financial Economics. second type practitioner-orientated. papers shorter, easier read, target finance professionals predominantly. Two emblematic examples Journal Portfolio Management Financial Analysts Journal. chapter reviews mentions articles published essentially first family journals.Beyond academic articles, several monographs already dedicated topic style allocation (synonym factor investing used instance theoretical articles (Barberis Shleifer (2003)) practitioner papers (Clifford Asness et al. (2015))). cite , mention:Ilmanen (2011): exhaustive excursion risk premia, across many asset classes, large spectrum descriptive statistics (across factors periods),Ang (2014): covers factor investing strong focus money management industry,Bali, Engle, Murray (2016): complete book cross-section signals statistical analyses (univariate metrics, correlations, persistence, etc.),Jurczenko (2017): tour various topics given field experts (factor purity, predictability, selection versus weighting, factor timing, etc.).Finally, mention wide-scope papers topic: Goyal (2012), Cazalet Roncalli (2014) Baz et al. (2015).","code":""},{"path":"factor.html","id":"introduction","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.1 Introduction","text":"topic factor investing, though decades-old academic theme, gained traction concurrently rise equity traded funds (ETFs) vectors investment. gathered momentum 2010 decade. surprisingly, feedback loop practical financial engineering academic research stimulated sides mutually beneficial manner. Practitioners rely key scholarly findings (e.g., asset pricing anomalies) researchers dig deeper pragmatic topics (e.g., factor exposure transaction costs). Recently, researchers also tried quantify qualify impact factor indices financial markets. instance, Krkoska Schenk-Hoppé (2019) analyze herding behaviors Cong Xu (2019) show introduction composite securities increases volatility cross-asset correlations.core aim factor models understand drivers asset prices. Broadly speaking, rationale behind factor investing financial performance firms depends factors, whether latent unobservable, related intrinsic characteristics (like accounting ratios instance). Indeed, Cochrane (2011) frames , first essential question characteristics really provide independent information average returns? Answering question helps understand cross-section returns may open door prediction.Theoretically, linear factor models can viewed special cases arbitrage pricing theory (APT) Ross (1976), assumes return asset \\(n\\) can modelled linear combination underlying factors \\(f_k\\):\n\\[\\begin{equation}\n\\tag{3.1}\nr_{t,n}= \\alpha_n+\\sum_{k=1}^K\\beta_{n,k}f_{t,k}+\\epsilon_{t,n}, \n\\end{equation}\\]usual econometric constraints linear models hold: \\(\\mathbb{E}[\\epsilon_{t,n}]=0\\), \\(\\text{cov}(\\epsilon_{t,n},\\epsilon_{t,m})=0\\) \\(n\\neq m\\) \\(\\text{cov}(\\textbf{f}_n,\\boldsymbol{\\epsilon}_n)=0\\). factors exist, contradiction cornerstone model asset pricing: capital asset pricing model (CAPM) Sharpe (1964), Lintner (1965) Mossin (1966). Indeed, according CAPM, driver returns market portfolio. explains factors also called ‘anomalies.’ Pesaran Smith (2021), authors define strength factors using sum squared \\(\\beta_{n,k}\\) (across firms).Empirical evidence asset pricing anomalies accumulated since dual publication Fama French (1992) Fama French (1993). seminal work paved way blossoming stream literature meta-studies (e.g., Green, Hand, Zhang (2013), C. R. Harvey, Liu, Zhu (2016) McLean Pontiff (2016)). regression (3.1) can evaluated (unconditionally) sequentially different time frames. latter case, parameters (coefficient estimates) change models thus called conditional (refer Ang Kristensen (2012) Cooper Maio (2019) recent results topic well detailed review related research). Conditional models flexible acknowledge drivers asset prices may constant, seems like reasonable postulate.","code":""},{"path":"factor.html","id":"detecting-anomalies","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.2 Detecting anomalies","text":"","code":""},{"path":"factor.html","id":"challenges","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.2.1 Challenges","text":"Obviously, crucial step able identify anomaly complexity task underestimated. Given publication bias towards positive results (see, e.g., C. R. Harvey (2017) financial economics), researchers often tempted report partial results sometimes invalidated studies. need replication therefore high many findings tomorrow (Linnainmaa Roberts (2018), Johannesson, Ohlson, Zhai (2020), Cakici Zaremba (2021)), especially transaction costs taken account (Patton Weller (2020), . Y. Chen Velikov (2020)). Nevertheless, demonstrated . Y. Chen (2019), \\(p\\)-hacking alone account anomalies documented literature. One way reduce risk spurious detection increase hurdles (often, \\(t\\)-statistics) debate still ongoing (C. R. Harvey, Liu, Zhu (2016), . Y. Chen (2020a), C. R. Harvey Liu (2021)), resort multiple testing (C. R. Harvey, Liu, Saretto (2020), Vincent, Hsu, Lin (2020)). Nevertheless, large sample sizes used finance may mechanically lead low \\(p\\)-values refer Michaelides (2020) discussion topic.researchers document fading anomalies publication: anomaly becomes public, agents invest , pushes prices anomaly disappears. McLean Pontiff (2016) Shanaev Ghimire (2020) document effect US H. Jacobs Müller (2020) find countries experience sustained post-publication factor returns (see also Zaremba, Umutlu, Maydubura (2020)). different methodology, . Y. Chen Zimmermann (2020) introduce publication bias adjustment returns authors note (negative) adjustment fact rather small. Likewise, . Y. Chen (2020b) finds \\(p\\)-hacking responsible anomalies reported literature.\nPenasse (2019) recommends notion alpha decay study persistence attenuation anomalies (see also Falck, Rej, Thesmar (2021) matter). Horenstein (2020) even builds model agents invest according anomalies reporting academic research.destruction factor premia may due herding (Krkoska Schenk-Hoppé (2019), Volpati et al. (2020)) accelerated democratization -called smart-beta products (ETFs notably) allow investors directly invest particular styles (value, low volatility, etc.) - see S. Huang, Song, Xiang (2020). theoretical perspective attractiveness factor investing, refer Jin (2019) impact active fund industry, Densmore (2021). empirical study links crowding factor returns point Kang, Rouwenhorst, Tang (2021). D. H. Bailey Lopez de Prado (2021) (via Brightman, Li, Liu (2015)) recall launch, ETFs report 5% excess return, experience 0% return average posterior launch.hand, DeMiguel, Martin Utrera, Uppal (2019) argue price impact crowding smart-beta universe mitigated trading diversification stemming external institutions trade according strategies outside space (e.g., high frequency traders betting via order-book algorithms).remainder subsection inspired Baker, Luo, Taliaferro (2017) C. Harvey Liu (2019).","code":""},{"path":"factor.html","id":"simple-portfolio-sorts","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.2.2 Simple portfolio sorts  ","text":"common procedure one used Fama French (1992). idea simple. one date,rank firms according particular criterion (e.g., size, book--market ratio);form \\(J\\ge 2\\) portfolios (.e., homogeneous groups) consisting number stocks according ranking (usually, \\(J=2\\), \\(J=3\\), \\(J=5\\) \\(J=10\\) portfolios built, based median, terciles, quintiles deciles criterion);weight stocks inside portfolio either uniform (equal weights), proportional market capitalization;future date (usually one month), report returns portfolios.\n, iterate procedure chronological end sample reached.outcome time series portfolio returns \\(r_t^j\\) grouping \\(j\\). anomaly identified \\(t\\)-test first (\\(j=1\\)) last group (\\(j=J\\)) unveils significant difference average returns. robust tests described Cattaneo et al. (2020). strong limitation approach sorting criterion non-monotonic impact returns test based two extreme portfolios detect . Several articles address concern: Patton Timmermann (2010) Romano Wolf (2013) instance. Another concern sorted portfolios may capture priced risk associated characteristic, also unpriced risk. K. Daniel et al. (2020) show possible disentangle two make altered sorted portfolios.Instead focusing one criterion, possible group asset according characteristics. original paper Fama French (1992) also combines market capitalization book--market ratios. characteristic divided 10 buckets, makes 100 portfolios total. Beyond data availability, upper bound number features can included sorting process. fact, authors investigate complex sorting algorithms can manage potentially large number characteristics (see e.g., Feng, Polson, Xu (2019) Bryzgalova, Pelger, Zhu (2019)).Finally, refer Olivier Ledoit, Wolf, Zhao (2020) refinements take account covariance structure asset returns Cattaneo et al. (2020) theoretical study statistical properties sorting procedure (including theoretical links regression-based approaches). Notably, latter paper discusses optimal number portfolios suggests probably larger usual 10 often used literature.code Figure 3.1 , compute size portfolios (equally weighted: versus median capitalization). According size anomaly, firms median market cap earn higher returns average. verified whenever orange bar plot blue one (happens time).\nFIGURE 3.1: size factor: average returns small versus large firms.\n","code":"\ndata_ml %>%\n    group_by(date) %>%                                            \n    mutate(large = Mkt_Cap_12M_Usd > median(Mkt_Cap_12M_Usd)) %>% # Creates the cap sort\n    ungroup() %>%                                                 # Ungroup\n    mutate(year = lubridate::year(date)) %>%                      # Creates a year variable\n    group_by(year, large) %>%                                     # Analyze by year & cap\n    summarize(avg_return = mean(R1M_Usd)) %>%                     # Compute average return\n    ggplot(aes(x = year, y = avg_return, fill = large)) +         # Plot!\n    geom_col(position = \"dodge\") + theme_light() +                # Bars side-to-side\n    theme(legend.position = c(0.8, 0.2)) +                        # Legend location\n    coord_fixed(124) + theme(legend.title=element_blank()) +      # x/y aspect ratio\n    scale_fill_manual(values=c(\"#F87E1F\", \"#0570EA\"), name = \"\",  # Colors\n                      labels=c(\"Small\", \"Large\"))  +\n    ylab(\"Average returns\") + theme(legend.text=element_text(size=9)) "},{"path":"factor.html","id":"factors","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.2.3 Factors","text":"construction -called factors follows lines . Portfolios based one characteristic factor long-short ensemble one extreme portfolio minus opposite extreme (small minus large size factor high book--market ratio minus low book--market ratio value factor). Sometimes, subtleties include forming bivariate sorts aggregating several portfolios together, original contribution Fama French (1993). common factors listed , along references. refer books listed beginning chapter exhaustive treatment factor idiosyncrasies. anomalies, theoretical justifications brought forward, whether risk-based behavioral. list frequently cited factors :Size (SMB = small firms minus large firms): Banz (1981), Fama French (1992), Fama French (1993), Van Dijk (2011), Clifford Asness et al. (2018) Astakhov, Havranek, Novak (2019).Value (HML = high minus low: undervalued minus `growth’ firms): Fama French (1992), Fama French (1993), C. S. Asness, Moskowitz, Pedersen (2013). See Israel, Laursen, Richardson (2020) Roca (2021) recent discussions.Momentum (WML = winners minus losers): Jegadeesh Titman (1993), Carhart (1997) C. S. Asness, Moskowitz, Pedersen (2013). winners assets experienced highest returns last year (sometimes computation return truncated omit last month). Cross-sectional momentum linked, equivalent, time series momentum (trend following), see e.g., Moskowitz, Ooi, Pedersen (2012) Lempérière et al. (2014). Momentum also related contrarian movements occur higher lower frequencies (short-term long-term reversals), see Luo, Subrahmanyam, Titman (2020).Profitability (RMW = robust minus weak profits): Fama French (2015), Bouchaud et al. (2019). former reference, profitability measured (revenues - (cost expenses))/equity.Investment (CMA = conservative minus aggressive): Fama French (2015), Hou, Xue, Zhang (2015). Investment measured via growth total assets (divided total assets). Aggressive firms experience largest growth assets.Low `risk’ (sometimes, BAB = betting beta): Ang et al. (2006), Baker, Bradley, Wurgler (2011), Frazzini Pedersen (2014), Boloorforoosh et al. (2020), Baker, Hoeyer, Wurgler (2020) Cliff Asness et al. (2020). case, computation risk changes one article (simple volatility, market beta, idiosyncratic volatility, etc.).notable exception low risk premium, mainstream anomalies kept updated data library Kenneth French (https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html). course, computation factors follows particular set rules, generally accepted academic sphere. Another source data AQR repository: https://www.aqr.com/Insights/Datasets.dataset use book, proxy value anomaly book--market ratio price--book ratio (book value located denominator). shown Clifford Asness Frazzini (2013), choice variable value can sizable effects., import data Ken French’s data library. word caution: data updated frequently sometimes, experiences methodological changes. refer Akey, Robertson, Simutin (2021) study changes common Fama-French factors. use data later chapter.\nTABLE 3.1: Sample monthly factor returns.\nPosterior discovery stylized facts, contributions aimed building theoretical models capture properties. cite handful :size value: Berk, Green, Naik (1999), K. D. Daniel, Hirshleifer, Subrahmanyam (2001), Barberis Shleifer (2003), Gomes, Kogan, Zhang (2003), Carlson, Fisher, Giammarino (2004), R. D. Arnott et al. (2014);momentum: T. C. Johnson (2002), Grinblatt Han (2005), Vayanos Woolley (2013), Choi Kim (2014).addition, recent bridges built risk-based factor representations behavioural theories. refer essentially Barberis, Mukherjee, Wang (2016) K. Daniel, Hirshleifer, Sun (2020) references therein.factors (.e., long-short portfolios) exhibit time-varying risk premia magnified corporate news announcements (Engelberg, McLean, Pontiff (2018)), well-documented (accepted) deliver positive returns long horizons.6 refer Gagliardini, Ossola, Scaillet (2016) survey Gagliardini, Ossola, Scaillet (2019), well related bibliography technical details estimation procedures risk premia corresponding empirical results. Large sample studies documents regime changes factor premia also carried Ilmanen et al. (2019), S. Smith Timmermann (2021) Chib, Zhao, Zhou (2021). Moreover, predictability returns also time-varying (documented Farmer, Schmidt, Timmermann (2019), Tsiakas, Li, Zhang (2020) Liu, Pan, Wang (2020)), estimation methods can improved (T. L. Johnson (2019)).Figure 3.2, plot average monthly return aggregated calendar year five common factors. risk free rate (factor per se) stable, market factor (aggregate market returns minus risk-free rate) volatile. makes sense long equity factor among five series.\nFIGURE 3.2: Average returns common anomalies (1963-2020). Source: Ken French library.\nindividual attributes investors allocate towards particular factors blossoming topic. list references , even though somewhat lie scope book. Betermier, Calvet, Sodini (2017) show value investors older, wealthier face lower income risk compared growth investors best position take financial risks. study Cronqvist, Siegel, Yu (2015) leads different conclusions: finds propensity invest value versus growth assets roots genetics life events (latter effect confirmed Cocco, Gomes, Lopes (2020), former detailed general context Cronqvist et al. (2015)). Psychological traits can also explain factors: agents extrapolate, likely fuel momentum (topic thoroughly reviewed Barberis (2018)). Micro- macro-economic consequences preferences detailed Bhamra Uppal (2019). conclude paragraph, mention theoretical models also proposed link agents’ preferences beliefs (via prospect theory) market anomalies (see instance Barberis, Jin, Wang (2020)).Finally, highlight need replicability factor premia echo recent editorial C. R. Harvey (2020). shown Linnainmaa Roberts (2018) Hou, Xue, Zhang (2020), many proclaimed factors fact much data-dependent often fail deliver sustained profitability investment universe altered definition variable changes (Clifford Asness Frazzini (2013)).Campbell Harvey co-authors, series papers, tried synthesize research factors C. R. Harvey, Liu, Zhu (2016), C. Harvey Liu (2019) C. R. Harvey Liu (2019). work underlines need set high bars anomaly called ‘true’ factor. Increasing thresholds \\(p\\)-values partial answer, always possible resort data snooping order find optimized strategy fail --sample deliver \\(t\\)-statistic larger three (even four). C. R. Harvey (2017) recommends resort Bayesian approach blends data-based significance prior -called Bayesianized p-value (see subsection ).Following work, researchers continued explore richness zoo. Bryzgalova, Huang, Julliard (2019) propose tractable Bayesian estimation large-dimensional factor models evaluate possible combinations 50 factors, yielding incredibly large number coefficients. combined Bayesianized Fama MacBeth (1973) procedure allows distinguish pervasive superfluous factors. Chordia, Goyal, Saretto (2020) use simulations 2 million trading strategies estimate rate false discoveries, , spurious factor detected (type error). also advise use thresholds t-statistics well three. similar vein, C. R. Harvey Liu (2020) also underline sometimes true anomalies may missed one time \\(t\\)-statistic low (type II error).propensity journals publish positive results led researchers estimate difference reported returns true returns. . Y. Chen Zimmermann (2020) call difference publication bias estimate roughly 12%. , published average return 8%, actual value may fact closer (1-12%)*8%=7%. Qualitatively, estimation 12% smaller --sample reduction returns found McLean Pontiff (2016).","code":"\nlibrary(quantmod)                         # Package for data extraction\nlibrary(xtable)                           # Package for LaTeX exports \nmin_date <- \"1963-07-31\"                  # Start date\nmax_date <- \"2020-03-28\"                  # Stop date\ntemp <- tempfile()\nKF_website <- \"http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/\"\nKF_file <- \"ftp/F-F_Research_Data_5_Factors_2x3_CSV.zip\"\nlink <- paste0(KF_website, KF_file)       # Link of the file\ndownload.file(link, temp, quiet = TRUE)   # Download!\nFF_factors <- read_csv(unz(temp, \"F-F_Research_Data_5_Factors_2x3.csv\"), \n                       skip = 3) %>%          # Check the number of lines to skip!\n    rename(date = `...1`, MKT_RF = `Mkt-RF`) %>%  # Change the name of first columns\n    mutate_at(vars(-date), as.numeric) %>%                 # Convert values to number\n    mutate(date = ymd(parse_date_time(date, \"%Y%m\"))) %>%  # Date in right format\n    mutate(date = rollback(date + months(1)))              # End of month date\nFF_factors <- FF_factors %>% mutate(MKT_RF = MKT_RF / 100, # Scale returns\n                                    SMB = SMB / 100,\n                                    HML = HML / 100,\n                                    RMW = RMW / 100,\n                                    CMA = CMA / 100,\n                                    RF = RF/100) %>%\n    filter(date >= min_date, date <= max_date)             # Finally, keep only recent points\nknitr::kable(head(FF_factors),  booktabs = TRUE,\n             caption = \"Sample of monthly factor returns.\") # A look at the data (see table)                   \nFF_factors %>%\n    mutate(date = year(date)) %>%                       # Turn date into year\n    gather(key = factor, value = value, - date) %>%     # Put in tidy shape\n    group_by(date, factor) %>%                          # Group by year and factor\n    summarise(value = mean(value)) %>%                  # Compute average return\n    ggplot(aes(x = date, y = value, color = factor)) +  # Plot\n    geom_line() + coord_fixed(500) + theme_light()      # Fix x/y ratio + theme"},{"path":"factor.html","id":"predictive-regressions-sorts-and-p-value-issues","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.2.4 Predictive regressions, sorts, and p-value issues","text":"simplicity, assume simple form:\n\\[\\begin{equation}\n\\tag{3.2}\n\\textbf{r} = +b\\textbf{x}+\\textbf{e},\n\\end{equation}\\]\nvector \\(\\textbf{r}\\) stacks returns stocks \\(\\textbf{x}\\) lagged variable regression indeed predictive. estimate \\(\\hat{b}\\) significant given specified threshold, can tempting conclude \\(\\textbf{x}\\) good job predicting returns. Hence, long-short portfolios related extreme values \\(\\textbf{x}\\) (mind sign \\(\\hat{b}\\)) expected generate profits. unfortunately often false \\(\\hat{b}\\) gives information past ability \\(\\textbf{x}\\) forecast returns. happens future may another story.Statistical tests also used portfolio sorts. Assume two extreme portfolios expected yield different average returns (like small cap versus large cap, strong winners versus bad losers). portfolio returns written \\(r_t^+\\) \\(r_t^-\\). simplest test mean \\(t=\\sqrt{T}\\frac{m_{r_+}-m_{r_-}}{\\sigma_{r_+-r_-}}\\), \\(T\\) number points \\(m_{r_\\pm}\\) denotes means returns \\(\\sigma_{r_+-r_-}\\) standard deviation difference two series, .e., volatility long-short portfolio. short, statistic can viewed scaled Sharpe ratio (though usually ratios computed long-portfolios) can turn used compute \\(p\\)-values assess robustness anomaly. shown Linnainmaa Roberts (2018) Hou, Xue, Zhang (2020), many factors discovered researchers fail survive --sample tests.One reason people overly optimistic anomalies detect widespread reverse interpretation p-value. Often, thought probability one hypothesis (e.g., anomaly exists) given data. fact, ’s opposite; ’s likelihood data sample, knowing anomaly holds.\n\\[\\begin{align*}\np-\\text{value} &= P[D|H] \\\\\n\\text{target prob.}& = P[H|D]=\\frac{P[D|H]}{P[D]}\\times P[H],\n\\end{align*}\\]\n\\(H\\) stands hypothesis \\(D\\) data. equality second row plain application Bayes’ identity: interesting probability fact transform \\(p\\)-value.Two articles (least) discuss idea. C. R. Harvey (2017) introduces Bayesianized \\(p\\)-values:\n\\[\\begin{equation}\n\\tag{3.3}\n\\text{Bayesianized } p-\\text{value}=\\text{Bpv}= e^{-t^2/2}\\times\\frac{\\text{prior}}{1+e^{-t^2/2}\\times \\text{prior}} ,\n\\end{equation}\\]\n\\(t\\) \\(t\\)-statistic obtained regression (.e., one defines p-value) prior analyst’s estimation odds hypothesis (anomaly) true. prior coded follows. Suppose p% chance null holds (.e., (1-p)% anomaly). odds coded \\(p/(1-p)\\).\nThus, t-statistic equal 2 (corresponding p-value 5% roughly) prior odds equal 6, Bpv equal \\(e^{-2}\\times 6 \\times(1+e^{-2}\\times 6)^{-1}\\approx 0.448\\) 44.8% chance null true. interpretation stands sharp contrast original \\(p\\)-value viewed probability null holds. course, one drawback level prior crucial solely user-specified.work Alexander Chinco, Neuhierl, Weber (2020) different shares key concepts, like introduction Bayesian priors regression outputs. show coercing predictive regression \\(L^2\\) constraint (see ridge regression Chapter 5) amounts introducing views true distribution \\(b\\) . stronger constraint, estimate \\(\\hat{b}\\) shrunk towards zero. One key idea work assumption distribution true \\(b\\) across many anomalies. assumed Gaussian centered. interesting parameter standard deviation: larger , frequently significant anomalies discovered. Notably, authors show parameter changes time refer original paper details subject.","code":""},{"path":"factor.html","id":"fama-macbeth-regressions","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.2.5 Fama-Macbeth regressions","text":"\nAnother detection method proposed Fama MacBeth (1973) two-stage regression analysis risk premia. first stage simple estimation relationship (3.1): regressions run stock--stock basis corresponding time series. resulting estimates \\(\\hat{\\beta}_{,k}\\) plugged second series regressions:\n\\[\\begin{equation}\nr_{t,n}= \\gamma_{t,0} + \\sum_{k=1}^K\\gamma_{t,k}\\hat{\\beta}_{n,k} + \\varepsilon_{t,n},\n\\end{equation}\\]\nrun date--date cross-section assets.7 Theoretically, betas known regression run \\(\\beta_{n,k}\\) instead estimated values.\n\\(\\hat{\\gamma}_{t,k}\\) estimate premia factor \\(k\\) time \\(t\\). suitable distributional assumptions \\(\\varepsilon_{t,n}\\), statistical tests can performed determine whether premia significant . Typically, statistic time-aggregated (average) premia \\(\\hat{\\gamma}_k=\\frac{1}{T}\\sum_{t=1}^T\\hat{\\gamma}_{t,k}\\):\n\\[t_k=\\frac{\\hat{\\gamma}_k}{\\hat{\\sigma_k}/\\sqrt{T}}\\]\noften used pure Gaussian contexts assess whether factor significant (\\(\\hat{\\sigma}_k\\) standard deviation \\(\\hat{\\gamma}_{t,k}\\)).refer Jagannathan Wang (1998) Petersen (2009) technical discussions biases losses accuracy can induced standard ordinary least squares (OLS) estimations. Moreover, \\(\\hat{\\beta}_{,k}\\) second-pass regression estimates, second level errors can arise (-called errors variables). interested reader find extensions solutions Shanken (1992), Ang, Liu, Schwarz (2018) Jegadeesh et al. (2019)., perform Fama MacBeth (1973) regressions sample. start first pass: individual estimation betas. build dedicated function use functional programming automate process. stick original implementation estimation perform synchronous regressions.\nTABLE 3.2: Sample beta values (row numbers stock IDs).\ntable, MKT_RF market return minus risk free rate. corresponding coefficient often referred beta, especially univariate regressions. reformat betas Table 3.2 prepare second pass. line corresponds one asset: first 5 columns estimated factor loadings remaining ones asset returns (date date).\nTABLE 3.3: Sample reformatted beta values (ready regression).\nobserve values first column (market betas) revolve around one, expect.\nFinally, ready second round regressions.\nTABLE 3.4: Sample gamma (premia) values.\nVisually, estimated premia also volatile. plot estimated values market, SMB HML factors.\nFIGURE 3.3: Time series plot gammas (premia) Fama-Macbeth regressions.\ntwo spikes end sample signal potential colinearity issues; two factors seem compensate unclear aggregate effect. underlines usefulness penalized estimates (see Chapter 5).","code":"\nnb_factors <- 5                                                     # Number of factors\ndata_FM <- left_join(data_ml %>%                                    # Join the 2 datasets\n                         dplyr::select(date, stock_id, R1M_Usd) %>% # (with returns...\n                         filter(stock_id %in% stock_ids_short),     # ... over some stocks)\n                     FF_factors, \n                     by = \"date\") %>% \n    group_by(stock_id) %>%                                          # Grouping\n    mutate(R1M_Usd = lag(R1M_Usd)) %>%                              # Lag returns\n    ungroup() %>%\n    na.omit() %>%                                                   # Remove missing points\n    pivot_wider(names_from = \"stock_id\", values_from = \"R1M_Usd\")\nmodels <- lapply(paste0(\"`\", stock_ids_short, \n                        '` ~  MKT_RF + SMB + HML + RMW + CMA'),           # Model spec\n                 function(f){ lm(as.formula(f), data = data_FM,           # Call lm(.)\n                                 na.action=\"na.exclude\") %>%       \n                         summary() %>%                                    # Gather the output\n                         \"$\"(coef) %>%                                    # Keep only coefs\n                         data.frame() %>%                                 # Convert to dataframe\n                         dplyr::select(Estimate)}                         # Keep the estimates\n                 )\nbetas <- matrix(unlist(models), ncol = nb_factors + 1, byrow = T) %>%     # Extract the betas\n    data.frame(row.names = stock_ids_short)                               # Format: row names\ncolnames(betas) <- c(\"Constant\", \"MKT_RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\")    # Format: col names\nloadings <- betas %>%                            # Start from loadings (betas)\n    dplyr::select(-Constant) %>%                 # Remove constant\n    data.frame()                                 # Convert to dataframe             \nret <- returns %>%                               # Start from returns\n    dplyr::select(-date) %>%                     # Keep the returns only\n    data.frame(row.names = returns$date) %>%     # Set row names\n    t()                                          # Transpose\nFM_data <- cbind(loadings, ret)                  # Aggregate both\nmodels <- lapply(paste(\"`\", returns$date, \"`\", ' ~  MKT_RF + SMB + HML + RMW + CMA', sep = \"\"),\nfunction(f){ lm(as.formula(f), data = FM_data) %>%                        # Call lm(.)\n                         summary() %>%                                    # Gather the output\n                         \"$\"(coef) %>%                                    # Keep only the coefs\n                         data.frame() %>%                                 # Convert to dataframe\n                         dplyr::select(Estimate)}                         # Keep only estimates\n                 )\ngammas <- matrix(unlist(models), ncol = nb_factors + 1, byrow = T) %>%    # Switch to dataframe\n    data.frame(row.names = returns$date)                                  # & set row names\ncolnames(gammas) <- c(\"Constant\", \"MKT_RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\")   # Set col names\ngammas[2:nrow(gammas),] %>%                                         # Take gammas:\n    # The first row is omitted because the first row of returns is undefined\n    dplyr::select(MKT_RF, SMB, HML) %>%                             # Select 3 factors\n    bind_cols(date = data_FM$date) %>%                              # Add date\n    gather(key = factor, value = gamma, -date) %>%                  # Put in tidy shape\n    ggplot(aes(x = date, y = gamma, color = factor)) +              # Plot\n    geom_line() + facet_grid( factor~. ) +                          # Lines & facets\n    scale_color_manual(values=c(\"#F87E1F\", \"#0570EA\", \"#F81F40\")) + # Colors\n    coord_fixed(980) + theme_light()                                # Fix x/y ratio"},{"path":"factor.html","id":"factor-competition","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.2.6 Factor competition","text":"\ncore purpose factors explain cross-section stock returns. theoretical practical reasons, preferable redundancies within factors avoided. Indeed, redundancies imply collinearity known perturb estimates (Belsley, Kuh, Welsch (2005)). addition, asset managers decompose performance returns factors, overlaps (high absolute correlations) factors yield exposures less interpretable; positive negative exposures compensate spuriously.simple protocol sort redundant factors run regressions factor others:\n\\[\\begin{equation}\n \\tag{3.4}\nf_{t,k} = a_k +\\sum_{j\\neq k} \\delta_{k,j} f_{t,j} + \\epsilon_{t,k}.\n\\end{equation}\\]\ninteresting metric test statistic associated estimation \\(a_k\\). \\(a_k\\) significantly different zero, cross-section () factors fails explain exhaustively average return factor \\(k\\). Otherwise, return factor can captured exposures factors thus redundant.One mainstream application technique performed Fama French (2015), authors show HML factor redundant taking account four factors (Market, SMB, RMW CMA). , reproduce analysis updated sample. start analysis directly database maintained Kenneth French. can run regressions determine redundancy factors via procedure defined Equation (3.4).obtain vector \\(\\alpha\\) values Equation ((3.4)). , format figures along \\(p\\)-value thresholds export summary table. significance levels coefficients coded follows: \\(0<(***)<0.001<(**)<0.01<(*)<0.05\\).\n\nTABLE 3.5: Factor competition among Fama French (2015) five factors.\nconfirm HML factor remains redundant four others present asset pricing model. figures obtain close ones original paper (Fama French (2015)), makes sense, since add 5 years initial sample.macro-level, researchers also try figure models (.e., combinations factors) likely, given data empirically observed (possibly given priors formulated econometrician). instance, stream literature seeks quantify extent 3-factor model Fama French (1993) outperforms 5 factors Fama French (2015). direction, De Moor, Dhaene, Sercu (2015) introduce novel computation p-values compare relative likelihood two models pass zero-alpha test. generally, Bayesian method Barillas Shanken (2018) subsequently improved Chib, Zeng, Zhao (2020) - see also Chib Zeng (2020) Chib et al. (2020) (R package exists former: czfactor). discussion model comparison transaction cost perspective, refer S. . Li, DeMiguel, Martin-Utrera (2020). Lastly, even optimal number factors subject disagreement among conclusions recent work. traditional literature focuses limited number (3-5) factors (see also Hwang Rubesam (2021)), recent research DeMiguel et al. (2020), . , Huang, Zhou (2020), Kozak, Nagel, Santosh (2019) Freyberger, Neuhierl, Weber (2020) advocates need use least 15 (contrast, Kelly, Pruitt, Su (2019) argue small number latent factors may suffice). Green, Hand, Zhang (2017) even find number characteristics help explain cross-section returns varies time.8 ","code":"\nfactors <- c(\"MKT_RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\")\nmodels <- lapply(paste(factors, ' ~  MKT_RF + SMB + HML + RMW + CMA-',factors),\n function(f){ lm(as.formula(f), data = FF_factors) %>%               # Call lm(.)\n                         summary() %>%                               # Gather the output\n                         \"$\"(coef) %>%                               # Keep only the coefs\n                         data.frame() %>%                            # Convert to dataframe\n                         filter(rownames(.) == \"(Intercept)\") %>%    # Keep only the Intercept\n                         dplyr::select(Estimate,`Pr...t..`)}         # Keep the coef & p-value\n                 )\nalphas <- matrix(unlist(models), ncol = 2, byrow = T) %>%       # Switch from list to dataframe\n    data.frame(row.names = factors)\n# alphas # To see the alphas (optional)\nresults <- matrix(NA, nrow = length(factors), ncol = length(factors) + 1)   # Coefs\nsignif  <- matrix(NA, nrow = length(factors), ncol = length(factors) + 1)   # p-values\nfor(j in 1:length(factors)){\n    form <- paste(factors[j],\n                  ' ~  MKT_RF + SMB + HML + RMW + CMA-',factors[j])         # Build model\n    fit <- lm(form, data = FF_factors) %>% summary()                        # Estimate model\n    coef <- fit$coefficients[,1]                                            # Keep coefficients\n    p_val <- fit$coefficients[,4]                                           # Keep p-values\n    results[j,-(j+1)] <- coef                                               # Fill matrix\n    signif[j,-(j+1)] <- p_val\n}\nsignif[is.na(signif)] <- 1                                                  # Kick out NAs\nresults <- results %>% round(3)  %>% data.frame()                           # Basic formatting\nresults[signif<0.001] <- paste(results[signif<0.001],\" (***)\")              # 3 star signif\nresults[signif>0.001&signif<0.01] <-                                        # 2 star signif\n    paste(results[signif>0.001&signif<0.01],\" (**)\")\nresults[signif>0.01&signif<0.05] <-                                         # 1 star signif\n    paste(results[signif>0.01&signif<0.05],\" (*)\")     \nresults <- cbind(as.character(factors), results)                            # Add dep. variable\ncolnames(results) <- c(\"Dep. Variable\",\"Intercept\", factors)                # Add column names"},{"path":"factor.html","id":"advanced-techniques","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.2.7 Advanced techniques","text":"ever increasing number factors combined importance asset management led researchers craft subtle methods order ``organize’’ -called factor zoo , importantly, detect spurious anomalies compare different asset pricing model specifications. list .\n- Feng, Giglio, Xiu (2020) combine LASSO selection Fama-MacBeth regressions test new factor models worth . quantify gain adding one new factor set predefined factors show many factors reported papers published 2010 decade add much incremental value;\n- C. Harvey Liu (2019) (similar vein) use bootstrap orthogonalized factors. make case correlations among predictors major issue method aims solving problem. lengthy procedure seeks test maximal additional contribution candidate variable significant;\n- Fama French (2018) compare asset pricing models squared maximum Sharpe ratios;\n- Giglio Xiu (2019) estimate factor risk premia using three-pass method based principal component analysis;\n- Pukthuanthong, Roll, Subrahmanyam (2018) disentangle priced non-priced factors via combination principal component analysis Fama MacBeth (1973) regressions;\n- Gospodinov, Kan, Robotti (2019) warn factor misspecification (spurious factors included list regressors). Traded factors (\\(resp.\\) macro-economic factors) seem likely (\\(resp.\\) less likely) yield robust identifications (see also Bryzgalova (2019)).obviously infallible method, number contributions field highlights need robustness. evidently major concern crafting investment decisions based factor intuitions. One major hurdle short-term strategies likely time-varying feature factors. refer instance Ang Kristensen (2012), Cooper Maio (2019), Briere Szafarz (2021) practical results Gagliardini, Ossola, Scaillet (2016) S. Ma et al. (2020) theoretical treatments (additional empirical results).","code":""},{"path":"factor.html","id":"factors-or-characteristics","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.3 Factors or characteristics?","text":"decomposition returns linear factor models convenient simple interpretation. nonetheless debate academic literature whether firm returns indeed explained exposure macro-economic factors simply characteristics firms. early study, Lakonishok, Shleifer, Vishny (1994) argue one explanation value premium comes incorrect extrapolation past earning growth rates. Investors overly optimistic firms subject recent profitability. Consequently, future returns (also) driven core (accounting) features firm. question disentangle effect pronounced explaining returns: characteristics versus exposures macro-economic factors.seminal contribution topic, K. Daniel Titman (1997) provide evidence favour former (two follow-papers K. Daniel, Titman, Wei (2001) K. Daniel Titman (2012)). show firms high book--market ratios small capitalizations display higher average returns, even negatively loaded HML SMB factors. Therefore, seems indeed intrinsic characteristics matter, factor exposure. material characteristics’ role return explanation prediction, refer following contributions:\n- Haugen Baker (1996) estimate predictive regressions based firms characteristics show possible build profitable portfolios based resulting predictions. method subsequently enhanced adaptive LASSO Guo (2020).\n- Section 2.5.2. Goyal (2012) surveys pre-2010 results topic;\n- Chordia, Goyal, Shanken (2019) find characteristics explain larger proportion variation estimated expected returns factor loadings;\n- Kozak, Nagel, Santosh (2018) reconcile factor-based explanations premia theoretical model agents’ demands sentiment driven;\n- Han et al. (2019) show penalized regressions 20 30 characteristics (94) useful prediction monthly returns US stocks. methodology interesting: regress returns characteristics build forecasts regress returns forecast assess reliable. latter regression uses LASSO-type penalization (see Chapter 5) useless characteristics excluded model. penalization extended elasticnet D. Rapach Zhou (2019).\n- Kelly, Pruitt, Su (2019) S. Kim, Korajczyk, Neuhierl (2019) estimate models factors latent loadings (betas) possibly alphas depend characteristics. Kirby (2020) generalizes first approach introducing regime-switching. contrast, Lettau Pelger (2020a) Lettau Pelger (2020b) estimate latent factors without link particular characteristics (provide large sample asymptotic properties methods).\n- vein Hoechle, Schmid, Zimmermann (2018), Gospodinov, Kan, Robotti (2019) Bryzgalova (2019) discuss potential errors arise working portfolio sorts yield long-short returns. authors show cases, tests based procedure may deceitful. happens characteristic chosen perform sort correlated external (unobservable) factor. propose novel regression-based approach aimed bypassing problem.recently separate stream literature, R. S. J. Koijen Yogo (2019) introduced demand model investors form portfolios according preferences towards particular firm characteristics. show allows mimic portfolios large institutional investors. model, aggregate demands (hence, prices) directly linked characteristics, factors. follow-paper, R. S. Koijen, Richmond, Yogo (2019) show sets characteristics suffice predict future returns. also show , based institutional holdings UK US, largest investors influencial formation prices. similar vein, Betermier, Calvet, Jo (2019) derive elegant (theoretical) general equilibrium model generates well-documented anomalies (size, book--market). models R. D. Arnott et al. (2014) Alti Titman (2019) also able theoretically generate known anomalies. Finally, . Martin Nagel (2019), characteristics influence returns via role play predictability dividend growth. paper discussed asymptotic case number assets number characteristics proportional increase infinity.","code":""},{"path":"factor.html","id":"hot-topics-momentum-timing-and-esg","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.4 Hot topics: momentum, timing and ESG","text":"","code":""},{"path":"factor.html","id":"factor-momentum","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.4.1 Factor momentum","text":"recent body literature unveils time series momentum property factor returns. instance, T. Gupta Kelly (2019) report autocorrelation patterns within returns statistically significant.9 Similar results obtained Falck, Rej, Thesmar (2020). vein, R. D. Arnott et al. (2020) make case industry momentum found Moskowitz Grinblatt (1999) can fact explained factor momentum. Going even , Ehsani Linnainmaa (2019) conclude original momentum factor fact aggregation autocorrelation can found factors. Recently, strength factor momentum scrutinized Fan et al. (2021). authors find robust small number factors.Acknowledging profitability factor momentum, H. Yang (2020b) seeks understand source decomposes stock factor momentum portfolios two components: factor timing portfolio static portfolio. former seeks profit serial correlations factor returns latter tries harness factor premia. author shows static portfolio explains larger portion factor momentum returns. H. Yang (2020a), author presents new estimator gauge factor momentum predictability. Words caution provided Leippold Yang (2021).Lastly, Garcia, Medeiros, Ribeiro (2021) document factor momentum daily frequency.Given data obtained Ken French’s website, compute autocorrelation function (ACF) factors. recall \n\\[\\text{ACF}_k(\\textbf{x}_t)=\\mathbb{E}[(\\textbf{x}_t-\\bar{\\textbf{x}})(\\textbf{x}_{t+k}-\\bar{\\textbf{x}})].\\]\nFIGURE 3.4: Autocorrelograms common factor portfolios.\nfour chosen series, size factor significantly autocorrelated first order.","code":"\nlibrary(cowplot)                   # For stacking plots\nlibrary(forecast)                  # For autocorrelation function\nacf_SMB <- ggAcf(FF_factors$SMB, lag.max = 10) + labs(title = \"\")  # ACF SMB\nacf_HML <- ggAcf(FF_factors$HML, lag.max = 10) + labs(title = \"\")  # ACF HML\nacf_RMW <- ggAcf(FF_factors$RMW, lag.max = 10) + labs(title = \"\")  # ACF RMW\nacf_CMA <- ggAcf(FF_factors$CMA, lag.max = 10) + labs(title = \"\")  # ACF CMA\nplot_grid(acf_SMB, acf_HML, acf_RMW, acf_CMA,  # Plot\n          labels = c('SMB', 'HML', 'RMW', 'CMA')) "},{"path":"factor.html","id":"factor-timing","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.4.2 Factor timing","text":"Given abundance evidence time-varying nature factor premia, legitimate wonder possible predict factor perform well badly. evidence effectiveness timing diverse: positive Greenwood Hanson (2012), Hodges et al. (2017), Hasler, Khapko, Marfe (2019), Haddad, Kozak, Santosh (2020) Lioui Tarelli (2020), negative Clifford Asness et al. (2017) mixed Dichtl et al. (2019). consensus predictors use (general macroeconomic indicators Hodges et al. (2017), stock issuances versus repurchases Greenwood Hanson (2012), aggregate fundamental data Dichtl et al. (2019)). method building reasonable timing strategies long-portfolios sustainable transaction costs laid Leippold Rüegg (2020). cross-section characteristics used factor timing purposes Kagkadis et al. (2021).\nML-based factor investing, possible resort granularity combining firm-specific attributes large-scale economic data explain Section 4.7.2.","code":""},{"path":"factor.html","id":"the-green-factors","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.4.3 The green factors","text":"demand ethical financial products sharply risen 2010 decade, leading creation funds dedicated socially responsible investing (SRI - see Camilleri (2020)). Though phenomenon really new (Schueth (2003), Hill et al. (2007)), acceleration prompted research whether characteristics related ESG criteria (environment, social, governance) priced. Dozens even possibly hundreds papers devoted question, consensus reached. , researchers study financial impact climate change (see Bernstein, Gustafson, Lewis (2019), Hong, Li, Xu (2019) Hong, Karolyi, Scheinkman (2020)) societal push responsible corporate behavior (Fabozzi (2020), Kurtz (2020)).\ngather short list papers suggests conflicting results:favorable: ESG investing works (Kempf Osthoff (2007), Cheema-Fox et al. (2020)), can work (Nagy, Kassam, Lee (2016), Alessandrini Jondeau (2020)), can least rendered efficient (Branch Cai (2012)). large meta-study reports overwhelming favorable results (Friede, Busch, Bassen (2015)), course, well stem publication bias towards positive results.unfavorable: Ethical investing profitable according Adler Kritzman (2008) Blitz Swinkels (2020). ESG factor long unethical firms short ethical ones (Lioui (2018)).mixed: ESG investing may beneficial globally locally (Chakrabarti Sen (2020)). Portfolios relying ESG screening significantly outperform screening subject lower levels volatility (Gibson et al. (2020), Gougler Utz (2020)). often case, devil details, results depend whether use E, S G (Bruder et al. (2019)).top contradicting results, several articles point towards complexities measurement ESG. Depending chosen criteria data provider, results can change drastically (see Galema, Plantinga, Scholtens (2008), Berg, Koelbel, Rigobon (2020) Atta-Darkua et al. (2020)).end short section noting course ESG criteria can directly integrated ML model, instance done Franco et al. (2020).","code":""},{"path":"factor.html","id":"the-links-with-machine-learning","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.5 The links with machine learning","text":"Given exponential increase data availability, obvious temptation asset manager try infer future returns abundance attributes available firm level. allude classical data like accounting ratios alternative data, sentiment. task precisely aim Machine Learning. Given large set predictor variables (\\(\\mathbf{X}\\)), goal predict proxy future performance \\(\\mathbf{y}\\) model form (2.1).fundamental data (accounting ratios, earnings, relative valuations, etc.) help predict returns, one refinement predict fundamental data upfront. may allow anticipate changes gain informational edges. Recent contributions directions include K. Cao (2020) D. Huang et al. (2020).earlier attempts already made aim explain predict returns firm attributes (e.g., Brandt, Santa-Clara, Valkanov (2009), Hjalmarsson Manchev (2012), Ammann, Coqueret, Schade (2016), DeMiguel et al. (2020) McGee Olmo (2020)), ML intent focus originally. retrospect, approaches share links ML tools. general formulation following. time \\(T\\), agent investor seeks solve following program:\n\\[\\begin{align*}\n\\underset{\\boldsymbol{\\theta}_T}{\\max} \\ \\mathbb{E}_T\\left[ u(r_{p,T+1})\\right] = \\underset{\\boldsymbol{\\theta}_T}{\\max} \\ \\mathbb{E}_T\\left[ u\\left(\\left(\\bar{\\textbf{w}}_T+\\textbf{x}_T\\boldsymbol{\\theta}_T\\right)'\\textbf{r}_{T+1}\\right)\\right] , \n\\end{align*}\\]\n\\(u\\) utility function \\(r_{p,T+1}=\\left(\\bar{\\textbf{w}}_T+\\textbf{x}_T\\boldsymbol{\\theta}_T\\right)'\\textbf{r}_{T+1}\\) return portfolio, defined benchmark \\(\\bar{\\textbf{w}}_T\\) plus deviations benchmark linear function features \\(\\textbf{x}_T\\boldsymbol{\\theta}_T\\). program may subject external constraints (e.g., limit leverage).practice, vector \\(\\boldsymbol{\\theta}_T\\) must estimated using past data (\\(T-\\tau\\) \\(T-1\\)): agent seeks solution \n\\[\\begin{align}\n\\tag{3.5}\n\\underset{\\boldsymbol{\\theta}_T}{\\text{max}} \\ \\frac{1}{\\tau} \\sum_{t=T-\\tau}^{T-1} u \\left( \\sum_{=1}^{N_T}\\left(\\bar{w}_{,t}+ \\boldsymbol{\\theta}'_T \\textbf{x}_{,t} \\right)r_{,t+1} \\right) \n\\end{align}\\]sample size \\(\\tau\\) \\(N_T\\) number asset universe. formulation can viewed learning task parameters chosen reward (average return) maximized.","code":""},{"path":"factor.html","id":"a-short-list-of-recent-references","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.5.1 A short list of recent references","text":"Independent characteristics-based approach, ML applications finance blossomed, initially working price data later integrating firm characteristics predictors. cite references , grouped methodological approach:penalized quadratic programming: Goto Xu (2015), Ban, El Karoui, Lim (2016) Perrin Roncalli (2019),regularized predictive regressions: D. E. Rapach, Strauss, Zhou (2013) Alexander Chinco, Clark-Joseph, Ye (2019), support vector machines: L.-J. Cao Tay (2003) (references therein), model comparison /aggregation: K. Kim (2003), W. Huang, Nakamori, Wang (2005), Matı́Reboredo (2012), Reboredo, Matı́, Garcia-Rubio (2012), Dunis et al. (2013), Gu, Kelly, Xiu (2020b), Guida Coqueret (2018b) Tobek Hronec (2021). latter two recent articles work large cross-section characteristics.provide detailed lists tree-based methods, neural networks reinforcement learning techniques Chapters 6, 7 16, respectively. Moreover, refer Ballings et al. (2015) comparison classifiers Henrique, Sobreiro, Kimura (2019) Bustos Pomares-Quimbaya (2020) surveys ML-based forecasting techniques.","code":""},{"path":"factor.html","id":"explicit-connections-with-asset-pricing-models","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.5.2 Explicit connections with asset pricing models","text":"first obvious link factor investing asset pricing (average) return prediction. main canonical academic reference Gu, Kelly, Xiu (2020b). Let us first write general equation comment :\n\\[\\begin{equation}\n\\tag{3.6}\nr_{t+1,n}=g(\\textbf{x}_{t,n}) + \\epsilon_{t+1}.\n\\end{equation}\\]interesting discussion lies differences model Equation (3.1). first obvious difference introduction nonlinear function \\(g\\): indeed, reason (beyond simplicity interpretability) restrict model linear relationships. One early reference nonlinearities asset pricing kernels Bansal Viswanathan (1993).importantly, second difference (3.6) (3.1) shift time index. Indeed, investor’s perspective, interest able predict information structure cross-section assets. Explaining asset returns synchronous factors useful realization factor values known advance. Hence, one seeks extract value model, needs time interval observation state space (call \\(\\textbf{x}_{t,n}\\)) occurrence returns. model \\(\\hat{g}\\) estimated, time-\\(t\\) (measurable) value \\(g(\\textbf{x}_{t,n})\\) give forecast (average) future returns. predictions can serve signals crafting portfolio weights (see Chapter 12 topic).studies work returns l.h.s. (3.6), reason indicators used. Returns straightforward simple compute, well replaced sophisticated metrics, like Sharpe ratio, instance. firms’ features used predict risk-adjusted performance rather simple returns.Beyond explicit form Equation (3.6), several ML-related tools can also used estimate asset pricing models. can achieved several ways, list .First, one mainstream problem asset pricing characterize stochastic discount factor (SDF) \\(M_t\\), satisfies \\(\\mathbb{E}_t[M_{t+1}(r_{t+1,n}-r_{t+1,f})]=0\\) asset \\(n\\) (see Cochrane (2009)). equation natural playing field generalized method moment (Hansen (1982)): \\(M_t\\) must \n\\[\\begin{equation}\n\\tag{3.7}\n\\mathbb{E}[M_{t+1}R_{t+1,n}g(V_t)]=0,\n\\end{equation}\\]\ninstrumental variables \\(V_t\\) \\(\\mathcal{F}_t\\)-measurable (.e., known time \\(t\\)) capital \\(R_{t+1,n}\\) denotes excess return asset \\(n\\). order reduce simplify estimation problem, customary define SDF portfolio assets (see chapter 3 Back (2010)). Luyang Chen, Pelger, Zhu (2020), authors use generative adversarial network (GAN, see Section 7.7.1) estimate weights portfolios closest satisfy (3.7) strongly penalizing form. second approach try model asset returns linear combinations factors, just (3.1). write compact notation \\[r_{t,n}=\\alpha_n+\\boldsymbol{\\beta}_{t,n}'\\textbf{f}_t+\\epsilon_{t,n},\\]\nallow loadings \\(\\boldsymbol{\\beta}_{t,n}\\) time-dependent. trick introduce firm characteristics equation. Traditionally, characteristics present definition factors (seminal definition Fama French (1993)). decomposition return made according exposition firm’s return factors constructed according market size, accounting ratios, past performance, etc. Given exposures, performance stock attributed particular style profiles (e.g., small stock, value stock, etc.).Habitually, factors heuristic portfolios constructed simple rules like thresholding. instance, firms 1/3 quantile book--market growth firms 2/3 quantile value firms. value factor can defined long-short portfolio two sets, uniform weights. Note Fama French (1993) use complex approach also takes market capitalization account weighting scheme also composition portfolios.One advances enabled machine learning automate construction factors. instance approach Feng, Polson, Xu (2019). Instead building factors heuristically, authors optimize construction maximize fit cross-section returns. optimization performed via relatively deep feed-forward neural network feature space lagged relationship indeed predictive, Equation (3.6). Theoretically, resulting factors help explain substantially larger proportion -sample variance returns. prediction ability model depends well generalizes --sample.third approach Kelly, Pruitt, Su (2019) (though statistical treatment machine learning per se).10 idea opposite: factors latent (unobserved) betas (loadings) depend characteristics. allows many degrees freedom  \\(r_{t,n}=\\alpha_n+(\\boldsymbol{\\beta}_{t,n}(\\textbf{x}_{t-1,n}))'\\textbf{f}_t+\\epsilon_{t,n},\\)\ncharacteristics \\(\\textbf{x}_{t-1,n}\\) known factors \\(\\textbf{f}_t\\) functional forms \\(\\boldsymbol{\\beta}_{t,n}(\\cdot)\\) must estimated. article, Kelly, Pruitt, Su (2019) work linear form, naturally tractable.Lastly, fourth approach (introduced Gu, Kelly, Xiu (2020a)) goes even combines two neural network architectures. first neural network takes characteristics \\(\\textbf{x}_{t-1}\\) inputs generates factor loadings \\(\\boldsymbol{\\beta}_{t-1}(\\textbf{x}_{t-1})\\). second network transforms returns \\(\\textbf{r}_t\\) factor values \\(\\textbf{f}_t(\\textbf{r}_t)\\) (Feng, Polson, Xu (2019)). aggregate model can written:\n\\[\\begin{equation}\n\\tag{3.8}\n\\textbf{r}_t=\\boldsymbol{\\beta}_{t-1}(\\textbf{x}_{t-1})'\\textbf{f}_t(\\textbf{r}_t)+\\boldsymbol{\\epsilon}_t.\n\\end{equation}\\]specification quite special output (l.h.s.) also present input (r.h.s.). machine learning, autoencoders (see Section 7.7.2) share property. aim, just like principal component analysis, find parsimonious nonlinear representation form dataset (case, returns). Equation (3.8), input \\(\\textbf{r}_t\\) output function \\(\\boldsymbol{\\beta}_{t-1}(\\textbf{x}_{t-1})'\\textbf{f}_t(\\textbf{r}_t)\\). aim minimize difference two just regression-like model.Autoencoders neural networks outputs close possible inputs objective dimensional reduction. innovation Gu, Kelly, Xiu (2020a) pure autoencoder part merged vanilla perceptron used model loadings. structure neural network summarized .\\[\\left. \\begin{array}{rl}\n\\text{returns } (\\textbf{r}_t) & \\overset{NN_1}{\\longrightarrow} \\quad \\text{ factors } (\\textbf{f}_t=NN_1(\\textbf{r}_t)) \\\\\n\\text{characteristics } (\\textbf{x}_{t-1}) & \\overset{NN_2}{\\longrightarrow} \\quad \\text{ loadings } (\\boldsymbol{\\beta}_{t-1}=NN_2(\\textbf{x}_{t-1}))\n\\end{array} \\right\\} \\longrightarrow \\text{ returns } (r_t)\\]simple autoencoder consist first line model. specification discussed details Section 7.7.2.conclusion chapter, appears undeniable intersection two fields asset pricing machine learning offers rich variety applications. literature already exhaustive often hard disentangle noise great ideas continuous flow publications topics. Practice implementation way forward extricate value hype. especially true agents often tend overestimate role factors allocation decision process real-world investors (see Alex Chinco, Hartzmark, Sussman (2019) Castaneda Sabat (2019)).","code":""},{"path":"factor.html","id":"coding-exercises","chapter":"3 Factor investing and asset pricing anomalies","heading":"3.6 Coding exercises","text":"Compute annual returns growth versus value portfolios, , average return firms median price--book ratio (variable called `Pb’ dataset).exercise, compute monthly returns plot value (time) corresponding portfolios.Instead unique threshold, compute simply sorted portfolios based quartiles market capitalization. Compute annual returns plot .","code":""},{"path":"Data.html","id":"Data","chapter":"4 Data preprocessing","heading":"4 Data preprocessing","text":"methods describe chapter driven financial applications. introduction non-financial data processing, recommend two references: chapter 3 general purpose ML book Boehmke Greenwell (2019) monograph dedicated subject Kuhn Johnson (2019).","code":""},{"path":"Data.html","id":"know-your-data","chapter":"4 Data preprocessing","heading":"4.1 Know your data","text":"first step, quantitative study, obviously make sure data trustworthy, .e., comes reliable provider (minima). landscape financial data provision vast say least: providers well established (e.g., Bloomberg, Thomson-Reuters, Datastream, CRSP, Morningstar), recent (e.g., Capital IQ, Ravenpack) focus alternative data niches (see https://alternativedata.org/data-providers/ exhaustive list). Unfortunately, best knowledge, study published evaluates large spectrum providers terms data reliability.second step look summary statistics: ranges (minimum maximum values), averages medians. Histograms plots time series carry course information analyzed properly high dimensions. nonetheless sometimes useful track local patterns errors given stock /particular feature.\nBeyond first order moments, second order quantities (variances covariances/correlations) also matter help spot colinearities. two features highly correlated, problems may arise models (e.g., simple regressions, see Section 15.1).Often, number predictors large unpractical look simple metrics. minimal verification recommended. ease analysis:focus subset predictors, e.g., ones linked common factors (market-capitalization, price--book book--market, momentum (past returns), profitability, asset growth, volatility);track outliers summary statistics (maximum/median median/minimum ratios seem suspicious)., Figure 4.1, show box plot illustrates distribution correlations features one month ahead return. correlations computed date--date basis, whole cross-section stocks. mostly located close zero, dates seem experience extreme shifts (outliers shown black circles). market capitalization median negative volatility predictor positive median correlation (particular example seems refute low risk anomaly).\nFIGURE 4.1: Boxplot correlations 1M forward return (label).\nimportantly, seeking work supervised learning (time), link features dependent variable can characterized smoothed conditional average shows features impact label. use conditional average deep theoretical grounding. Suppose one feature \\(X\\) seek model \\(Y=f(X)+\\text{error}\\), variables real-valued. function \\(f\\) minimizes average squared error \\(\\mathbb{E}[(Y-f(X))^2]\\) -called regression function (see Section 2.4 Hastie, Tibshirani, Friedman (2009)):\n\\[\\begin{equation}\n\\tag{4.1}\nf(x)=\\mathbb{E}[Y|X=x].\n\\end{equation}\\]Figure 4.2, plot two illustrations function dependent variable (\\(Y\\)) one month ahead return. first one pertains average market capitalization past year second volatility past year well. predictors uniformized (see Section 4.4.2 ) values uniformly distributed cross-section assets given time period. Thus, range features \\([0,1]\\) shown \\(x\\)-axis plot. grey corridors around lines show 95% level confidence interval computation mean. Essentially, narrow () many data points available (ii) points dispersed.\nFIGURE 4.2: Conditional expectations: average returns smooth functions features.\ntwo variables close monotonic impact future returns. Returns, average, decrease market capitalization (thereby corroborating -called size effect). reverse pattern less pronounced volatility: curve rather flat first half volatility scores progressively increases, especially last quintile volatility values (thereby contradicting low-volatility anomaly).One important empirical property features autocorrelation (absence thereof). high level autocorrelation one predictor makes plausible use simple imputation techniques data points missing. autocorrelation also important moving towards prediction tasks discuss issue shortly Section 4.6. Figure 4.3, build histogram autocorrelations, computed stock--stock feature--feature.\nFIGURE 4.3: Histogram sample feature autocorrelations.\nGiven large number values evaluate, chunk quite time-consuming. output shows predictors highly autocorrelated: first order autocorrelation 0.80.","code":"\ndata_ml %>% \n    dplyr::select(c(features_short, \"R1M_Usd\", \"date\")) %>%     # Keep few features, label & date\n    group_by(date) %>%                                          # Group: dates!\n    summarise_all(funs(cor(.,R1M_Usd))) %>%                     # Compute correlations\n    dplyr::select(-R1M_Usd) %>%                                 # Remove label\n    gather(key = Predictor, value = value, -date) %>%           # Put in tidy format\n    ggplot(aes(x = Predictor, y = value, color = Predictor)) +  # Plot\n    geom_boxplot(outlier.colour = \"black\") + coord_flip() + \n    theme(aspect.ratio = 0.6) + xlab(element_blank()) + theme_light()\ndata_ml %>%                                                      # From dataset:\n  ggplot(aes(y = R1M_Usd)) +                                     # Plot\n  geom_smooth(aes(x = Mkt_Cap_12M_Usd, color = \"Market Cap\")) +  # Cond. Exp. Mkt_cap\n  geom_smooth(aes(x = Vol1Y_Usd, color = \"Volatility\")) +        # Cond. Exp. Vol\n  scale_color_manual(values=c(\"#F87E1F\", \"#0570EA\")) +           # Change color\n  coord_fixed(10) + theme_light() +                              # Change x/y ratio\n  labs(color = \"Predictor\") + xlab(element_blank())\nautocorrs <- data_ml %>%                                         # From dataset:\n  dplyr::select(c(\"stock_id\", features)) %>%                     # Keep ids & features\n  gather(key = feature, value = value, -stock_id) %>%            # Put in tidy format\n  group_by(stock_id, feature) %>%                                # Group\n  summarize(acf = acf(value, lag.max = 1, plot = FALSE)$acf[2])  # Compute ACF\nautocorrs %>% ggplot(aes(x = acf)) + xlim(-0.1,1) +              # Plot\n   geom_histogram(bins = 60) + theme_light() "},{"path":"Data.html","id":"missing-data","chapter":"4 Data preprocessing","heading":"4.2 Missing data","text":"Similarly empirical discipline, portfolio management bound face missing data issues. topic well known several books detail solutions problem (e.g., Allison (2001), Enders (2010), Little Rubin (2014) Van Buuren (2018)). researchers continuously propose new methods cope absent points (Honaker King (2010) Che et al. (2018) cite ), believe simple, heuristic treatment usually sufficient long basic cautious safeguards enforced.First , mainly two ways deal missing data: removal imputation. Removal agnostic costly, especially one whole instance eliminated one missing feature value. Imputation often preferred relies underlying potentially erroneous assumption.simplified classification imputation following:basic imputation choice median (mean) feature stock past available values. trend time series, nonetheless alter trend. Relatedly, method can forward-looking, unless training testing sets treated separately.time series contexts views towards backtesting, simple imputation comes previous values: \\(x_t\\) missing, replace \\(x_{t-1}\\). makes sense time past values available definition backward-looking. However, particular cases, may bad choice (see words caution ).Medians means can also computed cross-section assets. roughly implies missing feature value relocated bulk observed values. many values missing, creates atom distribution feature alters original distribution. One advantage imputation forward-looking.Many techniques rely modelling assumptions data generating process. refer nonparametric approaches (Stekhoven Bühlmann (2011) Shah et al. (2014), rely random forests, see Chapter 6), Bayesian imputation (Schafer (1999)), maximum likelihood approaches (Enders (2001), Enders (2010)), interpolation extrapolation nearest neighbor algorithms (Garcı́-Laencina et al. (2009)). generally, four books cited begining subsection detail many imputation processes. Advanced techniques much demanding computationally.words caution:Interpolation avoided cost. Accounting values ratios released every quarter must never linearly interpolated simple reason forward-looking. numbers disclosed January April, interpolating February March requires knowledge April figure, , live trading known. Resorting past values better way go.Nevertheless, feature types imputation past values avoided. First , returns replicated. default, superior choice set missing return indicators zero (often close average median). good indicator can help decision persistence feature time. highly autocorrelated (time series plot create smooth curve, like market capitalization), imputation past can make sense. , avoided.cases can require attention. Let us consider following fictitious sample dividend yield:TABLE 4.1:  Challenges chronological imputation.case, yield released quarterly, March, June, September, etc. June, value missing. problem know missing genuine data glitch, firm simply pay dividends June. Thus, imputation past value may erroneous . perfect solution decision must nevertheless taken. dividend data, three options :Keep previous value. R, function na.locf() zoo package incredibly efficient task.Extrapolate previous observations (different interpolation): instance, evaluate trend past data pursue trend.Set value zero. tempting may sub-optimal due dividend smoothing practices executives (see instance Leary Michaely (2011) Long Chen, Da, Priestley (2012) details subject). persistent time series, first two options probably better.Tests can performed evaluate relative performance option. also important remember design choices. many easy forget. Keeping track obviously compulsory. ML pipeline, scripts pertaining data preparation often key serve !Finally, mention many packages exist R deal data imputation: Amelia, imputeTS, mice, mtsdi, simputation VIM. interested reader can look .","code":""},{"path":"Data.html","id":"outlier-detection","chapter":"4 Data preprocessing","heading":"4.3 Outlier detection","text":"topic outlier detection also well documented surveys (Hodge Austin (2004), Chandola, Banerjee, Kumar (2009) M. Gupta et al. (2014)) dedicated books (Aggarwal (2013) Rousseeuw Leroy (2005), though latter focused regression analysis)., incredibly sophisticated methods may require lot efforts possibly limited gain. Simple heuristic methods, long documented process, may suffice. often rely ‘hard’ thresholds:one given feature (possibly filtered time), point outside interval \\([\\mu-m\\sigma, \\mu+m\\sigma]\\) can deemed outlier. \\(\\mu\\) mean sample \\(\\sigma\\) standard deviation. multiple value \\(m\\) usually belongs set \\(\\{3, 5, 10\\}\\), course arbitrary.likewise, largest value \\(m\\) times second--largest, can also classified outlier (reasoning applied side tail).finally, given small threshold \\(q\\), value outside \\([q,1-q]\\) quantile range can considered outliers.latter idea popularized winsorization. Winsorizing amounts setting \\(x^{(q)}\\) values \\(x^{(q)}\\) \\(x^{(1-q)}\\) values \\(x^{(1-q)}\\). winsorized variable \\(\\tilde{x}\\) :\n\\[\\tilde{x}_i=\\left\\{\\begin{array}{ll}\nx_i & \\text{ }  x_i \\[x^{(q)},x^{(1-q)}] \\quad \\text{ (unchanged)}\\\\\nx^{(q)} & \\text{ }  x_i < x^{(q)} \\\\\nx^{(1-q)} & \\text{ }  x_i > x^{(1-q)}\n \\end{array} \\right. .\\]range \\(q\\) usually \\((0.5\\%, 5\\%)\\) 1% 2% often used.winsorization stage must performed feature--feature date--date basis. However, keeping time series perspective also useful. instance, $800B market capitalization may seems range, except looking history Apple’s capitalization.conclude subsection recalling true outliers (.e., extreme points due data extraction errors) valuable likely carry important information.","code":""},{"path":"Data.html","id":"feateng","chapter":"4 Data preprocessing","heading":"4.4 Feature engineering","text":"Feature engineering important step portfolio construction process. Computer scientists often refer saying “garbage , garbage .” thus paramount prevent ML engine allocation trained ill-designed variables.\ninvite interested reader look recent work Kuhn Johnson (2019) topic. (shorter) academic reference Guyon Elisseeff (2003).","code":""},{"path":"Data.html","id":"feature-selection","chapter":"4 Data preprocessing","heading":"4.4.1 Feature selection","text":"first step selection. obvious determine set predictors include. instance, Bali et al. (2020) show fixed-income related variables help predict equity returns. One heuristic choice chose variables often mentioned literature (academic practical). Though course, sticking common characteristics may complicate generation alpha trading agents take account. Choices can stem empirical studies . Y. Chen Zimmermann (2021), theoretical models like Ohlson (1995), one many papers justify inclusion fundamental values independent variables predictive models., given large set predictors, seems sound idea filter unwanted redundant exogenous variables. Heuristically, simple methods include:computing correlation matrix features making sure (absolute) value threshold (0.7 common value) redundant variables pollute learning engine;carrying linear regression removing non significant variables (e.g., \\(p\\)-value 0.05).perform clustering analysis set features retain one feature within cluster (see Chapter 15).methods somewhat reductive overlook nonlinear relationships. Another approach fit decision tree (random forest) retain features high variable importance. methods developed Chapter 6 trees Chapter 13 variable importance.","code":""},{"path":"Data.html","id":"scaling","chapter":"4 Data preprocessing","heading":"4.4.2 Scaling the predictors","text":"premise need pre-process data comes large variety scales financial data:returns time smaller one absolute value;stock volatility lies usually 5% 80%;market capitalization expressed million billion units particular currency;accounting values well;accounting ratios can inhomogeneous units;synthetic attributes like sentiment also idiosyncrasies.widely considered monotonic transformations features marginal impact prediction outcomes, Galili Meilijson (2016) show always case (see also Section 4.8.2). Hence, choice normalization may fact well matter.write \\(x_i\\) raw input \\(\\tilde{x}_i\\) transformed data, common scaling practices include: standardization: \\(\\tilde{x}_i=(x_i-m_x)/\\sigma_x\\), \\(m_x\\) \\(\\sigma_x\\) mean standard deviation \\(x\\), respectively;min-max rescaling [0,1]: \\(\\tilde{x}_i=(x_i-\\min(\\mathbf{x}))/(\\max(\\mathbf{x})-\\min(\\mathbf{x}))\\);min-max rescaling [-1,1]: \\(\\tilde{x}_i=2\\frac{x_i-\\min(\\mathbf{x})}{\\max(\\mathbf{x})-\\min(\\mathbf{x})}-1\\);uniformization: \\(\\tilde{x}_i=F_\\mathbf{x}(x_i)\\), \\(F_\\mathbf{x}\\) empirical c.d.f. \\(\\mathbf{x}\\). case, vector \\(\\tilde{\\mathbf{x}}\\) defined follow uniform distribution [0,1].Sometimes, possible apply logarithmic transform variables large values (market capitalization) large outliers. scaling can come transformation. Obviously, technique prohibited features negative values.often advised scale inputs range [0,1] sending training neural networks instance. dataset use book based variables uniformized: point time, cross-sectional distribution feature uniform unit interval. factor investing, scaling features must operated separately date feature. point critical. makes sure every rebalancing date, predictors similar shape carry information cross-section stocks.Uniformization sometimes presented differently: given characteristic time, characteristic values ranked rank divided number non-missing points. done Freyberger, Neuhierl, Weber (2020) example. Kelly, Pruitt, Su (2019), authors perform operation subtract 0.5 features values lie [-0.5,0.5].Scaling features across dates proscribed. Take example case market capitalization. long run (market crashes notwithstanding), feature increases time. Thus, scaling across dates lead small values beginning sample large values end sample. completely alter dilute cross-sectional content features. ","code":""},{"path":"Data.html","id":"labelling","chapter":"4 Data preprocessing","heading":"4.5 Labelling","text":"","code":""},{"path":"Data.html","id":"simple-labels","chapter":"4 Data preprocessing","heading":"4.5.1 Simple labels","text":"\nseveral ways define labels constructing portfolio policies. course, finality portfolio weight, rarely considered best choice label.11Usual labels factor investing following:raw asset returns;future relative returns (versus benchmark: market-wide index, sector-based portfolio instance). One simple choice take returns minus cross-sectional mean median;probability positive return (return specified threshold);probability outperforming benchmark (computed given time frame);binary version : YES (outperforming) versus (underperforming);risk-adjusted versions : Sharpe ratios, information ratios, MAR CALMAR ratios (see Section 12.3).creating binary variables, often tempting create test compares returns zero (profitable versus non profitable). optimal much time-dependent. good times, many assets positive returns, market crashes, experience positive returns, thereby creating unbalanced classes. better idea split returns two comparing time-\\(t\\) median (average). case, indicator relative two classes much balanced.discuss later chapter, choices still leave room additional degrees freedom. labels rescaled, just like features processed? best time horizon compute performance metrics?","code":""},{"path":"Data.html","id":"categorical-labels","chapter":"4 Data preprocessing","heading":"4.5.2 Categorical labels","text":"\ntypical ML analysis, \\(y\\) proxy future performance, ML engine try minimize distance predicted value realized values. mathematical convenience, sum squared error (\\(L^2\\) norm) used simplest derivative makes gradient descent accessible easy compute.Sometimes, can interesting focus raw performance proxies, like returns Sharpe ratios, discrete investment decisions, can derived proxies. simple example (decision rule) following:\\[\\begin{equation}\n\\tag{4.2}\ny_{t,}=\\left\\{  \\begin{array}{rll}\n-1 & \\text{ } & \\hat{r}_{t,} < r_- \\\\\n0 & \\text{ } & \\hat{r}_{t,} \\[r_-,r_+] \\\\\n+1 & \\text{ } & \\hat{r}_{t,} > r_+ \\\\\n\\end{array} \\right.,\n\\end{equation}\\]\n\\(\\hat{r}_{t,}\\) performance proxy (e.g., returns Sharpe ratio) \\(r_\\pm\\) decision thresholds. predicted performance \\(r_-\\), decision -1 (e.g., sell), \\(r_+\\), decision +1 (e.g., buy) middle (model neither optimistic pessimistic), decision neutral (e.g., hold). performance proxy can course relative benchmark decision directly related benchmark. often advised thresholds \\(r_\\pm\\) chosen three categories relatively balanced, , end comparable number instances.case, final output can considered categorical numerical belongs important subgroup categorical variables: ordered categorical (ordinal) variables. \\(y\\) taken number, usual regression tools apply.\\(y\\) treated non-ordered (nominal) categorical variable, new layer processing required ML tools work numbers. Hence, categories must recoded digits. mapping often used called ‘one-hot encoding.’ vector classes split sparse matrix column dedicated one class. matrix filled zeros ones. one allocated column corresponding class instance. provide simple illustration table .TABLE 4.2:  Concise example one-hot encoding.classification tasks, output larger dimension. instance, gives probability belonging class assigned model. see Chapters 6 7, easily handled via softmax function.standpoint allocation, handling categorical predictions necessarily easy. long-short portfolios, plus minus one signals can provide sign position. long-portfolio, two possible solutions: () work binary classes (versus portfolio) (ii) adapt weights according prediction: zero weight -1 prediction, 0.5 weight 0 prediction full weight +1 prediction. Weights course normalized comply budget constraint.","code":""},{"path":"Data.html","id":"the-triple-barrier-method","chapter":"4 Data preprocessing","heading":"4.5.3 The triple barrier method","text":"conclude section advanced labelling technique mentioned De Prado (2018). idea consider full dynamics trading strategy simple performance proxy. rationale extension often money managers implement P&L triggers cash gains sufficient opt stop losses. Upon inception strategy, three barriers fixed (see Figure 4.4):one current level asset (magenta line), measures reasonable expected profit;one current level asset (cyan line), acts stop-loss signal prevent large negative returns;finally, one fixes horizon strategy terminated (black line).strategy hits first (resp. second) barrier, output +1 (resp. -1), hits last barrier, output equal zero linear interpolation (-1 +1) represents position terminal value relative two horizontal barriers. Computationally, method much demanding, evaluates whole trajectory instance. , nonetheless considered realistic trading strategies often accompanied automatic triggers stop-loss, etc.\nFIGURE 4.4:  Illustration triple barrier method.\n","code":""},{"path":"Data.html","id":"filtering-the-sample","chapter":"4 Data preprocessing","heading":"4.5.4 Filtering the sample","text":"\nOne main challenges Machine Learning extract much signal possible. signal, mean patterns hold --sample. Intuitively, may seem reasonable think data gather, signal can extract. fact false generality data also means noise. Surprisingly, filtering training samples can improve performance. idea example implemented successfully Fu et al. (2018), Guida Coqueret (2018a) Guida Coqueret (2018b).Coqueret Guida (2020), investigate smaller samples may lead superior --sample accuracy particular type ML algorithm: decision trees (see Chapter 6). focus particular kind filter: exclude labels (e.g., returns) extreme retain 20% values smallest 20% largest (bulk distribution removed). , alter structure trees two ways:\n- splitting points altered, always closer center distribution splitting variable (.e., resulting clusters balanced possibly robust);\n- choice splitting variables (sometimes) pushed towards features monotonic impact label.\ntwo properties desirable. first reduces risk fitting small groups instances may spurious. second gives importance features appear globally relevant explaining returns. However, filtering must intense. , instead retaining 20% tail predictor, keep just 10%, loss signal becomes severe performance deteriorates.","code":""},{"path":"Data.html","id":"horizons","chapter":"4 Data preprocessing","heading":"4.5.5 Return horizons","text":"subsection deals one least debated issues factor-based machine learning models: horizons. Several horizons come play whole ML-driven allocation workflow: horizon label, estimation window (chronological depth training samples) holding periods. One early reference looks aspects founding academic paper momentum Jegadeesh Titman (1993). authors compute profitability portfolios based returns past \\(J=3, 6, 9, 12\\) months. Four holding periods tested: \\(K=3,6,9,12\\) months. report: “successful zero-cost (long-short) strategy selects stocks based returns previous 12 months holds portfolio 3 months.” machine learning whatsoever contribution, possible conclusion horizons matter may also hold sophisticated methods. topic fact much discussed, shown continuing debate impact horizons momentum profitability (see, e.g., Novy-Marx (2012), Gong, Liu, Liu (2015) Goyal Wahal (2015)).debate also considered working ML algorithms (see instance Geertsema Lu (2020)). issues estimation windows holding periods mentioned later book, Chapter 12. Naturally, present chapter, horizon label important ingredient. Heuristically, four possible combinations consider one feature simplicity:oscillating label feature;oscillating label, smooth feature (highly autocorrelated);smooth label, oscillating feature;smooth label feature.options, last one probably preferable robust, things equal.12 things equal, mean case, model capable extracting relevant pattern. pattern holds two slowly moving series likely persist time. Thus, since features often highly autocorrelated (cf Figure 4.3), combining smooth labels probably good idea. illustrate critical point , purposefully use 1-month returns examples book show corresponding results often disappointing. returns weakly autocorrelated 6-month 12-month returns much persistent better choices labels.Theoretically, possible understand may case. simplicity, let us assume single feature \\(x\\) explains returns \\(r\\): \\(r_{t+1}=f(x_t)+e_{t+1}\\). \\(x_t\\) highly autocorrelated noise embeded \\(e_{t+1}\\) large, two-period ahead return \\((1+r_{t+1})(1+r_{t+2})-1\\) may carry signal \\(r_{t+1}\\) relationship \\(x_t\\) diffused compounded time. Consequently, may also beneficial embed memory considerations directly modelling function, done instance Matthew F. Dixon (2020). discuss practicalities related autocorrelations next section.","code":""},{"path":"Data.html","id":"pers","chapter":"4 Data preprocessing","heading":"4.6 Handling persistence","text":"\nseparated steps feature engineering labelling two different subsections, probably wiser consider jointly. One important property dataset processed ML algorithm consistency persistence features labels. Intuitively, autocorrelation patterns label \\(y_{t,n}\\) (future performance) features \\(x_{t,n}^{(k)}\\) distant.One problematic example dataset sampled monthly frequency (unusual money management industry) labels monthly returns features risk-based fundamental attributes. case, label weakly autocorrelated, features often highly autocorrelated. situation, sophisticated forecasting tools arbitrage features probably result lot noise. linear predictive models, configuration known generate bias estimates (see study Stambaugh (1999) review Gonzalo Pitarakis (2018)).Among technical options, two simple solutions facing issue: either introduce autocorrelation label, remove features. , first option advised statistical inference linear models. rather easy econometrically:increase autocorrelation label, compute performance longer time ranges. instance, working monthly data, considering annual biennial returns trick. get rid autocorrelation, shortest route resort differences/variations: \\(\\Delta x_{t,n}^{(k)}=x_{t,n}^{(k)}-x_{t-1,n}^{(k)}\\). One advantage procedure makes sense, economically: variations features may better drivers performance, compared raw levels.mix persistent oscillating variables feature space course possible, long driven economic motivations.","code":""},{"path":"Data.html","id":"extensions","chapter":"4 Data preprocessing","heading":"4.7 Extensions","text":"","code":""},{"path":"Data.html","id":"transforming-features","chapter":"4 Data preprocessing","heading":"4.7.1 Transforming features","text":"\nfeature space can easily augmented simple operations. One lagging, , considering older values features assuming memory effect impact label. naturally useful mostly features oscillating (adding layer memory persistent features can somewhat redundant). New variables defined \\(\\breve{x}_{t,n}^{(k)}=x_{t-1,n}^{(k)}\\).cases (e.g., insufficient number features), possible consider ratios products features. Accounting ratios like price--book, book--market, debt--equity examples functions raw features make sense. gains brought larger spectrum features obvious. risk overfitting increases, just like simple linear regression adding variables mechanically increases \\(R^2\\). choices must make sense, economically.Another way increase feature space (mentioned ) consider variations. Variations sentiment, variations book--market ratio, etc., can relevant predictors sometimes, change important level. case, new predictor \\(\\breve{x}_{t,n}^{(k)}=x_{t,n}^{(k)}-x_{t-1,n}^{(k)}\\).","code":""},{"path":"Data.html","id":"macrovar","chapter":"4 Data preprocessing","heading":"4.7.2 Macro-economic variables","text":"\nFinally, discuss important topic. data never separated context comes (environment). classical financial terms, means particular model likely depend overarching situation often proxied macro-economic indicators. One way take account data level simply multiply feature exogenous indicator \\(z_{t}\\) case, new predictor \n\\[\\begin{equation}\n\\tag{4.3}\n\\breve{x}_{t,n}^{(k)}=z_t \\times x_{t,n}^{(k)}\n\\end{equation}\\]\ntechnique used Gu, Kelly, Xiu (2020b) use 8 economic indicators (plus original predictors (\\(z_t=1\\))). increases feature space ninefold.Another route integrates shifting economic environments conditional engineering. Suppose labels coded via formula (4.2). thresholds can made dependent exogenous variable. times turbulence, might good idea increase \\(r_+\\) (buy threshold) \\(r_-\\) (sell threshold) labels become conservative: takes higher return make buy category, short positions favored. One example dynamic thresholding \\[\\begin{equation}\n\\tag{4.4}\nr_{t,\\pm}=r_{\\pm} \\times e^{\\pm\\delta(\\text{VIX}_t-\\bar{\\text{VIX}})},\n\\end{equation}\\]\\(\\text{VIX}_t\\) time-\\(t\\) value VIX, \\(\\bar{\\text{VIX}}\\) average median value. VIX average risk seems increasing, thresholds also increase. parameter \\(\\delta\\) tunes magnitude correction. example, assume \\(r_-<0<r_+\\).","code":""},{"path":"Data.html","id":"active-learning","chapter":"4 Data preprocessing","heading":"4.7.3 Active learning","text":"end section notion active learning. best knowledge, widely used quantitative investment, underlying concept enlightening, hence dedicate paragraphs notion sake completeness.general supervised learning, sometimes asymmetry ability gather features versus labels. instance, free access images, labelling content image (e.g., “dog,” “truck,” “pizza,” etc.) costly requires human annotation. formal terms, \\(\\textbf{X}\\) cheap corresponding \\(\\textbf{y}\\) expensive.often case facing cost constraints, evident solution greed. Ahead usual learning process, filter (often called query) used decide data label train (possibly relationship ML algorithm). labelling performed -called oracle (/knows truth), usually human. technique focuses informative instances referred active learning. refer surveys Settles (2009) Settles (2012) detailed account field (briefly summarize ). term active comes fact learner passively accept data samples actively participates choices items learns .One major dichotomy active learning pertains data source \\(\\textbf{X}\\) query based. One obvious case original sample \\(\\textbf{X}\\) large labelled learner asks particular instances within sample labelled. second case learner ability simulate/generate values \\(\\textbf{x}_i\\). can sometimes problematic oracle recognize data generated machine. instance, purpose label images characters numbers, learner may generate shapes correspond letter digit: oracle label .active learning, one key question , learner choose instances labelled? Heuristically, answer picking observations maximize learning efficiency. binary classification, simple criterion probability belonging one particular class. probability far 0.5, algorithm difficulty picking one class (even though can wrong). interesting case probability close 0.5: machine may hesitate particular instance. Thus, oracle label useful case helps learner configuration undecided.methods seek estimate fit can obtained including particular (new) instances training set, optimize fit. Recalling Section 3.1 Geman, Bienenstock, Doursat (1992) variance-bias tradeoff, , training dataset \\(D\\) one instance \\(x\\) (omit bold font simplicity),\n\\[\\mathbb{E}\\left[\\left.(y-\\hat{f}(x;D))^2\\right|\\{D,x\\}\\right]=\\mathbb{E}\\left[\\left.\\underbrace{(y-\\mathbb{E}[y|x])^2}_{\\text{indep. }D\\text{ }\\hat{f}} \\right|\\{D,x\\} \\right]+(\\hat{f}(x;D)-\\mathbb{E}[y|x])^2,\\]\nnotation \\(f(x;D)\\) used highlight dependence model \\(\\hat{f}\\) dataset \\(D\\): model trained \\(D\\). first term irreducible, depend \\(\\hat{f}\\). Thus, second term interest. take average quantity, taken possible values \\(D\\):\n\\[\\mathbb{E}_D\\left[(\\hat{f}(x;D)-\\mathbb{E}[y|x])^2  \\right]=\\underbrace{\\left(\\mathbb{E}_D\\left[\\hat{f}(x;D)-\\mathbb{E}[y|x]\\right]\\right)^2}_{\\text{squared bias}} \\ + \\ \\underbrace{\\mathbb{E}_D\\left[(\\hat{f}(x,D)-\\mathbb{E}_D[\\hat{f}(x;D)])^2\\right]}_{\\text{variance}}\\]\nexpression complicated compute, learner can query \\(x\\) minimizes tradeoff. Thus, average, new instance one yields best learning angle (measured \\(L^2\\) error). Beyond approach (limited requires oracle label possibly irrelevant instance), many criteria exist querying refer section 3 Settles (2009) exhaustive list.One final question: active learning applicable factor investing? One straightfoward answer data annotated human intervention. Thus, learners simulate instances ask corresponding labels. One possible option provide learner \\(\\textbf{X}\\) \\(\\textbf{y}\\) keep queried subset observations corresponding labels. spirit, close done Coqueret Guida (2020) except query performed machine human user. Indeed, shown paper observations carry amount signal. Instances ‘average’ label values seem average less informative compared extreme label values.","code":""},{"path":"Data.html","id":"additional-code-and-results","chapter":"4 Data preprocessing","heading":"4.8 Additional code and results","text":"","code":""},{"path":"Data.html","id":"impact-of-rescaling-graphical-representation","chapter":"4 Data preprocessing","heading":"4.8.1 Impact of rescaling: graphical representation","text":"start simple illustration different scaling methods. generate arbitrary series rescale . series random time code chunk executed, output remains .define plot scaled variables .Finally, look histogram newly created variables.respect shape, green red distributions close original one. support changes: min/max rescaling ensures values lie \\([0,1]\\) interval. cases, smallest values (left) display spike distribution. construction, spike disappears uniformization: points evenly distributed unit interval.","code":"\nLength <- 100                                 # Length of the sequence\nx <- exp(sin(1:Length))                       # Original data\ndata <- data.frame(index = 1:Length, x = x)   # Data framed into dataframe\nggplot(data, aes(x = index, y = x)) + \n    theme_light() + geom_col()                # Plot\nnorm_unif <-  function(v){  # This is a function that uniformalises a vector.\n    v <- v %>% as.matrix()\n    return(ecdf(v)(v))\n}\n\nnorm_0_1 <-  function(v){  # This is a function that uniformalises a vector.\n    return((v-min(v))/(max(v)-min(v)))\n}\n\ndata_norm <- data.frame(                        # Formatting the data\n    index = 1:Length,                           # Index of point/instance\n    standard = (x - mean(x)) / sd(x),           # Standardisation\n    norm_0_1 = norm_0_1(x),                     # [0,1] reduction\n    unif = norm_unif(x)) %>%                    # Uniformisation\n    gather(key = Type, value = value, -index)   # Putting in tidy format\nggplot(data_norm, aes(x = index, y = value, fill = Type)) +   # Plot!\n    geom_col() + theme_light() + \n    facet_grid(Type~.)          # This option creates 3 concatenated graphs to ease comparison\nggplot(data_norm, aes(x = value, fill = Type)) + geom_histogram(position = \"dodge\")"},{"path":"Data.html","id":"impact-of-rescaling-toy-example","chapter":"4 Data preprocessing","heading":"4.8.2 Impact of rescaling: toy example","text":"illustrate impact choosing one particular rescaling method,13 build simple dataset, comprising 3 firms 3 dates.\nTABLE 4.3: Sample data toy example.\nLet’s briefly comment synthetic data. assume dates ordered chronologically far away: date stands year beginning decade, (forward) returns computed monthly basis. first firm hugely successful multiplies cap ten times periods. second firm remains stable cap-wise, third one plummets. look ‘local’ future returns, strongly negatively related size first third firms. second one, clear pattern.Date--date, analysis fairly similar, though slightly nuanced.date 1, smallest firm largest return two others negative returns.date 2, biggest firm negative return two smaller firms .date 3, returns decreasing size.relationship always perfectly monotonous, seems link size return , typically, investing smallest firm good strategy sample.Now let us look output simple regressions. , package broom part tidyverse. great format regression outputs.\nTABLE 4.4: Regression output independent var. comes\nmin-max rescaling\n\n\nTABLE 4.5: Regression output indep. var. comes uniformization\nterms p-value (last column), first estimation cap coefficient 5% (Table 4.4) second 1% (Table 4.5). One possible explanation discrepancy standard deviation variables. deviations equal 0.47 0.29 cap_0 cap_u, respectively. Values like market capitalizations can large ranges thus subject substantial deviations (even scaling). Working uniformized variables reduces dispersion can help solve problem.Note double-edged sword: can help avoid false negatives, can also lead false positives.","code":"\nfirm <- c(rep(1,3), rep(2,3), rep(3,3))             # Firms (3 lines for each)\ndate <- rep(c(1,2,3),3)                             # Dates\ncap <- c(10, 50, 100,                               # Market capitalization\n         15, 10, 15, \n         200, 120, 80)\nreturn <- c(0.06, 0.01, -0.06,                      # Return values\n            -0.03, 0.00, 0.02,\n            -0.04, -0.02,0.00)\ndata_toy <- data.frame(firm, date, cap, return)     # Aggregation of data\ndata_toy <- data_toy %>%                            # Transformation of data\n    group_by(date) %>%                            \n    mutate(cap_0_1 = norm_0_1(cap), cap_u = norm_unif(cap))\nlm(return ~ cap_0_1, data = data_toy) %>% # First regression (min-max rescaling)\n    broom::tidy() %>% \n    knitr::kable(caption = 'Regression output when the independent var. comes \n                 from min-max rescaling',  booktabs = T) \nlm(return ~ cap_u, data = data_toy) %>%   # Second regression (uniformised feature)\n    broom::tidy() %>%   \n    knitr::kable(caption = 'Regression output when the indep. var. comes from uniformization',\n                  booktabs = T)   "},{"path":"Data.html","id":"coding-exercises-1","chapter":"4 Data preprocessing","heading":"4.9 Coding exercises","text":"Federal Reserve Saint Louis (https://fred.stlouisfed.org) hosts thousands time series economic indicators can serve conditioning variables. Pick one apply formula (4.3) expand number predictors. need , use function defined .Create new categorical label based formulae (4.4) (4.2). time series VIX can also retrieved Federal Reserve’s website: https://fred.stlouisfed.org/series/VIXCLS.Plot histogram R12M_Usd variable. Clearly, outliers present. Identify stock highest value variable determine value can correct .","code":""},{"path":"lasso.html","id":"lasso","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5 Penalized regressions and sparse hedging for minimum variance portfolios","text":"chapter, introduce widespread concept regularization linear models. fact several possible applications models. first one straightforward: resort penalizations improve robustness factor-based predictive regressions. outcome can used fuel allocation scheme. instance, Han et al. (2019) D. Rapach Zhou (2019) use penalized regressions improve stock return prediction combining forecasts emanate individual characteristics.Similar ideas can developed macroeconomic predictions instance, Uematsu Tanaka (2019).\nsecond application stems less known result originates Stevens (1998). links weights optimal mean-variance portfolios particular cross-sectional regressions. idea different purpose improve quality mean-variance driven portfolio weights. present two approaches introduction regularization techniques linear models.examples financial applications penalization can found d’Aspremont (2011), Ban, El Karoui, Lim (2016) Kremer et al. (2019). case, idea seminal paper Tibshirani (1996): standard (unconstrained) optimization programs may lead noisy estimates, thus adding structuring constraint helps remove noise (cost possible bias). instance, Kremer et al. (2019) use concept build robust mean-variance (Markowitz (1952)) portfolios Freyberger, Neuhierl, Weber (2020) use single characteristics really help explain cross-section equity returns.","code":""},{"path":"lasso.html","id":"penalized-regressions","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.1 Penalized regressions","text":"","code":""},{"path":"lasso.html","id":"penreg","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.1.1 Simple regressions","text":" \nideas behind linear models least two centuries old (Legendre (1805) early reference least squares optimization). Given matrix predictors \\(\\textbf{X}\\), seek decompose output vector \\(\\textbf{y}\\) linear function columns \\(\\textbf{X}\\) (written \\(\\textbf{X}\\boldsymbol{\\beta}\\)) plus error term \\(\\boldsymbol{\\epsilon}\\): \\(\\textbf{y}=\\textbf{X}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}\\).best choice \\(\\boldsymbol{\\beta}\\) naturally one minimizes error. analytical tractability, sum squared errors minimized: \\(L=\\boldsymbol{\\epsilon}'\\boldsymbol{\\epsilon}=\\sum_{=1}^\\epsilon_i^2\\). loss \\(L\\) called sum squared residuals (SSR). order find optimal \\(\\boldsymbol{\\beta}\\), imperative differentiate loss \\(L\\) respect \\(\\boldsymbol{\\beta}\\) first order condition requires gradient equal zero:\n\\[\\begin{align*}\n\\nabla_{\\boldsymbol{\\beta}} L&=\\frac{\\partial}{\\partial \\boldsymbol{\\beta}}(\\textbf{y}-\\textbf{X}\\boldsymbol{\\beta})'(\\textbf{y}-\\textbf{X}\\boldsymbol{\\beta})=\\frac{\\partial}{\\partial \\boldsymbol{\\beta}}\\boldsymbol{\\beta}'\\textbf{X}'\\textbf{X}\\boldsymbol{\\beta}-2\\textbf{y}'\\textbf{X}\\boldsymbol{\\beta} \\\\\n&=2\\textbf{X}'\\textbf{X}\\boldsymbol{\\beta}  -2\\textbf{X}'\\textbf{y}\n\\end{align*}\\]\nfirst order condition \\(\\nabla_{\\boldsymbol{\\beta}}=\\textbf{0}\\) satisfied \n\\[\\begin{equation}\n\\tag{5.1}\n\\boldsymbol{\\beta}^*=(\\textbf{X}'\\textbf{X})^{-1}\\textbf{X}'\\textbf{y},\n\\end{equation}\\]\nknown standard ordinary least squares (OLS) solution linear model. matrix \\(\\textbf{X}\\) dimensions \\(\\times K\\), \\(\\textbf{X}'\\textbf{X}\\) can inverted number rows \\(\\) strictly superior number columns \\(K\\). cases, may hold; predictors instances unique value \\(\\boldsymbol{\\beta}\\) minimizes loss. \\(\\textbf{X}'\\textbf{X}\\) nonsingular (positive definite), second order condition ensures \\(\\boldsymbol{\\beta}^*\\) yields global minimum loss \\(L\\) (second order derivative \\(L\\) respect \\(\\boldsymbol{\\beta}\\), Hessian matrix, exactly \\(\\textbf{X}'\\textbf{X}\\)).now, made distributional assumption quantities. Standard assumptions following:\n- \\(\\mathbb{E}[\\textbf{y}|\\textbf{X}]=\\textbf{X}\\boldsymbol{\\beta}\\): linear shape regression function;\n- \\(\\mathbb{E}[\\boldsymbol{\\epsilon}|\\textbf{X}]=\\textbf{0}\\): errors independent predictors;\n- \\(\\mathbb{E}[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}'| \\textbf{X}]=\\sigma^2\\textbf{}\\): homoscedasticity - errors uncorrelated identical variance;\n- \\(\\epsilon_i\\) normally distributed.hypotheses, possible perform statistical tests related \\(\\hat{\\boldsymbol{\\beta}}\\) coefficients. refer chapters 2 4 Greene (2018) thorough treatment linear models well chapter 5 book details corresponding tests.","code":""},{"path":"lasso.html","id":"forms-of-penalizations","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.1.2 Forms of penalizations","text":"\nPenalized regressions popularized since seminal work Tibshirani (1996). idea impose constraint coefficients regression, namely total magnitude restrained. original paper, Tibshirani (1996) proposes estimate following model (LASSO):\n\\[\\begin{equation}\n\\tag{5.2}\ny_i = \\sum_{j=1}^J \\beta_jx_{,j} + \\epsilon_i, \\quad =1,\\dots,, \\quad \\text{s.t.} \\quad \\sum_{j=1}^J |\\beta_j| < \\delta, \n\\end{equation}\\]\nstrictly positive constant \\(\\delta\\). least square minimization, amounts solve Lagrangian formulation:\n\\[\\begin{equation}\n\\tag{5.3}\n\\underset{\\mathbf{\\beta}}{\\min} \\, \\left\\{ \\sum_{=1}^\\left(y_i - \\sum_{j=1}^J \\beta_jx_{,j} \\right)^2+\\lambda \\sum_{j=1}^J |\\beta_j| \\right\\},\n\\end{equation}\\]\nvalue \\(\\lambda>0\\) naturally depends \\(\\delta\\) (lower \\(\\delta\\), higher \\(\\lambda\\): constraint binding). specification seems close ridge regression (\\(L^2\\) regularization), fact anterior Lasso:\n\\[\\begin{equation}\n\\tag{5.4}\n\\underset{\\mathbf{\\beta}}{\\min} \\, \\left\\{ \\sum_{=1}^\\left(y_i - \\sum_{j=1}^J\\beta_jx_{,j} \\right)^2+\\lambda \\sum_{j=1}^J \\beta_j^2 \\right\\},\n\\end{equation}\\]\nequivalent estimating following model\n\\[\\begin{equation}\n\\tag{5.5}\ny_i = \\sum_{j=1}^J \\beta_jx_{,j} + \\epsilon_i, \\quad =1,\\dots,, \\quad \\text{s.t.} \\quad \\sum_{j=1}^J \\beta_j^2 < \\delta, \n\\end{equation}\\]\noutcome fact quite different, justifies separate treatment. Mechanically, \\(\\lambda\\), penalization intensity, increases (\\(\\delta\\) (5.5) decreases), coefficients ridge regression slowly decrease magnitude towards zero. case LASSO, convergence somewhat brutal coefficients shrink zero quickly. \\(\\lambda\\) sufficiently large, one coefficient remain nonzero, ridge regression, zero value reached asymptotically coefficients. invite interested read look survey Hastie (2020) applications ridge regressions data science links topics like cross-validation dropout regularization, among others.depict difference Lasso ridge regression, let us consider case \\(K=2\\) predictors shown Figure 5.1. optimal unconstrained solution \\(\\boldsymbol{\\beta}^*\\) pictured red middle space. problem naturally satisfy imposed conditions. constraints shown light grey: take shape square \\(|\\beta_1|+|\\beta_2| \\le \\delta\\) case Lasso circle \\(\\beta_1^2+\\beta_2^2 \\le \\delta\\) ridge regression. order satisfy constraints, optimization needs look vicinity \\(\\boldsymbol{\\beta}^*\\) allowing larger error levels. error levels shown orange ellipsoids figure. requirement error loose enough, one ellipsoid touches acceptable boundary (grey) constrained solution located.\nFIGURE 5.1: Schematic view Lasso (left) versus ridge (right) regressions.\nmethods work number exogenous variables surpasses observations, .e., case classical regressions ill-defined. easy see case ridge regression OLS solution simply\n\\[\\hat{\\boldsymbol{\\beta}}=(\\mathbf{X}'\\mathbf{X}+\\lambda \\mathbf{}_N)^{-1}\\mathbf{X}'\\mathbf{Y}.\\]\nadditional term \\(\\lambda \\mathbf{}_N\\) compared Equation (5.1) ensures inverse matrix well-defined whenever \\(\\lambda>0\\). \\(\\lambda\\) increases, magnitudes \\(\\hat{\\beta}_i\\) decrease, explains penalizations sometimes referred shrinkage methods (estimated coefficients see values shrink). Zou Hastie (2005) propose benefit best worlds combining penalizations convex manner (call elasticnet):\n\\[\\begin{equation}\n\\tag{5.6}\ny_i = \\sum_{j=1}^J \\beta_jx_{,j} + \\epsilon_i, \\quad \\text{s.t.} \\quad \\alpha \\sum_{j=1}^J |\\beta_j| +(1-\\alpha)\\sum_{j=1}^J \\beta_j^2< \\delta, \\quad =1,\\dots,N,\n\\end{equation}\\]\nassociated optimization program\n\\[\\begin{equation}\n\\tag{5.7}\n\\underset{\\mathbf{\\beta}}{\\min} \\, \\left\\{ \\sum_{=1}^\\left(y_i - \\sum_{j=1}^J\\beta_jx_{,j} \\right)^2+\\lambda \\left(\\alpha\\sum_{j=1}^J |\\beta_j|+ (1-\\alpha)\\sum_{j=1}^J \\beta_j^2\\right) \\right\\}.\n\\end{equation}\\]main advantage LASSO compared ridge regression selection capability. Indeed, given large number variables (predictors), LASSO progressively rule least relevant. elasticnet preserves selection ability Zou Hastie (2005) argue cases, even effective LASSO. parameter \\(\\alpha \\[0,1]\\) tunes smoothness convergence (coefficients) towards zero. closer \\(\\alpha\\) zero, smoother convergence.","code":""},{"path":"lasso.html","id":"illustrations","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.1.3 Illustrations","text":"begin simple illustrations penalized regressions. start LASSO. original implementation authors R, practical. syntax slightly different, compared usual linear models. illustrations run whole dataset. First, estimate coefficients. default, function chooses large array penalization values results different penalization intensities (\\(\\lambda\\)) can shown immediately.coefficients computed, require wrangling plotting. Also, many , plot subset .\nFIGURE 5.2: LASSO model. dependent variable 1 month ahead return.\ngraph plots evolution coefficients penalization intensity, \\(\\lambda\\), increases. characteristics, like Ebit_Ta (orange), convergence zero rapid. variables resist penalization longer, like Mkt_Cap_3M_Usd, last one vanish. Essentially, means first order, variable important driver future 1-month returns sample. Moreover, negative sign coefficient confirmation (, sample) size anomaly, according small firms experience higher future returns compared larger counterparts.Next, turn ridge regressions.\nFIGURE 5.3: Ridge regression. dependent variable 1 month ahead return.\nFigure 5.3, convergence zero much smoother. underline x-axis (penalization intensities) log-scale. allows see early patterns (close zero, left) clearly. previous figure, Mkt_Cap_3M_Usd predictor clearly dominates, large negative coefficients. Nonetheless, \\(\\lambda\\) increases, domination predictor fades.definition, elasticnet produce curves behave like blend two approaches. Nonetheless, long \\(\\alpha >0\\), selective property LASSO preserved: features see coefficients shrink rapidly zero. fact, strength LASSO balanced mix two penalizations reached \\(\\alpha = 1/2\\), rather much smaller value (possibly 0.1).","code":"\nlibrary(glmnet)\ny_penalized <- data_ml$R1M_Usd                              # Dependent variable\nx_penalized <- data_ml %>%                                  # Predictors\n    dplyr::select(all_of(features)) %>% as.matrix() \nfit_lasso <- glmnet(x_penalized, y_penalized, alpha = 1)    # Model alpha = 1: LASSO\nlasso_res <- summary(fit_lasso$beta)                        # Extract LASSO coefs\nlambda <- fit_lasso$lambda                                  # Values of the penalisation const\nlasso_res$Lambda <- lambda[lasso_res$j]                     # Put the labels where they belong\nlasso_res$Feature <- features[lasso_res$i] %>% as.factor()  # Add names of variables to output\nlasso_res[1:120,] %>%                                       # Take the first 120 estimates\n    ggplot(aes(x = Lambda, y = x, color = Feature)) +       # Plot!\n    geom_line() + coord_fixed(0.25) + ylab(\"beta\") +        # Change aspect ratio of graph\n    theme(legend.text = element_text(size = 7))             # Reduce legend font size\nfit_ridge <- glmnet(x_penalized, y_penalized, alpha = 0)                  # alpha = 0: ridge\nridge_res <- summary(fit_ridge$beta)                                      # Extract ridge coefs\nlambda <- fit_ridge$lambda                                                # Penalisation const\nridge_res$Feature <- features[ridge_res$i] %>% as.factor()\nridge_res$Lambda <- lambda[ridge_res$j]                                   # Set labels right\nridge_res %>% \n    filter(Feature %in% levels(droplevels(lasso_res$Feature[1:120]))) %>% # Keep same features \n    ggplot(aes(x = Lambda, y = x, color = Feature)) + ylab(\"beta\") +      # Plot!\n    geom_line() + scale_x_log10() + coord_fixed(45) +                     # Aspect ratio \n    theme(legend.text = element_text(size = 7))"},{"path":"lasso.html","id":"sparse-hedging-for-minimum-variance-portfolios","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.2 Sparse hedging for minimum variance portfolios","text":"","code":""},{"path":"lasso.html","id":"presentation-and-derivations","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.2.1 Presentation and derivations","text":"idea constructing sparse portfolios new per se (see, e.g., Brodie et al. (2009), Fastrich, Paterlini, Winker (2015)) link selective property LASSO rather straightforward classical quadratic programs. Note choice \\(L^1\\) norm imperative enforcing simple \\(L^2\\) norm, diversification portfolio increases (see Coqueret (2015)).idea behind section stems Goto Xu (2015) cornerstone result first published Stevens (1998) present . provide details derivations commonplace literature.usual mean-variance allocations, one core ingredient inverse covariance matrix assets \\(\\mathbf{\\Sigma}^{-1}\\). instance, maximum Sharpe ratio (MSR) portfolio given \\[\\begin{equation}\n\\tag{5.8}\n\\mathbf{w}^{\\text{MSR}}=\\frac{\\mathbf{\\Sigma}^{-1}\\boldsymbol{\\mu}}{\\mathbf{1}'\\mathbf{\\Sigma}^{-1}\\boldsymbol{\\mu}},\n\\end{equation}\\]\n\\(\\mathbf{\\mu}\\) vector expected (excess) returns. Taking \\(\\mathbf{\\mu}=\\mathbf{1}\\) yields minimum variance portfolio, agnostic terms first moment expected returns (, , usually robust alternatives try estimate \\(\\boldsymbol{\\mu}\\) often fail).Usually, traditional way estimate \\(\\boldsymbol{\\Sigma}\\) invert get MSR weights. However, several approaches aim estimating \\(\\boldsymbol{\\Sigma}^{-1}\\)  present one . proceed one asset time, , one line \\(\\boldsymbol{\\Sigma}^{-1}\\) time.\ndecompose matrix \\(\\mathbf{\\Sigma}\\) :\n\\[\\mathbf{\\Sigma}= \\left[\\begin{array}{cc} \\sigma^2 & \\mathbf{c}' \\\\\n\\mathbf{c}& \\mathbf{C}\\end{array} \\right],\\]\nclassical partitioning results (e.g., Schur complements) imply\n\\[\\small \\mathbf{\\Sigma}^{-1}= \\left[\\begin{array}{cc} (\\sigma^2 -\\mathbf{c}'\\mathbf{C}^{-1}\\mathbf{c})^{-1} & - (\\sigma^2 -\\mathbf{c}'\\mathbf{C}^{-1}\\mathbf{c})^{-1}\\mathbf{c}'\\mathbf{C}^{-1} \\\\\n- (\\sigma^2 -\\mathbf{c}'\\mathbf{C}^{-1}\\mathbf{c})^{-1}\\mathbf{C}^{-1}\\mathbf{c}& \\mathbf{C}^{-1}+ (\\sigma^2 -\\mathbf{c}'\\mathbf{C}^{-1}\\mathbf{c})^{-1}\\mathbf{C}^{-1}\\mathbf{cc}'\\mathbf{C}^{-1}\\end{array} \\right].\\]\ninterested first line, 2 components: factor \\((\\sigma^2 -\\mathbf{c}'\\mathbf{C}^{-1}\\mathbf{c})^{-1}\\) line vector \\(\\mathbf{c}'\\mathbf{C}^{-1}\\). \\(\\mathbf{C}\\) covariance matrix assets \\(2\\) \\(N\\) \\(\\mathbf{c}\\) covariance first asset assets. first line \\(\\mathbf{\\Sigma}^{-1}\\) \n\\[\\begin{equation}\n\\tag{5.9}\n(\\sigma^2 -\\mathbf{c}'\\mathbf{C}^{-1}\\mathbf{c})^{-1} \\left[1 \\quad  \\underbrace{-\\mathbf{c}'\\mathbf{C}^{-1}}_{N-1 \\text{ terms}} \\right]. \n\\end{equation}\\]now consider alternative setting. regress returns first asset assets:\n\\[\\begin{equation}\n\\tag{5.10}\nr_{1,t}=a_1+\\sum_{n=2}^N\\beta_{1|n}r_{n,t}+\\epsilon_t, \\quad \\text{ .e., } \\quad  \\mathbf{r}_1=a_1\\mathbf{1}_T+\\mathbf{R}_{-1}\\mathbf{\\beta}_1+\\epsilon_1,\n\\end{equation}\\]\n\\(\\mathbf{R}_{-1}\\) gathers returns assets except first one. OLS estimator \\(\\mathbf{\\beta}_1\\) \n\\[\\begin{equation}\n\\tag{5.11}\n\\hat{\\mathbf{\\beta}}_{1}=\\mathbf{C}^{-1}\\mathbf{c},\n\\end{equation}\\]partitioned form (constant included regression) stemming Frisch-Waugh-Lovell theorem (see chapter 3 Greene (2018)).addition,\n\\[\\begin{equation}\n\\tag{5.12}\n(1-R^2)\\sigma_{\\mathbf{r}_1}^2=\\sigma_{\\mathbf{r}_1}^2- \\mathbf{c}'\\mathbf{C}^{-1}\\mathbf{c} =\\sigma^2_{\\epsilon_1}.\n\\end{equation}\\]\nproof last fact given .\\(\\mathbf{X}\\) concatenation \\(\\mathbf{1}_T\\) returns \\(\\mathbf{R}_{-1}\\) \\(\\mathbf{y}=\\mathbf{r}_1\\), classical expression \\(R^2\\) \\[R^2=1-\\frac{\\mathbf{\\epsilon}'\\mathbf{\\epsilon}}{T\\sigma_Y^2}=1-\\frac{\\mathbf{y}'\\mathbf{y}-\\hat{\\mathbf{\\beta}'}\\mathbf{X}'\\mathbf{X}\\hat{\\mathbf{\\beta}}}{T\\sigma_Y^2}=1-\\frac{\\mathbf{y}'\\mathbf{y}-\\mathbf{y}'\\mathbf{X}\\hat{\\mathbf{\\beta}}}{T\\sigma_Y^2},\\]\nfitted values \\(\\mathbf{X}\\hat{\\mathbf{\\beta}}= \\hat{a_1}\\mathbf{1}_T+\\mathbf{R}_{-1}\\mathbf{C}^{-1}\\mathbf{c}\\). Hence,\n\\[\\begin{align*}\nT\\sigma_{\\mathbf{r}_1}^2R^2&=T\\sigma_{\\mathbf{r}_1}^2-\\mathbf{r}'_1\\mathbf{r}_1+\\hat{a_1}\\mathbf{1}'_T\\mathbf{r}_1+\\mathbf{r}'_1\\mathbf{R}_{-1}\\mathbf{C}^{-1}\\mathbf{c} \\\\\nT(1-R^2)\\sigma_{\\mathbf{r}_1}^2&=\\mathbf{r}'_1\\mathbf{r}_1-\\hat{a_1}\\mathbf{1}'_T\\mathbf{r}_1-\\left(\\mathbf{\\tilde{r}}_1+\\frac{\\mathbf{1}_T\\mathbf{1}'_T}{T}\\mathbf{r}_1\\right)'\\left(\\tilde{\\mathbf{R}}_{-1}+\\frac{\\mathbf{1}_T\\mathbf{1}'_T}{T}\\mathbf{R}_{-1}\\right)\\mathbf{C}^{-1}\\mathbf{c} \\\\\nT(1-R^2)\\sigma_{\\mathbf{r}_1}^2&=\\mathbf{r}'_1\\mathbf{r}_1-\\hat{a_1}\\mathbf{1}'_T\\mathbf{r}_1-T\\mathbf{c}'\\mathbf{C}^{-1}\\mathbf{c} -\\mathbf{r}'_1\\frac{\\mathbf{1}_T\\mathbf{1}'_T}{T}\\mathbf{R}_{-1} \\mathbf{C}^{-1}\\mathbf{c} \\\\\nT(1-R^2)\\sigma_{\\mathbf{r}_1}^2&=\\mathbf{r}'_1\\mathbf{r}_1-\\frac{(\\mathbf{1}'_T\\mathbf{r}_1)^2}{T}- T\\mathbf{c}'\\mathbf{C}^{-1}\\mathbf{c} \\\\\n(1-R^2)\\sigma_{\\mathbf{r}_1}^2&=\\sigma_{\\mathbf{r}_1}^2- \\mathbf{c}'\\mathbf{C}^{-1}\\mathbf{c} \n\\end{align*}\\]\nfourth equality plugged \\(\\hat{}_1=\\frac{\\mathbf{1'}_T}{T}(\\mathbf{r}_1-\\mathbf{R}_{-1}\\mathbf{C}^{-1}\\mathbf{c})\\). Note probably simpler proof, see, e.g., section 3.5 Greene (2018).Combining ((5.9), ((5.11)) ((5.12)), get first line \\(\\mathbf{\\Sigma}^{-1}\\) equal \n\\[\\begin{equation}\n\\tag{5.13}\n\\frac{1}{\\sigma^2_{\\epsilon_1}}\\times \\left[ 1 \\quad  -\\hat{\\boldsymbol{\\beta}}_1'\\right].\n\\end{equation}\\]Given first line \\(\\mathbf{\\Sigma}^{-1}\\), suffices multiply \\(\\boldsymbol{\\mu}\\) get portfolio weight first asset (scaling constant).nice economic intuition behind results justifies term “sparse hedging.” take case minimum variance portfolio, \\(\\boldsymbol{\\mu}=\\boldsymbol{1}\\). Equation (5.10), try explain return asset 1 assets. equation, scaling constant, portfolio unit position first asset \\(-\\hat{\\boldsymbol{\\beta}}_1\\) positions assets. Hence, purpose assets clearly hedge return first one. fact, positions aimed minimizing squared errors aggregate portfolio first asset (errors exactly \\(\\mathbf{\\epsilon}_1\\)). Moreover, scaling factor \\(\\sigma^{-2}_{\\epsilon_1}\\) also simple interpret: trust regression output (small \\(\\sigma^{2}_{\\epsilon_1}\\)), invest hedging portfolio asset.reasoning easily generalized line \\(\\mathbf{\\Sigma}^{-1}\\), can obtained regressing returns asset \\(\\) returns assets. allocation scheme form ((5.8)) given values \\(\\boldsymbol{\\mu}\\), pseudo-code sparse portfolio strategy following.date (omit notational convenience),stocks \\(\\),estimate elasticnet regression \\(t=1,\\dots,T\\) samples get \\(^{th}\\) line \\(\\hat{\\mathbf{\\Sigma}}^{-1}\\):\n\\[ \\small \\left[\\hat{\\mathbf{\\Sigma}}^{-1}\\right]_{,\\cdot}= \\underset{\\mathbf{\\beta}_{|}}{\\text{argmin}}\\, \\left\\{\\sum_{t=1}^T\\left( r_{,t}-a_i+\\sum_{n\\neq }^N\\beta_{|n}r_{n,t}\\right)^2+\\lambda \\alpha ||  \\mathbf{\\beta}_{|}||_1+\\lambda (1-\\alpha)||\\mathbf{\\beta}_{|}||_2^2\\right\\}\n\\]get weights asset \\(\\), compute \\(\\mathbf{\\mu}\\)-weighted sum:\n\\(w_i= \\sigma_{\\epsilon_i}^{-2}\\left(\\mu_i- \\sum_{j\\neq }\\mathbf{\\beta}_{|j}\\mu_j\\right)\\),recall vectors \\(\\mathbf{\\beta}_{|}=[\\mathbf{\\beta}_{|1},\\dots,\\mathbf{\\beta}_{|-1},\\mathbf{\\beta}_{|+1},\\dots,\\mathbf{\\beta}_{|N}]\\) coefficients regressing returns asset \\(\\) returns assets.\nintroduction penalization norms new ingredient, compared original approach Stevens (1998). benefits twofold: first, introducing constraints yields weights robust less subject errors estimates \\(\\mathbf{\\mu}\\); second, sparsity, weights stable, less leveraged thus strategy less impacted transaction costs. turn numerical applications, mention direct route estimation robust inverse covariance matrix: Graphical LASSO. GLASSO estimates precision matrix (inverse covariance matrix) via maximum likelihood imposing constraints/penalizations weights matrix. penalization strong enough, yields sparse matrix, .e., matrix possibly many coefficients zero. refer original article J. Friedman, Hastie, Tibshirani (2008) details subject.","code":""},{"path":"lasso.html","id":"sparseex","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.2.2 Example","text":"interest sparse hedging portfolios propose robust approach estimation minimum variance policies. Indeed, since vector expected returns \\(\\boldsymbol{\\mu}\\) usually noisy, simple solution adopt agnostic view setting \\(\\boldsymbol{\\mu}=\\boldsymbol{1}\\). order test added value sparsity constraint, must resort full backtest. , anticipate content Chapter 12.first prepare variables. Sparse portfolios based returns ; thus base analysis dedicated variable matrix/rectangular format (returns) created end Chapter 1., initialize output variables: portfolio weights portfolio returns. want compare three strategies: equally weighted (EW) benchmark stocks, classical global minimum variance portfolio (GMV) sparse-hedging approach minimum variance.Next, purpose section, isolate computation weights sparse-hedging portfolios. case minimum variance portfolios, \\(\\boldsymbol{\\mu}=\\boldsymbol{1}\\), weight asset 1 simply sum terms Equation (5.13) weights similar forms.order benchmark strategy, define meta-weighting function embeds three strategies: (1) EW benchmark, (2) classical GMV (3) sparse-hedging minimum variance. GMV, since much assets dates, covariance matrix singular. Thus, small heuristic shrinkage term. rigorous treatment technique, refer original article Olivier Ledoit Wolf (2004) recent improvements mentioned Olivier Ledoit Wolf (2017). short, use \\(\\hat{\\boldsymbol{\\Sigma}}=\\boldsymbol{\\Sigma}_S+\\delta \\boldsymbol{}\\) small constant \\(\\delta\\) (equal 0.01 code ).Finally, proceed backtesting loop. Given number assets, execution loop takes minutes. end loop, compute standard deviation portfolio returns (monthly volatility). key indicator minimum variance seeks minimize particular metric.aim sparse hedging restrictions provide better estimate covariance structure assets estimation minimum variance portfolio weights accurate. exercise, see monthly volatility indeed reduced building covariance matrices based sparse hedging relationships. case use shrunk sample covariance matrix probably much noise estimates correlations assets. Working daily returns likely improve quality estimates. backtest shows penalized methodology performs well even number observations (dates) small compared number assets.","code":"\nt_oos <- returns$date[returns$date > separation_date] %>%            # Out-of-sample dates \n    unique() %>%                                                     # Remove duplicates\n    as.Date(origin = \"1970-01-01\")                                   # Transform in date format\nTt <- length(t_oos)                                                  # Nb of dates, avoid T \nnb_port <- 3                                                         # Nb of portfolios/strats.\nportf_weights <- array(0, dim = c(Tt, nb_port, ncol(returns) - 1))   # Initial portf. weights\nportf_returns <- matrix(0, nrow = Tt, ncol = nb_port)                # Initial portf. returns \nweights_sparsehedge <- function(returns, alpha, lambda){  # The parameters are defined here\n    w <- 0                                                # Initiate weights\n    for(i in 1:ncol(returns)){                            # Loop on the assets\n        y <- returns[,i]                                  # Dependent variable\n        x <- returns[,-i]                                 # Independent variable\n        fit <- glmnet(x,y, family = \"gaussian\", alpha = alpha, lambda = lambda)\n        err <- y-predict(fit, x)                          # Prediction errors\n        w[i] <- (1-sum(fit$beta))/var(err)                # Output: weight of asset i\n    }\n    return(w / sum(w))                                    # Normalisation of weights\n}\nweights_multi <- function(returns,j, alpha, lambda){\n    N <- ncol(returns)\n    if(j == 1){                                    # j = 1 => EW\n        return(rep(1/N,N))\n    }\n    if(j == 2){                                    # j = 2 => Minimum Variance\n        sigma <- cov(returns) + 0.01 * diag(N)     # Covariance matrix + regularizing term\n        w <- solve(sigma) %*% rep(1,N)             # Inverse & multiply\n        return(w / sum(w))                         # Normalize\n    }\n    if(j == 3){                                    # j = 3 => Penalised / elasticnet\n        w <- weights_sparsehedge(returns, alpha, lambda)\n    }\n}\nfor(t in 1:length(t_oos)){                                                 # Loop = rebal. dates\n    temp_data <- returns %>%                                               # Data for weights\n        filter(date < t_oos[t]) %>%                                        # Expand. window\n        dplyr::select(-date) %>%\n        as.matrix() \n    realised_returns <- returns %>%                                        # OOS returns\n        filter(date ==  t_oos[t]) %>% \n        dplyr::select(-date)\n    for(j in 1:nb_port){                                                   # Loop over strats\n        portf_weights[t,j,] <- weights_multi(temp_data, j, 0.1, 0.1)       # Hard-coded params!\n        portf_returns[t,j] <- sum(portf_weights[t,j,] * realised_returns)  # Portf. returns\n    }\n}\ncolnames(portf_returns) <- c(\"EW\", \"MV\", \"Sparse\") # Colnames\napply(portf_returns, 2, sd)                        # Portfolio volatilities (monthly scale)##         EW         MV     Sparse \n## 0.04180422 0.03350424 0.02672169"},{"path":"lasso.html","id":"predictive-regressions","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.3 Predictive regressions","text":"","code":""},{"path":"lasso.html","id":"literature-review-and-principle","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.3.1 Literature review and principle","text":"topic predictive regressions sits collection interesting articles. One influential contribution Stambaugh (1999), author shows perils regressions independent variables autocorrelated. case, usual OLS estimate biased must therefore corrected. results since extended numerous directions (see Campbell Yogo (2006) Hjalmarsson (2011), survey Gonzalo Pitarakis (2018) , recently, study Xu (2020) predictability multiple horizons).second important topic pertains time-dependence coefficients predictive regressions. One contribution direction Dangl Halling (2012), coefficients estimated via Bayesian procedure. recently Kelly, Pruitt, Su (2019) use time-dependent factor loadings model cross-section stock returns. time-varying nature coefficients predictive regressions documented Henkel, Martin, Nardari (2011) short term returns. Lastly, Farmer, Schmidt, Timmermann (2019) introduce concept pockets predictability: assets markets experience different phases; stages, predictable others, aren’t. Pockets measured number days t-statistic particular threshold magnitude \\(R^2\\) considered period. Formal statistical tests developed Demetrescu et al. (2020).introduction penalization within predictive regressions goes back least D. E. Rapach, Strauss, Zhou (2013), used assess lead-lag relationships US markets international stock exchanges. recently, Alexander Chinco, Clark-Joseph, Ye (2019) use LASSO regressions forecast high frequency returns based past returns (cross-section) various horizons. report statistically significant gains. Han et al. (2019) D. Rapach Zhou (2019) use LASSO elasticnet regressions (respectively) improve forecast combinations single characteristics matter explaining stock returns.contributions underline relevance overlap predictive regressions penalized regressions. simple machine-learning based asset pricing, often seek build models Equation (3.6). stick linear relationship add penalization terms, model becomes:\n\\[r_{t+1,n} = \\alpha_n + \\sum_{k=1}^K\\beta_n^kf^k_{t,n}+\\epsilon_{t+1,n}, \\quad \\text{s.t.} \\quad (1-\\alpha)\\sum_{j=1}^J |\\beta_j| +\\alpha\\sum_{j=1}^J \\beta_j^2< \\theta\\]\nuse \\(f^k_{t,n}\\) \\(x_{t,n}^k\\) interchangeably \\(\\theta\\) penalization intensity. , one aims regularization generate robust estimates. patterns extracted hold sample, \n\\[\\hat{r}_{t+1,n} = \\hat{\\alpha}_n + \\sum_{k=1}^K\\hat{\\beta}_n^kf^k_{t,n},\\]\nrelatively reliable proxy future performance.","code":""},{"path":"lasso.html","id":"code-and-results","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.3.2 Code and results","text":"Given form dataset, implementing penalized predictive regressions easy.report two key performance measures: mean squared error hit ratio, proportion times prediction guesses sign return correctly. detailed account metrics given later book (Chapter 12).investor’s standpoint, MSEs (even mean absolute error) hard interpret complicated map mentally intuitive financial indicator. perspective, hit ratio natural. tells proportion correct signs achieved predictions. investor long positive signals short negative ones, hit ratio indicates proportion ‘correct’ bets (positions go expected direction). natural threshold 50% transaction costs, 51% accurate forecasts probably won’t profitable. figure 0.546 can deemed relatively good hit ratio, though impressive one.","code":"\ny_penalized_train <- training_sample$R1M_Usd                 # Dependent variable\nx_penalized_train <- training_sample %>%                     # Predictors\n    dplyr::select(all_of(features)) %>% as.matrix()                  \nfit_pen_pred <- glmnet(x_penalized_train, y_penalized_train, # Model\n                       alpha = 0.1, lambda = 0.1)\nx_penalized_test <- testing_sample %>%                                     # Predictors\n    dplyr::select(all_of(features)) %>% as.matrix()         \nmean((predict(fit_pen_pred, x_penalized_test) - testing_sample$R1M_Usd)^2) # MSE## [1] 0.03699696\nmean(predict(fit_pen_pred, x_penalized_test) * testing_sample$R1M_Usd > 0) # Hit ratio## [1] 0.5460346"},{"path":"lasso.html","id":"coding-exercise","chapter":"5 Penalized regressions and sparse hedging for minimum variance portfolios","heading":"5.4 Coding exercise","text":"test sample, evaluate impact two elastic net parameters --sample accuracy.","code":""},{"path":"trees.html","id":"trees","chapter":"6 Tree-based methods","heading":"6 Tree-based methods","text":"\n  \nClassification regression trees simple yet powerful clustering algorithms popularized monograph Breiman et al. (1984). Decision trees extensions known quite efficient forecasting tools working tabular data. large proportion winning solutions ML contests (especially Kaggle website14) resort improvements simple trees. instance, meta-study bioinformatics Olson et al. (2018) finds boosted trees random forests top 2 algorithms group 13, excluding neural networks.Recently, surge Machine Learning applications Finance led multiple publications use trees portfolio allocation problems. long, though exhaustive, list includes: Ballings et al. (2015), Patel et al. (2015a), Patel et al. (2015b), Moritz Zimmermann (2016), Krauss, , Huck (2017), Gu, Kelly, Xiu (2020b), Guida Coqueret (2018a), Coqueret Guida (2020) Simonian et al. (2019). One notable contribution Bryzgalova, Pelger, Zhu (2019) authors create factors trees sorting portfolios via simple trees, call Asset Pricing Trees. Another recent article (X. et al. (2021)) seeks create global splitting criteria purpose asset pricing.chapter, review methodologies associated trees applications portfolio choice.","code":""},{"path":"trees.html","id":"simple-trees","chapter":"6 Tree-based methods","heading":"6.1 Simple trees","text":"","code":""},{"path":"trees.html","id":"principle","chapter":"6 Tree-based methods","heading":"6.1.1 Principle","text":"Decision trees seek partition datasets homogeneous clusters. Given exogenous variable \\(\\mathbf{Y}\\) features \\(\\mathbf{X}\\), trees iteratively split sample groups (usually two time) homogeneous \\(\\mathbf{Y}\\) possible. splits made according one variable within set features. short word nomenclature: \\(\\mathbf{Y}\\) consists real numbers, talk regression trees \\(\\mathbf{Y}\\) categorical, use term classification trees.formalizing idea, illustrate process Figure 6.1. 12 stars three features: color, size complexity (number branches).\nFIGURE 6.1: Elementary tree scheme; visualization splitting process.\ndependent variable color (let’s consider wavelength associated color simplicity). first split made according size complexity. Clearly, complexity better choice: complicated stars blue green, simple stars yellow, orange red. Splitting according size mixed blue yellow stars (small ones) green orange stars (large ones).second step split two clusters one level . Since one variable (size) relevant, secondary splits straightforward. end, stylized tree four consistent clusters. analogy factor investing simple: color represents performance: red high performance blue mediocre performance. features (size complexity stars) replaced firm-specific attributes, capitalization, accounting ratios, etc. Hence, purpose exercise find characteristics allow split firms ones perform well versus likely fare poorly.now turn technical construction regression trees (splitting process). follow standard literature exposed Breiman et al. (1984) chapter 9 Hastie, Tibshirani, Friedman (2009). Given sample (\\(y_i\\),\\(\\mathbf{x}_i\\)) size \\(\\), regression tree seeks splitting points minimize total variation \\(y_i\\) inside two child clusters. two clusters need size. order , proceeds two steps. First, finds, feature \\(x_i^{(k)}\\), best splitting point (clusters homogeneous \\(\\mathbf{Y}\\)). Second, selects feature achieves highest level homogeneity.Homogeneity regression trees closely linked variance. Since want \\(y_i\\) inside cluster similar, seek minimize variability (dispersion) inside cluster sum two figures. sum variances take account relative sizes clusters. Hence, work total variation, variance times number elements clusters., notation bit heavy resort superscripts \\(k\\) (index feature), largely possible ignore superscripts ease understanding. first step find best split feature, , solve \\(\\underset{c^{(k)}}{\\text{argmin}} \\ V^{(k)}_I(c^{(k)})\\) \n\\[\\begin{equation}\n\\tag{6.1}\nV^{(k)}_I(c^{(k}))= \\underbrace{\\sum_{x_i^{(k)}<c^{(k)}}\\left(y_i-m_I^{k,-}(c^{(k)}) \\right)^2}_{\\text{Total dispersion first cluster}} + \\underbrace{\\sum_{x_i^{(k)}>c^{(k)}}\\left(y_i-m_I^{k,+}(c^{(k)}) \\right)^2}_{\\text{Total dispersion second cluster}},\n\\end{equation}\\]\n\n\\[\\begin{align*}\nm_I^{k,-}(c^{(k)})&=\\frac{1}{\\#\\{,x_i^{(k)}<c^{(k)} \\}}\\sum_{\\{x_i^{(k)}<c^{(k)} \\}}y_i \\quad \\text{ } \\\\ m_I^{k,+}(c^{(k)})&=\\frac{1}{\\#\\{,x_i^{(k)}>c^{(k)} \\}}\\sum_{\\{x_i^{(k)}>c^{(k)} \\}}y_i\n\\end{align*}\\]\naverage values \\(Y\\), conditional \\(X^{(k)}\\) smaller larger \\(c\\). cardinal function \\(\\#\\{\\cdot\\}\\) counts number instances argument. feature \\(k\\), optimal split \\(c^{k,*}\\) thus one total dispersion two subgroups smallest.optimal splits satisfy \\(c^{k,*}= \\underset{c^{(k)}}{\\text{argmin}} \\ V^{(k)}_I(c^{(k)})\\). possible splitting variables, tree choose one minimizes total dispersion splits, also variables: \\(k^*=\\underset{k}{\\text{argmin}} \\ V^{(k)}_I(c^{k,*})\\).one split performed, procedure continues two newly formed clusters. several criteria can determine stop splitting process (see Section 6.1.3). One simple criterion fix maximum number levels (depth) tree. usual condition impose minimum gain expected split. reduction dispersion split marginal specified threshold, split executed. technical discussions decision trees, refer instance section 9.2.4 Hastie, Tibshirani, Friedman (2009).tree built (trained), prediction new instances easy make. Given feature values, instance ends one leaf tree. leaf average value label: predicted outcome. course, works label numerical. discuss changes occur categorical.","code":""},{"path":"trees.html","id":"treeclass","chapter":"6 Tree-based methods","heading":"6.1.2 Further details on classification","text":"\nClassification exercises somewhat complex regression tasks. obvious difference measure dispersion heterogeneity. loss function must take account fact final output simple number, vector. output \\(\\tilde{\\textbf{y}}_i\\) many elements categories label element probability instance belongs corresponding category.instance, 3 categories: buy, hold sell, instance label many columns classes. Following example, one label (1,0,0) buy position instance. refer Section 4.5.2 introduction topic.Inside tree, labels aggregated cluster level. typical output look like (0.6,0.1,0.3): proportions class represented within cluster. case, cluster 60% buy, 10% hold 30% sell.loss function must take account multidimensionality label. building trees, since aim favor homogeneity, loss penalizes outputs concentrated towards one class. Indeed, facing diversified output (0.3,0.4,0.3) much harder handle concentrated case (0.8,0.1,0.1).algorithm thus seeking purity: searches splitting criterion lead clusters pure possible, .e., one dominant class, least just dominant classes. several metrics proposed literature based proportions generated output. \\(J\\) classes, denote proportions \\(p_j\\). leaf, usual loss functions :Gini impurity index: \\(1-\\sum_{j=1}^Jp_j^2;\\)misclassification error: \\(1-\\underset{j}{\\text{max}}\\, p_j;\\)entropy: \\(-\\sum_{j=1}^J\\log(p_j)p_j.\\)Gini index nothing one minus Herfindahl index measures diversification portfolio. Trees seek partitions least diversified. minimum value Gini index zero reached one \\(p_j=1\\) others equal zero. maximum value equal \\(1-1/J\\) reached \\(p_j=1/J\\). Similar relationships hold two losses. One drawback misclassification error lack differentiability explains two options often favored.tree grown, new instances automatically belong one final leaf. leaf associated proportions classes nests. Usually, make prediction, class highest proportion (probability) chosen new instance associated leaf.","code":""},{"path":"trees.html","id":"pruning-criteria","chapter":"6 Tree-based methods","heading":"6.1.3 Pruning criteria","text":"\nbuilding tree, splitting process can pursued full tree grown, , :instances belong separate leaves, /orall leaves comprise instances segregated based current set features.stage, splitting process pursued.Obviously, fully grown trees often lead almost perfect fits predictors relevant, numerous numerical. Nonetheless, fine grained idiosyncrasies training sample little interest --sample predictions. instance, able perfectly match patterns 2000 2006 probably interesting period 2007 2009. reliable sections trees closest root embed large portions data: average values early clusters trustworthy computed large number observations. first splits matter determine general patterns. deepest splits deal peculiarities sample.Thus, imperative limit size tree avoid overfitting. several ways prune tree depend particular criteria. list :Impose minimum number instances terminal node (leaf). ensures final cluster composed sufficient number observations. Hence, average value label reliable calculated large amount data.Similarly, can imposed cluster minimal size even considering split. criterion course related one .Require certain threshold improvement fit. split sufficiently reduce loss, can deemed unnecessary. user specifies small number \\(\\epsilon>0\\) split validated loss obtained post-split smaller \\(1-\\epsilon\\) times loss split.Limit depth tree. depth defined overal maximum number splits root leaf tree.example , implement criteria time, usually, two suffice.","code":""},{"path":"trees.html","id":"code-and-interpretation","chapter":"6 Tree-based methods","heading":"6.1.4 Code and interpretation","text":"start simple tree interpretation. use package rpart plotting engine rpart.plot. label future 1-month return features predictors available sample. tree trained full sample.\nFIGURE 6.2: Simple characteristics-based tree. dependent variable 1 month future return.\nusually exists convention representation trees. node, condition describes split Boolean expression. expression true, instance goes left cluster; , goes right cluster. Given whole sample, initial split tree (Figure 6.2) performed according price--book ratio. Pb score (value) instance 0.025, instance placed left bucket; otherwise, goes right bucket.node, two important metrics. first one average value label cluster, second one proportion instances cluster. top tree, instances (100%) present average 1-month future return 1.3%. One level , left cluster far crowded, roughly 98% observations averaging 1.2% return. right cluster much smaller (2%) concentrates instances much higher average return (5.9%). possibly idiosyncracy sample.splitting process continues similarly node condition satisfied (typically : maximum depth reached). color codes average return: white (low return) blue (high return). leftmost cluster lowest average return consists firms satisfy following criteria:Pb score 0.025;3-month market capitalization score 0.16;score average daily volume past 3 months 0.85.Notice one peculiarity trees possible heterogeneity cluster sizes. Sometimes, clusters gather almost observations small groups embed outliers. favorable property trees, small groups likely flukes may fail generalize --sample.imposed restrictions construction tree. first one (minbucket = 3500 code) imposes cluster consists least 3500 instances. second one (minsplit) imposes cluster comprises least 8000 observations order pursue splitting process. values logically depend size training sample. cp = 0.0001 parameter code requires split reduce loss 0.9999 times original value split. Finally, maximum depth three essentially means three splits root tree terminal leaf.complexity tree (measured number terminal leaves) decreasing function minbucket, minsplit cp increasing function maximum depth.model trained (.e., tree grown), prediction instance average value label within cluster instance land.Given figure, immediately conclude first six instances belong second cluster (starting left).verification first splits, plot smoothed average future returns, conditionally market capitalization, price--book ratio trading volume.\nFIGURE 6.3: Average 1-month future returns, conditionally market capitalization, price--book volatility scores.\ngraph shows relevance clusters based market capitalizations price--book ratios. low score values two features, average return high (close +4% monthly basis left curves). pattern pronounced compared volume instance.Finally, assess predictive quality single tree testing set (tree grown training set). use deeper tree, maximum depth five.mean squared error usually hard interpret. ’s easy map error returns impact investment decisions. hit ratio intuitive indicator evaluates proportion correct guesses (hence profitable investments). Obviously, perfect: 55% small gains can mitigated 45% large losses. Nonetheless, popular metric moreover corresponds usual accuracy measure often computed binary classification exercises. , accuracy 0.542 satisfactory. Even number 50% may seem valuable, must forgotten transaction costs curtail benefits. Hence, benchmark threshold probably least 52%.","code":"\nlibrary(rpart)              # Tree package  \nlibrary(rpart.plot)         # Tree plot package\nformula <- paste(\"R1M_Usd ~\", paste(features, collapse = \" + \")) # Defines the model \nformula <- as.formula(formula)                                   # Forcing formula object\nfit_tree <- rpart(formula,\n             data = data_ml,     # Data source: full sample\n             minbucket = 3500,   # Min nb of obs required in each terminal node (leaf)\n             minsplit = 8000,    # Min nb of obs required to continue splitting\n             cp = 0.0001,        # Precision: smaller = more leaves\n             maxdepth = 3        # Maximum depth (i.e. tree levels)\n             ) \nrpart.plot(fit_tree)             # Plot the tree\npredict(fit_tree, data_ml[1:6,]) # Test (prediction) on the first six instances of the sample##          1          2          3          4          5          6 \n## 0.01088066 0.01088066 0.01088066 0.01088066 0.01088066 0.01088066\ndata_ml %>% ggplot() +\n    stat_smooth(aes(x = Mkt_Cap_3M_Usd, y = R1M_Usd, color = \"Market Cap\"), se = FALSE) +\n    stat_smooth(aes(x = Pb, y = R1M_Usd, color = \"Price-to-Book\"), se = FALSE) +\n    stat_smooth(aes(x = Advt_3M_Usd, y = R1M_Usd, color = \"Volume\"), se = FALSE) +\n    xlab(\"Predictor\") + coord_fixed(11) + labs(color = \"Characteristic\")\nfit_tree2 <- rpart(formula, \n             data = training_sample,     # Data source: training sample\n             minbucket = 1500,           # Min nb of obs required in each terminal node (leaf)\n             minsplit = 4000,            # Min nb of obs required to continue splitting\n             cp = 0.0001,                # Precision: smaller cp = more leaves\n             maxdepth = 5                # Maximum depth (i.e. tree levels)\n             ) \nmean((predict(fit_tree2, testing_sample) - testing_sample$R1M_Usd)^2) # MSE## [1] 0.03700039\nmean(predict(fit_tree2, testing_sample) * testing_sample$R1M_Usd > 0) # Hit ratio## [1] 0.5416619"},{"path":"trees.html","id":"random-forests","chapter":"6 Tree-based methods","heading":"6.2 Random forests","text":"\ntrees give intuitive representations relationships \\(\\mathbf{Y}\\) \\(\\mathbf{X}\\), can improved via simple idea ensembles predicting tools combined (topic model aggregation discussed generally details Chapter 11).","code":""},{"path":"trees.html","id":"principle-1","chapter":"6 Tree-based methods","heading":"6.2.1 Principle","text":"time, several modelling options hand, obvious upfront individual model best, hence combination seems reasonable path towards diversification prediction errors (correlated). theoretical foundations model diversification laid Schapire (1990).practical considerations proposed later T. K. Ho (1995) importantly Breiman (2001) major reference random forests. Bagging successfully used Yin (2020) aggregate equity forecasts. two ways create multiple predictors simple trees, random forests combine :first, model can trained similar yet different datasets. One way achieve via bootstrap: instances resampled without replacement (individual tree), yielding new training data time new tree built.second, data can altered curtailing number predictors. Alternative models built based different sets features. user chooses many features retain algorithm selects features randomly try.Hence, becomes simple grow many different trees ensemble simply weighted combination trees. Usually, equal weights used, agnostic robust choice. illustrate idea simple combinations (also referred bagging) Figure 6.4 . terminal prediction simply mean intermediate predictions.\nFIGURE 6.4: Combining tree outputs via random forests.\nRandom forests, built idea bootstrapping, efficient simple trees. used Ballings et al. (2015), Patel et al. (2015a), Krauss, , Huck (2017), Huck (2019) shown perform well papers. original theoretical properties random forests demonstrated Breiman (2001) classification trees. classification exercises, decision taken vote: tree votes particular class class votes wins (possible random picks case ties). Breiman (2001) defines margin function \n\\[mg=M^{-1}\\sum_{m=1}^M1_{\\{h_m(\\textbf{x})=y\\}}-\\max_{j\\neq y}\\left(M^{-1}\\sum_{m=1}^M1_{\\{h_m(\\textbf{x})=j\\}}\\right),\\]\nleft part average number votes based \\(M\\) trees \\(h_m\\) correct class (models \\(h_m\\) based \\(\\textbf{x}\\) matches data value \\(y\\)). right part maximum average class. margin reflects confidence aggregate forest classify properly. generalization error probability \\(mg\\) strictly negative. Breiman (2001) shows inaccuracy aggregation (measured generalization error) bounded \\(\\bar{\\rho}(1-s^2)/s^2\\), \n- \\(s\\) strength (average quality15) individual classifiers \n- \\(\\bar{\\rho}\\) average correlation learners.Notably, Breiman (2001) also shows number trees grows infinity, inaccuracy converges finite number explains random forests prone overfitting.original paper Breiman (2001) dedicated classification models, many articles since tackled problem regression trees. refer interested reader Biau (2012) Scornet et al. (2015). Finally, results classifying ensembles can obtained Biau, Devroye, Lugosi (2008) mention short survey paper Denil, Matheson, De Freitas (2014) sums recent results field.","code":""},{"path":"trees.html","id":"code-and-results-1","chapter":"6 Tree-based methods","heading":"6.2.2 Code and results","text":"Several implementations random forests exist. simplicity, choose work original R library, another choice one developed h2o, highly efficient meta-environment machine learning (coded Java).syntax randomForest follows many ML libraries. full list options random forest implementations prohibitively large.16 , train model exhibit predictions first 5 instances testing sample.One first comment instance prediction, contrasts outcome simple tree-based outcomes. Combining many trees leads tailored forecasts. Note second line chunk freezes random number generation. Indeed, random forests construction contingent arbitrary combinations instances features chosen build individual learners.example, individual learner (tree) built 10,000 randomly chosen instances (without replacement) terminal leaf (cluster) must comprise least 240 elements (observations). total, 40 trees aggregated tree constructed based 30 randomly chosen predictors (whole set features).Unlike simple trees, possible simply illustrate outcome learning process (though solutions exist, see Section 13.1.1). possible extract 40 trees, synthetic visualization --reach. simplified view can obtained via variable importance, discussed Section 13.1.2.Finally, can assess accuracy model.MSE smaller 4% hit ratio close 54%, reasonably 50% 52% thresholds.Let’s see can improve hit ratio resorting classification exercise. start training model new formula (label R1M_Usd_C).can assess proportion correct (binary) guesses.\naccuracy disappointing. two potential explanations (beyond possibility different patterns training testing sets). first one sample size, may small. original training set 200,000 observations, hence retain one 10 training specification. thus probably sidelining relevant information cost can heavy. second reason number predictors, set 30, .e., one third total disposal. Unfortunately, leaves room algorithm pick less pertinent predictors. default numbers predictors chosen routines \\(\\sqrt{p}\\) \\(p/3\\) classification regression tasks, respectively. \\(p\\) total number features.","code":"\nlibrary(randomForest) \nset.seed(42)                                # Sets the random seed\nfit_RF <- randomForest(formula,             # Same formula as for simple trees!\n                 data = training_sample,    # Data source: training sample\n                 sampsize = 10000,          # Size of (random) sample for each tree\n                 replace = FALSE,           # Is the sampling done with replacement?\n                 nodesize = 250,            # Minimum size of terminal cluster\n                 ntree = 40,                # Nb of random trees\n                 mtry = 30                  # Nb of predictive variables for each tree\n    )\npredict(fit_RF, testing_sample[1:5,])       # Prediction over the first 5 test instances ##            1            2            3            4            5 \n##  0.009787728  0.012507087  0.008722386  0.009398814 -0.011511758\nmean((predict(fit_RF, testing_sample) - testing_sample$R1M_Usd)^2) # MSE## [1] 0.03698197\nmean(predict(fit_RF, testing_sample) * testing_sample$R1M_Usd > 0) # Hit ratio## [1] 0.5370186\nformula_C <- paste(\"R1M_Usd_C ~\", paste(features, collapse = \" + \")) # Defines the model \nformula_C <- as.formula(formula_C)                                   # Forcing formula object\nfit_RF_C <- randomForest(formula_C,         # New formula! \n                 data = training_sample,    # Data source: training sample\n                 sampsize = 20000,          # Size of (random) sample for each tree\n                 replace = FALSE,           # Is the sampling done with replacement?\n                 nodesize = 250,            # Minimum size of terminal cluster\n                 ntree = 40,                # Number of random trees\n                 mtry = 30                  # Number of predictive variables for each tree \n    )\nmean(predict(fit_RF_C, testing_sample) == testing_sample$R1M_Usd_C) # Hit ratio## [1] 0.4971371"},{"path":"trees.html","id":"adaboost","chapter":"6 Tree-based methods","heading":"6.3 Boosted trees: Adaboost","text":"\nidea boosting slightly advanced compared agnostic aggregation. random forest, hope diversification many trees improve overall quality model. boosting, sought iteratively improve model whenever new tree added. many ways boost learning present two can easily implemented trees. first one (Adaboost, adaptive boosting) improves learning process progressively focusing instances yield largest errors. second one (xgboost) flexible algorithm new tree focused minimization training sample loss.","code":""},{"path":"trees.html","id":"methodology","chapter":"6 Tree-based methods","heading":"6.3.1 Methodology","text":"origins adaboost go back Freund Schapire (1997) Freund Schapire (1996), sake completeness, also mention book dedicated boosting Schapire Freund (2012). Extensions ideas proposed J. Friedman et al. (2000) (-called real Adaboost algorithm) Drucker (1997) (regression analysis). Theoretical treatments derived Breiman et al. (2004).start directly stating general structure algorithm:set equal weights \\(w_i=^{-1}\\);\\(m=1,\\dots,M\\) :Find learner \\(l_m\\) minimizes weighted loss \\(\\sum_{=1}^Iw_iL(l_m(\\textbf{x}_i),\\textbf{y}_i)\\);Compute learner weight\n\\[\\begin{equation}\n\\tag{6.2}\na_m=f_a(\\textbf{w},l_m(\\textbf{x}),\\textbf{y});\n\\end{equation}\\]Update instance weights\n\\[\\begin{equation}\n\\tag{6.3}\nw_i \\leftarrow w_ie^{f_w(l_m(\\textbf{x}_i), \\textbf{y}_i)};\n\\end{equation}\\]Normalize \\(w_i\\) sum one.output instance \\(\\textbf{x}_i\\) simple function \\(\\sum_{m=1}^M a_ml_m(\\textbf{x}_i)\\),\n\\[\\begin{equation}\n\\tag{6.4}\n\\tilde{y}_i=f_y\\left(\\sum_{m=1}^M a_ml_m(\\textbf{x}_i) \\right).\n\\end{equation}\\]Let us comment steps algorithm. formulation holds many variations Adaboost specify functions \\(f_a\\) \\(f_w\\) .first step seeks find learner (tree) \\(l_m\\) minimizes weighted loss. base loss function \\(L\\) essentially depends task (regression versus classification).second third steps interesting heart Adaboost: define way algorithm adapts sequentially. purpose aggregate models, sophisticated approach compared uniform weights learners tailored weight learner. natural property (\\(f_a\\)) learner yields smaller error larger weight accurate.third step change weights observations. case, model aims improving learning process, \\(f_w\\) constructed give weight observations current model good job (.e., generates largest errors). Hence, next learner incentivized pay attention pathological cases.third step simple scaling procedure.Table 6.1, detail two examples weighting functions used literature. original Adaboost (Freund Schapire (1996), Freund Schapire (1997)), label binary values +1 -1 . second example stems Drucker (1997) dedicated regression analysis (real-valued label). interested reader can look possibilities Schapire (2003) Ridgeway, Madigan, Richardson (1999).TABLE 6.1:  Examples functions Adaboost-like algorithms.Let us comment original Adaboost specification. basic error term \\(\\epsilon_i=\\textbf{1}_{\\left\\{y_i\\neq l_m(\\textbf{x}_i) \\right\\}}\\) dummy number indicating prediction correct (recall two values possible, +1 -1). average error \\(\\epsilon\\[0,1]\\) simply weighted average individual errors weight \\(m^{th}\\) learner defined Equation (6.2) given \\(a_m=\\log\\left(\\frac{1-\\epsilon}{\\epsilon} \\right)\\). function \\(x\\mapsto \\log((1-x)x^{-1})\\) decreases \\([0,1]\\) switches sign (positive negative) \\(x=1/2\\). Hence, average error small, learner large positive weight, error becomes large, learner can even obtain negative weight. Indeed, threshold \\(\\epsilon>1/2\\) indicated learner wrong 50% time. Obviously, indicates problem learner even discarded.change instance weights follows similar logic. new weight proportional \\(w_i\\left(\\frac{1-\\epsilon}{\\epsilon} \\right)^{\\epsilon_i}\\). prediction right \\(\\epsilon_i=0\\), weight unchanged. prediction wrong \\(\\epsilon_i=1\\), weight adjusted depending aggregate error \\(\\epsilon\\). error small learner efficient (\\(\\epsilon<1/2\\)), \\((1-\\epsilon)/\\epsilon>1\\) weight instance increases. means next round, learner focus instance \\(\\).Lastly, final prediction model corresponds sign weighted sums individual predictions: sum positive, model predict +1 yield -1 otherwise.17 odds zero sum negligible. case numerical labels, process slightly complicated refer Section 3, step 8 Drucker (1997) details proceed.end presentation one word instance weighting. two ways deal topic. first one works level loss functions. regression trees, Equation (6.1) naturally generalize \n\\[V^{(k)}_N(c^{(k)}, \\textbf{w})= \\sum_{x_i^{(k)}<c^{(k)}}w_i\\left(y_i-m_N^{k,-}(c^{(k)}) \\right)^2 + \\sum_{x_i^{(k)}>c^{(k)}}w_i\\left(y_i-m_N^{k,+}(c^{(k)}) \\right)^2,\\]hence instance large weight \\(w_i\\) contribute dispersion cluster. classification objectives, alteration complex refer Ting (2002) one example instance-weighted tree-growing algorithm. idea closely linked alteration misclassification risk via loss matrix (see Section 9.2.4 Hastie, Tibshirani, Friedman (2009)).second way enforce instance weighting via random sampling. instances weights \\(w_i\\), training learners can performed sample randomly extracted distribution equal \\(w_i\\). case, instance larger weight chances represented training sample. original adaboost algorithm relies method.","code":""},{"path":"trees.html","id":"illustration","chapter":"6 Tree-based methods","heading":"6.3.2 Illustration","text":", test implementation original Adaboost classifier. , work R1M_Usd_C variable change model formula. computational cost Adaboost high large datasets, thus work smaller sample impose three iterations.Finally, evaluate performance classifier. accuracy (evaluated hit ratio) clearly satisfactory. One reason may restrictions enforced training (smaller sample three trees).","code":"\nlibrary(fastAdaboost)                                                     # Adaboost package \nsubsample <- (1:52000)*4                                                  # Target small sample\nfit_adaboost_C <- adaboost(formula_C,                                     # Model spec.\n                         data = data.frame(training_sample[subsample,]),  # Data source\n                         nIter = 3)                                       # Number of trees              \nmean(testing_sample$R1M_Usd_C == predict(fit_adaboost_C, testing_sample)$class)## [1] 0.5028202"},{"path":"trees.html","id":"boosted-trees-extreme-gradient-boosting","chapter":"6 Tree-based methods","heading":"6.4 Boosted trees: extreme gradient boosting","text":"\nideas behind tree boosting popularized, among others, Mason et al. (2000), J. H. Friedman (2001), J. H. Friedman (2002). case, combination learners (prediction tools) agnostic random forest, adapted (optimized) learner level. step \\(s\\), sum models \\(M_S=\\sum_{s=1}^{S-1}m_s+m_S\\) last learner \\(m_S\\) precisely designed reduce loss \\(M_S\\) training sample., follow closely original work T. Chen Guestrin (2016) algorithm yields incredibly accurate predictions also highly customizable. implementation use empirical section. popular alternative lightgbm (see G. Ke et al. (2017)). XGBoost seeks minimize objective\n\\[O=\\underbrace{\\sum_{=1}^\\text{loss}(y_i,\\tilde{y}_i)}_{\\text{error term}} \\quad + \\underbrace{\\sum_{j=1}^J\\Omega(T_j)}_{\\text{regularization term}}.\\]\nfirst term (instances) measures distance true label output model. second term (trees) penalizes models complex.simplicity, propose full derivation simplest loss function \\(\\text{loss}(y,\\tilde{y})=(y-\\tilde{y})^2\\), :\n\\[O=\\sum_{=1}^\\left(y_i-m_{J-1}(\\mathbf{x}_i)-T_J(\\mathbf{x}_i)\\right)^2+ \\sum_{j=1}^J\\Omega(T_j).\\]","code":""},{"path":"trees.html","id":"managing-loss","chapter":"6 Tree-based methods","heading":"6.4.1 Managing loss","text":"Let us assume already built trees \\(T_{j}\\) \\(j=1,\\dots,J-1\\) (hence model \\(M_{J-1}\\)): choose tree \\(T_J\\) optimally? rewrite\n\\[\\begin{align*}\nO&=\\sum_{=1}^\\left(y_i-m_{J-1}(\\mathbf{x}_i)-T_J(\\mathbf{x}_i)\\right)^2+ \\sum_{j=1}^J\\Omega(T_j) \\\\\n&=\\sum_{=1}^\\left\\{y_i^2+m_{J-1}(\\mathbf{x}_i)^2+T_J(\\mathbf{x}_i)^2 \\right\\} + \\sum_{j=1}^{J-1}\\Omega(T_j)+\\Omega(T_J) \\quad \\text{(squared terms + penalization)}\\\\\n& \\quad -2 \\sum_{=1}^\\left\\{y_im_{J-1}(\\mathbf{x}_i)+y_iT_J(\\mathbf{x}_i)-m_{J-1}(\\mathbf{x}_i) T_J(\\mathbf{x}_i))\\right\\}\\quad \\text{(cross terms)} \\\\\n&= \\sum_{=1}^\\left\\{-2 y_iT_J(\\mathbf{x}_i)+2m_{J-1}(\\mathbf{x}_i) T_J(\\mathbf{x}_i))+T_J(\\mathbf{x}_i)^2 \\right\\} +\\Omega(T_J) + c\n\\end{align*}\\]\nterms known step \\(J\\) (.e., indexed \\(J-1\\)) vanish enter optimization scheme. embedded constant \\(c\\).Things fairly simple quadratic loss. complicated loss functions, Taylor expansions used (see original paper).","code":""},{"path":"trees.html","id":"penalization","chapter":"6 Tree-based methods","heading":"6.4.2 Penalization","text":"\norder go , need specify way penalization works. given tree \\(T\\), specify structure \\(T(x)=w_{q(x)}\\), \\(w\\) output value leaf \\(q(\\cdot)\\) function maps input final leaf. encoding illustrated Figure 6.5. function \\(q\\) indicates path, vector \\(\\textbf{w}=w_i\\) codes terminal leaf values.\nFIGURE 6.5: Coding decision tree: decomposition structure node leaf values.\nwrite \\(l=1,\\dots,L\\) indices leaves tree. XGBoost, complexity defined :\n\\[\\Omega(T)=\\gamma L+\\frac{\\lambda}{2}\\sum_{l=1}^Lw_l^2,\\]\nwherethe first term penalizes total number leaves;second term penalizes magnitude output values (helps reduce variance).first penalization term reduces depth tree, second shrinks size adjustments come latest tree.","code":""},{"path":"trees.html","id":"aggregation","chapter":"6 Tree-based methods","heading":"6.4.3 Aggregation","text":"aggregate sections objective (loss penalization). write \\(I_l\\) set indices instances belonging leaf \\(l\\). ,\\[\\begin{align*}\nO&= 2\\sum_{=1}^\\left\\{ -y_iT_J(\\mathbf{x}_i)+m_{J-1}(\\mathbf{x}_i) T_J(\\mathbf{x}_i))+\\frac{T_J(\\mathbf{x}_i)^2}{2} \\right\\} + \\gamma L+\\frac{\\lambda}{2}\\sum_{l=1}^Lw_l^2 \\\\\n&=2\\sum_{=1}^\\left\\{- y_iw_{q(\\mathbf{x}_i)}+m_{J-1}(\\mathbf{x}_i)w_{q(\\mathbf{x}_i)})+\\frac{w_{q(\\mathbf{x}_i)}^2}{2} \\right\\} + \\gamma L+\\frac{\\lambda}{2}\\sum_{l=1}^Lw_l^2 \\\\\n&=2 \\sum_{l=1}^L \\left(w_l\\sum_{\\I_l}(-y_i +m_{J-1}(\\mathbf{x}_i))+ \\frac{w_l^2}{2}\\sum_{\\I_l}\\left(1+\\frac{\\lambda}{2}\\right)\\right)+ \\gamma L\n\\end{align*}\\]\nfunction form \\(aw_l+\\frac{b}{2}w_l^2\\), minimum values \\(-\\frac{^2}{2b}\\) point \\(w_l=-/b\\). Thus, writing #(.) cardinal function counts number items set,\n\\[\\begin{align}\n\\tag{6.5}\n\\mathbf{\\rightarrow} \\quad w^*_l&=\\frac{\\sum_{\\I_l}(y_i -m_{J-1}(\\mathbf{x}_i))}{\\left(1+\\frac{\\lambda}{2}\\right)\\#\\{\\I_l\\}}, \\text{ } \\\\\nO_L(q)&=-\\frac{1}{2}\\sum_{l=1}^L \\frac{\\left(\\sum_{\\I_l}(y_i -m_{J-1}(\\mathbf{x}_i))\\right)^2}{\\left(1+\\frac{\\lambda}{2}\\right)\\#\\{\\I_l\\}}+\\gamma L, \\nonumber\n\\end{align}\\]\nadded dependence objective \\(q\\) (structure tree) \\(L\\) (number leaves). Indeed, meta-shape tree remains determined.","code":""},{"path":"trees.html","id":"tree-structure","chapter":"6 Tree-based methods","heading":"6.4.4 Tree structure","text":"\nFinal problem: tree structure! Let us take step back. construction simple regression tree, output value node equal average value label within node (cluster). adding new tree order reduce loss, node values must computed completely differently, purpose Equation (6.5).Nonetheless, growing iterative trees follows similar lines simple trees. Features must tested order pick one minimizes objective given split. final question : ’s best depth stop growing tree? method toproceed node--node;node, look whether split useful (terms objective) : \\[\\text{Gain}=\\frac{1}{2}\\left(\\text{Gain}_L+\\text{Gain}_R-\\text{Gain}_O \\right)-\\gamma\\]gain computed respect instances bucket (cluster): \\[\\text{Gain}_\\mathcal{X}= \\frac{\\left(\\sum_{\\I_\\mathcal{X}}(y_i -m_{J-1}(\\mathbf{x}_i))\\right)^2}{\\left(1+\\frac{\\lambda}{2}\\right)\\#\\{\\I_\\mathcal{X}\\}},\\]\n\\(I_\\mathcal{X}\\) set instances within cluster \\(\\mathcal{X}\\).\\(\\text{Gain}_O\\) original gain (split) \\(\\text{Gain}_L\\) \\(\\text{Gain}_R\\) gains left right clusters, respectively. One word \\(-\\gamma\\) adjustment formula: one unit new leaves (two new minus one old)! makes one leaf difference; hence \\(\\Delta L =1\\) penalization intensity new leaf equal \\(\\gamma\\).Lastly, underline fact XGBoost also applies learning rate: new tree scaled factor \\(\\eta\\), \\(\\eta \\(0,1]\\). step boosting new tree \\(T_J\\) sees values discounted multiplying \\(\\eta\\). useful pure aggregation 100 optimized trees best way overfit training sample.","code":""},{"path":"trees.html","id":"boostext","chapter":"6 Tree-based methods","heading":"6.4.5 Extensions","text":"Several additional features available prevent boosted trees overfit. Indeed, given sufficiently large number trees, aggregation able match training sample well, may fail generalize well --sample.Following pioneering work Srivastava et al. (2014), DART (Dropout Additive Regression Trees) model proposed Rashmi Gilad-Bachrach (2015). idea omit specified number trees training. trees removed model chosen randomly. full specifications can found https://xgboost.readthedocs.io/en/latest/tutorials/dart.html use 10% dropout first example ..Monotonicity constraints another element featured xgboost lightgbm. Sometimes, expected one particular feature monotonic impact label. instance, one deeply believes momentum, past returns increasing impact future returns (cross-section stocks).Given recursive nature splitting algorithm, possible choose perform split (according particular variable) . Figure 6.6, show algorithm proceeds. splits performed according feature. first split, things easy suffices verify averages cluster ranked right direction. Things complicated splits occur . Indeed, average values set splits matter give bounds acceptable values future average values lower splits. split violates bounds, overlooked another variable chosen instead.\nFIGURE 6.6: Imposing monotonic constraints. constraints shown bold blue bottom leaves.\n","code":""},{"path":"trees.html","id":"boostcode","chapter":"6 Tree-based methods","heading":"6.4.6 Code and results","text":"section, train model using XGBoost library. options include catboost, gbm, lightgbm, h2o’s version boosted machines. Unlike many packages, XGBoost function requires particular syntax dedicated formats. first step thus encapsulate data accordingly.Moreover, training times can long, shorten training sample advocated Coqueret Guida (2020). retain 40% extreme observations (terms label values: top 20% bottom 20%) work small subset features. coding sections dedicated boosted trees book, models trained 7 features.second (optional) step determine monotonicity constraints want impose. simplicity, enforce three constraints onmarket capitalization (negative, large firms smaller returns size anomaly);price--book ratio (negative, overvalued firms also smaller returns value anomaly);past annual returns (positive, winners outperform losers momentum anomaly).third step train model formatted training data. include monotonicity constraints DART feature (via rate_drop). Just like random forests, boosted trees can grow individual trees subsets data: row-wise (selecting random instances) column-wise (keeping smaller portion predictors). options implemented subsample colsample_bytree arguments function.Finally, evaluate performance model. Note , proper formatting testing sample required.performance comparable observed predictive tools. final exercise, show one implementation classification task XGBoost. label changes. XGBoost, labels must coded integer number, starting zero exactly. R, factors numerically coded integer numbers starting one, hence mapping simple.working categories, loss function usually softmax function (see Section 1.1).can proceed assessment quality model. adjust prediction value true label count proportion accurate forecasts.Consistently previous classification attempts, results underwhelming, switching binary labels incurred loss information.","code":"\nlibrary(xgboost)                                                # The package for boosted trees\ntrain_features_xgb <- training_sample %>% \n    filter(R1M_Usd < quantile(R1M_Usd, 0.2) | \n               R1M_Usd > quantile(R1M_Usd, 0.8)) %>%            # Extreme values only!\n    dplyr::select(all_of(features_short)) %>% as.matrix()       # Independent variable\ntrain_label_xgb <- training_sample %>%\n    filter(R1M_Usd < quantile(R1M_Usd, 0.2) | \n               R1M_Usd > quantile(R1M_Usd, 0.8)) %>%\n    dplyr::select(R1M_Usd) %>% as.matrix()                      # Dependent variable\ntrain_matrix_xgb <- xgb.DMatrix(data = train_features_xgb, \n                                label = train_label_xgb)        # XGB format!\nmono_const <- rep(0, length(features))                   # Initialize the vector\nmono_const[which(features == \"Mkt_Cap_12M_Usd\")] <- (-1) # Decreasing in market cap\nmono_const[which(features == \"Pb\")] <- (-1)              # Decreasing in price-to-book\nmono_const[which(features == \"Mom_11M_Usd\")] <- 1        # Increasing in past return\nfit_xgb <- xgb.train(data = train_matrix_xgb,     # Data source \n              eta = 0.3,                          # Learning rate\n              objective = \"reg:squarederror\",     # Objective function\n              max_depth = 4,                      # Maximum depth of trees\n              subsample = 0.6,                    # Train on random 60% of sample\n              colsample_bytree = 0.7,             # Train on random 70% of predictors\n              lambda = 1,                         # Penalisation of leaf values\n              gamma = 0.1,                        # Penalisation of number of leaves\n              nrounds = 30,                       # Number of trees used (rather low here)\n              monotone_constraints = mono_const,  # Monotonicity constraints\n              rate_drop = 0.1,                    # Drop rate for DART\n              verbose = 0                         # No comment from the algo \n    )## [14:55:38] WARNING: amalgamation/../src/learner.cc:576: \n## Parameters: { \"rate_drop\" } might not be used.\n## \n##   This could be a false alarm, with some parameters getting used by language bindings but\n##   then being mistakenly passed down to XGBoost core, or some parameter actually being used\n##   but getting flagged wrongly here. Please open an issue if you find any such cases.\nxgb_test <- testing_sample %>%                                # Test sample => XGB format\n    dplyr::select(all_of(features_short)) %>% \n    as.matrix() \nmean((predict(fit_xgb, xgb_test) - testing_sample$R1M_Usd)^2) # MSE## [1] 0.03908854\nmean(predict(fit_xgb, xgb_test) * testing_sample$R1M_Usd > 0) # Hit ratio## [1] 0.5077626\ntrain_label_C <- training_sample %>% \n    filter(R1M_Usd < quantile(R1M_Usd, 0.2) |          # Either low 20% returns \n               R1M_Usd > quantile(R1M_Usd, 0.8)) %>%   # Or top 20% returns\n    dplyr::select(R1M_Usd_C)\ntrain_matrix_C <- xgb.DMatrix(data = train_features_xgb, \n                              label = as.numeric(train_label_C == \"TRUE\")) # XGB format!\nfit_xgb_C <-  xgb.train(data = train_matrix_C,  # Data source (pipe input)\n              eta = 0.8,                        # Learning rate\n              objective = \"multi:softmax\",      # Objective function\n              num_class = 2,                    # Number of classes\n              max_depth = 4,                    # Maximum depth of trees\n              nrounds = 10,                     # Number of trees used\n              verbose = 0                       # No warning message \n    )\nmean(predict(fit_xgb_C, xgb_test) + 1 == as.numeric(testing_sample$R1M_Usd_C)) # Hit ratio## [1] 0.495613"},{"path":"trees.html","id":"instweight","chapter":"6 Tree-based methods","heading":"6.4.7 Instance weighting","text":"\ncomputation aggregate loss, possible introduce flexibility assign weights instances:\n\\[O=\\underbrace{\\sum_{=1}^\\mathcal{W}_i \\times \\text{loss}(y_i,\\tilde{y}_i)}_{\\text{weighted error term}} \\quad + \\underbrace{\\sum_{j=1}^J\\Omega(T_j)}_{\\text{regularization term (unchanged)}}.\\]factor investing, weights can well depend feature values (\\(\\mathcal{W}_i=\\mathcal{W}_i(\\textbf{x}_i)\\)). instance, one particular characteristic \\(\\textbf{x}^k\\), weights can increasing thereby giving importance assets high values characteristic (e.g., value stocks favored compared growth stocks). One option increase weights values characteristic become extreme (deep value deep growth stocks larger weights). features uniform, weights can simply \\(\\mathcal{W}_i(x_i^k)\\propto|x_i^k-0.5|\\): firms median value 0.5 zero weight feature value shifts towards 0 1, weight increases. Specifying weights instances biases learning process just like views introduced à la Black Litterman (1992) influence asset allocation process. difference nudge performed well ahead portfolio choice problem.xgboost, implementation instance weighting done early, definition xgb.DMatrix:, subsequent stages, optimization performed hard-coded weights. splitting points can altered (via total weighted loss clusters) terminal weight values (6.5) also impacted.","code":"\ninst_weights <- runif(nrow(train_features_xgb))               # Random weights\ninst_weights <- inst_weights / sum(inst_weights)              # Normalization\ntrain_matrix_xgb <- xgb.DMatrix(data = train_features_xgb, \n                                label = train_label_xgb,\n                                weight = inst_weights)        # Weights!"},{"path":"trees.html","id":"discussion","chapter":"6 Tree-based methods","heading":"6.5 Discussion","text":"end chapter discussion choice predictive engine view towards portfolio construction. recalled Chapter 2, ML signal just one building stage construction investment strategy. point, signal must translated portfolio weights.perspective, simple trees appear suboptimal. Tree depths usually set 3 6. implies 8 64 terminal leaves , possibly unbalanced clusters. likelihood one cluster 20% 30% sample high. means comes predictions, roughly 20% 30% instances given value.side process, portfolio policies commonly fixed number assets. Thus, assets equal signals permit discriminate select subset included portfolio. instance, policy requires exactly 100 stocks 105 stocks signal, signal used selection purposes. combined exogenous information covariance matrix mean-variance type allocation.Overall, one reason prefer aggregate models. number learners sufficiently large (5 almost enough), predictions assets unique tailored assets. becomes possible discriminate via signal select assets favorable signal. practice, random forests boosted trees probably best choices.","code":""},{"path":"trees.html","id":"coding-exercises-2","chapter":"6 Tree-based methods","heading":"6.6 Coding exercises","text":"Using formula chunks , build two simple trees training sample one parameter: cp. first tree, take cp=0.001 second take cp=0.01. Evaluate performance models testing sample. Comment.Using formula chunks , build two simple trees training sample one parameter: cp. first tree, take cp=0.001 second take cp=0.01. Evaluate performance models testing sample. Comment.smaller set predictors, build random forests training sample. Restrict learning 30,000 instances 5 predictors. Construct forests 10, 20, 40, 80 160 trees evaluate performance training sample. complexity worthwhile case ?smaller set predictors, build random forests training sample. Restrict learning 30,000 instances 5 predictors. Construct forests 10, 20, 40, 80 160 trees evaluate performance training sample. complexity worthwhile case ?Plot tree based data calendar year 2008 2009. Compare.Plot tree based data calendar year 2008 2009. Compare.","code":""},{"path":"NN.html","id":"NN","chapter":"7 Neural networks","heading":"7 Neural networks","text":"Neural networks (NNs) immensely rich complicated topic. chapter, introduce simple ideas concepts behind simple architectures NNs. exhaustive treatments NN idiosyncracies, refer monographs Haykin (2009), K.-L. Du Swamy (2013) Goodfellow et al. (2016). latter available freely online: www.deeplearningbook.org. practical introduction, recommend great book Chollet (2017).starters, briefly comment qualification “neural network.” experts agree term well chosen, NNs little human brain works (know much). explains often referred “artificial neural networks” - use adjective notational simplicity. consider appropriate, recall definition NNs given François Chollet: “chains differentiable, parameterised geometric functions, trained gradient descent (gradients obtained via chain rule).”Early references neural networks finance Bansal Viswanathan (1993) Eakins, Stansell, Buck (1998). different goals. first one, authors aim estimate nonlinear form pricing kernel. second one, purpose identify quantify relationships institutional investments stocks attributes firms (early contribution towards factor investing). early review (Burrell Folarin (1997)) lists financial applications NNs 1990s. recently, Sezer, Gudelek, Ozbayoglu (2019), W. Jiang (2020) Lim Zohren (2021) survey attempts forecast financial time series deep-learning models, mainly computer science scholars.pure predictive ability NNs financial markets popular subject cite example Kimoto et al. (1990), Enke Thawornwong (2005), Y. Zhang Wu (2009), Guresen, Kayakutlu, Daim (2011), Krauss, , Huck (2017), Fischer Krauss (2018), Aldridge Avellaneda (2019), Babiak Barunik (2020), Y. Ma, Han, Wang (2020), Soleymani Paquet (2020).18 last reference even combines several types NNs embedded inside overarching reinforcement learning structure. list far exhaustive. field financial economics, recent research neural networks includes:Feng, Polson, Xu (2019) use neural networks find factors best explaining cross-section stock returns.Gu, Kelly, Xiu (2020b) map firm attributes macro-economic variables future returns. creates strong predictive tool able forecast future returns accurately.Luyang Chen, Pelger, Zhu (2020) estimate pricing kernel complex neural network structure including generative adversarial network. gives crucial information structure expected stock returns can used portfolio construction (building accurate maximum Sharpe ratio policy).","code":""},{"path":"NN.html","id":"the-original-perceptron","chapter":"7 Neural networks","heading":"7.1 The original perceptron","text":"\norigins NNs go back least Rosenblatt (1958). aim binary classification. simplicity, let us assume output \\(\\{0\\) = invest\\(\\}\\) versus \\(\\{1\\) = invest\\(\\}\\) (e.g., derived return, negative versus positive). Given current nomenclature, perceptron can defined activated linear mapping. model following:\\[f(\\mathbf{x})=\\left\\{ \\begin{array}{lll}\n1 & \\text{} \\mathbf{x}'\\mathbf{w}+b >0\\\\\n0  &\\text{otherwise}\n\\end{array}\\right.\\]\nvector weights \\(\\mathbf{w}\\) scales variables bias \\(b\\) shifts decision barrier. Given values \\(b\\) \\(w_i\\), error \\(\\epsilon_i=y_i-1_{\\left\\{\\sum_{j=1}^Jx_{,j}w_j+w_0>0\\right\\}}\\). customary, set \\(b=w_0\\) add initial constant column \\(x\\): \\(x_{,0}=1\\), \\(\\epsilon_i=y_i-1_{\\left\\{\\sum_{j=0}^Jx_{,j}w_j>0\\right\\}}\\). contrast regressions, perceptrons closed-form solutions. optimal weights can approximated. Just like regression, one way derive good weights minimize sum squared errors. purpose, simplest way proceed tocompute current model value point \\(\\textbf{x}_i\\): \\(\\tilde{y}_i=1_{\\left\\{\\sum_{j=0}^Jw_jx_{,j}>0\\right\\}}\\),adjust weight vector: \\(w_j \\leftarrow w_j + \\eta (y_i-\\tilde{y}_i)x_{,j}\\),amounts shifting weights  direction. Just like tree methods, scaling factor \\(\\eta\\) learning rate. large \\(\\eta\\) imply large shifts: learning rapid convergence may slow may even occur. small \\(\\eta\\) usually preferable, helps reduce risk overfitting.Figure 7.1, illustrate mechanism. initial model (dashed grey line) trained 7 points (3 red 4 blue). new black point comes .\nFIGURE 7.1: Scheme perceptron.\npoint red, need adjustment: labelled correctly lies right side border.point blue, model needs updated appropriately. Given rule mentioned , means adjusting slope line downwards. Depending \\(\\eta\\), shift sufficient change classification new point - .time inception, perceptron immense breakthrough received intense media coverage (see Olazaran (1996) Anderson Rosenfeld (2000)). rather simple structure progressively generalized networks (combinations) perceptrons. one simple unit, units gathered layers. next section describes organization simple multilayer perceptrons (MLPs).","code":""},{"path":"NN.html","id":"multilayer-perceptron","chapter":"7 Neural networks","heading":"7.2 Multilayer perceptron","text":"","code":""},{"path":"NN.html","id":"introduction-and-notations","chapter":"7 Neural networks","heading":"7.2.1 Introduction and notations","text":"perceptron can viewed linear model applied particular function: Heaviside (step) function. choices functions naturally possible. NN jargon, called activation functions. purpose introduce nonlinearity otherwise linear models.Just like random forests trees, idea behind neural networks combine perceptron-like building blocks. popular representation neural networks shown Figure 7.2. scheme overly simplistic. hides really going : perceptron green circle output activated function sent final output aggregation. model called Multilayer Perceptron (MLP).\nFIGURE 7.2: Simplified scheme multi-layer perceptron.\nfaithful account going laid Figure 7.3.\nFIGURE 7.3: Detailed scheme perceptron 2 intermediate layers.\nproceed comments, introduce notation used thoughout chapter.data separated matrix \\(\\textbf{X}=x_{,j}\\) features vector output values \\(\\textbf{y}=y_i\\). \\(\\textbf{x}\\) \\(\\textbf{x}_i\\) denotes one line \\(\\textbf{X}\\).neural network \\(L\\ge1\\) layers layer \\(l\\), number units \\(U_l\\ge1\\).weights unit \\(k\\) located layer \\(l\\) denoted \\(\\textbf{w}_{k}^{(l)}=w_{k,j}^{(l)}\\) corresponding biases \\(b_{k}^{(l)}\\). length \\(\\textbf{w}_{k}^{(l)}\\) equal \\(U_{l-1}\\). \\(k\\) refers location unit layer \\(l\\) \\(j\\) unit layer \\(l-1\\).Outputs (post-activation) denoted \\(o_{,k}^{(l)}\\) instance \\(\\), layer \\(l\\) unit \\(k\\).process following. entering network, data goes though initial linear mapping:\\[v_{,k}^{(1)}=\\textbf{x}_i'\\textbf{w}^{(1)}_k+b_k^{(1)},  \\text{} l=1, \\quad k \\[1,U_1],  \\]\ntransformed non-linear function \\(f^{1}\\). result alteration given input next layer . linear forms repeated (different weights) layer network:\n\\[v_{,k}^{(l)}=(\\textbf{o}^{(l-1)}_i)'\\textbf{w}^{(l)}_k+b_k^{(l)}, \\text{} l \\ge 2,  \\quad k \\[1,U_l]. \\]\nconnections layers -called outputs, basically linear mappings activation functions \\(f^{(l)}\\) applied. output layer \\(l\\) input layer \\(l+1\\).\n\\[o_{,k}^{(l)}=f^{(l)}\\left(v_{,k}^{(l)}\\right).\\]\nFinally, terminal stage aggregates outputs last layer:\\[\\tilde{y}_i =f^{(L+1)} \\left((\\textbf{o}^{(L)}_i)'\\textbf{w}^{(L+1)}+b^{(L+1)}\\right).\\]forward-propagation input, activation function naturally plays important role. Figure 7.4, plot usual activation functions used neural network libraries.\nFIGURE 7.4: Plot common activation functions.\nLet us rephrase process lens factor investing. input \\(\\textbf{x}\\) characteristics firms. first step multiply value weights add bias. performed units first layer. output, linear combination input transformed activation function. unit provides one value values fed second layer following process. iterated end network. purpose last layer yield output shape corresponds label: label numerical, output single number, categorical, usually vector length equal number categories. vector indicates probability value belongs one particular category.possible use final activation function output. can huge importance result. Indeed, labels returns, applying sigmoid function end disastrous sigmoid always positive.","code":""},{"path":"NN.html","id":"universal-approximation","chapter":"7 Neural networks","heading":"7.2.2 Universal approximation","text":"One reason neural networks work well universal approximators. Given bounded continuous function, exists one-layer network can approximate function arbitrary precision (see Cybenko (1989) early references, section 4.2 K.-L. Du Swamy (2013) section 6.4.1 Goodfellow et al. (2016) exhaustive lists papers, Guliyev Ismailov (2018) recent results).Formally, one-layer perceptron defined \n\\[f_n(\\textbf{x})=\\sum_{l=1}^nc_l\\phi(\\textbf{x}\\textbf{w}_l+\\textbf{b}_l)+c_0,\\]\n\\(\\phi\\) (non-constant) bounded continuous function. , \\(\\epsilon>0\\), possible find one \\(n\\) continuous function \\(f\\) unit hypercube \\([0,1]^d\\),\n\\[|f(\\textbf{x})-f_n(\\textbf{x})|< \\epsilon, \\quad \\forall \\textbf{x} \\[0,1]^d.\\]result rather intuitive: suffices add units layer improve fit. process less analogous polynomial approximation, though subtleties arise depending properties activations functions (boundedness, smoothness, convexity, etc.). refer Costarelli, Spigler, Vinti (2016) survey topic.raw results universal approximation imply well-behaved function \\(f\\) can approached sufficiently closely simple neural network, long number units can arbitrarily large. Now, directly relate learning phase, .e., model optimized respect particular dataset. series papers (Barron (1993) Barron (1994), notably), Barron gives much precise characterization neural networks can achieve. Barron (1993) instance proved precise version universal approximation: particular neural networks (sigmoid activation), \\(\\mathbb{E}[(f(\\textbf{x})-f_n(\\textbf{x}))^2]\\le c_f/n\\), gives speed convergence related size network. expectation, random term \\(\\textbf{x}\\): corresponds case data considered sample ..d. observations fixed distribution (common assumption machine learning)., state one important result easy interpret; taken Barron (1994).sequel, \\(f_n\\) corresponds possibly penalized neural network one intermediate layer \\(n\\) units sigmoid activation function. Moreover, supports predictors label assumed bounded (major constraint). important metric regression exercise mean squared error (MSE) main result bound (order magnitude) quantity. \\(N\\) randomly sampled ..d. points \\(y_i=f(x_i)+\\epsilon_i\\) \\(f_n\\) trained, best possible empirical MSE behaves like\\[\\begin{equation}\n\\tag{7.1}\n\\mathbb{E}\\left[(f(x)-f_n(x))^2 \\right]=\\underbrace{O\\left(\\frac{c_f}{n} \\right)}_{\\text{size network}}+\\ \\underbrace{O\\left(\\frac{nK \\log(N)}{N} \\right)}_{\\text{size sample}},\n\\end{equation}\\]\n\\(K\\) dimension input (number columns) \\(c_f\\) constant depends generator function \\(f\\). quantity provides bound error can achieved best possible neural network given dataset size \\(N\\).clearly two components decomposition bound. first one pertains complexity network. Just original universal approximation theorem, error decreases number units network. enough! Indeed, sample size course key driver quality learning (..d. observations). second component bound indicates error decreases slightly slower pace respect number observations (\\(\\log(N)/N\\)) linear number units size input. clearly underlines link (trade-?) sample size model complexity: complex model useless sample small just like simple model catch fine relationships large dataset.Overall, neural network possibly complicated function lot parameters. linear regressions, possible increase fit spuriously adding exogenous variables. neural networks, suffices increase number parameters arbitrarily adding units layer(s). course bad idea high-dimensional networks mostly capture particularities sample trained .","code":""},{"path":"NN.html","id":"backprop","chapter":"7 Neural networks","heading":"7.2.3 Learning via back-propagation","text":"Just like tree methods, neural networks trained minimizing loss function subject penalization:\n\\[O=\\sum_{=1}^\\text{loss}(y_i,\\tilde{y}_i)+ \\text{penalization},\\]\n\\(\\tilde{y}_i\\) values obtained model \\(y_i\\) true values instances. simple requirement eases computation loss function differentiable. common choices squared error regression tasks cross-entropy classification tasks. discuss technicalities classification next subsection.training neural network amounts alter weights (biases) units layers \\(O\\) defined smallest possible. ease notation given \\(y_i\\) fixed, let us write \\(D(\\tilde{y}_i(\\textbf{W}))=\\text{loss}(y_i,\\tilde{y}_i)\\), \\(\\textbf{W}\\) denotes entirety weights biases network. updating weights performed via gradient descent, .e., via\\[\\begin{equation}\n\\tag{7.2}\n\\textbf{W} \\leftarrow \\textbf{W}-\\eta  \\frac{\\partial D(\\tilde{y}_i) }{\\partial \\textbf{W}}.\n\\end{equation}\\] mechanism classical optimization literature illustrate Figure 7.5. highlight possible suboptimality large learning rates. diagram, descent associated high \\(\\eta\\) oscillate around optimal point, whereas one related small eta converge directly.complicated task equation compute gradient (derivative) tells direction adjustment done. problem successive nested layers associated activations require many iterations chain rule differentiation.\nFIGURE 7.5: Outline gradient descent.\ncommon way approximate derivative probably finite difference method. usual assumptions (loss twice differentiable), centered difference satisfies:\\[\\frac{\\partial D(\\tilde{y}_i(w_k))}{\\partial w_k} = \\frac{D(\\tilde{y}_i(w_k+h))-D(\\tilde{y}_i(w_k-h))}{2h}+O(h^2),\\]\n\\(h>0\\) arbitrarily small number. spite apparent simplicity, method costly computationally requires number operations magnitude number weights.Luckily, small trick can considerably ease speed computation. idea simply follow chain rule recycle terms along way. Let us start recalling \n\\[\\tilde{y}_i =f^{(L+1)} \\left((\\textbf{o}^{(L)}_i)'\\textbf{w}^{(L+1)}+b^{(L+1)}\\right)=f^{(L+1)}\\left(b^{(L+1)}+\\sum_{k=1}^{U_L} w^{(L+1)}_ko^{(L)}_{,k} \\right),\\] differentiate immediate weights biases, get:\n\\[\\begin{align}\n\\frac{\\partial D(\\tilde{y}_i)}{\\partial w_k^{(L+1)}}&=D'(\\tilde{y}_i) \\left(f^{(L+1)} \\right)'\\left( b^{(L+1)}+\\sum_{k=1}^{U_L} w^{(L+1)}_ko^{(L)}_{,k}  \\right)o^{(L)}_{,k} \\\\   \\tag{7.3}\n&= D'(\\tilde{y}_i) \\left(f^{(L+1)} \\right)'\\left( v^{(L+1)}_{,k}  \\right)o^{(L)}_{,k} \\\\\n\\frac{\\partial D(\\tilde{y}_i)}{\\partial b^{(L+1)}}&=D'(\\tilde{y}_i) \\left(f^{(L+1)} \\right)'\\left( b^{(L+1)}+\\sum_{k=1}^{U_L} w^{(L+1)}_ko^{(L)}_{,k}  \\right). \n\\end{align}\\]easiest part. must now go back one layer can done via chain rule. access layer \\(L\\), recall identity \\(v_{,k}^{(L)}=(\\textbf{o}^{(L-1)}_i)'\\textbf{w}^{(L)}_k+b_k^{(L)}=b_k^{(L)}+\\sum_{j=1}^{U_L}o^{(L-1)}_{,j}w^{(L)}_{k,j}\\).\ncan proceed:\\[\\begin{align}\n\\frac{\\partial D(\\tilde{y}_i)}{\\partial w_{k,j}^{(L)}}&=\\frac{\\partial D(\\tilde{y}_i)}{\\partial v^{(L)}_{,k}}\\frac{\\partial v^{(L)}_{,k}}{\\partial w_{k,j}^{(L)}} = \\frac{\\partial D(\\tilde{y}_i)}{\\partial v^{(L)}_{,k}}o^{(L-1)}_{,j}\\\\\n&=\\frac{\\partial D(\\tilde{y}_i)}{\\partial o^{(L)}_{,k}} \\frac{\\partial o^{(L)}_{,k} }{\\partial v^{(L)}_{,k}}  o^{(L-1)}_{,j} = \\frac{\\partial D(\\tilde{y}_i)}{\\partial o^{(L)}_{,k}}  (f^{(L)})'(v_{,k}^{(L)})  o^{(L-1)}_{,j} \\\\\n&=\\underbrace{D'(\\tilde{y}_i) \\left(f^{(L+1)} \\right)'\\left(v^{(L+1)}_{,k}  \\right)}_{\\text{computed !}} w^{(L+1)}_k (f^{(L)})'(v_{,k}^{(L)})  o^{(L-1)}_{,j},\n\\end{align}\\], show last line, one part derivative already computed previous step (Equation (7.3)). Hence, can recycle number focus right part expression.magic -called back-propagation hold true step differentiation. computing gradient weights biases layer \\(l\\), two parts: one can recycled previous layers another, local part, depends values activation function current layer. nice illustration process given Google developer team: playground.tensorflow.org.data formatted using tensors, possible resort vectorization number calls limited order magnitude number nodes (units) network.back-propagation algorithm can summarized follows. Given sample points (possibly just one):data flows left described Figure 7.6. blue arrows show forward pass;allows computation error loss function;derivatives function (w.r.t. weights biases) computed, starting last layer diffusing left (hence term back-propagation) - green arrows show backward pass;weights biases can updated take sample points account (model adjusted reduce loss/error stemming points).\nFIGURE 7.6: Diagram back-propagation.\noperation can performed number times different sample sizes. discuss issue Section 7.3.learning rate \\(\\eta\\) can refined. One option reduce overfitting impose epoch, intensity update decreases. One possible parametric form \\(\\eta=\\alpha e^{- \\beta t}\\), \\(t\\) epoch \\(\\alpha,\\beta>0\\). One sophistication resort -called momentum (originates Polyak (1964)):\n\\[\\begin{align}\n\\tag{7.4}\n\\textbf{W}_{t+1} & \\leftarrow  \\textbf{W}_{t} - \\textbf{m}_t \\quad \\text{} \\nonumber \\\\\n\\textbf{m}_t & \\leftarrow \\eta  \\frac{\\partial D(\\tilde{y}_i)}{\\partial \\textbf{W}_{t}}+\\gamma \\textbf{m}_{t-1},\n\\end{align}\\]\n\\(t\\) index weight update. idea momentum speed convergence including memory term last adjustment (\\(\\textbf{m}_{t-1}\\)) going direction current update. parameter \\(\\gamma\\) often taken 0.9.complex enhanced methods progressively developed:\n- Nesterov (1983) improves momentum term forecasting future shift parameters;\n- Adagrad (Duchi, Hazan, Singer (2011)) uses different learning rate parameter;\n- Adadelta (Zeiler (2012)) Adam (Kingma Ba (2014)) combine ideas Adagrad momentum.Lastly, degenerate case, gradients may explode push weights far optimal values. order avoid phenomenon, learning libraries implement gradient clipping. user specifies maximum magnitude gradients, usually expressed norm. Whenever gradient surpasses magnitude, rescaled reach authorized threshold. Thus, direction remains , adjustment smaller.","code":""},{"path":"NN.html","id":"NNclass","chapter":"7 Neural networks","heading":"7.2.4 Further details on classification","text":"decision trees, ultimate goal create homogeneous clusters, process reach goal outlined previous chapter. neural networks, things work differently objective explicitly minimize error prediction \\(\\tilde{\\textbf{y}}_i\\) target label \\(\\textbf{y}_i\\). , \\(\\textbf{y}_i\\) vector full zeros one one denoting class instance.Facing classification problem, trick use appropriate activation function end network. dimension terminal output network equal \\(J\\) (number classes predict), , simplicity, write \\(\\textbf{x}_i\\) values output, commonly used activation -called softmax function:\\[\\tilde{\\textbf{y}}_i=s(\\textbf{x})_i=\\frac{e^{x_i}}{\\sum_{j=1}^Je^{x_j}}.\\]justification choice straightforward: can take value input (real line) sums one (finite-valued) output. Similarly trees, yields ‘probability’ vector classes. Often, chosen loss generalization entropy used trees. Given target label \\(\\textbf{y}_i=(y_{,1},\\dots,y_{,L})=(0,0,\\dots,0,1,0,\\dots,0)\\) predicted output \\(\\tilde{\\textbf{y}}_i=(\\tilde{y}_{,1},\\dots,\\tilde{y}_{,L})\\), cross-entropy defined \\[\\begin{equation}\n\\tag{7.5}\n\\text{CE}(\\textbf{y}_i,\\tilde{\\textbf{y}}_i)=-\\sum_{j=1}^J\\log(\\tilde{y}_{,j})y_{,j}.\n\\end{equation}\\]Basically, proxy dissimilarity two arguments. One simple interpretation following. nonzero label value, loss \\(-\\log(\\tilde{y}_{,l})\\), others, zero. log, loss minimal \\(\\tilde{y}_{,l}=1\\), exactly seek (.e., \\(y_{,l}=\\tilde{y}_{,l}\\)). applications, best case scenario happen, loss simply increase \\(\\tilde{y}_{,l}\\) drifts away downwards one.","code":""},{"path":"NN.html","id":"howdeep","chapter":"7 Neural networks","heading":"7.3 How deep we should go and other practical issues","text":"Beyond ones presented previous sections, user faces many degrees freedom building neural network. present classical choices available constructing training neural networks.","code":""},{"path":"NN.html","id":"architectural-choices","chapter":"7 Neural networks","heading":"7.3.1 Architectural choices","text":"Arguably, first choice pertains structure network. Beyond dichotomy feed-forward versus recurrent (see Section ??), immediate question : big (deep) networks .\nFirst , let us calculate number parameters (.e., weights plus biases) estimated (optimized) network.first layer, gives \\((U_0+1)U_1\\) parameters, \\(U_0\\) number columns \\(\\mathbb{X}\\) (.e., number explanatory variables) \\(U_1\\) number units layer.layer \\(l\\[2,L]\\), number parameters \\((U_{l-1}+1)U_l\\).final output, simply \\(U_L+1\\) parameters.total, means total number values optimize \n\\[\\mathcal{N}=\\left(\\sum_{l=1}^L(U_{l-1}+1)U_l\\right)+U_L+1\\]model, number parameters much smaller number instances. fixed ratio, preferable sample size least ten times larger number parameters. ratio 5, risk overfitting high. Given amount data readily available, constraint seldom issue, unless one wishes work large network.number hidden layers current financial applications rarely exceeds three four. number units per layer \\((U_k)\\) often chosen follow geometric pyramid rule (see, e.g., Masters (1993)). \\(L\\) hidden layers, \\(\\) features input \\(O\\) dimensions output (regression tasks, \\(O=1\\)), , \\(k^{th}\\) layer, rule thumb number units \n\\[U_k\\approx \\left\\lfloor O\\left( \\frac{}{O}\\right)^{\\frac{L+1-k}{L+1}}\\right\\rfloor.\\]\none intermediate layer, recommended proxy integer part \\(\\sqrt{IO}\\). , network starts many units number unit decreases exponentially towards output size. Often, number layers power two , high dimensions, networks trained Graphics Processing Units (GPUs) Tensor Processing Units (TPUs). pieces hardware can used optimally inputs sizes equals powers two.Several studies shown large architectures always perform better shallow ones (e.g., Gu, Kelly, Xiu (2020b) Orimoloye et al. (2019) high frequency data, .e., factor-based). rule thumb, maximum three hidden layers seem sufficient prediction purposes.","code":""},{"path":"NN.html","id":"frequency-of-weight-updates-and-learning-duration","chapter":"7 Neural networks","heading":"7.3.2 Frequency of weight updates and learning duration","text":"expression (7.2), implicit computation performed one given instance. sample size large (hundreds thousands millions instances), updating weights according point computationally costly. updating performed groups instances called batches. sample (randomly) split batches fixed sizes update performed following rule:\\[\\begin{equation}\n\\tag{7.6}\n\\textbf{W} \\leftarrow \\textbf{W}-\\eta  \\frac{\\partial \\sum_{\\\\text{batch}} D(\\tilde{y}_i)/\\text{card}(\\text{batch}) }{\\partial \\textbf{W}}.\n\\end{equation}\\]change weights computed average loss computed instances batch. terminology training includes:epoch: one epoch reached instance sample contributed update weights (.e., training). Often, training NN requires several epochs dozen.batch size: batch size number samples used one single update weights.iterations: number iterations can mean alternatively ratio sample size divided batch size ratio multiplied number epochs. ’s either number weight updates required reach one epoch total number updates whole training.batch equal one instance, method referred ‘stochastic gradient descent’ (SGD): instance chosen randomly. batch size strictly one total number instances, learning performed via ‘mini’ batches, , small groups instances. batches also chosen randomly, without replacement sample one epoch, union batches must equal full training sample.impossible know advance good number epochs . Sometimes, network stops learning just 5 epochs (validation loss decrease anymore). cases validation sample drawn distribution close training sample, network continues learn even 200 epochs. user test different values evaluate learning speed. examples , keep number epochs low computational purposes.","code":""},{"path":"NN.html","id":"penalizations-and-dropout","chapter":"7 Neural networks","heading":"7.3.3 Penalizations and dropout","text":"\nlevel (layer), possible enforce constraints penalizations weights (biases). Just tree methods, helps slow learning prevent overfitting training sample. Penalizations enforced directly loss function objective function takes form\\[O=\\sum_{=1}^\\text{loss}(y_i,\\tilde{y}_i)+ \\sum_{k} \\lambda_k||\\textbf{W}_k||_1+ \\sum_j\\delta_j||\\textbf{W}_j||_2^2,\\]\nsubscripts \\(k\\) \\(j\\) pertain weights \\(L^1\\) () \\(L^2\\) penalization applied.addition, specific constraints can enforced weights directly training. Typically, two types constraints used:norm constraints: maximum norm fixed weight vectors matrices;non-negativity constraint: weights must positive zero.Lastly, another (somewhat exotic) way reduce risk overfitting simply reduce size (number parameters) model. Srivastava et al. (2014) propose omit units training (hence term ‘dropout’). weights randomly chosen units set zero training. links unit ignored, mechanically shrinks network. testing phase, units back, values (weights) must scaled account missing activations training phase.interested reader can check advice compiled Bengio (2012), Hanin Rolnick (2018), L. N. Smith (2018) tips configure neural networks. paper dedicated hyperparameter tuning stock return prediction Lee (2020).","code":""},{"path":"NN.html","id":"code-samples-and-comments-for-vanilla-mlp","chapter":"7 Neural networks","heading":"7.4 Code samples and comments for vanilla MLP","text":"several frameworks libraries allow robust flexible constructions neural networks. Among , Keras Tensorflow (developed Google) probably used time write book (PyTorch, Facebook, one alternative). simplicity believe best choice, implement NN Keras (high level API Tensorflow, see https://www.tensorflow.org). original Python implementation referenced https://keras.io, details R version can found : https://keras.rstudio.com. recommend thorough installation proceeding. native versions Tensorflow Keras written Python (accessed R via reticulate package), running version Python required . install Keras, please follow instructions provided https://keras.rstudio.com.section, provide detailed (though far exhaustive) account train neural networks Keras. sake completeness, proceed two steps. first one relates simple regression exercise. purpose get reader familiar syntax Keras. second step, lay many options proposed Keras perform classification exercise. two examples, thus cover mainstream topics falling umbrella feed-forward multilayered perceptrons.","code":""},{"path":"NN.html","id":"regression-example","chapter":"7 Neural networks","heading":"7.4.1 Regression example","text":"head core NN, short stage data preparation required. Just penalized regressions (glmnet package) boosted trees (xgboost package), data must sorted four parts combination two dichotomies: training versus testing labels versus features. define corresponding variables . simplicity, first example regression exercise. classification task detailed .Keras, training neural networks performed three steps:Defining structure/architecture network;Setting loss function learning process (options updating weights);Train specifying batch sizes number rounds (epochs).start simple architecture two hidden layers.definition structure intuitive uses sequential syntax one input iteratively transformed layer last iteration gives output. layer depends two parameters: number units activation function applied output layer. One important point input_shape parameter first layer. required first layer equal number features. subsequent layers, input_shape dictated number units previous layer; hence required. activations currently available listed https://keras.io/activations/. use hyperbolic tangent second--last layer yields positive negative outputs. course, last layer can generate negative values well, ’s preferable satisfy property one step ahead final output.summary model lists layers order input output (forward pass). working 93 features, number parameters first layer (16 units) 93 plus one (bias) multiplied 16, makes 1504. second layer, number inputs equal size output previous layer (16). Hence given fact second layer 8 units, total number parameters (16+1)*8 = 136.set loss function standard mean squared error. losses listed https://keras.io/losses/, work regressions (MSE, MAE) others classification (categorical cross-entropy, see Equation (7.5)). RMS propragation optimizer classical mini-batch back-propagation implementation. weight updating algorithms, refer https://keras.io/optimizers/. metric function used assess quality model. can different loss: instance, using entropy training accuracy performance metric.final stage fits model data requires additional training parameters:\nFIGURE 7.7: Output trained neural network (regression task).\nbatch size quite arbitrary. technical reasons pertaining training GPUs, sizes often powers 2.Keras, plot trained model shows four different curves (shown Figure 7.7). top graph displays improvement (lack thereof) loss number epochs increases. Usually, algorithm starts learning rapidly converges point additional epoch improve fit. example , point arrives rather quickly hard notice gain beyond fourth epoch. two colors show performance two samples: training sample testing sample. construction, loss always improve (even marginally) training sample. impact negligible testing sample (curve flat, case ), model fails generalize --sample: gains obtained training original sample translate gains previously unseen data; thus, model seems learning noise.second graph shows behavior computed using metric function. correlation (absolute terms) two curves (loss metric) usually high. one flat, well.order obtain parameters model, user can call get_weights(model).19 execute code size output much large, thousands weights.Finally, practical point view, prediction obtained via usual predict() function. use function testing sample calculate hit ratio., hit ratio lies 50% 55%, seems reasonably good. time, neural networks weights initialized randomly. Hence, two independently trained networks architecture training data may well lead different predictions performance! One way bypass issue freeze random number generator. Models can also easily exchanged loading weights via set_weights() function.","code":"\nNN_train_features <- dplyr::select(training_sample, features) %>%    # Training features\n  as.matrix()                                                      # Matrix = important\nNN_train_labels <- training_sample$R1M_Usd                           # Training labels\nNN_test_features <- dplyr::select(testing_sample, features) %>%      # Testing features\n  as.matrix()                                                      # Matrix = important\nNN_test_labels <- testing_sample$R1M_Usd                             # Testing labels\nlibrary(keras)\n# install_keras() # To complete installation\nmodel <- keras_model_sequential()\nmodel %>%   # This defines the structure of the network, i.e. how layers are organized\n  layer_dense(units = 16, activation = 'relu', input_shape = ncol(NN_train_features)) %>%\n  layer_dense(units = 8, activation = 'tanh') %>%\n  layer_dense(units = 1) # No activation means linear activation: f(x) = x.\nmodel %>% compile(                             # Model specification\n  loss = 'mean_squared_error',               # Loss function\n  optimizer = optimizer_rmsprop(),           # Optimisation method (weight updating)\n  metrics = c('mean_absolute_error')         # Output metric\n)\nsummary(model)                                 # Model architecture## Model: \"sequential_24\"\n## __________________________________________________________________________________________\n## Layer (type)                            Output Shape                        Param #       \n## ==========================================================================================\n## dense_63 (Dense)                        (None, 16)                          1504          \n## __________________________________________________________________________________________\n## dense_62 (Dense)                        (None, 8)                           136           \n## __________________________________________________________________________________________\n## dense_61 (Dense)                        (None, 1)                           9             \n## ==========================================================================================\n## Total params: 1,649\n## Trainable params: 1,649\n## Non-trainable params: 0\n## __________________________________________________________________________________________\nfit_NN <- model %>% \n  fit(NN_train_features,                                       # Training features\n      NN_train_labels,                                         # Training labels\n      epochs = 10, batch_size = 512,                           # Training parameters\n      validation_data = list(NN_test_features, NN_test_labels) # Test data\n  ) \nplot(fit_NN) + theme_light()                                   # Plot, evidently!\nmean(predict(model, NN_test_features) * NN_test_labels > 0) # Hit ratio## [1] 0.5327883"},{"path":"NN.html","id":"classification-example","chapter":"7 Neural networks","heading":"7.4.2 Classification example","text":"\npursue exploration neural networks much detailed example. aim carry classification task binary label R1M_Usd_C. proceed, need format label properly. purpose, resort one-hot encoding (see Section 4.5.2).labels NN_train_labels_C NN_test_labels_C two columns: first flags instances median returns second flags median returns. Note alter feature variables: remain unchanged. , set structure networks many additional features compared first one.start commenting many options used , highlight Keras models, unlike many R variables, mutable objects. means piping %>% calling model alter . Hence, successive trainings start scratch result previous training.First, options used chosen illustrative examples serve particularly improve quality model. first change compared Section 7.4.1 activation functions. first two simply new cases, third one (output layer) imperative. Indeed, since goal classification, dimension output must equal number categories labels. activation yields multivariate softmax function. Note must also specify number classes (categories) terminal layer.second major innovation options pertaining parameters. One family options deals initialization weights biases. Keras, weights referred ‘kernel.’ list initializers quite long suggest interested reader look Keras reference (https://keras.io/initializers/). random, constant.Another family options constraints norm penalization applied weights biases training. example, weights first layer coerced non-negative, weights second layer see magnitude penalized factor (0.01) times \\(L^2\\) norm. Lastly, final novelty dropout layer (see Section 7.3.3) first second layers. According layer, one fourth units first layer (randomly) omitted training.specification training outlined ., many changes made: levels revised. loss now cross-entropy. work two categories, resort specific choice (binary cross-entropy), general form option categorical_crossentropy works number classes (strictly 1). optimizer also different allows several parameters refer Kingma Ba (2014). Simply put, two beta parameters control decay rates exponentially weighted moving averages used update weights. two averages estimates first second moment gradient can exploited increase speed learning. performance metric chunk categorical accuracy. multiclass classification, accuracy defined average accuracy classes predictions. Since prediction one instance vector weights, ‘terminal’ prediction class associated largest weight. accuracy measures proportion times prediction equal realized value (.e., class correctly guessed model).Finally, proceed training model.\nFIGURE 7.8: Output trained neural network (classification task) early stopping.\none major difference compared previous training call. Keras, callbacks functions can used given stages learning process. example, use one function stop algorithm progress made time.datasets large, training can long, especially batch sizes small /number epochs high. guaranteed going full number epochs useful, loss metric functions may plateauing much sooner. Hence, can convenient stop process improvement achieved specified time-frame. set number epochs 20, process likely stop .code, improvement focused validation accuracy (“val_loss”; one alternative “val_acc”). min_delta value sets minimum improvement needs attained algorithm continue. Therefore, unless validation accuracy gains 0.001 points epoch, training stop. Nevertheless, flexibility introduced via patience parameter, case asserts halting decision made three consecutive epochs improvement. option, verbose parameter dictates amount comments made function. simplicity, want comments, hence value set zero.Figure 7.8, two graphs yield different curves. One reason scale second graph. range accuracies narrow. change range represent much variation overall. pattern relatively clear training sample: loss decreases, accuracy improves. Unfortunately, translate testing sample indicates model generalize well --sample.","code":"\nlibrary(dummies)                                            # Package for one-hot encoding\nNN_train_labels_C <- training_sample$R1M_Usd_C %>% dummy()  # One-hot encoding of the label\nNN_test_labels_C <- testing_sample$R1M_Usd_C %>% dummy()    # One-hot encoding of the label\nmodel_C <- keras_model_sequential()\nmodel_C %>%   # This defines the structure of the network, i.e. how layers are organized\n  layer_dense(units = 16, activation = 'tanh',               # Nb units & activation\n              input_shape = ncol(NN_train_features),         # Size of input\n              kernel_initializer = \"random_normal\",          # Initialization of weights\n              kernel_constraint = constraint_nonneg()) %>%   # Weights should be nonneg\n  layer_dropout(rate = 0.25) %>%                             # Dropping out 25% units\n  layer_dense(units = 8, activation = 'elu',                 # Nb units & activation\n              bias_initializer = initializer_constant(0.2),  # Initialization of biases\n              kernel_regularizer = regularizer_l2(0.01)) %>% # Penalization of weights \n  layer_dense(units = 2, activation = 'softmax')             # Softmax for categorical output\nmodel_C %>% compile(                               # Model specification\n  loss = 'binary_crossentropy',                  # Loss function\n  optimizer = optimizer_adam(lr = 0.005,         # Optimisation method (weight updating)\n                             beta_1 = 0.9, \n                             beta_2 = 0.95),        \n  metrics = c('categorical_accuracy')            # Output metric\n)\nsummary(model_C)                                   # Model structure## Model: \"sequential_25\"\n## __________________________________________________________________________________________\n## Layer (type)                            Output Shape                        Param #       \n## ==========================================================================================\n## dense_66 (Dense)                        (None, 16)                          1504          \n## __________________________________________________________________________________________\n## dropout_4 (Dropout)                     (None, 16)                          0             \n## __________________________________________________________________________________________\n## dense_65 (Dense)                        (None, 8)                           136           \n## __________________________________________________________________________________________\n## dense_64 (Dense)                        (None, 2)                           18            \n## ==========================================================================================\n## Total params: 1,658\n## Trainable params: 1,658\n## Non-trainable params: 0\n## __________________________________________________________________________________________\nfit_NN_C <- model_C %>% \n  fit(NN_train_features,                                   # Training features\n      NN_train_labels_C,                                   # Training labels\n      epochs = 20, batch_size = 512,                       # Training parameters\n      validation_data = list(NN_test_features, \n                             NN_test_labels_C),            # Test data\n      verbose = 0,                                         # No comments from algo\n      callbacks = list(\n        callback_early_stopping(monitor = \"val_loss\",    # Early stopping:\n                                min_delta = 0.001,       # Improvement threshold\n                                patience = 3,            # Nb epochs with no improvmt \n                                verbose = 0              # No warnings\n        )\n      )\n  )\nplot(fit_NN_C) + theme_light()"},{"path":"NN.html","id":"custloss","chapter":"7 Neural networks","heading":"7.4.3 Custom losses","text":"\nKeras, possible define user-specified loss functions. may interesting cases. instance, quadratic error three terms \\(y_i^2\\), \\(\\tilde{y}_i^2\\) \\(-2y_i\\tilde{y}_i\\). practice, can make sense focus latter term essential: want predictions realized values sign! show optimize simple (product) function Keras, \\(l(y_i,\\tilde{y}_i)=(\\tilde{y}_i-\\tilde{m})^2-\\gamma (y_i-m)(\\tilde{y}_i-\\tilde{m})\\), \\(m\\) \\(\\tilde{m}\\) sample averages \\(y_i\\) \\(\\tilde{y}_i\\). \\(\\gamma>2\\), give weight cross term. start simple architecture.code loss function integrate model. important trick resort functions specific library (k_functions). code variance predicted values minus scaled covariance realized predicted values. use scale five.Finally, ready train briefly evaluate performance model.curves may go opposite direction. One reason improving correlation realized predicted values, also increasing sum squared predicted returns.outcome improved. several directions help. One arguably model dynamic static (see Chapter 12).","code":"\nmodel_custom <- keras_model_sequential()\nmodel_custom %>%   # This defines the structure of the network, i.e. how layers are organized\n  layer_dense(units = 16, activation = 'relu', input_shape = ncol(NN_train_features)) %>%\n  layer_dense(units = 8, activation = 'sigmoid') %>%\n  layer_dense(units = 1) # No activation means linear activation: f(x) = x.\n# Defines the loss, we use gamma = 5\nmetric_cust <- custom_metric(\"custom_loss\", \n                             function(y_true, y_pred) {\n                               k_mean((y_pred - k_mean(y_pred))*(y_pred - k_mean(y_pred)))-5*k_mean((y_true - k_mean(y_true))*(y_pred - k_mean(y_pred)))\n                             })\n\nmodel_custom %>% compile(                                          # Model specification\n  loss =  metric_cust, #function(y_true, y_pred) custom_loss(y_true, y_pred),  # New loss function!\n  optimizer = optimizer_rmsprop(),                               # Optim method \n  metrics = c('mean_absolute_error')                             # Output metric\n)\nfit_NN_cust <- model_custom %>% \n  fit(NN_train_features,                                       # Training features\n      NN_train_labels,                                         # Training labels\n      epochs = 10, batch_size = 512,                           # Training parameters\n      validation_data = list(NN_test_features, NN_test_labels) # Test data\n  ) \nplot(fit_NN_cust) + theme_light()  \nmean(predict(model_custom, NN_test_features) * NN_test_labels > 0) # Hit ratio## [1] 0.4469434"},{"path":"NN.html","id":"RNN","chapter":"7 Neural networks","heading":"7.5 Recurrent networks","text":"","code":""},{"path":"NN.html","id":"presentation","chapter":"7 Neural networks","heading":"7.5.1 Presentation","text":"\nMultilayer perceptrons feed-forward networks data flows left right looping . particular tasks sequential linkages (e.g., time-series speech recognition), might useful keep track happened previous sample (.e., natural ordering). One simple way model ‘memory’ consider following network one intermediate layer:\n\\[\\begin{align*}\n\\tilde{y}_i&=f^{(y)}\\left(\\sum_{j=1}^{U_1}h_{,j}w^{(y)}_j+b^{(2)}\\right) \\\\\n\\textbf{h}_{} &=f^{(h)}\\left(\\sum_{k=1}^{U_0}x_{,k}w^{(h,1)}_k+b^{(1)}+ \\underbrace{\\sum_{k=1}^{U_1}  w^{(h,2)}_{k}h_{-1,k}}_{\\text{memory part}} \\right),\n\\end{align*}\\]\\(h_0\\) customarily set zero (vector-wise).kinds models often referred Elman (1990) models Jordan (1997) models latter case \\(h_{-1}\\) replaced \\(y_{-1}\\) computation \\(h_i\\). types models fall overarching umbrella Recurrent Neural Networks (RNNs).\\(h_i\\) usually called state hidden layer. training model complicated must done unfolding network instances obtain simple feed-forward network train regularly. illustrate unfolding principle Figure 7.9. shows deep network. first input impacts first layer second one via \\(h_1\\) following layers fashion. Likewise, second input impacts layers except first instance \\(-1\\) going impact output \\(\\tilde{y}_i\\) outputs \\(\\tilde{y}_j\\) \\(j \\ge \\). Figure 7.9, parameters trained shown blue. appear many times, fact, level unfolded network.\nFIGURE 7.9: Unfolding recurrent network.\nmain problem architecture loss memory induced vanishing gradients. depth model, chain rule used back-propagation imply large number products derivatives activation functions. Now, shown Figure 7.4, functions smooth derivatives time smaller one (absolute value). Hence, multiplying many numbers smaller one leads small figures: beyond layers, learning propagate adjustments small.One way prevent progressive discounting memory introduced Hochreiter Schmidhuber (1997) (Long-Short Term Memory - LSTM model). model subsequently simplified authors Chung et al. (2015) present parsimonious model . Gated Recurrent Unit (GRU) slightly complicated version vanilla recurrent network defined . following representation:\n\\[\\begin{align*}\n\\tilde{y}_i&=z_i\\tilde{y}_{-1}+ (1-z_i)\\tanh \\left(\\textbf{w}_y'\\textbf{x}_i+ b_y+ u_yr_i\\tilde{y}_{-1}\\right) \\quad \\text{output (prediction)} \\\\\nz_i &= \\text{sig}(\\textbf{w}_z'\\textbf{x}_i+b_z+u_z\\tilde{y}_{-1})  \\hspace{9mm} \\text{`update gate'} \\ \\(0,1)\\\\\nr_i &= \\text{sig}(\\textbf{w}_r'\\textbf{x}_i+b_r+u_r\\tilde{y}_{-1}) \\hspace{9mm} \\text{`reset gate'}  \\ \\(0,1).\n\\end{align*}\\]\ncompact form, gives\n\\[\\tilde{y}_i=\\underbrace{z_i}_{\\text{weight}}\\underbrace{\\tilde{y}_{-1}}_{\\text{past value}}+ \\underbrace{(1-z_i)}_{\\text{weight}}\\underbrace{\\tanh \\left(\\textbf{w}_y'\\textbf{x}_i+ b_y+ u_yr_i\\tilde{y}_{-1}\\right)}_{\\text{candidate value (classical RNN)}}, \\]\\(z_i\\) decides optimal mix current past values. candidate value, \\(r_i\\) decides amount past/memory retain. \\(r_i\\) commonly referred ‘reset gate’ \\(z_i\\) ‘update gate.’subtleties training recurrent network. Indeed, chaining instances, batch must correspond coherent time series. logical choice thus one batch per asset instances (logically) chronologically ordered. Lastly, one option frameworks keep memory batches passing final value \\(\\tilde{y}_i\\) next batch (\\(\\tilde{y}_0\\)). often referred stateful mode considered meticulously. seem desirable portfolio prediction setting batch size corresponds observations asset: particular link assets. dataset divided several parts given asset, training must handled cautiously.Reccurrent networks LSTM especially found good forecasting tools financial contexts (see, e.g., Fischer Krauss (2018), W. Wang et al. (2020), Fister, Perc, Jagrič (2021)).","code":""},{"path":"NN.html","id":"code-and-results-2","chapter":"7 Neural networks","heading":"7.5.2 Code and results","text":"Recurrent networks theoretically complicated compared multilayered perceptrons. practice, also challenging implementation. Indeed, serial linkages require attention compared feed-forward architectures. asset pricing framework, must separate assets stock-specific time series bundled together. learning sequential, one stock time.dimensions variables crucial. Keras, defined RNNs :size batch: case, number assets. Indeed, recurrence relationship holds asset level, hence asset represent new batch model learn.time steps: case, simply number dates.number features: case, one possible figure number predictors.simplicity order reduce computation times, use subset stocks Section 5.2.2. yields perfectly rectangular dataset dates number observations.First, create new, intermediate variables., construct variables pass arguments. recall data file ordered first stocks date (see Section 1.2).Finally, move towards training part. simplicity, consider simple RNN one layer. structure outlined . terms recurrence structure, pick Gated Recurrent Unit (GRU). many options available recurrent layers. GRUs, refer Keras documentation https://keras.rstudio.com/reference/layer_gru.html. comment briefly option return_sequences activate. many cases, output simply terminal value sequence. require entirety sequence returned, face problem dimensionality label indeed full sequence.\nstructure determined, can move forward training stage.\nFIGURE 7.10: Output trained recurrent neural network (regression task).\nCompared previous models, major difference ouptut (graph Figure 7.10) input (code) absence validation (testing) data. One reason Keras restrictive RNNs imposes training testing samples share dimensions. situation obviously case, hence must bypass obstacle duplicating model.Finally, new model ready, matching dimensions, can push forward predicting test values. resort predict() function immediately compute hit ratio obtained model.hit ratio close 50%, hence model hardly better coin tossing.close section RNNs, mention new type architecture, called \\(\\alpha\\)-RNN simpler compared LSTMs GRUs. consist vanilla RNNs simple autocorrelation added generate long term memory. refer paper Matthew F. Dixon (2020) details subject.","code":"\ndata_rnn <- data_ml %>%                                  # Dedicated dataset\n  filter(stock_id %in% stock_ids_short)\ntraining_sample_rnn <- filter(data_rnn, date < separation_date)\ntesting_sample_rnn <- filter(data_rnn, date > separation_date)\nnb_stocks <- length(stock_ids_short)                     # Nb stocks \nnb_feats <- length(features)                             # Nb features\nnb_dates_train <- nrow(training_sample) / nb_stocks      # Nb training dates (size of sample)\nnb_dates_test <- nrow(testing_sample) / nb_stocks        # Nb testing dates\ntrain_features_rnn <- array(NN_train_features,           # Formats the training data into array\n                            dim = c(nb_dates_train, nb_stocks, nb_feats)) %>% # Tricky order\n  aperm(c(2,1,3))                                      # The order is: stock, date, feature \ntest_features_rnn <- array(NN_test_features,             # Formats the testing data into array\n                           dim = c(nb_dates_test, nb_stocks, nb_feats)) %>%  # Tricky order\n  aperm(c(2,1,3))                                      # The order is: stock, date, feature \ntrain_labels_rnn <- as.matrix(NN_train_labels) %>% \n  array(dim = c(nb_dates_train, nb_stocks, 1)) %>% aperm(c(2,1,3))\ntest_labels_rnn <- as.matrix(NN_test_labels) %>% \n  array(dim = c(nb_dates_test, nb_stocks, 1)) %>% aperm(c(2,1,3))\nmodel_RNN <- keras_model_sequential() %>% \n  layer_gru(units = 16,                              # Nb units in hidden layer\n            batch_input_shape = c(nb_stocks,         # Dimensions = tricky part!\n                                  nb_dates_train, \n                                  nb_feats), \n            activation = 'tanh',                     # Activation function\n            return_sequences = TRUE) %>%             # Return all the sequence\n  layer_dense(units = 1)                             # Final aggregation layer\nmodel_RNN %>% compile(\n  loss = 'mean_squared_error',                       # Loss = quadratic\n  optimizer = optimizer_rmsprop(),                   # Backprop\n  metrics = c('mean_absolute_error')                 # Output metric MAE\n)\nfit_RNN <- model_RNN %>% fit(train_features_rnn,   # Training features        \n                             train_labels_rnn,                # Training labels\n                             epochs = 10,                     # Number of rounds\n                             batch_size = nb_stocks,          # Length of sequences\n                             verbose = 0)                     # No comments\nplot(fit_RNN) + theme_light()\nnew_model <- keras_model_sequential() %>% \n  layer_gru(units = 16, \n            batch_input_shape = c(nb_stocks,          # New dimensions\n                                  nb_dates_test, \n                                  nb_feats), \n            activation = 'tanh',                      # Activation function\n            return_sequences = TRUE) %>%              # Return the full sequence\n  layer_dense(units = 1)                              # Output dimension\nnew_model %>% keras::set_weights(keras::get_weights(model_RNN))\npred_rnn <- predict(new_model, test_features_rnn, batch_size = nb_stocks) # Predictions\nmean(c(t(as.matrix(pred_rnn))) * test_labels_rnn > 0)           # Hit ratio## [1] 0.4961166"},{"path":"NN.html","id":"tabular-networks-tabnets","chapter":"7 Neural networks","heading":"7.6 Tabular networks (TabNets)","text":" superiority neural networks tasks related computer vision natural language processing now well established. However, many ML tournaments 2010 decade, neural networks often surpassed tree-based models dealing tabular data (see Shwartz-Ziv Armon (2021)). puzzle encouraged researchers construct novel NN structures better suited tabular databases. Examples include Arik Pfister (2020) Popov, Morozov, Babenko (2019). Surprisingly, reverse idea also exists: Nuti, Rugama, Thommen (2019) try adapt trees random forests behave like neural networks. interested reader can look original papers. subsection, detail architecture introduced Arik Pfister (2020), -called TabNets. Even quite young, neural networks tabular data already survey, Borisov et al. (2021).","code":""},{"path":"NN.html","id":"the-zoo-of-layers","chapter":"7 Neural networks","heading":"7.6.1 The zoo of layers","text":"Figure 7.3, layers type. take vector inputs return number linear combination inputs. ML jargon, type layer called “fully connected” (FC). Keras syntax, referred “layer_dense.”many layer types. recurrent layer described previous section 7.5 one example convolutional layers (see next section 7.7.3) another family layers. One simple yet useful layer batch normalization (BN). idea processing output previous layer, want normalize information coming new layer. applications, inputs outputs matrices BN amounts perform two operations columns matrices. first operation retrieve mean, column averages zero. second operation divide standard deviation, column variances equal one. One useful property inputs relatively similar statistical properties (though necessarily distributions).ML papers, models architectures thus represented series layers. short, Figure 7.3 written:\n\\[\\text{input} \\rightarrow FC \\rightarrow FC \\rightarrow \\text{output},\\]advantage compact, also omits important details, like numbers units per layer nature activation functions. Modern deep learning models complex succinct overviews like one easier read.\nAnother interesting layer type Gated Linear Unit (GLU). Given matrix input \\(\\textbf{X}\\), GLU yields\n\\[\\text{GLU}(\\textbf{X}) = (\\textbf{XW} + \\textbf{b}) \\cdot \\sigma(\\textbf{XW} + \\textbf{b}),\\]\n“\\(\\cdot\\)” Hadamard (element-wise) matrix product \\(\\sigma\\) sigmoid function (GLUs can generalized easily differentiable functions).","code":""},{"path":"NN.html","id":"sparsemax-activation","chapter":"7 Neural networks","heading":"7.6.2 Sparsemax activation","text":"proceed direct presentation TabNets, need present interesting concept introduced \nMartins Astudillo (2016): sparsemax transform. original idea sparsemax simplify softmax activation function multiclass outputs. final stage classification network (see Section 7.2.4), activation often taken \\(e^{x_i}/\\sum_{j=1}^Je^{x_j}\\), vector \\(\\textbf{x}\\) output final layer. property exponential function, means classes end strictly positive score probability. desirable often prefer decisions clear-cut, .e., improbable class gets zero probability.force weak values zeros, Martins Astudillo (2016) resort special projection call sparsemax. starting point \\(N-1\\)-dimensional simplex\\[ \\mathbb{S}_N=\\left\\{ \\mathbf{x} \\\\mathbb{R}^N \\left|\\sum_{n=1}^Nx_n=1, \\ x_n\\ge 0, \\ \\forall n=1,\\dots N.\\right.\\right\\} \\]\nspace encompasses possible combinations probabilities classification outcome \\(N\\) classes. Given vector \\(\\textbf{x}\\), sparsemax function defined \n\\[\\text{sparsemax}(\\textbf{x}) = \\underset{\\textbf{z} \\\\mathbb{S}_N}{\\text{argmin}} \\ ||\\textbf{z} - \\textbf{x}||,\\]\nequal projection \\(\\textbf{x}\\) onto \\(\\mathbb{S}_N\\). illustrate difference softmax sparsemax functions dimension 1 Figure 7.11. clear outcome much clearer sparsemax function: input small, output zero large, output one. generates discrepancies easier handle. large dimension, yields sparse outputs, desirable properties (smaller encoding sizes, simpler interpretation).\nFIGURE 7.11: Softmax versus sparsemax 1 dimension.\n","code":""},{"path":"NN.html","id":"feature-selection-1","chapter":"7 Neural networks","heading":"7.6.3 Feature selection","text":"One key element TabNets fact , speak “one-size fits ” (akin Auto-ML, aim providing packaged solution can tackle large spectrum problems.). batch normalization layers useful: can handle different type numerical inputs.first important component TabNets feature selection. rationale want learn intensely predictors matter lose time noisy variables. customary “vanilla” NNs, consider case rectangular (matrix-shaped) batch \\(\\textbf{f}\\) size \\(B \\times K\\). TabNets, selection features takes form mask, , another matrix dimension multiplies (.e., discounts) values. mask value element 1, feature remains, zero, disappears (metaphorically speaking), two, important simply attenuated.TabNets, learning sequential consists step. step indexed \\(\\). mask applied features step \\(\\) \\(\\textbf{M}[]\\), masked features \\(\\textbf{M}[] \\cdot \\textbf{f}\\), \\(\\cdot\\) denotes Hadamard product.[completed]","code":""},{"path":"NN.html","id":"the-full-architecture","chapter":"7 Neural networks","heading":"7.6.4 The full architecture","text":"[construction]","code":""},{"path":"NN.html","id":"code-and-results-3","chapter":"7 Neural networks","heading":"7.6.5 Code and results","text":"R, TabNets coded via torch framework. require packages torch & tabnet installed. start defining network structure, .e., setting hyperparameters. also resort package parsnip tidymodels suite, allows uniform grammar model declaration.Next, provide features label required learn. train smaller dataset simplicity. Note syntax simple models R (e.g., generalized linear models).Finally, make predictions compute hit ratio.","code":"\nif(!require(torch)){install.packages(c(\"torch\", \"tabnet\"))}\nlibrary(torch)          # General framework for NNs\nlibrary(tabnet)         # Package for tabular networks\nlibrary(recipes)        # Uniform ML models\nlibrary(parsnip)\nset.seed(42)            # Random seed\n\ntab_model <- tabnet(\n  mode = \"regression\",  # ML task\n  epochs = 5,           # Nb epochs / rounds\n  batch_size = 4000,    # Batch size\n  virtual_batch_size = 1024,\n  penalty = 1,\n  learn_rate = 0.01,\n  decision_width = 16,\n  attention_width = 8,\n  num_independent = 1,\n  num_shared = 1,\n  num_steps = 5,\n  momentum = 0.02\n) %>%\n  set_engine(\"torch\") \ndata_short <- data_ml %>%         # Shorter dataset\n  filter(stock_id %in% stock_ids_short,\n         date < \"2010-01-01\") %>%\n  dplyr::select(c(\"stock_id\", \"date\", features_short, \"R1M_Usd\"))\n\nfit_tabnet <- tab_model %>%\n  fit(R1M_Usd ~ Div_Yld + Eps + Mkt_Cap_12M_Usd + Mom_11M_Usd + Pb + Vol1Y_Usd, \n      data = data_short)   \ntab_pred <- predict(fit_tabnet,\n                    data_ml %>%                                                # A test set\n                      dplyr::filter(stock_id %in% stock_ids_short,\n                                    date > \"2010-01-01\") %>%\n                      dplyr::select(c(\"stock_id\", \"date\", features_short, \"R1M_Usd\"))) \nmean((data_ml %>%                                                # A test set\n  dplyr::filter(stock_id %in% stock_ids_short,\n                date > \"2010-01-01\") %>% \n  pull(R1M_Usd)) * tab_pred > 0)## [1] 0.5061184"},{"path":"NN.html","id":"other-common-architectures","chapter":"7 Neural networks","heading":"7.7 Other common architectures","text":"section, present network structures. less mainstream often harder implement, propose code examples stick theoretical introductions.","code":""},{"path":"NN.html","id":"generative-aversarial-networks","chapter":"7 Neural networks","heading":"7.7.1 Generative adversarial networks","text":"\nidea Generative Adversarial Networks (GANs) improve accuracy classical neural network trying fool . popular idea introduced Goodfellow et al. (2014). Imagine expert Picasso paintings boast able easily recognize piece work painter. One way refine skill test counterfeiter. true expert able discriminate true original Picasso one emanating forger. principle GANs.GANs consist two neural networks: first one tries learn second one tries fool first (induce error). Just like example , also two sets data: one (\\(\\textbf{x}\\)) true (correct), stemming classical training sample one (\\(\\textbf{z}\\)) fake generated counterfeiter network.GAN nomenclature, network learns \\(D\\) supposed discriminate, forger \\(G\\) generates false data. original formulation, GANs aimed classifying. ease presentation, keep scope. discriminant network simple (scalar) output: probability input comes true data (versus fake data). input \\(G\\) arbitrary noise output shape/form input \\(D\\).state theoretical formula GAN directly comment . \\(D\\) \\(G\\) play following minimax game:\n\\[\\begin{equation}\n\\tag{7.7}\n\\underset{G}{\\min} \\ \\underset{D}{\\max} \\ \\left\\{ \\mathbb{E}[\\log(D(\\textbf{x}))]+\\mathbb{E}[\\log(1-D(G(\\textbf{z})))] \\right\\}.\n\\end{equation}\\]First, let us decompose expression two parts (optimizers). first part (.e., first max) classical one: algorithm seeks maximize probability assigning correct label examples seeks classify. done economics finance, program maximize \\(D(\\textbf{x})\\) average, rather functional form (like utility function).left side, since expectation driven \\(\\textbf{x}\\), objective must increasing output. right side, expectation evaluated fake instances, right classification opposite, .e., \\(1-D(G(\\textbf{z}))\\).second, overarching, part seeks minimize performance algorithm simulated data: aims shrinking odds \\(D\\) finds data indeed corrupt. summarized version structure network provided Figure (7.8).\\[\\begin{equation}\n\\tag{7.8}\n\\left. \\begin{array}{rlll} \n\\text{training sample}  = \\textbf{x} = \\text{true data} && \\\\\n\\text{noise}= \\textbf{z} \\quad \\overset{G}{\\rightarrow} \\quad  \\text{fake data}  &\n\\end{array} \\right\\} \\overset{D}{\\rightarrow} \\text{output = probability label}\n\\end{equation}\\]ML-based asset pricing, notable application GANs introduced Luyang Chen, Pelger, Zhu (2020). aim make use method moment expression\n\\[\\mathbb{E}[M_{t+1}r_{t+1,n}g(I_t,I_{t,n})]=0,\\]\napplication Equation (3.7) instrumental variables \\(I_{t,n}\\) firm-dependent (e.g., characteristics attributes) \\(I_t\\) macro-economic variables (aggregate dividend yield, volatility level, credit spread, term spread, etc.). function \\(g\\) yields \\(d\\)-dimensional output, equation leads \\(d\\) moment conditions. trick model SDF unknown combination assets \\(M_{t+1}=1-\\sum_{n=1}^Nw(I_t,I_{t,n})r_{t+1,n}\\). primary discriminatory network (\\(D\\)) one approximates SDF via weights \\(w(I_t,I_{t,n})\\). secondary generative network one creates moment condition \\(g(I_t,I_{t,n})\\) equation.full specification network given program:\n\\[\\underset{w}{\\text{min}} \\ \\underset{g}{\\text{max}} \\ \\sum_{j=1}^N \\left\\| \\mathbb{E} \\left[\\left(1-\\sum_{n=1}^Nw(I_t,I_{t,n})r_{t+1,n} \\right)r_{t+1,j}g(I_t,I_{t,j})\\right] \\right\\|^2,\\]\\(L^2\\) norm applies \\(d\\) values generated via \\(g\\). asset pricing equations (moments) treated equalities relationship approximated. network defined \\(\\textbf{w}\\) asset pricing modeler tries determine best possible model, network defined \\(\\textbf{g}\\) seeks find worst possible conditions model performs badly. refer original article full specification networks. empirical section, Luyang Chen, Pelger, Zhu (2020) report adopting strong structure driven asset pricing imperatives add values compared pure predictive ‘vanilla’ approach one detailed Gu, Kelly, Xiu (2020b). --sample behavior decile sorted portfolios (based model’s prediction) display monotonic pattern respect order deciles.GANs can also used generate artificial financial data (see Efimov Xu (2019), Marti (2019), Wiese et al. (2020), Ni et al. (2020), , relatedly, Buehler et al. (2020)), topic outside scope book.","code":""},{"path":"NN.html","id":"autoencoders","chapter":"7 Neural networks","heading":"7.7.2 Autoencoders","text":"\nrecent literature, autoencoders (AEs) used Huck (2019) (portfolio management), Gu, Kelly, Xiu (2020a) (asset pricing).\nAEs strange family neural networks classified among non-supervised algorithms. supervised jargon, label equal input. Like GANS, autoencoders consist two networks, though structure different: first network encodes input intermediary output (usually called code), second network decodes code modified version input.\\[\\begin{array}{ccccccccc}\n\\textbf{x} & &\\overset{E}{\\longrightarrow} && \\textbf{z} && \\overset{D}{\\longrightarrow} && \\textbf{x}' \\\\\n\\text{input} && \\text{encoder} && \\text{code} && \\text{decoder} && \\text{modified input}\n\\end{array}\\]autoencoders belong large family supervised algorithms, postpone presentation Section 15.2.3.article Gu, Kelly, Xiu (2020a) resorts idea AEs time augmenting complexity asset pricing model. simple specification \\(r_t=\\boldsymbol{\\beta}_{t-1}\\textbf{f}_t+e_t\\) (omit asset dependence notational simplicity), add assumptions betas depend firm characteristics, factors possibly nonlinear functions returns . model takes following form:\n\\[\\begin{equation}\n\\tag{7.9}\nr_{t,}=\\textbf{NN}_{\\textbf{beta}}(\\textbf{x}_{t-1,})+\\textbf{NN}_{\\textbf{factor}}(\\textbf{r}_t)+e_{t,},\n\\end{equation}\\]\n\\(\\textbf{NN}_{\\textbf{beta}}\\) \\(\\textbf{NN}_{\\textbf{factor}}\\) two neural networks. equation looks like autoencoder returns inputs outputs. However, additional complexity comes second neural network \\(\\textbf{NN}_{\\textbf{beta}}\\). Modern neural network libraries Keras allow customized models like one . coding structure left exercise (see ).","code":""},{"path":"NN.html","id":"CNN","chapter":"7 Neural networks","heading":"7.7.3 A word on convolutional networks","text":"Neural networks gained popularity 2010 decade thanks series successes computer vision competitions. algorithms behind advances convolutional neural networks (CNNs). may seem surprising choice financial predictions, several teams researchers Computer Science field proposed approaches rely variation neural networks (J.-F. Chen et al. (2016), Loreggia et al. (2016), Dingli Fournier (2017), Tsantekidis et al. (2017), Hoseinzade Haratizadeh (2019)). Recently, J. Jiang, Kelly, Xiu (2020) propose extract signals images price trends.\nHence, briefly present principle final section neural networks. lay presentation CNNs dimension two, can also used dimension one three.reason CNNs useful allow progressively reduce dimension large dataset keeping local information. image rectangle pixels. pixel usually coded via three layers, one color: red, blue green. keep things simple, let’s just consider one layer , say 1,000 1,000 pixels, one value pixel. order analyze content image, convolutional layer reduce dimension inputs resorting convolution. Visually, simplification performed scanning altering values using rectangles arbitrary weights.Figure 7.12 sketches process (strongly inspired Hoseinzade Haratizadeh (2019)). original data matrix \\((\\times K)\\) \\(x_{,k}\\) weights also matrix \\(w_{j,l}\\) size \\((J\\times L)\\) \\(J<\\) \\(L<K\\). scanning transforms rectangle size \\((J\\times L)\\) one real number. Hence, output smaller size: \\((-J+1)\\times(K-L+1)\\). \\(=K=1,000\\) \\(J=L=201\\), output dimension \\((800\\times 800)\\) already much smaller. output values given \n\\[o_{,k}=\\sum_{j=1}^J\\sum_{l=1}^Lw_{j,l}x_{+j-1,k+l-1}.\\]\nFIGURE 7.12: Scheme convolutional unit. Note: dimensions general correspond number squares.\nIteratively reducing dimension output via sequences convolutional layers like one presented costly computation give rise overfitting number weights incredibly large. order efficiently reduce size outputs, pooling layers often used. job pooling units simplify matrices reducing simple metric minimum, maximum average value matrix:\\[o_{,k}=f(x_{+j-1,k+l-1}, 1\\le j\\le J, 1 \\le l\\le L),\\]\\(f\\) minimum, maximum average value. show examples pooling Figure 7.13 . order increase speed compression, possible add stride omit cells. stride value \\(v\\) perform operation every \\(v\\) value hence bypass intermediate steps. Figure 7.13, two cases left resort pooling, hence reduction dimension exactly equal size pooling size. stride action (right pane), reduction marked. 1,000 1,000 input, 2--2 pooling layer stride 2 yield 500--500 output: dimension shrinked fourfold, right scheme Figure 7.13.\nFIGURE 7.13: Scheme pooling units.\ntools hand, possible build new predictive tools. Hoseinzade Haratizadeh (2019), predictors price quotes, technical indicators macro-economic data fed complex neural network 6 layers order predict sign price variations. clearly interesting computer science exercise, deep economic motivation behind choice architecture remains unclear. Sangadiev et al. (2020) use CNN build portfolios relying limit order book data.","code":""},{"path":"NN.html","id":"coding-exercises-3","chapter":"7 Neural networks","heading":"7.8 Coding exercises","text":"purpose exercise code autoencoder model described Gu, Kelly, Xiu (2020a) (see Section 7.7.2). coding NNs, dimensions must rigorously reported. reproduce diagram model Figure 7.14 clearly shows inputs outputs along dimensions.\nFIGURE 7.14: Scheme autoencoder pricing model.\norder harness full potential Keras, imperative switch general formulations NNs. can done via -called functional API: https://keras.rstudio.com/articles/functional_api.html.purpose exercise demonstrate universal approximation simple NNs. Let’s take simple function, say sin(x) interval [0,6]. Use simple feed-forward neural network one layer 16 units mimic function. try 128 units see improves fit.\nFIGURE 7.15: Goal: approximate simple function.\n","code":""},{"path":"svm.html","id":"svm","chapter":"8 Support vector machines","heading":"8 Support vector machines","text":"\norigins support vector machines (SVMs) old (go back Vapnik Lerner (1963)), modern treatment initiated Boser, Guyon, Vapnik (1992) Cortes Vapnik (1995) (binary classification) Drucker et al. (1997) (regression). refer http://www.kernel-machines.org/books exhaustive bibliography theoretical empirical properties. SVMs popular since creation among machine learning community. Nonetheless, tools (neural networks especially) gained popularity progressively replaced SVMs many applications like computer vision notably.","code":""},{"path":"svm.html","id":"svm-for-classification","chapter":"8 Support vector machines","heading":"8.1 SVM for classification","text":"\noften case machine learning, easier explain complex tool illustration binary classification. fact, sometimes, originally tool designed (e.g., perceptron). Let us consider simple example plane, , two features. Figure 8.1, goal find model correctly classifies points: filled circles versus empty squares.\nFIGURE 8.1: Diagram binary classification support vectors.\nmodel consists two weights \\(\\textbf{w}=(w_1,w_2)\\) load variables create natural linear separation plane. example , show three separations. red one good classifier circles squares beneath . blue line good classifier: circles left squares right. Likewise, green line achieves perfect classification score. Yet, notable difference two.grey star top graph mystery point given location, data pattern holds, circle. blue model fails recognize green one succeeds. interesting features scheme mentioned yet, , grey dotted lines. lines represent -man’s land observation falls green model enforced. area, strip green line can viewed margin error model. Typically, grey star located inside margin.two margins computed parallel lines maximize distance model closest points correctly classified (sides). points called support vectors, justifies name technique. Obviously, green model greater margin blue one. core idea SVMs maximize margin, constraint classifier make mistake. Said differently, SVMs try pick robust model among yield correct classification.formally, numerically define circles +1 squares -1, ‘good’ linear model expected satisfy:\n\\[\\begin{equation}\n\\tag{8.1}\n\\left\\{\\begin{array}{lll}\n\\sum_{k=1}^Kw_kx_{,k}+b \\ge +1 & \\text{ } y_i=+1 \\\\\n\\sum_{k=1}^Kw_kx_{,k}+b \\le -1 & \\text{ } y_i=-1,\n\\end{array}\\right.\n\\end{equation}\\]can summarized compact form \\(y_i \\times \\left(\\sum_{k=1}^K w_kx_{,k}+b \\right)\\ge 1\\). Now, margin green model support vector dashed grey line equal \\(||\\textbf{w}||^{-1}=\\left(\\sum_{k=1}^Kw_k^2\\right)^{-1/2}\\). value comes fact distance point \\((x_0,y_0)\\) line parametrized \\(ax++c=0\\) equal \\(d=\\frac{|ax_0+by_0+c|}{\\sqrt{^2+b^2}}\\). case model defined (8.1), numerator equal 1 norm \\(\\textbf{w}\\). Thus, final problem following:\\[\\begin{equation}\n\\tag{8.2}\n\\underset{\\textbf{w}, b}{\\text{argmin}} \\ \\frac{1}{2} ||\\textbf{w}||^2 \\ \\text{ s.t. } y_i\\left(\\sum_{k=1}^Kw_kx_{,k}+b \\right)\\ge 1.\n\\end{equation}\\]dual form program (see chapter 5 Boyd Vandenberghe (2004)) \\[\\begin{equation}\n\\tag{8.3}\nL(\\textbf{w},b,\\boldsymbol{\\lambda})=\n \\frac{1}{2}||\\textbf{w}||^2 + \\sum_{=1}^\\lambda_i\\left(y_i\\left(\\sum_{k=1}^Kw_kx_{,k}+b \\right)- 1\\right),\n\\end{equation}\\]\neither \\(\\lambda_i=0\\) \\(y_i\\left(\\sum_{k=1}^Kw_kx_{,k}+b \\right)= 1\\). Thus, points matter solution (-called support vectors). first order conditions impose derivatives Lagrangian null:\n\\[\\frac{\\partial L}{\\partial \\textbf{w}}L(\\textbf{w},b,\\boldsymbol{\\lambda})=\\textbf{0}, \\quad \\frac{\\partial L}{\\partial b}L(\\textbf{w},b,\\boldsymbol{\\lambda})=0,\\]\nfirst condition leads \n\\[\\textbf{w}^*=\\sum_{=1}^\\lambda_iu_i\\textbf{x}_i.\\]\nsolution indeed linear form features, points taken account. inequalities (8.1) equalities.Naturally, problem becomes infeasible whenever condition satisfied, , simple line perfectly separate labels, matter choice coefficients. common configuration datasets called logically linearly separable. complicates process possible resort trick. idea introduce flexbility (8.1) adding correction variables allow conditions met:\\[\\begin{equation}\n\\tag{8.4}\n\\left\\{\\begin{array}{lll}\n\\sum_{k=1}^Kw_kx_{,k}+b \\ge +1-\\xi_i & \\text{ } y_i=+1 \\\\\n\\sum_{k=1}^Kw_kx_{,k}+b \\le -1+\\xi_i & \\text{ } y_i=-1,\n\\end{array}\\right.\n\\end{equation}\\]novelties, \\(\\xi_i\\) positive -called ‘slack’ variables make conditions feasible. illustrated Figure 8.2. new configuration, simple linear model can perfectly discriminate two classes.\nFIGURE 8.2: Diagram binary classification SVM - linearly inseparable data.\noptimization program becomes\n\\[\\begin{equation}\n\\tag{8.5}\n\\underset{\\textbf{w},b, \\boldsymbol{\\xi}}{\\text{argmin}} \\ \\frac{1}{2} ||\\textbf{w}||^2+C\\sum_{=1}^\\xi_i \\ \\text{ s.t. } \\left\\{ y_i\\left(\\sum_{k=1}^Kw_k\\phi(x_{,k})+b \\right)\\ge 1-\\xi_i \\ \\text{ } \\ \\xi_i\\ge 0, \\ \\forall  \\right\\},\n\\end{equation}\\]\nparameter \\(C>0\\) tunes cost mis-classification: \\(C\\) increases, errors become penalizing.addition, program can generalized nonlinear models, via kernel \\(\\phi\\) applied input points \\(x_{,k}\\). Nonlinear kernels can help cope patterns complex straight lines (see Figure 8.3). Common kernels can polynomial, radial sigmoid. solution found using less standard techniques constrained quadratic programs. weights \\(\\textbf{w}\\) bias \\(b\\) set via training, prediction new vector \\(\\textbf{x}_j\\) simply made computing \\(\\sum_{k=1}^Kw_k\\phi(x_{j,k})+b\\) choosing class based sign expression.\nFIGURE 8.3: Examples nonlinear kernels.\n","code":""},{"path":"svm.html","id":"svm-for-regression","chapter":"8 Support vector machines","heading":"8.2 SVM for regression","text":"ideas classification SVM can transposed regression exercises role margin different. One general formulation following\\[\\begin{align}\n\\underset{\\textbf{w},b, \\boldsymbol{\\xi}}{\\text{argmin}} \\  & \\frac{1}{2} ||\\textbf{w}||^2+C\\sum_{=1}^\\left(\\xi_i+\\xi_i^* \\right)\\\\\n \\text{ s.t. }&  \\sum_{k=1}^Kw_k\\phi(x_{,k})+b -y_i\\le \\epsilon+\\xi_i \\\\ \\tag{8.6}\n&  y_i-\\sum_{k=1}^Kw_k\\phi(x_{,k})-b \\le \\epsilon+\\xi_i^* \\\\\n&\\xi_i,\\xi_i^*\\ge 0, \\ \\forall  ,\n\\end{align}\\]illustrated Figure 8.4. user specifies margin \\(\\epsilon\\) model try find linear (kernel transformation) relationship labels \\(y_i\\) input \\(\\textbf{x}_i\\). Just classification task, data points inside strip, slack variables \\(\\xi_i\\) \\(\\xi_i^*\\) set zero. points violate threshold, objective function (first line code) penalized. Note setting large \\(\\epsilon\\) leaves room error. model trained, prediction \\(\\textbf{x}_j\\) simply \\(\\sum_{k=1}^Kw_k\\phi(x_{j,k})+b\\).\nFIGURE 8.4: Diagram regression SVM.\nLet us take step back simplify algorithm , : minimize sum squared weights \\(||\\textbf{w}||^2\\) subject error small enough (modulo slack variable). spirit, somewhat opposite penalized linear regressions seek minimize error, subject weights small enough.models laid section preview universe SVM engines several formulations developed. One reference library coded C C++ LIBSVM widely used many programming languages. interested reader can look corresponding article Chang Lin (2011) details SVM zoo (recent November 2019 version also available online).","code":""},{"path":"svm.html","id":"practice","chapter":"8 Support vector machines","heading":"8.3 Practice","text":"R LIBSVM library exploited several packages. One , e1071, good choice also nests many interesting functions, especially naive Bayes classifier see later .implementation LIBSVM, package requires specify label features separately. reason, recycle variables used boosted trees. Moreover, training slow, perform subsample sets (first thousand instances).results slightly better boosted trees. parameters completely arbitrary, especially choice kernel. finally turn classification example.small training sample arbitrariness choice parameters may\nexplain predictive accuracy poor.","code":"\nlibrary(e1071)\nfit_svm <- svm(y = train_label_xgb[1:1000],      # Train label\n               x = train_features_xgb[1:1000,],  # Training features\n               type = \"eps-regression\",          # SVM task type (see LIBSVM documentation)\n               kernel = \"radial\",                # SVM kernel (or: linear, polynomial, sigmoid)\n               epsilon = 0.1,                    # Width of strip for errors\n               gamma = 0.5,                      # Constant in the radial kernel \n               cost = 0.1)                       # Slack variable penalisation\ntest_feat_short <- dplyr::select(testing_sample,features_short)\nmean((predict(fit_svm, test_feat_short) - testing_sample$R1M_Usd)^2) # MSE## [1] 0.03839085\nmean(predict(fit_svm, test_feat_short) * testing_sample$R1M_Usd > 0) # Hit ratio## [1] 0.5222197\nfit_svm_C <- svm(y = training_sample$R1M_Usd_C[1:1000],   # Train label\n               x = training_sample[1:1000,] %>%\n                   dplyr::select(features),               # Training features\n               type = \"C-classification\",                 # SVM task type (see LIBSVM doc.)\n               kernel = \"sigmoid\",                        # SVM kernel\n               gamma = 0.5,                               # Parameter in the sigmoid kernel \n               coef0 = 0.3,                               # Parameter in the sigmoid kernel \n               cost = 0.2)                                # Slack variable penalisation\nmean(predict(fit_svm_C, \n             dplyr::select(testing_sample,features)) == testing_sample$R1M_Usd_C) # Accuracy## [1] 0.5008973"},{"path":"svm.html","id":"coding-exercises-4","chapter":"8 Support vector machines","heading":"8.4 Coding exercises","text":"simple example shown , extend SVM models kernels discuss impact fit.Train vanilla SVM model labels 12-month forward (.e., future) return evaluate testing sample. simple random forest. Compare.","code":""},{"path":"bayes.html","id":"bayes","chapter":"9 Bayesian methods","heading":"9 Bayesian methods","text":"section dedicated subset machine learning makes prior assumptions parameters. explain Bayes’ theorem can applied simple building blocks machine learning, introduce notations concepts subsection . Good references Bayesian analysis Gelman et al. (2013) Kruschke (2014). latter, like present book, illustrates concepts many lines R code. Bayesian inference used Feng (2021) estimate conditional expected returns residual covariance matrices view portfolio choice.","code":""},{"path":"bayes.html","id":"the-bayesian-framework","chapter":"9 Bayesian methods","heading":"9.1 The Bayesian framework","text":"now, models presented rely data . approach often referred ‘frequentist.’ Given one dataset, frequentist extract (.e., estimate) unique set optimal parameters consider best model. Bayesians, hand, consider datasets snapshots reality , , parameters thus random! Instead estimating one value parameters (e.g., coefficient linear model), ambitious try determine whole distribution parameter.order outline can achieved, introduce basic notations results. foundational concept Bayesian analysis conditional probability. Given two random sets (events) \\(\\) \\(B\\), define probability \\(\\) knowing \\(B\\) (equivalently, odds \\(\\), conditionally \\(B\\)) \n\\[P[|B]=\\frac{P[\\cap B]}{P[B]},\\]\n, probability intersection two sets divided probability \\(B\\). Likewise, probability events occur equal \\(P[\\cap B] = P[]P[B|]\\). Given \\(n\\) disjoint events \\(A_i\\), \\(=1,...n\\) \\(\\sum_{=1}^nP(A_i)=1\\), event \\(B\\), law total probabilities (implies)\n\\[P(B)=\\sum_{=1}^nP(B \\cap A_i)= \\sum_{=1}^nP(B|A_i)P(A_i).\\]Given expression, can formulate general version Bayes’ theorem:\n\\[\\begin{equation}\n\\tag{9.1}\nP(A_i|B)=\\frac{P(A_i)P(B|A_i)}{P(B)}= \\frac{P(A_i)P(B|A_i)}{\\sum_{=1}^nP(B|A_i)P(A_i)}.\n\\end{equation}\\]Endowed result, can move forward core topic section, estimation parameter \\(\\boldsymbol{\\theta}\\) (possibly vector) given dataset, denote \\(\\textbf{y}\\) thereby following conventions Gelman et al. (2013). notation suboptimal book nonetheless chapters, \\(\\textbf{y}\\) stands label dataset.Bayesian analysis, one sophistication (compared frequentist approach) comes fact data almighty. distribution parameter \\(\\boldsymbol{\\theta}\\) mix prior distribution set statistician (user, analyst) empirical distribution data. precisely, simple application Bayes’ formula yields\n\\[\\begin{equation}\n\\tag{9.2}\np(\\boldsymbol{\\theta}| \\textbf{y})=\\frac{p(\\boldsymbol{\\theta})p(\\textbf{y} |\\boldsymbol{\\theta})}{p(\\textbf{y})} \\propto p(\\boldsymbol{\\theta})p(\\textbf{y} |\\boldsymbol{\\theta}).\n\\end{equation}\\]interpretation immediate: distribution \\(\\boldsymbol{\\theta}\\) knowing data \\(\\textbf{y}\\) proportional distribution \\(\\boldsymbol{\\theta}\\) times distribution \\(\\textbf{y}\\) knowing \\(\\boldsymbol{\\theta}\\). term \\(p(\\textbf{y})\\) often omitted simply scaling number ensures density sums integrates one.use slightly different notation Equation (9.1) Equation (9.2). former, \\(P\\) denotes true probability, .e., number. latter, \\(p\\) stands whole probability density function \\(\\boldsymbol{\\theta}\\) \\(\\textbf{y}\\).whole purpose Bayesian analysis compute -called posterior distribution \\(p(\\boldsymbol{\\theta}| \\textbf{y})\\) via prior distribution \\(p(\\boldsymbol{\\theta})\\) likelihood function \\(p(\\textbf{y} |\\boldsymbol{\\theta})\\). Priors sometimes qualified informative, weakly informative uninformative, depending degree user confident relevance robustness prior. simplest way define non-informative prior set constant (uniform) distribution realistic interval(s).challenging part usually likelihood function. easiest way solve problem resort specific distribution (possibly parametric family) distribution data consider obsevations ..d., just simple maximum likelihood inference. assume new parameters distributions gathered \\(\\boldsymbol{\\lambda}\\), likelihood can written \n\\[\\begin{equation}\n\\tag{9.3}\np(\\textbf{y} |\\boldsymbol{\\theta}, \\boldsymbol{\\lambda})=\\prod_{=1}^f_{\\boldsymbol{\\lambda}}(y_i; \\boldsymbol{\\beta}), \n\\end{equation}\\]\ncase problem becomes slightly complex adding new parameters changes posterior distribution \\(p(\\boldsymbol{\\theta}, \\boldsymbol{\\lambda}|\\textbf{y})\\). user must find joint distribution \\(\\boldsymbol{\\theta}\\) \\(\\boldsymbol{\\lambda}\\) - given \\(\\textbf{y}\\). nested structure, models often called hierarchical models.Bayesian methods widely used portfolio choice. rationale distribution asset returns depends parameter main issue determine posterior distribution. briefly review vast literature . Bayesian asset allocation investigated Lai et al. (2011) (via stochastic optimization), Guidolin Liu (2016) Dangl Weissensteiner (2020). Shrinkage techniques (means covariance matrices) tested Frost Savarino (1986), Kan Zhou (2007) DeMiguel, Martı́n-Utrera, Nogales (2015). similar vein, Tu Zhou (2010) build priors coherent asset pricing theories. Finally, Bauder et al. (2020) sample portfolio returns allows dervive Bayesian optimal frontier. invite interested reader also dwelve references cited within articles.","code":""},{"path":"bayes.html","id":"bayesian-sampling","chapter":"9 Bayesian methods","heading":"9.2 Bayesian sampling","text":"","code":""},{"path":"bayes.html","id":"gibbs-sampling","chapter":"9 Bayesian methods","heading":"9.2.1 Gibbs sampling","text":"\nOne adjacent field applications Bayes’ theorem simulation. Suppose want simulate multivariate distribution random vector \\(\\textbf{X}\\) given density \\(p=p(x_1,\\dots,x_J)\\). Often, full distribution complex, marginals accessible. Indeed, simpler depend one variable (values known):\n\\[p(X_j=x_j|X_1= x_1,\\dots,X_{j-1}=x_{j-1},X_{j+1}=x_{j+1},\\dots,X_J=x_J)=p(X_j=x_j|\\textbf{X}_{-j}=\\textbf{x}_{-j}),\\]\nuse compact notation \\(\\textbf{X}_{-j}\\) variables except \\(X_j\\). One way generate samples law \\(p\\) following relies knowledge conditionals \\(p(x_j|\\textbf{x}_{-j})\\) notion Markov Chain Monte Carlo, outline . process iterative assumes possible draw samples aforementioned conditionals. write \\(x_j^{m}\\) \\(m^{th}\\) sample \\(j^{th}\\) variable (\\(X_j\\)). simulation starts prior (fixed, random) sample \\(\\textbf{x}^0=(x^0_1,\\dots,x^0_J)\\). , sufficiently large number times, say \\(T\\), new samples drawn according \n\\[\\begin{align*}\nx_1^{m+1} &= p(X_1|X_2=x_2^{m}, \\dots ,X_J=x_J^m) ;\\\\\nx_2^{m+1} &=p(X_2|X_1=x_1^{m+1}, X_3=x^{m}_3, \\dots, X_J=x_J^m); \\\\\n\\dots& \\\\\nx_J^{m+1}&= p(X_J|X_1=x_1^{m+1}, X_2=x_2^{m+1}, \\dots, X_{J-1}=x_{J-1}^{m+1}).\n\\end{align*}\\]important detail line, value variable updated. Hence, second line, \\(X_2\\) sampled knowledge \\(X_1=x_1^{m+1}\\) last line, variables except \\(X_J\\) updated \\((m+1)^{th}\\) state. algorithm called Gibbs sampling. relates Markov chains new iteration depends previous one.technical assumptions, \\(T\\) increases, distribution \\(\\textbf{x}_T\\) converges \\(p\\). conditions convergence occurs widely discussed series articles 1990s. interested reader can look instance Tierney (1994), Roberts Smith (1994), well section 11.7 Gelman et al. (2013).Sometimes, full distribution complex conditional laws hard determine sample. , general method, called Metropolis-Hastings, can used relies rejection method simulation random variables.","code":""},{"path":"bayes.html","id":"metropolis-hastings-sampling","chapter":"9 Bayesian methods","heading":"9.2.2 Metropolis-Hastings sampling","text":"\nGibbs algorithm can considered particular case Metropolis-Hastings (MH) method, , simplest version, introduced Metropolis Ulam (1949). premise similar: aim simulate random variables follow \\(p(\\textbf{x})\\) ability sample simpler form \\(p(\\textbf{x}|\\textbf{y})\\) gives probability future state \\(\\textbf{x}\\), given past one \\(\\textbf{y}\\).initial value \\(\\textbf{x}\\) sampled (\\(\\textbf{x}_0\\)), new iteration (\\(m\\)) simulation takes place three stages:generate candidate value \\(\\textbf{x}'_{m+1}\\) \\(p(\\textbf{x}|\\textbf{x}_m)\\),compute acceptance ratio \\(\\alpha=\\min\\left(\\frac{p(\\textbf{x}'_{m+1})p(\\textbf{x}_{m}|\\textbf{x}'_{m+1})}{p(\\textbf{x}_{m})p(\\textbf{x}'_{m+1}|\\textbf{x}_{m})} \\right)\\)pick \\(\\textbf{x}_{m+1}=\\textbf{x}'_{m+1}\\) probability \\(\\alpha\\) stick previous value (\\(\\textbf{x}_{m+1}=\\textbf{x}_{m}\\)) probability \\(1-\\alpha\\).interpretation acceptance ratio straightforward general case. sampling generator symmetric (\\(p(\\textbf{x}|\\textbf{y})=p(\\textbf{y}|\\textbf{x})\\)), candidate always chosen whenever \\(p(\\textbf{x}'_{m+1})\\ge p(\\textbf{x}_{m})\\). reverse condition holds (\\(p(\\textbf{x}'_{m+1})< p(\\textbf{x}_{m})\\)), candidate retained odds equal \\(p(\\textbf{x}'_{m+1})/p(\\textbf{x}_{m})\\), ratio likelihoods. likely new proposal, higher odds retaining .Often, first simulations discarded order leave time chain converge high probability region. procedure (often called ‘burn ’) ensures first retained samples located zone likely, .e., representative law trying simulate.sake brevity, stick succinct presentation , additional details outlined section 11.2 Gelman et al. (2013) chapter 7 Kruschke (2014).","code":""},{"path":"bayes.html","id":"bayesian-linear-regression","chapter":"9 Bayesian methods","heading":"9.3 Bayesian linear regression","text":"\nBayesian concepts rather abstract, useful illustrate theoretical notions simple example. linear model, \\(y_i=\\textbf{x}_i\\textbf{b}+\\epsilon_i\\) often statistically assumed \\(\\epsilon_i\\) ..d. normally distributed zero mean variance \\(\\sigma^2\\). Hence, likelihood Equation (9.3) translates \n\\[p(\\boldsymbol{\\epsilon}|\\textbf{b}, \\sigma)=\\prod_{=1}^\\frac{e^{-\\frac{\\epsilon_i^2}{2\\sigma}}}{\\sigma\\sqrt{2\\pi}}=(\\sigma\\sqrt{2\\pi})^{-}e^{-\\sum_{=1}^\\frac{\\epsilon_i^2}{2\\sigma^2}}.\\]regression analysis, data given \\(\\textbf{y}\\) \\(\\textbf{X}\\), hence reported notations. Simply acknowledging \\(\\boldsymbol{\\epsilon}=\\textbf{y}-\\textbf{Xb}\\), get\n\\[\\begin{align}\np(\\textbf{y},\\textbf{X}|\\textbf{b}, \\sigma)&=\\prod_{=1}^\\frac{e^{-\\frac{\\epsilon_i^2}{2\\sigma}}}{\\sigma\\sqrt{2\\pi}}\\\\\n&=(\\sigma\\sqrt{2\\pi})^{-}e^{-\\sum_{=1}^\\frac{\\left(y_i-\\textbf{x}_i'\\textbf{b}\\right)^2}{2\\sigma^2}}=(\\sigma\\sqrt{2\\pi})^{-} e^{-\\frac{\\left(\\textbf{y}-\\textbf{X}\\textbf{b}\\right)' \\left(\\textbf{y}-\\textbf{X}\\textbf{b}\\right)}{2\\sigma^2}} \\nonumber \\\\ \\tag{9.4}\n&=\\underbrace{(\\sigma\\sqrt{2\\pi})^{-} e^{-\\frac{\\left(\\textbf{y}-\\textbf{X}\\hat{\\textbf{b}}\\right)' \\left(\\textbf{y}-\\textbf{X}\\hat{\\textbf{b}}\\right)}{2\\sigma^2}}}_{\\text{depends } \\sigma, \\text{ } \\textbf{b}}\\times \\underbrace{e^{-\\frac{(\\textbf{b}-\\hat{\\textbf{b}})'\\textbf{X}'\\textbf{X}(\\textbf{b}-\\hat{\\textbf{b}})}{2\\sigma^2}}}_{\\text{ depends } \\sigma, \\text{ } \\textbf{b} }.\n\\end{align}\\]\nlast line, second term function difference \\(\\textbf{b}-\\hat{\\textbf{b}}\\), \\(\\hat{\\textbf{b}}=(\\textbf{X}'\\textbf{X})^{-1}\\textbf{X}'\\textbf{y}\\). surprising: \\(\\hat{\\textbf{b}}\\) natural benchmark mean \\(\\textbf{b}\\). Moreover, introducing \\(\\hat{\\textbf{b}}\\) yields relatively simple form probability.expression frequentist (data-based) block posterior: likelihood. want obtain tractable expression posterior, need find prior component form combine well likelihood. forms called conjugate priors. natural candidate right part (depends b \\(\\sigma\\)) multivariate Gaussian density:\n\\[\\begin{equation}\n\\tag{9.5}\np[\\textbf{b}|\\sigma]=\\sigma^{-k}e^{-\\frac{(\\textbf{b}-\\textbf{b}_0)'\\boldsymbol{\\Lambda}_0(\\textbf{b}-\\textbf{b}_0)}{2\\sigma^2}},\n\\end{equation}\\]\nobliged condition respect \\(\\sigma\\). density prior mean \\(\\textbf{b}_0\\) prior covariance matrix \\(\\boldsymbol{\\Lambda}_0^{-1}\\). prior gets us one step closer posterior \n\\[\\begin{align}\np[\\textbf{b},\\sigma|\\textbf{y},\\textbf{X}]& \\propto p[\\textbf{y},\\textbf{X}|\\textbf{b},\\sigma]p[\\textbf{b},\\sigma] \\nonumber \\\\\n\\tag{9.6}\n&\\propto p[\\textbf{y},\\textbf{X}|\\textbf{b},\\sigma]p[\\textbf{b}|\\sigma]p[\\sigma]. \n\\end{align}\\]order fully specify cascade probabilities, need take care \\(\\sigma\\) set density form\n\\[\\begin{equation}\n\\tag{9.7}\np[\\sigma^2]\\propto (\\sigma^2)^{-1-a_0}e^{-\\frac{b_0}{2\\sigma^2}},\n\\end{equation}\\]\nclose left part (9.4). corresponds inverse gamma distribution variance prior parameters \\(a_0\\) \\(b_0\\) (scalar notation optimal can confused prior mean \\(\\textbf{b}_0\\) must pay extra attention).Now, can simplify \\(p[\\textbf{b},\\sigma|\\textbf{y},\\textbf{X}]\\) (9.4), (9.5) (9.7):\n\\[\\begin{align*}\np[\\textbf{b},\\sigma|\\textbf{y},\\textbf{X}]& \\propto \n(\\sigma\\sqrt{2\\pi})^{-} \\sigma^{-2(1+a_0)} e^{-\\frac{\\left(\\textbf{y}-\\textbf{X}\\hat{\\textbf{b}}\\right)' \\left(\\textbf{y}-\\textbf{X}\\hat{\\textbf{b}}\\right)}{2\\sigma^2}} \\\\\n&\\quad \\times e^{-\\frac{(\\textbf{b}-\\hat{\\textbf{b}})'\\textbf{X}'\\textbf{X}(\\textbf{b}-\\hat{\\textbf{b}})}{2\\sigma^2}}\\sigma^{-k}e^{-\\frac{(\\textbf{b}-\\textbf{b}_0)'\\boldsymbol{\\Lambda}_0(\\textbf{b}-\\textbf{b}_0)}{2\\sigma^2}}e^{-\\frac{b_0}{2\\sigma^2}} \\\\\n\\end{align*}\\]\ncan rewritten\n\\[\\begin{align*}\np[\\textbf{b},\\sigma|\\textbf{y},\\textbf{X}]& \\propto  \\sigma^{--k-2(1+a_0)} \\\\\n&\\times  \\exp\\left(-\\frac{\\left(\\textbf{y}-\\textbf{X}\\hat{\\textbf{b}}\\right)' \\left(\\textbf{y}-\\textbf{X}\\hat{\\textbf{b}}\\right) + (\\textbf{b}-\\hat{\\textbf{b}})'\\textbf{X}'\\textbf{X}(\\textbf{b}-\\hat{\\textbf{b}}) + (\\textbf{b}-\\textbf{b}_0)'\\boldsymbol{\\Lambda}_0(\\textbf{b}-\\textbf{b}_0)+b_0}{2\\sigma^2} \\right) .\n\\end{align*}\\]expression simply quadratic form \\(\\textbf{b}\\) can rewritten burdensome algebra much compact manner:\n\\[\\begin{equation}\n\\label{eq:linpost}\np(\\textbf{b}|\\textbf{y},\\textbf{X},\\sigma) \\propto \\left[\\sigma^{-k}e^{-\\frac{(\\textbf{b}-\\textbf{b}_*)'\\boldsymbol{\\Lambda}_*(\\textbf{b}-\\textbf{b}_*)}{2\\sigma^2}}\\right] \\times \\left[ (\\sigma^2)^{-1-a_*}e^{-\\frac{b_*}{2\\sigma^2}}  \\right],\n\\end{equation}\\]\n\\[\\begin{align*}\n\\boldsymbol{\\Lambda}_* &= \\textbf{X}'\\textbf{X}+\\boldsymbol{\\Lambda}_0  \\\\\n\\textbf{b}_*&=  \\boldsymbol{\\Lambda}_*^{-1}(\\boldsymbol{\\Lambda}_0\\textbf{b}_0+\\textbf{X}'\\textbf{X}\\hat{\\textbf{b}}) \\\\\na_* & = a_0 + /2  \\\\\nb_* &=b_0+\\frac{1}{2}\\left(\\textbf{y}'\\textbf{y}+ \\textbf{b}_0'\\boldsymbol{\\Lambda}_0\\textbf{b}_0+\\textbf{b}_*'\\boldsymbol{\\Lambda}_*\\textbf{b}_* \\right).\\\\\n\\end{align*}\\]expression two parts: Gaussian component relates mostly \\(\\textbf{b}\\), inverse gamma component, entirely dedicated \\(\\sigma\\). mix prior data clear. posterior covariance matrix Gaussian part (\\(\\boldsymbol{\\Lambda}_*\\)) sum prior quadratic form data. posterior mean \\(\\textbf{b}_*\\) weighted average prior \\(\\textbf{b}_0\\) sample estimator \\(\\hat{\\textbf{b}}\\). blends quantities estimated data user-supplied version often called shrinkages. instance, original matrix cross-terms \\(\\textbf{X}'\\textbf{X}\\) shrunk towards prior \\(\\boldsymbol{\\Lambda}_0\\). can viewed regularization procedure: pure fit originating data mixed ‘external’ ingredient give structure final estimation.interested reader can also look section 16.3 Greene (2018) (case conjugate priors treated subsection 16.3.2).formulae can long risky implement. Luckily, R package (\\(spBayes\\)) performs Bayesian inference linear regression using conjugate priors. , provide one example works. simplify code curtail computation times, consider two predictors: market capitalization (size anomaly) price--book ratio (value anomaly). statistics, precision matrix inverse covariance matrix. parameters, first two priors relate Gaussian law last two inverse gamma distribution:\n\\[f_\\text{invgamma}(x, \\alpha, \\beta)=\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}x^{-1-\\alpha}e^{-\\frac{\\beta}{x}},\\]\n\\(\\alpha\\) shape \\(\\beta\\) scale.specification, must also provide prior constant. default, set average value 0.01, corresponds 1% average monthly return. model estimated, can plot distribution coefficient estimates.\nFIGURE 9.1: Distribution linear regression coefficients (betas).\ndistribution constant Figure 9.1 firmly right small dispersion, hence solidly positive. size coefficient, opposite; negative (small firms profitable). regard value, hard conclude, distribution balanced around zero: clear exposition price--book ratio variable.","code":"\nprior_mean <- c(0.01,0.1,0.1)                    # Average value of parameters (prior)\nprecision_mat <- diag(prior_mean^2) %>% solve()  # Inverse cov matrix of parameters (prior)\nfit_lmBayes <- bayesLMConjugate(\n    R1M_Usd ~ Mkt_Cap_3M_Usd + Pb,          # Model: size and value\n    data = testing_sample,                  # Data source, here, the test sample\n    n.samples = 2000,                       # Number of samples used\n    beta.prior.mean = prior_mean,           # Avg prior: size & value rewarded & unit beta\n    beta.prior.precision = precision_mat,   # Precision matrix\n    prior.shape = 0.5,                      # Shape for prior distribution of sigma\n    prior.rate = 0.5)                       # Scale for prior distribution of sigma\nfit_lmBayes$p.beta.tauSq.samples[,1:3] %>% as_tibble() %>%\n    `colnames<-`(c(\"Intercept\", \"Size\", \"Value\")) %>%\n    gather(key = coefficient, value = value) %>%\n    ggplot(aes(x = value, fill = coefficient)) + geom_histogram(alpha = 0.5)"},{"path":"bayes.html","id":"naive-bayes-classifier","chapter":"9 Bayesian methods","heading":"9.4 Naive Bayes classifier","text":"\nBayes’ theorem can also easily applied classification. formulate respect label features write\n\\[\\begin{equation}\n\\tag{9.8}\nP[\\textbf{y} | \\textbf{X}] = \\frac{P[ \\textbf{X} | \\textbf{y}]P[\\textbf{y}]}{P[\\textbf{X}]} \\propto P[ \\textbf{X} | \\textbf{y}]P[\\textbf{y}],\n\\end{equation}\\]\nsplit input matrix column vectors \\(\\textbf{X}=(\\textbf{x}_1,\\dots,\\textbf{x}_K)\\). yields\n\\[\\begin{equation}\n\\tag{9.9}\nP[\\textbf{y} | \\textbf{x}_1,\\dots,\\textbf{x}_K] \\propto P[\\textbf{x}_1,\\dots,\\textbf{x}_K| \\textbf{y}]P[\\textbf{y}].\n\\end{equation}\\]‘naive’ qualification method comes simplifying assumption features.20 mutually independent, likelihood expression can expanded \n\\[\\begin{equation}\n\\tag{9.10}\nP[\\textbf{y} | \\textbf{x}_1,\\dots,\\textbf{x}_K] \\propto P[\\textbf{y}]\\prod_{k=1}^K P[\\textbf{x}_k| \\textbf{y}].\n\\end{equation}\\]next step specific likelihood. can done non-parametrically (via kernel estimation) common distributions (Gaussian continuous data, Bernoulli binary data). factor investing, features continuous, thus Gaussian law adequate:\n\\[P[x_{,k}=z|\\textbf{y}_i= c]=\\frac{e^{-\\frac{(z-m_c)^2}{2\\sigma_c^2}}}{\\sigma_c\\sqrt{2\\pi}},\\]\n\\(c\\) value classes taken \\(y\\) \\(\\sigma_c\\) \\(m_c\\) standard error mean \\(x_{,k}\\), conditional \\(y_i\\) equal \\(c\\). practice, class spanned, training set filtered accordingly \\(\\sigma_c\\) \\(m_c\\) taken sample statistics. Gaussian parametrization probably ill-suited dataset features uniformly distributed. Even conditioning, unlikely distribution even remotely close Gaussian. Technically, can overcome via double transformation method. Given vector features \\(\\textbf{x}_k\\) empirical cdf \\(F_{\\textbf{x}_k}\\), variable\n\\[\\begin{equation}\n\\tag{9.11}\n\\tilde{\\textbf{x}}_k=\\Phi^{-1}\\left(F_{\\textbf{x}_k}(\\textbf{x}_k) \\right),\n\\end{equation}\\]\nstandard normal law whenever \\(F_{\\textbf{x}_k}\\) pathological. Non-pathological cases cdf continuous strictly increasing observations lie open interval (0,1). features independent, transformation impact correlation structure. Otherwise, refer literature NORmal--Anything (NORTA) method (see, e.g., H. Chen (2001) Coqueret (2017)).Lastly, prior \\(P[\\textbf{y}]\\) Equation (9.10) often either taken uniform across classes (\\(1/K\\) \\(k\\)) equal sample distribution.illustrate naive Bayes classification tool simple example. package e1071 embeds classifier, naivebayes library offers options (Gaussian, Bernoulli, multinomial nonparametric likelihoods). , since features uniformly distributed, thus transformation (9.11) amounts apply Gaussian quantile function (inverse cdf).visual clarity, use small set features.\nFIGURE 9.2: Distributions predictor variables, conditional class label. TRUE instance corresponds median return FALSE median return.\nplots Figure 9.2 show distributions features, conditionally value label. Essentially, densities \\(P[\\textbf{x}_k| \\textbf{y}]\\). feature, distributions similar.usual, model trained, accuracy predictions can evaluated.performance classifier satisfactory underperforms random guess.","code":"\nlibrary(naivebayes)                           # Load package\ngauss_features_train <- training_sample %>%   # Build sample\n    dplyr::select(features_short) %>% \n    as.matrix() %>%\n    `*`(0.999) %>%                            # Features smaller than 1\n    + (0.0001) %>%                            # Features larger than 0\n    qnorm() %>%                               # Inverse Gaussian cdf\n    `colnames<-`(features_short)\nfit_NB_gauss <- naive_bayes(x = gauss_features_train,      # Transformed features\n                            y = training_sample$R1M_Usd_C) # Label\nlayout(matrix(c(1,1,2,3,4,5,6,7), 4, 2, byrow = TRUE),     # Organize graphs\n       widths=c(0.9,0.45))\npar(mar=c(1, 1, 1, 1))\nplot(fit_NB_gauss, prob = \"conditional\")\ngauss_features_test <- testing_sample %>% \n    dplyr::select(features_short) %>% \n    as.matrix() %>%\n    `*`(0.999) %>%\n    + (0.0001) %>%\n    qnorm() %>%\n    `colnames<-`(features_short)\nmean(predict(fit_NB_gauss, gauss_features_test) == testing_sample$R1M_Usd_C) # Hit ratio## [1] 0.4956985"},{"path":"bayes.html","id":"BART","chapter":"9 Bayesian methods","heading":"9.5 Bayesian additive trees","text":"","code":""},{"path":"bayes.html","id":"general-formulation","chapter":"9 Bayesian methods","heading":"9.5.1 General formulation","text":"Bayesian additive regression trees (BARTs) ensemble technique mixes Bayesian thinking regression trees. spirit, close tree ensembles seen Chapter 6, differ greatly implementation. BARTs like Bayesian regressions, regularization comes prior. original article Chipman, George, McCulloch (2010) implementation (R) follows Sparapani, Spanbauer, McCulloch (2019). BARTs used Shu Tiwari (2021) identify characteristics priced. authors report stocks’ market capitalization one matters.Formally, model aggregation \\(M\\) models, write \n\\[\\begin{equation}\n\\tag{9.12}\ny = \\sum_{m=1}^M\\mathcal{T}_m(q_m,\\textbf{w}_m, \\textbf{x}) + \\epsilon,\n\\end{equation}\\]\n\\(\\epsilon\\) Gaussian noise variance \\(\\sigma^2\\), \\(\\mathcal{T}_m=\\mathcal{T}_m(q_m,\\textbf{w}_m, \\textbf{x})\\) decision trees structure \\(q_m\\) weights vectors \\(\\textbf{w}_m\\). decomposition tree one used boosted trees illustrated Figure 6.5. \\(q_m\\) codes splits (variables chosen splits levels splits) vectors \\(\\textbf{w}_m\\) correspond leaf values (terminal nodes).macro-level, BARTs can viewed traditional Bayesian objects, parameters \\(\\boldsymbol{\\theta}\\) unknowns coded \\(q_m\\), \\(\\textbf{w}_m\\) \\(\\sigma^2\\) focus set determining posterior\n\\[\\begin{equation}\n\\tag{9.13}\n\\left(q_m,\\textbf{w}_m,\\sigma^2\\right) | (\\textbf{X}, \\textbf{Y}).\n\\end{equation}\\]Given particular forms priors \\(\\left(q_m,\\textbf{w}_m,\\sigma^2\\right)\\), algorithm draws parameters using combination Metropolis-Hastings Gibbs samplers.","code":""},{"path":"bayes.html","id":"priors","chapter":"9 Bayesian methods","heading":"9.5.2 Priors","text":"\ndefinition priors tree models delicate intricate. first important assumption independence: independence \\(\\sigma^2\\) parameters independence trees, , couples \\((q_m,\\textbf{w}_m)\\) \\((q_n,\\textbf{w}_n)\\) \\(m\\neq n\\). assumption makes BARTs closer random forests spirit boosted trees. independence entails\\[P(\\left(q_1,\\textbf{w}_1\\right),\\dots,\\left(q_M,\\textbf{w}_M\\right),\\sigma^2)=P(\\sigma^2)\\prod_{m=1}^MP\\left(q_m,\\textbf{w}_m\\right).\\]Moreover, customary (simplicity) separate structure tree (\\(q_m\\)) terminal weights (\\(\\textbf{w}_m\\)), Bayesian conditioning\\[\\begin{equation}\n\\tag{9.14}\nP(\\left(q_1,\\textbf{w}_1\\right),\\dots,\\left(q_M,\\textbf{w}_M\\right),\\sigma^2)=\\underbrace{P(\\sigma^2)}_{\\text{noise term}}\\prod_{m=1}^M\\underbrace{P\\left(\\textbf{w}_m|q_m\\right)}_{\\text{tree weights}}\\underbrace{P(q_m)}_{\\text{tree struct.}}\n\\end{equation}\\]remains formulate assumptions three parts.start trees’ structures, \\(q_m\\). Trees defined splits (nodes) splits characterized splitting variable splitting level. First, size trees parametrized node depth \\(d\\) nonterminal probability given \n\\[\\begin{equation}\n\\tag{9.15}\n\\alpha(1+d)^{-\\beta}, \\quad \\alpha \\(0,1), \\quad \\beta >0.\n\\end{equation}\\]\nauthors recommend set \\(\\alpha = 0.95\\) \\(\\beta=2\\). gives probability 5% 1 node, 55% 2 nodes, 28% 3 nodes, 9% 4 nodes 3% 5 nodes. Thus, aim force relatively shallow structures.Second, choice splitting variables driven generalized Bernoulli (categorical) distribution defines odds picking one particular feature. original paper Chipman, George, McCulloch (2010), vector probabilities uniform (predictor odds chosen split). vector can also random sampled flexible Dirichlet distribution. level split drawn uniformly set possible values chosen predictor.determined prior structure tree \\(q_m\\), remains fix terminal values leaves (\\(\\textbf{w}_m|q_m\\)). weights leaves assumed follow Gaussian distribution \\(\\mathcal{N}(\\mu_\\mu,\\sigma_\\mu^2)\\), \\(\\mu_\\mu=(y_\\text{min}+y_\\text{max})/2\\) center range label values. variance \\(\\sigma_\\mu^2\\) chosen \\(\\mu_\\mu\\) plus minus two times \\(\\sigma_\\mu^2\\) covers 95% range observed training dataset. default values can altered user.Lastly, computational purposes similar linear regressions, parameter \\(\\sigma^2\\) (variance \\(\\epsilon\\) (9.12)) assumed follow inverse Gamma law \\(\\text{IG}(\\nu/2,\\lambda \\nu/2)\\) akin used Bayesian regressions. parameters default computed data distribution \\(\\sigma^2\\) realistic prevents overfitting. refer original article, section 2.2.4, details topic.sum, addition \\(M\\) (number trees), prior depends small number parameters: \\(\\alpha\\) \\(\\beta\\) (tree structure), \\(\\mu_\\mu\\) \\(\\sigma_\\mu^2\\) (tree weights) \\(\\nu\\) \\(\\lambda\\) (noise term).","code":""},{"path":"bayes.html","id":"sampling-and-predictions","chapter":"9 Bayesian methods","heading":"9.5.3 Sampling and predictions","text":"\nposterior distribution (9.13) obtained analytically simulations efficient shortcut model (9.12). Just Gibbs Metropolis-Hastings sampling, distribution simulations expected converge sought posterior. burn-sample, prediction newly observed set \\(\\textbf{x}_*\\) simply average (median) predictions simulations. assume \\(S\\) simulations burn-, average equal \n\\[\\tilde{y}(\\textbf{x}_*):=\\frac{1}{S}\\sum_{s=1}^S\\sum_{m=1}^M\\mathcal{T}_m\\left(q_m^{(s)},\\textbf{w}_m^{(s)}, \\textbf{x}_*\\right).\\]complex part naturally generate simulations. tree sampled using Metropolis-Hastings method: tree proposed, replaces existing one (possibly random) criterion. procedure repeated Gibbs-like fashion.Let us start MH building block. seek simulate conditional distribution\\[(q_m,\\textbf{w}_m) \\ | \\ (q_{-m},\\textbf{w}_{-m},\\sigma^2, \\textbf{y}, \\textbf{x}),\\]\\(q_{-m}\\) \\(\\textbf{w}_{-m}\\) collect structures weights trees except tree number \\(m\\). One tour de force BART simplify Gibbs draws \n\\[(q_m,\\textbf{w}_m) \\ | \\ (\\textbf{R}_{m},\\sigma^2 ),\\]\n\\(\\textbf{R}_{m}=\\textbf{y}-\\sum_{l \\neq m}\\mathcal{T}_l(q_l,\\textbf{w}_l, \\textbf{x})\\) partial residual prediction excludes \\(m^{th}\\) tree.new MH proposition \\(q_m\\) based previous tree three possible (random) alterations tree:\n- growing terminal node (increase complexity tree adding supplementary leaf);\n- pruning pair terminal nodes (opposite operation: reducing complexity);\n- changing splitting rules.simplicity, third option often excluded. tree structure defined (.e., sampled), terminal weights independently drawn according Gaussian distribution \\(\\mathcal{N}(\\mu_\\mu, \\sigma_\\mu^2)\\).tree sampled, MH principle requires accepted rejected based probability. probability increases odds new tree increases likelihood model. detailed computation cumbersome refer section 2.2 Sparapani, Spanbauer, McCulloch (2019) details matter.Now, must outline overarching Gibbs procedure. First, algorithm starts trees simple nodes. , specified number loops include following sequential steps:step \\(m\\), residual \\(\\textbf{R}_{m}\\) updated values step \\(m-1\\). illustrate process Figure 9.3 \\(M=3\\). step 1, partition proposed first tree, simple node. particular case, tree accepted. scheme, terminal weights omitted simplicity. step 2, another partition proposed tree, rejected. third step, proposition third accepted. third step, new value \\(\\sigma^2\\) drawn new round Gibbs sampling can commence.\nFIGURE 9.3: Diagram MH/Gibbs sampling BARTs. step 2, proposed tree validated.\n","code":""},{"path":"bayes.html","id":"code","chapter":"9 Bayesian methods","heading":"9.5.4 Code","text":"several R packages implement BART methods: BART, bartMachine older one (original), BayesTree. first one highly efficient, hence work . resort parameters, like power base, \\(\\beta\\) \\(\\alpha\\) defined (9.15). program bit verbose delivers parametric details.model trained,21 evaluated performance. simply compute hit ratio. predictions embedded within fit variable, name ‘yhat.test.’performance seems reasonable means impressive. data sampled trees available fit_bart variable. nonetheless complex structure (often case trees). simplest information can extract value \\(\\sigma\\) across 300 simulations (see Figure 9.4).\nFIGURE 9.4: Evolution sigma across BART simulations.\nsee , number samples increases, \\(\\sigma\\) decreases.","code":"\nlibrary(BART)                                                           # Load package\nfit_bart <- gbart(                                                      # Main function\n    x.train = dplyr::select(training_sample, features_short) %>%        # Training features\n        data.frame(), \n    y.train = dplyr::select(training_sample, R1M_Usd) %>%               # Training label\n        as.matrix() ,        \n    x.test = dplyr::select(testing_sample, features_short)  %>%         # Testing features\n        data.frame(),  \n    type = \"wbart\",                                          # Option: label is continuous\n    ntree = 20,                                              # Number of trees in the model \n    nskip = 100,                                             # Size of burn-in sample\n    ndpost = 200,                                            # Number of posteriors drawn\n    power = 2,                                               # beta in the tree structure prior\n    base = 0.95)                                             # alpha in the tree structure prior## *****Calling gbart: type=1\n## *****Data:\n## data:n,p,np: 198128, 7, 70208\n## y1,yn: -0.049921, 0.024079\n## x1,x[n*p]: 0.010000, 0.810000\n## xp1,xp[np*p]: 0.270000, 0.880000\n## *****Number of Trees: 20\n## *****Number of Cut Points: 100 ... 100\n## *****burn,nd,thin: 100,200,1\n## *****Prior:beta,alpha,tau,nu,lambda,offset: 2,0.95,1.57391,3,2.84908e-31,0.0139209\n## *****sigma: 0.000000\n## *****w (weights): 1.000000 ... 1.000000\n## *****Dirichlet:sparse,theta,omega,a,b,rho,augment: 0,0,1,0.5,1,7,0\n## *****printevery: 100\n## \n## MCMC\n## done 0 (out of 300)\n## done 100 (out of 300)\n## done 200 (out of 300)\n## time: 36s\n## trcnt,tecnt: 200,200\nmean(fit_bart$yhat.test * testing_sample$R1M_Usd > 0)## [1] 0.5432794\ndata.frame(simulation = 1:300, sigma = fit_bart$sigma) %>%\n    ggplot(aes(x = simulation, y = sigma)) + geom_point(size = 0.7)"},{"path":"valtune.html","id":"valtune","chapter":"10 Validating and tuning","heading":"10 Validating and tuning","text":"shown Chapters 5 11, ML models require user-specified choices can trained. choices encompass parameter values (learning rate, penalization intensity, etc.) architectural choices (e.g., structure network). Alternative designs ML engines can lead different predictions, hence selecting good one can critical. refer work Probst, Bischl, Boulesteix (2018) study impact hyperparameter tuning model performance. models (neural networks boosted trees), number degrees freedom large finding right parameters can become complicated challenging. chapter addresses issues reader must aware shortcut building good models. Crafting effective model time-consuming often result many iterations.","code":""},{"path":"valtune.html","id":"mlmetrics","chapter":"10 Validating and tuning","heading":"10.1 Learning metrics","text":"\nparameter values set training called hyperparameters. order able choose good hyperparameters, imperative define metrics evaluate performance ML models. often case ML, dichotomy models seek predict numbers (regressions) try forecast categories (classifications). outline common evaluation benchmarks, mention econometric approach J. Li, Liao, Quaedvlieg (2020). authors propose assess performance forecasting method compared given benchmark, conditional external variable. helps monitor (economic) conditions model beats benchmark. full implementation test intricate, recommend interested reader look derivations paper.","code":""},{"path":"valtune.html","id":"regression-analysis","chapter":"10 Validating and tuning","heading":"10.1.1 Regression analysis","text":" \nErrors regression analyses usually evaluated straightforward way. \\(L^1\\) \\(L^2\\) norms mainstream; easy interpret compute. second one, root mean squared error (RMSE) differentiable everywhere harder grasp gives weight outliers. first one, mean absolute error gives average distance realized value differentiable zero. Formally, define \n\\[\\begin{align}\n \\tag{10.1}\n\\text{MAE}(\\textbf{y},\\tilde{\\textbf{y}})&=\\frac{1}{}\\sum_{=1}^|y_i-\\tilde{y}_i|, \\\\  \\tag{10.2} \n\\text{MSE}(\\textbf{y},\\tilde{\\textbf{y}})&=\\frac{1}{}\\sum_{=1}^(y_i-\\tilde{y}_i)^2, \n\\end{align}\\]RMSE simply square root MSE. always possible generalize formulae adding weights \\(w_i\\) produce heterogeneity importance instances. Let us briefly comment MSE. far common loss function machine learning, necessarily exact best choice return prediction portfolio allocation task. decompose loss 3 terms, get sum squared realized returns, sum squared predicted returns product two (roughly speaking, covariance term assume zero means). first term matter. second controls dispersion around zero predictions. third term interesting allocator’s standpoint. negativity cross-product \\(-2y_i\\tilde{y}_i\\) always investor’s benefit: either terms positive model recognized profitable asset, negative identified bad opportunity. \\(y_i\\) \\(\\tilde{y}_i\\) don’t sign problems arise. Thus, compared \\(\\tilde{y}_i^2\\), cross-term important. Nonetheless, algorithms optimize respect indicator.22These metrics (MSE RMSE) widely used outside ML assess forecasting errors. , present indicators also sometimes used quantify quality model. line linear regressions, \\(R^2\\) can computed predictive exercise.\n\\[\\begin{equation}\n\\tag{10.3} \nR^2(\\textbf{y},\\tilde{\\textbf{y}})=1- \\frac{\\sum_{=1}^(y_i-\\tilde{y}_i)^2}{\\sum_{=1}^(y_i-\\bar{y})^2},\n\\end{equation}\\]\n \n\\(\\bar{y}\\) sample average label. One important difference classical \\(R^2\\) quantity can computed testing sample training sample. case, \\(R^2\\) can negative mean squared error numerator larger (biased) variance testing sample. Sometimes, average value \\(\\bar{y}\\) omitted denominator (Gu, Kelly, Xiu (2020b) instance). benefit removing average value compares predictions model zero prediction. particularly relevant returns simplest prediction constant zero value \\(R^2\\) can measure model beats naive benchmark. zero prediction always preferable sample average latter can much period dependent. Also, removing \\(\\bar{y}\\) denominator makes metric conservative mechanically reduces \\(R^2\\).Beyond simple indicators detailed , several exotic extensions exist consist altering error taking averages. Two notable examples Mean Absolute Percentage Error (MAPE) Mean Square Percentage Error (MSPE). Instead looking raw error, compute error relative original value (predicted). Hence, error expressed percentage score averages simply equal :\n\\[\\begin{align}\n\\tag{10.4}  \n\\text{MAPE}(\\textbf{y},\\tilde{\\textbf{y}})&=\\frac{1}{}\\sum_{=1}^\\left|\\frac{y_i-\\tilde{y}_i}{y_i}\\right|, \\\\ \\tag{10.5}\n\\text{MSPE}(\\textbf{y},\\tilde{\\textbf{y}})&=\\frac{1}{}\\sum_{=1}^\\left(\\frac{y_i-\\tilde{y}_i}{y_i}\\right)^2, \n\\end{align}\\]latter can scaled square root need . label positive possibly large values, possible scale magnitude errors, can large. One way resort Root Mean Squared Logarithmic Error (RMSLE), defined :\\[\\begin{equation}\n \\tag{10.6} \n\\text{RMSLE}(\\textbf{y},\\tilde{\\textbf{y}})=\\sqrt{\\frac{1}{}\\sum_{=1}^\\log\\left(\\frac{1+y_i}{1+\\tilde{y}_i}\\right)}, \n\\end{equation}\\]obvious \\(y_i=\\tilde{y}_i\\), error metric equal zero.move categorical losses, briefly comment one shortcoming MSE, far widespread metric objective regression tasks. simple decomposition yields:\n\\[\\text{MSE}(\\textbf{y},\\tilde{\\textbf{y}})=\\frac{1}{}\\sum_{=1}^(y_i^2+\\tilde{y}_i^2-2y_i\\tilde{y}_i).\\]sum, first term given, nothing done , hence models focus minimization two. second term dispersion model values. third term cross-product. variations \\(\\tilde{y}_i\\) matter, third term far important, especially cross-section. valuable reduce MSE increasing \\(y_i\\tilde{y}_i\\). product indeed positive two terms sign, exactly investor looking : correct directions bets. algorithms (like neural networks), possible manually specify custom losses. Maximizing sum \\(y_i\\tilde{y}_i\\) may good alternative vanilla quadratic optimization (see Section 7.4.3 example implementation).","code":""},{"path":"valtune.html","id":"classification-analysis","chapter":"10 Validating and tuning","heading":"10.1.2 Classification analysis","text":"performance metrics categorical outcomes substantially different compared numerical outputs. large proportion metrics dedicated binary classes, though can easily generalized multiclass models.present concepts pertaining metrics increasing order complexity start two dichotomies true versus false positive versus negative. binary classification, convenient think terms true versus false. investment setting, true can related positive return, return benchmark - false opposite.4 types possible results prediction. Two prediction right (predict true true realization predict false false outcome) two prediction wrong (predict true false realization opposite). define corresponding aggregate metrics :frequency true positive: \\(TP=^{-1}\\sum_{=1}^I1_{\\{y_i=\\tilde{y}_i=1 \\}},\\)frequency true negative: \\(TN=^{-1}\\sum_{=1}^I1_{\\{y_i=\\tilde{y}_i=0 \\}},\\)frequency false positive: \\(FP=^{-1}\\sum_{=1}^I1_{\\{\\tilde{y}_i=1,y_i=0 \\}},\\)frequency false negative: \\(FN=^{-1}\\sum_{=1}^I1_{\\{\\tilde{y}_i=0,y_i=1 \\}},\\)true conventionally encoded 1 false 0. sum four figures equal one. four numbers different impacts --sample results, shown Figure 10.1. table (also called confusion matrix), assumed proxy future profitability forecast model. row stands model’s prediction column realization profitability. important cases top row, model predicts positive result likely assets positive predicted profitability (possibly relative benchmark) end portfolio. course, problem asset well (left cell), becomes penalizing model wrong portfolio suffer.\nFIGURE 10.1: Confusion matrix: summary binary outcomes.\nAmong two types errors, type daunting investors direct effect portfolio. type II error simply missed opportunity somewhat less impactful. Finally, true negatives assets correctly excluded portfolio.four baseline rates, possible derive interesting metrics:Accuracy = \\(TP+TN\\) percentage correct forecasts;Recall = \\(\\frac{TP}{TP+FN}\\) measures ability detect winning strategy/asset (left column analysis). Also known sensitivity true positive rate (TPR);Precision = \\(\\frac{TP}{TP+FP}\\) computes probability good investments (top row analysis);Specificity = \\(\\frac{TN}{FP+TN}\\) measures proportion actual negatives correctly identified (right column analysis);Fallout = \\(\\frac{FP}{FP+TN}=1-\\)Specificity probability false alarm (false positive rate), .e., frequence algorithm detects falsely performing assets (right column analysis);F-score, \\(\\mathbf{F}_1=2\\frac{\\text{recall}\\times \\text{precision}}{\\text{recall}+ \\text{precision}}\\) harmonic average recall precision.items lie unit interval model deemed perform better increase (except fallout opposite). Many indicators also exist, like false discovery rate false omission rate, mainstream less cited. Moreover, often simple functions ones mentioned .metric popular complex Area (ROC) Curve, often referred AUC. complicated part ROC curve ROC stands Receiver Operating Characteristic; name comes signal theory. explain built .seen Chapters 6 7, classifiers generate output probabilities one instance belongs one class. probabilities translated class choosing class highest value. binary classification, class score 0.5 basically wins.practice, 0.5 threshold may optimal model well correctly predict false instances probability 0.4 true ones otherwise. Hence, natural idea test happens decision threshold changes. ROC curve just plots recall function fallout threshold increases zero one.threshold equal 0, true positives equal zero model never forecasts positive values. Thus, recall fallout equal zero. threshold equal one, false negatives shrink zero true negatives , hence recall fallout equal one. behavior relationship two extremes called ROC curve. provide stylized examples Figure 10.2. random classifier fare equally good recall fallout thus ROC curve linear line point (0,0) (1,1). prove , imagine sample \\(p\\(0,1)\\) proportion true instances classifier predicts true randomly probability \\(p'\\(0,1)\\). sample predictions independent, \\(TP=p'p\\), \\(FP = p'(1-p)\\), \\(TN=(1-p')(1-p)\\) \\(FN=(1-p')p\\). Given definition, yields recall fallout equal \\(p'\\).\nFIGURE 10.2: Stylized ROC curves.\nalgorithm ROC curve 45° angle performing better average classifier. Indeed, curve can seen tradeoff benefits (probability detecting good strategies \\(y\\) axis) minus costs (odds selecting wrong assets \\(x\\) axis). Hence 45° paramount. best possible classifier ROC curve goes point (0,0) point (0,1) point (1,1). point (0,1), fallout null, hence false positives, recall equal one also false negatives: model always right. opposite true: point (1,0), model always wrong., use particular package (caTools) compute ROC curve given set predictions testing sample.\nFIGURE 10.3: Example ROC curve.\nFigure 10.3, curve close 45° angle model seems good (, rather, bad) random classifier.Finally, one entire curve practical comparison purposes, hence information whole curve synthesized area curve, .e., integral corresponding function. 45° angle (quadrant bisector) area 0.5 (half unit square unit area). Thus, good model expected area curve (AUC) 0.5. perfect model AUC one.end subsection word multiclass data. output (.e., label) two categories, things become complex. still possible compute confusion matrix, dimension larger harder interpret. simple indicators like \\(TP\\), \\(TN\\), etc., must generalized non-standard way. simplest metric case cross-entropy defined Equation (7.5). refer Section 6.1.2 details losses related categorical labels.","code":"\nif(!require(caTools)){install.packages(\"caTools\")}\nlibrary(caTools)  # Package for AUC computation\ncolAUC(X = predict(fit_RF_C, testing_sample, type = \"prob\"), \n       y = testing_sample$R1M_Usd_C, \n       plotROC = TRUE)##                    FALSE      TRUE\n## FALSE vs. TRUE 0.5003885 0.5003885"},{"path":"valtune.html","id":"validation","chapter":"10 Validating and tuning","heading":"10.2 Validation","text":"\nValidation stage model tested tuned starts deployed real live data (e.g., trading purposes). Needless say, critical.","code":""},{"path":"valtune.html","id":"the-variance-bias-tradeoff-theory","chapter":"10 Validating and tuning","heading":"10.2.1 The variance-bias tradeoff: theory","text":"\nvariance-bias tradeoff one core concepts supervised learning. explain , let us assume data generated simple model\n\\[y_i=f(\\textbf{x}_i)+\\epsilon_i, \\quad   \\mathbb{E}[\\boldsymbol{\\epsilon}]=0, \\quad \\mathbb{V}[\\boldsymbol{\\epsilon}]=\\sigma^2,\\]model estimated yields\\[y_i=\\hat{f}(\\textbf{x}_i)+\\hat{\\epsilon}_i. \\]Given unknown sample \\(\\textbf{x}\\), decomposition average squared error \\[\\begin{align}\n \\tag{10.7}\n\\mathbb{E}[\\hat{\\epsilon}^2]&=\\mathbb{E}[(y-\\hat{f}(\\textbf{x}))^2]=\\mathbb{E}[(f(\\textbf{x})+\\epsilon-\\hat{f}(\\textbf{x}))^2]   \\\\\n&= \\underbrace{\\mathbb{E}[(f(\\textbf{x})-\\hat{f}(\\textbf{x}))^2]}_{\\text{total quadratic error}}+\\underbrace{\\mathbb{E}[\\epsilon^2]}_{\\text{irreducible error}} \\nonumber \\\\\n&= \\mathbb{E}[\\hat{f}(\\textbf{x})^2]+\\mathbb{E}[f(\\textbf{x})^2]-2\\mathbb{E}[f(\\textbf{x})\\hat{f}(\\textbf{x})]+\\sigma^2\\nonumber\\\\\n&=\\mathbb{E}[\\hat{f}(\\textbf{x})^2]+f(\\textbf{x})^2-2f(\\textbf{x})\\mathbb{E}[\\hat{f}(\\textbf{x})]+\\sigma^2\\nonumber\\\\\n&=\\left[ \\mathbb{E}[\\hat{f}(\\textbf{x})^2]-\\mathbb{E}[\\hat{f}(\\textbf{x})]^2\\right]+\\left[\\mathbb{E}[\\hat{f}(\\textbf{x})]^2+f(\\textbf{x})^2-2f(\\textbf{x})\\mathbb{E}[\\hat{f}(\\textbf{x})]\\right]+\\sigma^2\\nonumber\\\\\n&=\\underbrace{\\mathbb{V}[\\hat{f}(\\textbf{x})]}_{\\text{variance model}}+ \\quad \\underbrace{\\mathbb{E}[(f(\\textbf{x})-\\hat{f}(\\textbf{x}))]^2}_{\\text{squared bias}}\\quad +\\quad\\sigma^2 \\nonumber\n\\end{align}\\]derivation, \\(f(x)\\) random, \\(\\hat{f}(x)\\) . Also, second line, assumed \\(\\mathbb{E}[\\epsilon(f(x)-\\hat{f}(x))]=0\\), may always hold (though common assumption). average squared error thus three components:variance model (predictions);squared bias model;one irreducible error (independent choice particular model).last one immune changes models, challenge minimize sum first two. known variance-bias tradeoff reducing one often leads increasing . goal thus assess small increase either one can lead larger decrease .several ways represent tradeoff display two . first one relates archery (see Figure 10.4) . best case (top left) shots concentrated middle: average, archer aims correctly arrows close one another. worst case (bottom right) exact opposite: average arrow center target (bias nonzero) dispersion arrows large.\nFIGURE 10.4: First representation variance-bias tradeoff.\noften encountered cases ML two configurations: either arrows (predictions) concentrated small perimeter, perimeter center target; arrows average well distributed around center, , average, far .second way variance bias tradeoff often depicted via notion model complexity. simple model constant one: prediction always , instance equal average value label training set. course, prediction often far realized values testing set (bias large), least variance zero. side spectrum, decision tree many leaves instances complex structure. probably smaller bias, undoubtedly obvious compensate increase variance incurred intricacy model.facet tradeoff depicted Figure 10.5 . left graph, simple model small variance large bias, right opposite complex model. Good models often lie somewhere middle, best mix hard find.\nFIGURE 10.5: Second representation variance-bias tradeoff.\ntractable theoretical form variance-bias tradeoff ridge regression.23 coefficient estimates type regression given \\(\\hat{\\mathbf{b}}_\\lambda=(\\mathbf{X}'\\mathbf{X}+\\lambda \\mathbf{}_N)^{-1}\\mathbf{X}'\\mathbf{Y}\\) (see Section 5.1.1), \\(\\lambda\\) penalization intensity. Assuming true linear form data generating process (\\(\\textbf{y}=\\textbf{Xb}+\\boldsymbol{\\epsilon}\\) \\(\\textbf{b}\\) unknown \\(\\sigma^2\\) variance errors - identity correlation matrix), yields\n\\[\\begin{align}  \n\\mathbb{E}[\\hat{\\textbf{b}}_\\lambda]&=\\textbf{b}-\\lambda(\\textbf{X}'\\textbf{X}+\\lambda \\textbf{}_N)^{-1} \\textbf{b}, \\\\  \\tag{10.8}\n\\mathbb{V}[\\hat{\\textbf{b}}_\\lambda]&=\\sigma^2(\\textbf{X}'\\textbf{X}+\\lambda \\textbf{}_N)^{-1}\\textbf{X}'\\textbf{X}   (\\textbf{X}'\\textbf{X}+\\lambda \\textbf{}_N)^{-1}.\n\\end{align}\\]Basically, means bias estimator equal \\(-\\lambda(\\textbf{X}'\\textbf{X}+\\lambda \\textbf{}_N)^{-1} \\textbf{b}\\), zero absence penalization (classical regression) converges finite number \\(\\lambda \\rightarrow \\infty\\), .e., model becomes constant. Note estimator zero bias, predictions : \\(\\mathbb{E}[\\textbf{X}(\\textbf{b}-\\hat{\\textbf{b}})]=\\textbf{0}\\).variance (estimates) case unconstrained regression equal \\(\\mathbb{V}[\\hat{\\textbf{b}}]=\\sigma (\\textbf{X}'\\textbf{X})^{-1}\\). Equation (10.8), \\(\\lambda\\) reduces magnitude figures inverse matrix. overall effect \\(\\lambda\\) increases, variance decreases limit \\(\\lambda \\rightarrow \\infty\\), variance zero model constant. variance predictions \n\\[\\begin{align*}\n\\mathbb{V}[\\textbf{X}\\hat{\\textbf{b}}]&=\\mathbb{E}[(\\textbf{X}\\hat{\\textbf{b}}-\\mathbb{E}[\\textbf{X}\\hat{\\textbf{b}}])(\\textbf{X}\\hat{\\textbf{b}}-\\mathbb{E}[\\textbf{X}\\hat{\\textbf{b}}])'] \\\\\n&= \\textbf{X}\\mathbb{E}[(\\hat{\\textbf{b}}-\\mathbb{E}[\\hat{\\textbf{b}}])(\\hat{\\textbf{b}}-\\mathbb{E}[\\hat{\\textbf{b}}])']\\textbf{X}' \\\\\n&= \\textbf{X}\\mathbb{V}[\\hat{\\textbf{b}}]\\textbf{X}\n\\end{align*}\\], ridge regressions handy single parameter, able provide cursor directly tunes variance-bias tradeoff.’s easy illustrate simple display tradeoff ridge regression. example , recycle ridge model trained Chapter 5.\nFIGURE 10.6: Error decomposition ridge regression.\nFigure 10.6, pattern different one depicted Figure 10.5. graph, intensity lambda increases, magnitude parameters shrinks model becomes simpler. Hence, simple model seems like best choice: adding complexity increases variance improve bias! One possible reason features don’t actually carry much predictive value hence constant model just good sophisticated ones based irrelevant variables.","code":"\nridge_errors <- predict(fit_ridge, x_penalized_test) -          # Errors from all models\n    (rep(testing_sample$R1M_Usd, 100) %>% \n    matrix(ncol = 100, byrow = FALSE))\nridge_bias <- ridge_errors %>% apply(2, mean)                                # Biases\nridge_var <- predict(fit_ridge, x_penalized_test) %>% apply(2, var)          # Variance\ntibble(lambda, ridge_bias^2, ridge_var, total = ridge_bias^2+ridge_var) %>%  # Plot\n    gather(key = Error_Component, value = Value, -lambda) %>%\n    ggplot(aes(x = lambda, y = Value, color = Error_Component)) + geom_line()"},{"path":"valtune.html","id":"the-variance-bias-tradeoff-illustration","chapter":"10 Validating and tuning","heading":"10.2.2 The variance-bias tradeoff: illustration","text":"\nvariance-bias tradeoff often presented theoretical terms easy grasp. nonetheless useful demonstrate operates true algorithmic choices. , take example trees complexity easy evaluate. Basically, tree many terminal nodes complex tree handful clusters.start parsimonious model, train .\nFIGURE 10.7: Simple tree.\nmodel depicted Figure 10.7 4 clusters, means predictions can take four values. smallest one 0.011 encompasses large portion sample (85%) largest one 0.062 corresponds 4% training sample.\nable compute bias variance predictions testing set.average, error slightly positive, overall overestimation 0.005. expected, variance small (10^{-4}).complex model, take boosted tree obtained Section 6.4.6 (fit_xgb). model aggregates 40 trees maximum depth 4, thus undoubtedly complex. bias indeed smaller compared simple model, exchange, variance increases substantially. net effect (via squared bias) favor simpler model.","code":"\nfit_tree_simple <- rpart(formula, \n             data = training_sample,     # Data source: training sample\n             cp = 0.0001,                # Precision: smaller = more leaves\n             maxdepth = 2                # Maximum depth (i.e. tree levels)\n             ) \nrpart.plot(fit_tree_simple)\nmean(predict(fit_tree_simple, testing_sample) - testing_sample$R1M_Usd) # Bias## [1] 0.004973917\nvar(predict(fit_tree_simple, testing_sample))                           # Variance## [1] 0.0001398003\nmean(predict(fit_xgb, xgb_test) - testing_sample$R1M_Usd) # Bias## [1] 0.003347682\nvar(predict(fit_xgb, xgb_test))                           # Variance## [1] 0.00354207"},{"path":"valtune.html","id":"the-risk-of-overfitting-principle","chapter":"10 Validating and tuning","heading":"10.2.3 The risk of overfitting: principle","text":"notion overfitting one important machine learning. model overfits, accuracy predictions disappointing, thus one major reason strategies fail --sample. Therefore, important understand overfitting , also mitigate effects.One recent reference topic impact portfolio strategies Hsu et al. (2018), builds work White (2000). references deal ML models, principle . given dataset, sufficiently intense level analysis (human machine) always able detect patterns. Whether patterns spurious key question.Figure 10.8, illustrate idea simple visual example. try find model maps x y. (training) data points small black circles. simplest model constant one (one parameter), two parameters (level slope), fit already quite good. shown blue line. sufficient number parameters, possible build model flows points. One example high-dimensional polynomial. One model represented red line. Now seems strange point dataset complex model fits closely match point.\nFIGURE 10.8: Illustration overfitting: model closely matching training data rarely good idea.\nnew point added light green. fair say follows general pattern points. simple model perfect error non-negligible. Nevertheless, error stemming complex model (shown dotted gray line) approximately twice large. simplified example shows models close training data catch idiosyncracies occur datasets. good model overlook idiosyncracies stick enduring structure data.","code":""},{"path":"valtune.html","id":"the-risk-of-overfitting-some-solutions","chapter":"10 Validating and tuning","heading":"10.2.4 The risk of overfitting: some solutions","text":"\nObviously, easiest way avoid overfitting resist temptation complicated models (e.g., high-dimensional neural networks tree ensembles).complexity models often proxied via two measures: number parameters model magnitude (often synthesized norm). proxies perfect complex models may require small number parameters (even small parameter values), least straightforward easy handle. universal way handling overfitting. , detail tricks families ML tools.regressions, two simple ways deal overfitting. first number parameters, , number predictors. Sometimes, can better select subsample features, especially highly correlated (often, threshold 70% considered high absolute correlations features). second solution penalization (via LASSO, ridge elasticnet), helps reduce magnitude estimates thus variance predictions.tree-based methods, variety ways reduce risk overfitting. dealing simple trees, way proceed limit number leaves. can done many ways. First, imposing maximum depth. equal \\(d\\), tree can \\(2^d\\) terminal nodes. often advised go beyond \\(d=6\\). complexity parameter rpart (cp) another way shrink size trees: new split must lead reduction loss least equal cp. , split deemed useful thus performed. Thus cp large, tree grown. last two parameters available rpart minimum number instances required leaf minimum number instances per cluster requested order continue splitting process. higher (.e., coercive) figures , harder grow complex trees.addition options, random forests allow control number trees forest. Theoretically (see Breiman (2001)), parameter supposed impact risk overfitting new trees help reduce total error via diversification. practice, sake computation times, recommended go beyond 1,000 trees. Two hyperparameters subsample size (learner trained) number features retained learning. straightforward impact bias tradeoff, rather raw performace. instance, subsamples small, trees learn enough. problem number features low. hand, choosing large number predictors (.e., close total number) may lead high correlations learner’s prediction overlap information contained training samples may high.Boosted trees options can help alleviate risk overfitting. obvious one learning rate, discounts impact new tree \\(\\eta \\(0,1)\\). learning rate high, algorithm learns quickly prone sticking close training data. ’s low, model learns progressively, can efficient sufficiently many trees ensemble. Indeed, learning rate number trees must chosen synchronously: low, ensemble learn nothing large, overfit. arsenal boosted tree parameters stop . penalizations, score values number leaves, naturally tool prevent model going deep particularities training sample. Finally, constraints monotonicity like mentioned Section 6.4.5 also efficient way impose structure model force detect particular patterns.Lastly neural networks also many options aimed protecting overfitting. Just like boosted trees, learning rate penalization weights biases (via norm). Constraints, like nonnegative constraints, can also help model theoretically requires positive inputs. Finally, dropout always direct way reduce dimension (number parameters) network.","code":""},{"path":"valtune.html","id":"the-search-for-good-hyperparameters","chapter":"10 Validating and tuning","heading":"10.3 The search for good hyperparameters","text":"","code":""},{"path":"valtune.html","id":"methods","chapter":"10 Validating and tuning","heading":"10.3.1 Methods","text":"Let us assume \\(p\\) parameters defined model run. simplest way proceed test different values parameters choose one yields best results. mainly two ways perform tests: independently sequentially.Independent tests easy come two families: grid (deterministic) search random exploration. advantage deterministic approach covers space uniformly makes sure corners omitted. drawback computation time. Indeed, parameter, seems reasonable test least five values, makes \\(5^p\\) combinations. \\(p\\) small (smaller 3), manageable backtests lengthy. \\(p\\) large, number combinations may become prohibitive. random exploration can useful case, user specifies number tests upfront parameters drawn randomly (usually uniformly given range parameter). flaw random search areas parameter space may covered, can problematic best choice located . nonetheless shown Bergstra Bengio (2012) random exploration preferable grid search.grid random searches suboptimal likely spend time zones parameter space irrelevant, thereby wasting computation time. Given number parameter points tested, preferable focus search areas best points likely. possible via interative process adapts search new point tested. large field finance, papers dedicated tuning Lee (2020) Nystrup, Lindstrom, Madsen (2020).One popular approach direction Bayesian optimization (BO). central object objective function learning process. call function \\(O\\) can widely seen loss function possibly combined penalization constraints. simplicity , mention training/testing samples considered fixed. variable interest vector \\(\\textbf{p}=(p_1,\\dots,p_l)\\) synthesizes hyperparameters (learning rate, penalization intensities, number models, etc.) impact \\(O\\). program interested \\[\\begin{equation}\n\\tag{10.9}\n\\textbf{p}_*=\\underset{\\textbf{p}}{\\text{argmin}} \\ O(\\textbf{p}).\n\\end{equation}\\]main problem optimization computation \\(O(\\textbf{p})\\) costly. Therefore, critical choose trial \\(\\textbf{p}\\) wisely. One key assumption BO distribution \\(O\\) Gaussian \\(O\\) can proxied linear combination \\(p_l\\). Said differently, aim build Bayesian linear regression input \\(\\textbf{p}\\) output (dependent variable) \\(O\\). model estimated, information concentrated posterior density \\(O\\) used make educated guess look new values \\(\\textbf{p}\\).educated guess made based -called acquisition function. Suppose tested \\(m\\) values \\(\\textbf{p}\\), write \\(\\textbf{p}^{(m)}\\). current best parameter written \\(\\textbf{p}_m^*=\\underset{1\\le k\\le m}{\\text{argmin}} \\ O(\\textbf{p}^{(k)})\\). test new point \\(\\textbf{p}\\), lead improvement \\(O(\\textbf{p})<O(\\textbf{p}_m^*)\\), new objective improves minimum value already know. average value improvement \n\\[\\begin{equation}\n\\tag{10.10}\n\\textbf{EI}_m(\\textbf{p})=\\mathbb{E}_m[[O(\\textbf{p}_m^*)-O(\\textbf{p})]_+],\n\\end{equation}\\]positive part \\([\\cdot]_+\\) emphasizes \\(O(\\textbf{p})\\ge O(\\textbf{p}_m^*)\\), gain zero. expectation indexed \\(m\\) computed respect posterior distribution \\(O(\\textbf{p})\\) based \\(m\\) samples \\(\\textbf{p}^{(m)}\\). best choice next sample \\(\\textbf{p}^{m+1}\\) \n\\[\\begin{equation}\n\\tag{10.11}\n\\textbf{p}^{m+1}=\\underset{\\textbf{p}}{\\text{argmax}} \\ \\textbf{EI}_m(\\textbf{p}),\n\\end{equation}\\]\ncorresponds maximum location expected improvement. Instead EI, optimization can performed measures, like probability improvement, \\(\\mathbb{P}_m[O(\\textbf{p})<O(\\textbf{p}_m^*)]\\).compact form, iterative process can outlined follows:step 1: compute \\(O(\\textbf{p}^{(m)})\\) \\(m=1,\\dots,M_0\\) values parameters.step 2a: compute sequentially posterior density \\(O\\) available points.step 2b: compute optimal new point test \\(\\textbf{p}^{(m+1)}\\) given Equation (10.11).step 2c: compute new objective value \\(O(\\textbf{p}^{(m+1)})\\).step 3: repeat steps 2a 2c much deemed reasonable return \\(\\textbf{p}^{(m)}\\) yields smallest objective value.interested reader can look Snoek, Larochelle, Adams (2012) Frazier (2018) details numerical facets method.Finally, sake completeness, mention last way tune hyperparameters. Since optimization scheme \\(\\underset{\\textbf{p}}{\\text{argmin}} \\ O(\\textbf{p})\\), natural way proceed use sensitivity \\(O\\) respect \\(\\textbf{p}\\). Indeed, gradient \\(\\frac{\\partial O}{\\partial p_l}\\) known, gradient descent always improve objective value. problem hard compute reliable gradient (finite differences can become costly). Nonetheless, methods (e.g., Maclaurin, Duvenaud, Adams (2015)) applied successfully optimize large dimensional parameter spaces.conclude mentioning survey Bouthillier Varoquaux (2020), spans 2 major AI conferences took place 2019. shows papers resort hyperparameter tuning. two often cited methods manual tuning (hand-picking) grid search.","code":""},{"path":"valtune.html","id":"example-grid-search","chapter":"10 Validating and tuning","heading":"10.3.2 Example: grid search","text":"\norder illustrate process grid search, try find best parameters boosted tree. seek quantify impact three parameters:eta, learning rate,nrounds, number trees grown,lambda, weight regularizer penalizes objective function total sum squared weights/scores., create grid values want test parameters.Given computational cost grid search, perform exploration dataset small number features (recycle Chapter 6). order avoid burden loops, resort functional programming capabilities R, via purrr package. allows us define function lighten simplify code. function, coded , takes data parameter inputs returns error metric algorithm. choose mean squared error evaluate impact hyperparameter values.grid_par function can processed functional programming tool pmap going perform loop parameter values automatically.squared mean errors gathered, possible plot . chose work 3 parameters purpose influence can simultaneuously plotted one graph.\nFIGURE 10.9: Plot error metrics (SMEs) many parameter values. row graph corresponds nrounds column lambda.\nFigure 10.9, main information small learning rate (\\(\\eta=0.1\\)) detrimental quality forecasts number trees small (nrounds=10), means algorithm learn enough.Grid search can performed two stages: first stage helps locate zones interest (lowest loss/objective values) zoom zones refined values parameter grid. results , mean considering many learners (50, possibly 100), avoiding large learning rates \\(\\eta=0.9\\) \\(\\eta=0.8\\).","code":"\neta <- c(0.1, 0.3, 0.5, 0.7, 0.9)         # Values for eta\nnrounds <- c(10, 50, 100)                 # Values for nrounds\nlambda <- c(0.01, 0.1, 1, 10, 100)        # Values for lambda\npars <- expand.grid(eta, nrounds, lambda) # Exploring all combinations!\nhead(pars)                                # Let's see the parameters##   Var1 Var2 Var3\n## 1  0.1   10 0.01\n## 2  0.3   10 0.01\n## 3  0.5   10 0.01\n## 4  0.7   10 0.01\n## 5  0.9   10 0.01\n## 6  0.1   50 0.01\neta <- pars[,1]\nnrounds <- pars[,2]\nlambda <- pars[,3]\ngrid_par <- function(train_matrix, test_features, test_label, eta, nrounds, lambda){\n    fit <- train_matrix %>% \n        xgb.train(data = .,                            # Data source (pipe input)\n                  eta = eta,                           # Learning rate\n                  objective = \"reg:squarederror\",  # Objective function\n                  max_depth = 5,                       # Maximum depth of trees\n                  lambda = lambda,                     # Penalisation of leaf values\n                  gamma = 0.1,                         # Penalisation of number of leaves\n                  nrounds = nrounds,                   # Number of trees used\n                  verbose = 0                          # No comment from algo\n        )\n    \n    pred <- predict(fit, test_features)           # Predictions based on model & test values\n    return(mean((pred-test_label)^2))             # Mean squared error\n} \n# grid_par(train_matrix_xgb, xgb_test, testing_sample$R1M_Usd, 0.1, 3, 0.1) # Possible test \ngrd <- pmap(list(eta, nrounds, lambda),             # Parameters for the grid search\n            grid_par,                               # Function on which to apply the search\n            train_matrix = train_matrix_xgb,        # Input for function: training data\n            test_features = xgb_test,               # Input for function: test features\n            test_label = testing_sample$R1M_Usd     # Input for function: test labels (returns) \n) \ngrd <- data.frame(eta, nrounds, lambda, error = unlist(grd)) # Dataframe with all results\ngrd$eta <- as.factor(eta)                                  # Params as categories (for plot)\ngrd %>% ggplot(aes(x = eta, y = error, fill = eta)) +      # Plot!\n    geom_bar(stat = \"identity\") +\n    facet_grid(rows = vars(nrounds), cols = vars(lambda)) +\n    theme(axis.text.x = element_text(size = 6))"},{"path":"valtune.html","id":"example-bayesian-optimization","chapter":"10 Validating and tuning","heading":"10.3.3 Example: Bayesian optimization","text":"\nseveral packages R relate Bayesian optimization. work rBayesianOptimization, general purpose also needs coding involvement.Just grid search, need code objective function hyperparameters optimized. rBayesianOptimization, output particular form, score prediction variable. function maximize score, hence define minus mean squared error.objective function defined, can plugged Bayesian optimizer.final parameters indicate advised resist overfitting: small number learners large penalization seem best choices.confirm results, plot relationship loss (sign) two hyperparameters. point corresponds value tested optimization. best values clearly left left graph right right graph pattern reliably pronounced. According graphs, seems indeed wiser pick smaller number trees larger penalization factor (maximize minus loss).\nFIGURE 10.10: Relationship (minus) loss hyperparameter values.\n","code":"\nbayes_par_opt <- function(train_matrix = train_matrix_xgb,        # Input for func: train data\n                          test_features = xgb_test,               # Input for func: test feats\n                          test_label = testing_sample$R1M_Usd,    # Input for func: test label\n                          eta, nrounds, lambda){                  # Input for func params\n    fit <- train_matrix %>% \n        xgb.train(data = .,                       # Data source (pipe input)\n                  eta = eta,                      # Learning rate\n                  objective = \"reg:squarederror\", # Objective function\n                  max_depth = 5,                  # Maximum depth of trees\n                  lambda = lambda,                # Penalisation of leaf values\n                  gamma = 0.1,                    # Penalisation of number of leaves\n                  nrounds = round(nrounds),       # Number of trees used\n                  verbose = 0                     # No comment from algo\n        )\n\n    pred <- predict(fit, test_features)           # Forecast based on fitted model & test values\n    list(Score = -mean((pred-test_label)^2),      # Minus RMSE\n         Pred = pred)                             # Predictions on test set\n}\nlibrary(rBayesianOptimization)\nbayes_opt <- BayesianOptimization(bayes_par_opt,           # Function to maximize\n                     bounds = list(eta = c(0.2, 0.8),      # Bounds for eta\n                                   lambda = c(0.1, 1),     # Bounds for lambda\n                                   nrounds = c(10, 100)),  # Bounds for nrounds\n                     init_points = 10,            # Nb initial points for first estimation\n                     n_iter = 24,                 # Nb optimization steps/trials\n                     acq = \"ei\",                  # Acquisition function = expected improvement\n                     verbose = FALSE)## \n##  Best Parameters Found: \n## Round = 14   eta = 0.3001394 lambda = 0.4517514  nrounds = 10.0000   Value = -0.03793923\nbayes_opt$Best_Par##        eta     lambda    nrounds \n##  0.3001394  0.4517514 10.0000000\nlibrary(\"ggpubr\") # Package for combining plots\nplot_rounds <- bayes_opt$History %>% \n    ggplot(aes(x = nrounds, y = Value)) + geom_point() + geom_smooth(method = \"lm\")\nplot_lambda <- bayes_opt$History %>% \n    ggplot(aes(x = lambda, y = Value)) + geom_point() + geom_smooth(method = \"lm\")\npar(mar = c(1,1,1,1))\nggarrange(plot_rounds, plot_lambda, ncol = 2)"},{"path":"valtune.html","id":"short-discussion-on-validation-in-backtests","chapter":"10 Validating and tuning","heading":"10.4 Short discussion on validation in backtests","text":" \ntopic validation backtests complex seems. fact two scales can operate, depending whether forecasting model dynamic (updated rebalancing) fixed.Let us start first option. case, aim build unique model test different time periods. ongoing debate methods suitable validate model case. Usually, makes sense test model successive dates, moving forward posterior training. makes sense, replicates happen live situation.\nmachine learning, popular approach split data \\(K\\) partitions test \\(K\\) different models: one tested one partitions trained \\(K-1\\) others. -called cross-validation (CV) proscribed experts (common sense) simple reason: time, training set encompasses data future dates tests past values. Nonetheless, advocate one particular form CV aims making sure informational overlap training testing set (Sections 7.4 12.4 De Prado (2018)). premise structure cross-section returns constant time, training future points testing past data problematic long overlap. paper Schnaubelt (2019) provides comprehensive exhaustive tour many validation schemes.One example cited De Prado (2018) reaction model unseen crisis. Following market crash 2008, least 11 years followed without major financial shake. One option test reaction recent model crash train recent years (say 2015-2019) test various points (e.g., months) 2008 see performs.advantage fixed model validation easy: one set hyperparameters, test model set dates, evaluate performance model. Repeat process parameters choose best alternative (use Bayesian optimization).second major option model updated (retrained) rebalancing. underlying idea structure returns evolves time dynamic model capture recent trends. drawback validation must (?) rerun rebalancing date.Let us recall dimensions backtests:\n- number strategies: possibly dozens hundreds, even ;\n- number trading dates: hundreds monthly rebalancing;\n- number assets: hundreds thousands;\n- number features: dozens hundreds.Even lot computational power (GPUs, etc.), training many models many dates time-consuming, especially comes hyperparameter tuning parameter space large. Thus, validating models trading date --sample period realistic.One solution keep early portion training data perform smaller scale validation subsample. Hyperparameters tested limited number dates time, exhibit stability: satisfactory parameters one date usually acceptable next one following one well. Thus, full backtest can carried values updating models period. backtest nonetheless remains compute-intensive model retrained recent data rebalancing date.","code":""},{"path":"ensemble.html","id":"ensemble","chapter":"11 Ensemble models","heading":"11 Ensemble models","text":"\nLet us honest. facing prediction task, obvious determine best choice ML tools: penalized regressions, tree methods, neural networks, SVMs, etc. natural tempting alternative combine several algorithms (predictions result ) try extract value engine (learner). intention new contributions towards goal go back least Bates Granger (1969) (purpose passenger flow forecasting)., outline books topic ensembles. latter many names synonyms, forecast aggregation, model averaging, mixture experts prediction combination. first four references monographs, last two compilations contributions:   Zhou (2012): didactic book covers main ideas ensembles;Schapire Freund (2012): main reference boosting (hence, ensembling) many theoretical results thus strong mathematical groundings;Seni Elder (2010): introduction dedicated tree methods mainly;Claeskens Hjort (2008): overview model selection techniques chapters focused model averaging;C. Zhang Ma (2012): collection thematic chapters ensemble learning;Okun, Valentini, Re (2011): examples applications ensembles.chapter, cover basic ideas concepts behind notion ensembles. refer books deeper treatments topic. underline several ensemble methods already mentioned covered earlier, notably Chapter 6. Indeed, random forests boosted trees examples ensembles.  Hence, early articles combination learners Schapire (1990), R. . Jacobs et al. (1991) (neural networks particularly), Freund Schapire (1997). Ensembles can instance used aggregate models built different datasets (Pesaran Pick (2011)), can made time-dependent (Sun et al. (2020)). theoretical view ensembles Bayesian perspective, refer Razin Levy (2020). Finally, perspectives linked asset pricing factor modelling provided Gospodinov Maasoumi (2020) De Nard, Hediger, Leippold (2020) (subsampling forecast aggregation).","code":""},{"path":"ensemble.html","id":"linear-ensembles","chapter":"11 Ensemble models","heading":"11.1 Linear ensembles","text":"","code":""},{"path":"ensemble.html","id":"principles","chapter":"11 Ensemble models","heading":"11.1.1 Principles","text":"\nchapter adopt following notations. work \\(M\\) models \\(\\tilde{y}_{,m}\\) prediction model \\(m\\) instance \\(\\) errors \\(\\epsilon_{,m}=y_i-\\tilde{y}_{,m}\\) stacked \\((\\times M)\\) matrix \\(\\textbf{E}\\). linear combination models sample errors equal \\(\\textbf{Ew}\\), \\(\\textbf{w}=w_m\\) weights assigned model assume \\(\\textbf{w}'\\textbf{1}_M=1\\). Minimizing total (squared) error thus simple quadratic program unique constraint. Lagrange function \\(L(\\textbf{w})=\\textbf{w}'\\textbf{E}'\\textbf{E}\\textbf{w}-\\lambda (\\textbf{w}'\\textbf{1}_M-1)\\) hence\n\\[\\frac{\\partial}{\\partial \\textbf{w}}L(\\textbf{w})=\\textbf{E}'\\textbf{E}\\textbf{w}-\\lambda \\textbf{1}_M=0 \\quad \\Leftrightarrow \\quad \\textbf{w}=\\lambda(\\textbf{E}'\\textbf{E})^{-1}\\textbf{1}_M,\\]constraint imposes \\(\\textbf{w}^*=\\frac{(\\textbf{E}'\\textbf{E})^{-1}\\textbf{1}_M}{(\\textbf{1}_M'\\textbf{E}'\\textbf{E})^{-1}\\textbf{1}_M}\\). form similar minimum variance portfolios. errors unbiased (\\(\\textbf{1}_I'\\textbf{E}=\\textbf{0}_M'\\)), \\(\\textbf{E}'\\textbf{E}\\) covariance matrix errors.expression shows important feature optimized linear ensembles: can add value models tell different stories. two models redundant, \\(\\textbf{E}'\\textbf{E}\\) close singular \\(\\textbf{w}^*\\) arbitrage one spurious fashion. exact problem mean-variance portfolios constituted highly correlated assets: case, diversification fails things go wrong, assets go . Another problem arises number observations small compared number assets covariance matrix returns singular. issue ensembles number observations usually much larger number models (\\(>>M\\)).limit correlations increase one, formulation becomes highly unstable ensembles trusted. One heuristic way see \\(M=2\\) \n\\[\\textbf{E}'\\textbf{E}=\\left[\n\\begin{array}{cc} \\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\\n\\rho\\sigma_1\\sigma_2 & \\sigma_2^2 \\\\\n\\end{array}\n\\right] \\quad \\Leftrightarrow  \\quad \n(\\textbf{E}'\\textbf{E})^{-1}=\\frac{1}{1-\\rho^2}\\left[\n\\begin{array}{cc} \\sigma_1^{-2} & -\\rho(\\sigma_1\\sigma_2)^{-1} \\\\\n-\\rho(\\sigma_1\\sigma_2)^{-1} & \\sigma_2^{-2} \\\\\n\\end{array}\n\\right]\\]\\(\\rho \\rightarrow 1\\), model smallest errors (minimum \\(\\sigma_i^2\\)) see weight increasing towards infinity model similarly large negative weight: model arbitrages two highly correlated variables. seems like bad idea.another illustration issues caused correlations. Let’s assume face \\(M\\) correlated errors \\(\\epsilon_m\\) pairwise correlation \\(\\rho\\), zero mean variance \\(\\sigma^2\\). variance errors \n\\[\\begin{align*}\n\\mathbb{E}\\left[\\frac{1}{M}\\sum_{m=1}^M \\epsilon_m^2 \\right]&=\\frac{1}{M^2}\\left[\\sum_{m=1}^M\\epsilon_m^2+\\sum_{m\\neq n}\\epsilon_n\\epsilon_m\\right] \\\\\n&=\\frac{\\sigma^2}{M}+\\frac{1}{M^2}\\sum_{n\\neq m} \\rho \\sigma^2 \\\\\n& =\\rho \\sigma^2 +\\frac{\\sigma^2(1-\\rho)}{M}\n\\end{align*}\\]\nsecond term converges zero \\(M\\) increases, first term remains linearly increasing \\(\\rho\\). passing, variances always positive, result implies common pairwise correlation \\(M\\) variables bounded \\(-(M-1)^{-1}\\). result interesting rarely found textbooks.One improvement proposed circumvent trouble caused correlations, advocated seminal publication (Breiman (1996)), enforce positivity constraints weights solve\\[\\underset{\\textbf{w}}{\\text{argmin}} \\ \\textbf{w}'\\textbf{E}'\\textbf{E}\\textbf{w} , \\quad \\text{s.t.} \\quad \\left\\{ \n\\begin{array}{l} \\textbf{w}'\\textbf{1}_M=1 \\\\ w_m \\ge 0 \\quad \\forall m \\end{array}\\right. .\\]Mechanically, several models highly correlated, constraint impose one nonzero weight. many models, just selected minimization program. context portfolio optimization, Jagannathan Ma (2003) shown counter-intuitive benefits constraints construction mean-variance allocations. setting, constraint similarly help discriminate wisely among ‘best’ models.literature, forecast combination model averaging (synonyms ensembles) tested stock markets early Von Holstein (1972). Surprisingly, articles published Finance journals rather fields Management (Virtanen Yli-Olli (1987), J.-J. Wang et al. (2012)), Economics Econometrics (Donaldson Kamstra (1996), Clark McCracken (2009), Mascio, Fabozzi, Zumwalt (2020)), Operations Reasearch (W. Huang, Nakamori, Wang (2005), Leung, Daouk, Chen (2001), Bonaccolto Paterlini (2019)), Computer Science (Harrald Kamstra (1997), Hassan, Nath, Kirley (2007)).general forecasting literature, many alternative (refined) methods combining forecasts studied. Trimmed opinion pools (Grushka-Cockayne, Jose, Lichtendahl Jr (2016)) compute averages predictions extreme (noisy, see Chiang, Liao, Zhou (2021)). Ensembles weights depend previous past errors developed Pike Vazquez-Grande (2020). refer Gaba, Tsetlin, Winkler (2017) exhaustive list combinations well empirical study respective efficiency. Finally, theoretical discussion model averaging versus model selection, point Peng Yang (2021).\nOverall, findings mixed heuristic simple average , usual, hard beat (see, e.g., Genre et al. (2013)).","code":""},{"path":"ensemble.html","id":"example","chapter":"11 Ensemble models","heading":"11.1.2 Example","text":"order build ensemble, must gather predictions corresponding errors \\(\\textbf{E}\\) matrix. work 5 models trained previous chapters: penalized regression, simple tree, random forest, xgboost feed-forward neural network. training errors zero means, hence \\(\\textbf{E}'\\textbf{E}\\) covariance matrix errors models.shown correlation matrix, models fail generate heterogeneity predictions. minimum correlation (though 95%!) obtained boosted tree models. , compare training accuracy models computing average absolute value errors.best performing ML engine random forest. boosted tree model worst, far. , compute optimal (non-constrained) weights combination models.high correlations, optimal weights balanced diversified: load heavily random forest learner (best sample model) ‘short’ models order compensate. one expect, model largest negative weights (Pen_reg) high correlation random forest algorithm (0.997).Note weights course computed training errors. optimal combination tested testing sample. , compute --sample (testing) errors average absolute value.boosted tree model still worst performing algorithm simple models (regression simple tree) ones fare best. naive combination simple average model predictions.errors correlated, equally weighted combination forecasts yields average error lies ‘middle’ individual errors. diversification benefits small. Let us now test ‘optimal’ combination \\(\\textbf{w}^*=\\frac{(\\textbf{E}'\\textbf{E})^{-1}\\textbf{1}_M}{(\\textbf{1}_M'\\textbf{E}'\\textbf{E})^{-1}\\textbf{1}_M}\\)., result disappointing lack diversification across models. correlations errors high training sample, also testing sample, shown .leverage optimal solution exacerbates problem underperforms heuristic uniform combination. end section constrained formulation Breiman (1996) using quadprog package. write \\(\\mathbf{\\Sigma}\\) covariance matrix errors, seek\n\\[\\mathbf{w}^*=\\underset{\\mathbf{w}}{\\text{argmin}} \\ \\mathbf{w}'\\mathbf{\\Sigma}\\mathbf{w}, \\quad \\mathbf{1}'\\mathbf{w}=1, \\quad w_i\\ge 0,\\]\nconstraints handled :\\[\\mathbf{} \\mathbf{w}= \\begin{bmatrix} \n1 & 1 & 1 \\\\\n1 & 0 & 0\\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix} \\mathbf{w} \\hspace{9mm} \\text{ compared } \\hspace{9mm} \\mathbf{b}=\\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix},  \\]first line equality (weights sum one) last three inequalities (weights positive).Compared unconstrained solution, weights sparse concentrated one two models, usually small training sample errors.","code":"\nerr_pen_train <- predict(fit_pen_pred, x_penalized_train) - training_sample$R1M_Usd  # Reg.\nerr_tree_train <- predict(fit_tree, training_sample) - training_sample$R1M_Usd       # Tree\nerr_RF_train <- predict(fit_RF, training_sample) - training_sample$R1M_Usd           # RF\nerr_XGB_train <- predict(fit_xgb, train_matrix_xgb) - training_sample$R1M_Usd        # XGBoost\nerr_NN_train <- predict(model, NN_train_features) - training_sample$R1M_Usd          # NN\nE <- cbind(err_pen_train, err_tree_train, err_RF_train, err_XGB_train, err_NN_train) # E matrix\ncolnames(E) <- c(\"Pen_reg\", \"Tree\", \"RF\", \"XGB\", \"NN\")                               # Names\ncor(E)                                                                               # Cor. mat.##           Pen_reg      Tree        RF       XGB        NN\n## Pen_reg 1.0000000 0.9984394 0.9968224 0.9310186 0.9933772\n## Tree    0.9984394 1.0000000 0.9974647 0.9296081 0.9952573\n## RF      0.9968224 0.9974647 1.0000000 0.9281725 0.9960774\n## XGB     0.9310186 0.9296081 0.9281725 1.0000000 0.9249837\n## NN      0.9933772 0.9952573 0.9960774 0.9249837 1.0000000\napply(abs(E), 2, mean) # Mean absolute error or columns of E ##    Pen_reg       Tree         RF        XGB         NN \n## 0.08345916 0.08362133 0.08327121 0.08986993 0.08444371\nw_ensemble <- solve(t(E) %*% E) %*% rep(1,5)                             # Optimal weights\nw_ensemble <- w_ensemble / sum(w_ensemble)\nw_ensemble##                 [,1]\n## Pen_reg -0.523861499\n## Tree    -0.008467403\n## RF       1.409400628\n## XGB     -0.001480602\n## NN       0.124408875\nerr_pen_test <- predict(fit_pen_pred, x_penalized_test) - testing_sample$R1M_Usd     # Reg.\nerr_tree_test <- predict(fit_tree, testing_sample) - testing_sample$R1M_Usd          # Tree\nerr_RF_test <- predict(fit_RF, testing_sample) - testing_sample$R1M_Usd              # RF\nerr_XGB_test <- predict(fit_xgb, xgb_test) - testing_sample$R1M_Usd                  # XGBoost\nerr_NN_test <- predict(model, NN_test_features) - testing_sample$R1M_Usd             # NN\nE_test <- cbind(err_pen_test, err_tree_test, err_RF_test, err_XGB_test, err_NN_test) # E matrix\ncolnames(E_test) <- c(\"Pen_reg\", \"Tree\", \"RF\", \"XGB\", \"NN\")\napply(abs(E_test), 2, mean)             # Mean absolute error or columns of E ##    Pen_reg       Tree         RF        XGB         NN \n## 0.06618181 0.06653527 0.06710349 0.07170801 0.06889048\nerr_EW_test <- apply(E_test, 1, mean)  # Equally weighted combination\nmean(abs(err_EW_test))## [1] 0.06717362\nerr_opt_test <- E_test %*% w_ensemble   # Optimal unconstrained combination\nmean(abs(err_opt_test))## [1] 0.06837302\ncor(E_test)##           Pen_reg      Tree        RF       XGB        NN\n## Pen_reg 1.0000000 0.9987069 0.9968882 0.9537914 0.9935255\n## Tree    0.9987069 1.0000000 0.9978366 0.9583641 0.9955690\n## RF      0.9968882 0.9978366 1.0000000 0.9606570 0.9966003\n## XGB     0.9537914 0.9583641 0.9606570 1.0000000 0.9626207\n## NN      0.9935255 0.9955690 0.9966003 0.9626207 1.0000000\nlibrary(quadprog)                       # Package for quadratic programming\nSigma <- t(E) %*% E                     # Unscaled covariance matrix\nnb_mods <- nrow(Sigma)                  # Number of models\nw_const <- solve.QP(Dmat = Sigma,       # D matrix =  Sigma\n              dvec = rep(0, nb_mods),   # Zero vector\n              Amat = rbind(rep(1, nb_mods), diag(nb_mods)) %>% t(), # A matrix for constraints\n              bvec = c(1,rep(0, nb_mods)),                          # b vector for constraints\n              meq = 1                   # 1 line of equality constraints, others = inequalities\n              )\nw_const$solution %>% round(3)           # Solution## [1] 0.000 0.000 0.906 0.000 0.094"},{"path":"ensemble.html","id":"stacked-ensembles","chapter":"11 Ensemble models","heading":"11.2 Stacked ensembles","text":"","code":""},{"path":"ensemble.html","id":"two-stage-training","chapter":"11 Ensemble models","heading":"11.2.1 Two-stage training","text":"Stacked ensembles natural generalization linear ensembles. idea generalizing linear ensembles goes back least Wolpert (1992b). general case, training performed two stages. first stage simple one, whereby \\(M\\) models trained independently, yielding predictions \\(\\tilde{y}_{,m}\\) instance \\(\\) model \\(m\\). second step consider output trained models input new level machine learning optimization. second level predictions \\(\\breve{y}_i=h(\\tilde{y}_{,1},\\dots,\\tilde{y}_{,M})\\), \\(h\\) new learner (see Figure 11.1). Linear ensembles course stacked ensembles second layer linear regression.techniques applied minimize error true values \\(y_i\\) predicted ones \\(\\breve{y}_i\\).\nFIGURE 11.1: Scheme stacked ensembles.\n","code":""},{"path":"ensemble.html","id":"code-and-results-4","chapter":"11 Ensemble models","heading":"11.2.2 Code and results","text":", create low-dimensional neural network takes individual predictions model compiles synthetic forecast.configuration simple. include optional arguments hence model likely overfit. seek predict returns, loss function standard \\(L^2\\) norm.\nFIGURE 11.2: Training metrics ensemble model.\nperformance ensemble disappointing: learning curve flat Figure 11.2, hence rounds back-propagation useless. training adds little value means new overarching layer ML enhance original predictions. , ML engines seem capturing patterns linear non-linear combinations fail improve performance.","code":"\nmodel_stack <- keras_model_sequential()\nmodel_stack %>%   # This defines the structure of the network, i.e. how layers are organized\n    layer_dense(units = 8, activation = 'relu', input_shape = nb_mods) %>%\n    layer_dense(units = 4, activation = 'tanh') %>%\n    layer_dense(units = 1) \nmodel_stack %>% compile(                       # Model specification\n    loss = 'mean_squared_error',               # Loss function\n    optimizer = optimizer_rmsprop(),           # Optimisation method (weight updating)\n    metrics = c('mean_absolute_error')         # Output metric\n)\nsummary(model_stack)                           # Model architecture## Model: \"sequential_29\"\n## __________________________________________________________________________________________\n## Layer (type)                            Output Shape                        Param #       \n## ==========================================================================================\n## dense_74 (Dense)                        (None, 8)                           48            \n## __________________________________________________________________________________________\n## dense_73 (Dense)                        (None, 4)                           36            \n## __________________________________________________________________________________________\n## dense_72 (Dense)                        (None, 1)                           5             \n## ==========================================================================================\n## Total params: 89\n## Trainable params: 89\n## Non-trainable params: 0\n## __________________________________________________________________________________________\ny_tilde <- E + matrix(rep(training_sample$R1M_Usd, nb_mods), ncol = nb_mods)    # Train preds\ny_test <- E_test + matrix(rep(testing_sample$R1M_Usd, nb_mods), ncol = nb_mods) # Testing\nfit_NN_stack <- model_stack %>% fit(y_tilde,                                  # Train features\n                     training_sample$R1M_Usd,                                 # Train labels\n                     epochs = 12, batch_size = 512,                           # Train parameters\n                     validation_data = list(y_test,                           # Test features\n                                            testing_sample$R1M_Usd)           # Test labels\n)\nplot(fit_NN_stack)                                                            # Plot, evidently!"},{"path":"ensemble.html","id":"extensions-1","chapter":"11 Ensemble models","heading":"11.3 Extensions","text":"","code":""},{"path":"ensemble.html","id":"exogenous-variables","chapter":"11 Ensemble models","heading":"11.3.1 Exogenous variables","text":"financial context, macro-economic indicators add value process. possible models perform better certain conditions exogenous predictors can help introduce flavor economic-driven conditionality predictions.Adding macro-variables set predictors (, predictions) \\(\\tilde{y}_{,m}\\) seem like one way achieve . However, amount mix predicted values (possibly scaled) economic indicators make much sense.One alternative outside perimeter ensembles train simple trees set macro-economic indicators. labels (possibly absolute) errors stemming original predictions, trees create clusters homogeneous error values. hint towards conditions lead best worst forecasts.\ntest idea , using aggregate data Federal Reserve Saint Louis. simple downloading function available quantmod package. download format data next chunk. CPIAUCSL code consumer price index T10Y2YM code term spread (10Y minus 2Y).can now build tree tries explain accuracy models function macro-variables.\nFIGURE 11.3: Conditional performance ML engine.\ntree creates clusters homogeneous values absolute errors. One big cluster gathers 92% predictions (left one) one smallest average. corresponds periods term spread 0.29 (percentage points). two groups (term spread 0.29%) determined according level inflation. latter positive, average absolute error 7%, , 12%. last number, highest three clusters, indicates term spread low inflation negative, model’s predictions trustworthy errors magnitude twice large periods. circumstances (seem linked dire economic environment), may wiser use ML-based forecasts.","code":"\nlibrary(quantmod)                                     # Package that extracts the data\nlibrary(lubridate)                                    # Package for date management\ngetSymbols(\"CPIAUCSL\", src = \"FRED\")                  # FRED is the Fed of St Louis## [1] \"CPIAUCSL\"\ngetSymbols(\"T10Y2YM\", src = \"FRED\") ## [1] \"T10Y2YM\"\ncpi <- fortify(CPIAUCSL) %>% \n    mutate (inflation = CPIAUCSL / lag(CPIAUCSL) - 1) # Inflation via Consumer Price Index\nts <- fortify(T10Y2YM)                                # Term spread (10Y minus 2Y rates)\ncolnames(ts)[2] <- \"termspread\"                       # To make things clear\nens_data <- testing_sample %>%                        # Creating aggregate dataset\n    dplyr::select(date) %>% \n    cbind(err_NN_test) %>%\n    mutate(Index = make_date(year = lubridate::year(date),  # Change date to first day of month\n                             month = lubridate::month(date), \n                             day = 1)) %>% \n    left_join(cpi) %>%                                # Add CPI to the dataset\n    left_join(ts)                                     # Add termspread\nhead(ens_data)                                        # Show first lines##         date  err_NN_test      Index CPIAUCSL   inflation termspread\n## 1 2014-01-31 -0.151823168 2014-01-01  235.288 0.002424175       2.47\n## 2 2014-02-28  0.076599573 2014-02-01  235.547 0.001100779       2.38\n## 3 2014-03-31  0.002358824 2014-03-01  236.028 0.002042055       2.32\n## 4 2014-04-30 -0.059511532 2014-04-01  236.468 0.001864186       2.29\n## 5 2014-05-31 -0.076865514 2014-05-01  236.918 0.001903006       2.17\n## 6 2014-06-30  0.050708934 2014-06-01  237.231 0.001321132       2.15\nlibrary(rpart.plot)     # Load package for tree plotting\nfit_ens <- rpart(abs(err_NN_test) ~ inflation + termspread, # Tree model\n                 data = ens_data,\n                 cp = 0.001)                                # Complexity param (size of tree)\nrpart.plot(fit_ens)                                         # Plot tree"},{"path":"ensemble.html","id":"shrinking-inter-model-correlations","chapter":"11 Ensemble models","heading":"11.3.2 Shrinking inter-model correlations","text":"\nshown earlier chapter, one major problem ensembles arises first layer predictions highly correlated. case, ensembles pretty much useless. several tricks can help reduce correlation, simplest best probably alter training samples. algorithms see data, probably infer different patterns.several ways split training data build different subsets training samples. first dichotomy random versus deterministic splits. Random splits easy require target sample size fixed. Note training samples can overlapping long overlap large. Hence original training sample \\(\\) instance ensemble requires \\(M\\) models, subsample size \\(\\lfloor /M \\rfloor\\) may conservative especially training sample large. case \\(\\lfloor /\\sqrt{M} \\rfloor\\) may better alternative. Random forests one example ensembles built random training samples.One advantage deterministic splits easy reproduce outcome depend random seed. nature factor-based training samples, second splitting dichotomy time assets. split within assets straightforward: model trained different set stocks. Note choices sets can random, dictacted factor-based criterion: size, momentum, book--market ratio, etc.split dates requires decisions: data split large blocks (like years) model gets block, may stand one particular kind market condition? training dates divided regularly? instance, 12 models ensemble, model can trained data given month (e.g., January first models, February second, etc.)., train four models four different years see helps reduce inter-model correlations. process bit lengthy samples models need redefined. start creating four training samples. third model works small subset features, hence sample smaller., proceed training models. syntaxes used previous chapters, nothing new . start penalized regression. predictions , original testing sample used models.continue random forest.third model boosted tree.Finally, last model simple neural network.Endowed errors four models, can compute correlation matrix.results overall disappointing. one model manages extract patterns somewhat different ones, resulting 65% correlation across board. Neural networks (2013 data) penalized regressions (2007) remain highly correlated. One possible explanation models capture mainly noise little signal. Working long-term labels like annual returns help improve diversification across models.  ","code":"\ntraining_sample_2007 <- training_sample %>% \n    filter(date > \"2006-12-31\", date < \"2008-01-01\")\ntraining_sample_2009 <- training_sample %>% \n    filter(date > \"2008-12-31\", date < \"2010-01-01\")\ntraining_sample_2011 <- training_sample %>% \n    dplyr::select(c(\"date\",features_short, \"R1M_Usd\")) %>%\n    filter(date > \"2010-12-31\", date < \"2012-01-01\")\ntraining_sample_2013 <- training_sample %>% \n    filter(date > \"2012-12-31\", date < \"2014-01-01\")\ny_ens_2007 <- training_sample_2007$R1M_Usd                                       # Dep. var.\nx_ens_2007 <- training_sample_2007 %>%                                           # Predictors\n    dplyr::select(features) %>% as.matrix() \nfit_ens_2007 <- glmnet(x_ens_2007, y_ens_2007, alpha = 0.1, lambda = 0.1)        # Model\nerr_ens_2007 <- predict(fit_ens_2007, x_penalized_test) - testing_sample$R1M_Usd # Pred. errs\nfit_ens_2009 <- randomForest(formula,            # Same formula as for simple trees!\n                 data = training_sample_2009,    # Data source: 2011 training sample\n                 sampsize = 4000,                # Size of (random) sample for each tree\n                 replace = FALSE,                # Is the sampling done with replacement?\n                 nodesize = 100,                 # Minimum size of terminal cluster\n                 ntree = 40,                     # Nb of random trees\n                 mtry = 30                       # Nb of predictive variables for each tree\n    )\nerr_ens_2009 <- predict(fit_ens_2009, testing_sample) - testing_sample$R1M_Usd # Pred. errs\ntrain_features_2011 <- training_sample_2011 %>% \n    dplyr::select(features_short) %>% as.matrix()               # Independent variable\ntrain_label_2011 <- training_sample_2011 %>%\n    dplyr::select(R1M_Usd) %>% as.matrix()                      # Dependent variable\ntrain_matrix_2011 <- xgb.DMatrix(data = train_features_2011, \n                                label = train_label_2011)       # XGB format!\nfit_ens_2011 <- xgb.train(data = train_matrix_2011,             # Data source \n              eta = 0.4,                                        # Learning rate\n              objective = \"reg:linear\",                         # Objective function\n              max_depth = 4,                                    # Maximum depth of trees\n              nrounds = 18                                      # Number of trees used\n    )## [14:58:00] WARNING: amalgamation/../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\nerr_ens_2011 <- predict(fit_ens_2011, xgb_test) -  testing_sample$R1M_Usd # Prediction errors\nNN_features_2013 <- dplyr::select(training_sample_2013, features) %>% \n    as.matrix()      # Matrix format is important\nNN_labels_2013 <- training_sample_2013$R1M_Usd\nmodel_ens_2013 <- keras_model_sequential()\nmodel_ens_2013 %>%   # This defines the structure of the network, i.e. how layers are organized\n    layer_dense(units = 16, activation = 'relu', input_shape = ncol(NN_features_2013)) %>%\n    layer_dense(units = 8, activation = 'tanh') %>%\n    layer_dense(units = 1) \nmodel_ens_2013 %>% compile(                    # Model specification\n    loss = 'mean_squared_error',               # Loss function\n    optimizer = optimizer_rmsprop(),           # Optimisation method (weight updating)\n    metrics = c('mean_absolute_error')         # Output metric\n)\nmodel_ens_2013 %>% fit(NN_features_2013,                        # Training features\n                       NN_labels_2013,                          # Training labels\n                       epochs = 9, batch_size = 128             # Training parameters\n)\nerr_ens_2013 <- predict(model_ens_2013, NN_test_features) - testing_sample$R1M_Usd\nE_subtraining <- tibble(err_ens_2007,\n                        err_ens_2009,\n                        err_ens_2011,\n                        err_ens_2013)\ncor(E_subtraining)##              err_ens_2007 err_ens_2009 err_ens_2011 err_ens_2013\n## err_ens_2007    1.0000000    0.9570006    0.6460091    0.9993493\n## err_ens_2009    0.9570006    1.0000000    0.6290043    0.9589916\n## err_ens_2011    0.6460091    0.6290043    1.0000000    0.6458086\n## err_ens_2013    0.9993493    0.9589916    0.6458086    1.0000000"},{"path":"ensemble.html","id":"exercise","chapter":"11 Ensemble models","heading":"11.4 Exercise","text":"Build integrated ensemble top 3 neural networks trained entirely Keras. network obtains one third predictors input. three networks yield classification (yes/buy/sell). overarching network aggregates three outputs final decision. Evaluate performance testing sample. Use functional API.","code":""},{"path":"backtest.html","id":"backtest","chapter":"12 Portfolio backtesting","heading":"12 Portfolio backtesting","text":"\n\nsection, introduce notations framework used analyzing comparing investment strategies. Portfolio backtesting often conceived perceived quest find best strategy - least solidly profitable one. carried thoroughly, possibly long endeavor may entice layman confuse fluke robust policy. Two papers published back--back warn perils data snooping, related \\(p\\)-hacking. cases, researcher torture data sought result found.Fabozzi Prado (2018) acknowledge strategies work make public, thousands (least) tested. Picking pleasing outlier (strategy seemed work) likely generate disappointment switching real trading. similar vein, R. Arnott, Harvey, Markowitz (2019) provide list principles safeguards analyst follow avoid type error backtesting strategies. worst type arguably false positives whereby strategies found (often cherrypicking) outperform one particular setting, likely fail live implementation.addition recommendations portfolio constructions, R. Arnott et al. (2019) also warn hazards blindly investing smart beta products related academic factors. Plainly, expectations set high face risk disappointed. Another takeaway article economic cycles strong impact factor returns: correlations change quickly drawdowns can magnified times major downturns.Backtesting complicated seems easy make small mistakes lead apparently good portfolio policies. chapter lays rigorous approach exercise, discusses caveats, proposes lengthy example.","code":""},{"path":"backtest.html","id":"protocol","chapter":"12 Portfolio backtesting","heading":"12.1 Setting the protocol","text":"consider dataset three dimensions: time \\(t=1,\\dots,T\\), assets \\(n=1,\\dots,N\\) characteristics \\(k=1,\\dots,K\\). One attributes must price asset \\(n\\) time \\(t\\), denote \\(p_{t,n}\\). , computation arithmetic return straightforward (\\(r_{t,n}=p_{t,n}/p_{t-1,n}-1\\)) heuristic measure profitability. simplicity, assume time points equidistant uniform, .e., \\(t\\) index trading day month example. point time \\(t\\) data available assets, makes dataset \\(=T\\times N\\) rows.dataset first split two: --sample period initial buffer period. buffer period required train models first portfolio composition. period determined size training sample. two options size: fixed (usually equal 2 10 years) expanding. first case, training sample roll time, taking account recent data. second case, models built available data, size increases time. last option can create problems first dates backtest based much smaller amounts information compared last dates. Moreover, ongoing debate whether including full history returns characteristics advantageous . Proponents argue allows models see many different market conditions. Opponents make case old data definition outdated thus useless possibly misleading won’t reflect current future short-term fluctuations.Henceforth, choose rolling period option training sample, depicted Figure 12.1.\nFIGURE 12.1: Backtesting rolling windows. training set first period simply buffer period.\nTwo crucial design choices rebalancing frequency horizon label computed. obvious equal choice make sense. can seem right train 12-month forward label (captures longer trends) invest monthly quarterly. However, seems odd opposite train short-term movements (monthly) invest long horizon.choices direct impact backtest carried . note:\\(\\Delta_h\\) holding period 2 rebalancing dates (days months);\\(\\Delta_s\\) size desired training sample (days months - taking number assets consideration);\\(\\Delta_l\\) horizon label computed (days months),total length training sample \\(\\Delta_s+\\Delta_l\\). Indeed, moment \\(t\\), training sample stop \\(t-\\Delta_l\\) last point corresponds label calculated time \\(t\\). highlighted Figure 12.2 form red danger zone. call red zone observation time index \\(s\\) inside interval \\((t-\\Delta_l,t]\\) engender forward looking bias. Indeed feature indexed \\(s \\(t-\\Delta_l,t]\\), definition, label covers period \\([s,s+\\Delta_l]\\) \\(s+\\Delta_l>t\\). time \\(t\\), requires knowledge future naturally realistic.\nFIGURE 12.2: subtleties rolling training samples.\n","code":""},{"path":"backtest.html","id":"turning-signals-into-portfolio-weights","chapter":"12 Portfolio backtesting","heading":"12.2 Turning signals into portfolio weights","text":"predictive tools outlined Chapters 5 11 meant provide signal expected give information future profitability assets. many ways signal can integrated investment decision (see Snow (2020) ways integrate ML tools task).First foremost, least two steps portfolio construction process signal can used stages. Relying signal steps puts lot emphasis predictions considered level confidence forecasts high.first step selection. forecasting exercise can carried large number assets, compulsory invest assets. fact, long-portfolios, make sense take advantage signal exclude assets presumably likely underperform future. Often, portfolio policies fixed sizes impose constant number assets. One heuristic way exploit signal select assets favorable predictions discard others. naive idea often used asset pricing literature: portfolios formed according quantiles underlying characteristics characteristics deemed interesting corresponding sorted portfolios exhibit different profitabilities (e.g., high average return high quantiles versus low average return low quantiles).instance efficient way test relevance signal. \\(Q\\) portfolios \\(q=1,\\dots,Q\\) formed according rankings assets respect signal, one expect --sample performance portfolios monotonic \\(q\\). rigorous test monotonicity require account portfolios (see, e.g., Romano Wolf (2013)), often assumed extreme portfolios suffice. difference portfolio number 1 portfolio number \\(Q\\) substantial, signal valuable. Whenever investor able short assets, amounts dollar neutral strategy.second step weighting. selection process relied signal, simple weighting scheme often good idea. Equally weighted portfolios known hard beat (see DeMiguel, Garlappi, Uppal (2009)), especially compared cap-weighted alternative, shown Plyakha, Uppal, Vilkov (2016). advanced schemes include equal risk contributions (Maillard, Roncalli, Teiletche (2010)) constrained minimum variance (Coqueret (2015)). rely covariance matrix assets proxy vector expected returns.sake completeness, explicitize generalization Coqueret (2015) generic constrained quadratic program:\n\\[\\begin{equation}\n\\tag{12.1}\n\\underset{\\textbf{w}}{\\text{min}} \\ \\frac{\\lambda}{2} \\textbf{w}'\\boldsymbol{\\Sigma}\\textbf{w}-\\textbf{w}'\\boldsymbol{\\mu} , \\quad \\text{s.t.} \\quad \\begin{array}{ll} \\textbf{w}'\\textbf{1}=1, \\\\ (\\textbf{w}-\\textbf{w}_-)'\\boldsymbol{\\Lambda}(\\textbf{w}-\\textbf{w}_-) \\le \\delta_R,\\\\\n\\textbf{w}'\\textbf{w} \\le \\delta_D,\n\\end{array}\n\\end{equation}\\]easy recognize usual mean-variance optimization left-hand side. impose three constraints right-hand side.24 first one budget constraint (weights sum one). second one penalizes variations weights (compared current allocation, \\(\\textbf{w}_-\\)) via diagonal matrix \\(\\boldsymbol{\\Lambda}\\) penalizes trading costs. crucial point. Portfolios rarely constructed scratch time adjustments existing positions. order reduce orders corresponding transaction costs, possible penalize large variations existing portfolio. program, current weights written \\(\\textbf{w}_-\\) desired ones \\(\\textbf{w}\\) \\(\\textbf{w}-\\textbf{w}_-\\) vector deviations current positions. term \\((\\textbf{w}-\\textbf{w}_-)'\\boldsymbol{\\Lambda}(\\textbf{w}-\\textbf{w}_-)\\) expression characterizes sum squared deviations, weighted diagonal coefficients \\(\\Lambda_{n,n}\\). can helpful assets may costly trade due liquidity (large cap stocks liquid trading costs lower). \\(\\delta_R\\) decreases, rotation reduced weights allowed deviate much \\(\\textbf{w}_-\\). last constraint enforces diversification via Herfindhal-Hirschmann index portfolio: smaller \\(\\delta_D\\), diversified portfolio.Recalling \\(N\\) assets universe, Lagrange form (12.1) :\\[\\begin{equation}\n\\tag{12.2}\nL(\\textbf{w})= \\frac{\\lambda}{2} \\textbf{w}'\\boldsymbol{\\Sigma}\\textbf{w}-\\textbf{w}'\\boldsymbol{\\mu}-\\eta (\\textbf{w}'\\textbf{1}_N-1)+\\kappa_R ( (\\textbf{w}-\\textbf{w}_-)'\\boldsymbol{\\Lambda}(\\textbf{w}-\\textbf{w}_-) - \\delta_R)+\\kappa_D(\\textbf{w}'\\textbf{w}-\\delta_D),\n\\end{equation}\\]first order condition\n\\[\\frac{\\partial}{\\partial \\textbf{w}}L(\\textbf{w})= \\lambda \\boldsymbol{\\Sigma}\\textbf{w}-\\boldsymbol{\\mu}-\\eta\\textbf{1}_N+2\\kappa_R \\boldsymbol{\\Lambda}(\\textbf{w}-\\textbf{w}_-)+2\\kappa_D\\textbf{w}=0,\\]\nyields\n\\[\\begin{equation}\n\\tag{12.3}\n\\textbf{w}^*_\\kappa=  (\\lambda \\boldsymbol{\\Sigma}+2\\kappa_R \\boldsymbol{\\Lambda} +2\\kappa_D\\textbf{}_N)^{-1} \\left(\\boldsymbol{\\mu} + \\eta_{\\lambda,\\kappa_R,\\kappa_D} \\textbf{1}_N+2\\kappa_R \\boldsymbol{\\Lambda}\\textbf{w}_-\\right),\n\\end{equation}\\]\n\n\\[\\eta_{\\lambda,\\kappa_R,\\kappa_D}=\\frac{1- \\textbf{1}_N'(\\lambda\\boldsymbol{\\Sigma}+2\\kappa_R \\boldsymbol{\\Lambda}+2\\kappa_D\\textbf{}_N)^{-1}(\\boldsymbol{\\mu}+2\\kappa_R\\boldsymbol{\\Lambda}\\textbf{w}_-)}{\\textbf{1}'_N(\\lambda \\boldsymbol{\\Sigma}+2\\kappa_R \\boldsymbol{\\Lambda}+2\\kappa_D\\textbf{}_N)^{-1}\\textbf{1}_N}.\\]parameter ensures budget constraint satisfied. optimal weights (12.3) depend three tuning parameters: \\(\\lambda\\), \\(\\kappa_R\\) \\(\\kappa_D\\).\n- \\(\\lambda\\) large, focus set risk reduction profit maximization (often good idea given risk easier predict);\n- \\(\\kappa_R\\) large, importance transaction costs (12.2) high thus, limit \\(\\kappa_R \\rightarrow \\infty\\), optimal weights equal old ones \\(\\textbf{w}_-\\) (finite values parameters).\n- \\(\\kappa_D\\) large, portfolio diversified (things equal) \\(\\kappa_D \\rightarrow \\infty\\), weights equal (\\(1/N\\)).\n- \\(\\kappa_R=\\kappa_D=0\\), recover classical mean-variance weights mix maximum Sharpe ratio portfolio proportional \\((\\boldsymbol{\\Sigma})^{-1} \\boldsymbol{\\mu}\\) minimum variance portfolio proportional \\((\\boldsymbol{\\Sigma})^{-1} \\textbf{1}_N\\).seemingly complex formula fact flexible tractable. requires tests adjustments finding realistic values \\(\\lambda\\), \\(\\kappa_R\\) \\(\\kappa_D\\) (see exercise end chapter). Pedersen, Babu, Levine (2020), authors recommend similar form, except covariance matrix shrunk towards diagonal matrix sample variances expected returns mix signal anchor portfolio. authors argue general formulation links robust optimization (see also W. C. Kim, Kim, Fabozzi (2014)), Bayesian inference (Lai et al. (2011)), matrix denoising via random matrix theory, , naturally, shrinkage. fact, shrunk expected returns around quite time (Jorion (1985), Kan Zhou (2007) Bodnar, Parolya, Schmid (2013)) simply seek diversify reduce estimation risk.","code":""},{"path":"backtest.html","id":"perfmet","chapter":"12 Portfolio backtesting","heading":"12.3 Performance metrics","text":"evaluation performance key stage backtest. section, exhaustive, intended cover important facets portfolio assessment.","code":""},{"path":"backtest.html","id":"discussion-1","chapter":"12 Portfolio backtesting","heading":"12.3.1 Discussion","text":"evaluation accuracy ML tools (See Section 10.1) course valuable (imperative!), portfolio returns ultimate yardstick backtest. One essential element exercise benchmark raw absolute metrics don’t mean much .true portfolio level, also ML engine level. trials previous chapters, MSE models testing set revolves around 0.037. interesting figure variance one-month returns set, corresponds error made constant prediction 0 time. figure equal 0.037, means sophisticated algorithms don’t really improve naive heuristic. benchmark one used --sample \\(R^2\\) Gu, Kelly, Xiu (2020b).portfolio choice, elementary allocation uniform one, whereby asset receives weight. seemingly simplistic solution fact incredible benchmark, one hard beat consistently (see DeMiguel, Garlappi, Uppal (2009) Plyakha, Uppal, Vilkov (2016)). Theoretically, uniform portfolios optimal uncertainty, ambiguity estimation risk high (Pflug, Pichler, Wozabal (2012), Maillet, Tokpavi, Vaucher (2015)) empirically, outperformed even factor level (Dichtl, Drobetz, Wendt (2020)). , pick equally weighted (EW) portfolio stocks benchmark.","code":""},{"path":"backtest.html","id":"pure-performance-and-risk-indicators","chapter":"12 Portfolio backtesting","heading":"12.3.2 Pure performance and risk indicators","text":"turn definition usual metrics used practitioners academics alike. Henceforth, write \\(r^P=(r_t^P)_{1\\le t\\le T}\\) \\(r^B=(r_t^B)_{1\\le t\\le T}\\) returns portfolio benchmark, respectively. referring generic returns, simply write \\(r_t\\). many ways analyze rely distribution.simplest indicator average return:\n\\[\\bar{r}_P=\\mu_P=\\mathbb{E}[r^P]\\approx \\frac{1}{T}\\sum_{t=1}^T r_t^P, \\quad \\bar{r}_B=\\mu_B=\\mathbb{E}[r^B]\\approx \\frac{1}{T}\\sum_{t=1}^T r_t^B,\\], obviously, portfolio noteworthy \\(\\mathbb{E}[r^P]>\\mathbb{E}[r^B]\\). Note use arithmetic average geometric one also option, case:\n\\[\\tilde{\\mu}_P\\approx \\left(\\prod_{t=1}^T(1+r^P_t) \\right)^{1/T}-1 , \\quad \\tilde{\\mu}_B \\approx  \\left(\\prod_{t=1}^T(1+r^B_t) \\right)^{1/T}-1.\\]\nbenefit second definition takes compounding returns account hence compensates volatility pumping. see , consider simple two-period model returns \\(-r\\) \\(+r\\). arithmetic average zero, geometric one \\(\\sqrt{1-r^2}-1\\) negative.Akin accuracy, ratios evaluate proportion times position right direction (long realized return positive short negative). Hence hit ratios evaluate propensity make good guesses. can computed asset level (proportion positions correct direction25) portfolio level. cases, computation can performed raw returns relative returns (e.g., compared benchmark). meaningful hit ratio proportion times strategy beats benchmark. course sufficient, many small gains can offset large losses.Lastly, one important precision. examples supervised learning tools book, compared hit ratios 0.5. fact wrong investor bullish, may always bet upward moves. case, hit ratio percentage time returns positive. long run, probability 0.5. sample, equal 0.556, well 0.5. viewed benchmark surpassed.Pure performance measures almost always accompanied risk measures. second moment returns usually used quantify magnitude fluctuations portfolio. large variance implies sizable movements returns, hence portfolio values. standard deviation returns called volatility portfolio.\n\\[\\sigma^2_P=\\mathbb{V}[r^P]\\approx \\frac{1}{T-1}\\sum_{t=1}^T (r_t^P-\\mu_P)^2, \\quad \\sigma^2_B=\\mathbb{V}[r^B]\\approx \\frac{1}{T-1}\\sum_{t=1}^T (r_t^B-\\mu_B)^2.\\]case, portfolio can preferred less risky compared benchmark, .e., \\(\\sigma_P^2<\\sigma_B^2\\) average returns equal (comparable).Higher order moments returns sometimes used (skewness kurtosis), far less common. refer instance C. R. Harvey et al. (2010) one method takes account portfolio construction process.people, volatility incomplete measure risk. can argued decomposed ‘good’ volatility (prices go ) versus ‘bad’ volatility go . downward semi-variance computed variance taken negative returns:\n\\[\\sigma^2_-\\approx \\frac{1}{\\text{card}(r_t<0)}\\sum_{t=1}^T (r_t-\\mu_P)^21_{\\{r_t<0\\}}.\\]average return volatility typical moment-based metrics used practitioners. indicators rely different aspects distribution returns focus tails extreme events. Value--Risk (VaR) one example. \\(F_r\\) empirical cdf returns, VaR level confidence \\(\\alpha\\) (often taken 95%) \n\\[\\text{VaR}_\\alpha(\\textbf{r}_t)=F_r(1-\\alpha).\\]equal realization bad scenario (return) expected happen \\((1-\\alpha)\\)% time average.\neven conservative measure -called Conditional Value Risk (CVaR), also known expected shortfall, computes average loss worst (\\(1-\\alpha\\))% scenarios. empirical evaluation \n\\[\\text{CVaR}_\\alpha(\\textbf{r}_t)=\\frac{1}{\\text{Card}(r_t < \\text{VaR}_\\alpha(\\text{r}_t))}\\sum_{r_t < \\text{VaR}_\\alpha(\\text{r}_t)}r_t.\\]Going crescendo severity risk measures, ultimate evaluation loss maximum drawdown. equal maximum loss suffered peak value strategy. write \\(P_t\\) time-\\(t\\) value portfolio, drawdown \n\\[D_T^P=\\underset{0 \\le t \\le T}{\\text{max}} P_t-P_T ,\\]\nmaximum drawdown \n\\[MD_T^P=\\underset{0 \\le s \\le T}{\\text{max}} \\left(\\underset{0 \\le t \\le s}{\\text{max}} P_t-P_s, 0\\right) .\\]quantity evaluates greatest loss time frame \\([0,T]\\) thus conservative risk measure .","code":""},{"path":"backtest.html","id":"factor-based-evaluation","chapter":"12 Portfolio backtesting","heading":"12.3.3 Factor-based evaluation","text":"spirit factor models, performance can also assessed lens exposures. recall original formulation Equation (3.1):\n\\[r_{t,n}= \\alpha_n+\\sum_{k=1}^K\\beta_{t,k,n}f_{t,k}+\\epsilon_{t,n}, \\]estimated \\(\\hat{\\alpha}_n\\) performance explained factors. returns excess returns (risk-free rate) one factor, market factor, quantity called Jensen’s alpha (Jensen (1968)). Often, simply referred alpha. estimate, \\(\\hat{\\beta}_{t,M,n}\\) (\\(M\\) market), market beta.rise factor investing, become customary also report alpha exhaustive regressions. Adding size value premium (Fama French (1993)) even momentum (Carhart (1997)) helps understand strategy generates value beyond can obtained usual factors.","code":""},{"path":"backtest.html","id":"risk-adjusted-measures","chapter":"12 Portfolio backtesting","heading":"12.3.4 Risk-adjusted measures","text":"Now, tradeoff average return volatility cornerstone modern finance, since Markowitz (1952). simplest way synthesize metrics via information ratio:\n\\[IR(P,B)=\\frac{\\mu_{P-B}}{\\sigma_{P-B}},\\]\nindex \\(P-B\\) implies mean standard deviations computed long-short portfolio returns \\(r_t^P-r_t^B\\). denominator \\(\\sigma_{P-B}\\) sometimes called tracking error.widespread information ratio Sharpe ratio (Sharpe (1966)) benchmark riskless asset. Instead directly computing information ratio two portfolios strategies, often customary compare Sharpe ratios. Simple comparisons can benefit statistical tests (see, e.g., Oliver Ledoit Wolf (2008)).extreme risk measures can serve denominator risk-adjusted indicators. Managed Account Report (MAR) ratio , example, computed \n\\[MAR^P = \\frac{\\tilde{\\mu}_P}{MD^P},\\]\nTreynor ratio equal \n\\[\\text{Treynor}=\\frac{\\mu_P}{\\hat{\\beta}_M},\\]\n.e., (excess) return divided market beta (see Treynor (1965)). definition generalized multifactor expositions Hübner (2005) generalized Treynor ratio:\n\\[\\text{GT}=\\mu_P\\frac{\\sum_{k=1}^K\\bar{f}_k}{\\sum_{k=1}^K\\hat{\\beta}_k\\bar{f}_k},\\]\n\\(\\bar{f}_k\\) sample average factors \\(f_{t,k}\\). refer original article detailed account analytical properties ratio.","code":""},{"path":"backtest.html","id":"transaction-costs-and-turnover","chapter":"12 Portfolio backtesting","heading":"12.3.5 Transaction costs and turnover","text":"\nUpdating portfolio composition free. generality, total cost one rebalancing time \\(t\\) proportional \\(C_t=\\sum_{n=1}^N | \\Delta w_{t,n}|c_{t,n}\\), \\(\\Delta w_{t,n}\\) change position asset \\(n\\) \\(c_{t,n}\\) corresponding fee. last quantity often hard predict, thus customary use proxy depends instance market capitalization (large stocks liquid shares thus require smaller fees) bid-ask spreads (smaller spreads mean smaller fees).first order approximation, often useful compute average turnover:\n\\[\\text{Turnover}=\\frac{1}{T-1}\\sum_{t=2}^T\\sum_{n=1}^N|w_{t,n}-w_{t-,n}|,\\]\n\\(w_{t,n}\\) desired \\(t\\)-time weights portfolio \\(w_{t-,n}\\) weights just rebalancing. positions first period (launching weights) exluded computation convention. Transaction costs can proxied multiple turnover (times average median cost cross-section firms). first order estimate realized costs take consideration evolution scale portfolio. Nonetheless, rough figure much better none .transaction costs (TCs) annualized, can deducted average returns yield realistic picture profitability. vein, transaction cost-adjusted Sharpe ratio portfolio \\(P\\) given \n\\[\\begin{equation}\n\\tag{12.4}\nSR_{TC}=\\frac{\\mu_P-TC}{\\sigma_P}.\n\\end{equation}\\]Transaction costs often overlooked academic articles can sizable impact real life trading (see, e.g., Novy-Marx Velikov (2015)). DeMiguel et al. (2020) show use factor investing (exposures) combine offset positions reduce overall fees.","code":""},{"path":"backtest.html","id":"common-errors-and-issues","chapter":"12 Portfolio backtesting","heading":"12.4 Common errors and issues","text":"","code":""},{"path":"backtest.html","id":"forward-looking-data","chapter":"12 Portfolio backtesting","heading":"12.4.1 Forward looking data","text":"One common mistakes portfolio backtesting use forward looking data. instance easy fall trap danger zone depicted Figure 12.2. case, labels used time \\(t\\) computed knowledge happens times \\(t+1\\), \\(t+2\\), etc. worth triple checking every step code make sure strategies built prescient data.","code":""},{"path":"backtest.html","id":"backov","chapter":"12 Portfolio backtesting","heading":"12.4.2 Backtest overfitting","text":"\nsecond major problem backtest overfitting. analogy training set overfitting easy grasp. well-known issue formalized instance White (2000) Romano Wolf (2005). portfolio choice, refer Bajgrowicz Scaillet (2012), D. H. Bailey Prado (2014) Lopez de Prado Bailey (2020), references therein.given moment, backtest depends one particular dataset. Often, result first backtest satisfactory - many possible reasons. Hence, tempting another try, altering parameters probably optimal. second test may better, quite good enough - yet. Thus, third trial, new weighting scheme can tested, along new forecasting engine (sophisticated). Iteratively, backtester can end strategy performs well enough, just matter time trials.One consequence backtest overfitting illusory hope Sharpe ratios live trading obtained backtest. Reasonable professionals divide Sharpe ratio two least (C. R. Harvey Liu (2015), Suhonen, Lennkh, Perez (2017)). D. H. Bailey Prado (2014), authors even propose statistical test Sharpe ratios, provided metrics tested strategies stored memory. formula deflated Sharpe ratios :\n\\[\\begin{equation}\n\\tag{12.5}\nt = \\phi\\left((SR-SR^*)\\sqrt{\\frac{T-1}{1-\\gamma_3SR+\\frac{\\gamma_4-1}{4}SR^2}} \\right),\n\\end{equation}\\]\n\\(SR\\) Sharpe Ratio obtained best strategy among tested, \n\\[SR^*=\\mathbb{E}[SR]+\\sqrt{\\mathbb{V}[SR]}\\left((1-\\gamma)\\phi^{-1}\\left(1-\\frac{1}{N}\\right)+\\gamma \\phi^{-1}\\left(1-\\frac{1}{Ne}\\right)  \\right),\\]\ntheoretical average maximum SR. Moreover,\\(T\\) number trading dates;\\(\\gamma_3\\) \\(\\gamma_4\\) \\(skewness\\) \\(kurtosis\\) returns chosen (best) strategy;\\(\\phi\\) cdf standard Gaussian law \\(\\gamma\\approx 0,577\\) Euler-Mascheroni constant;\\(N\\) refers number strategy trials.\\(t\\) defined certain threshold (e.g., 0.95), \\(SR\\) deemed significant:  compared tested. time, sadly, case. Equation (12.5), realized SR must theoretical maximum \\(SR^*\\) scaling factor must sufficiently large push argument inside \\(\\phi\\) close enough two, \\(t\\) surpasses 0.95.scientific community, test overfitting also known p-hacking. rather common financial economics reading C. R. Harvey (2017) strongly advised grasp magnitude phenomenon. p-hacking also present fields use statistical tests (see, e.g., Head et al. (2015) cite one reference). several ways cope p-hacking:don’t rely p-values (Amrhein, Greenland, McShane (2019));use detection tools (Elliott, Kudrin, Wuthrich (2019));, finally, use advanced methods process arrays statistics (e.g., Bayesianized versions p-values include prior assessment C. R. Harvey (2017), tests proposed Romano Wolf (2005) Simonsohn, Nelson, Simmons (2014)).first option wise, drawback decision process left another arbitrary yardstick.","code":""},{"path":"backtest.html","id":"simple-safeguards","chapter":"12 Portfolio backtesting","heading":"12.4.3 Simple safeguards","text":"mentioned beginning chapter, two common sense references backtesting Fabozzi Prado (2018) R. Arnott, Harvey, Markowitz (2019). pieces advice provided two articles often judicious thoughtful.One additional comment pertains output backtest. One simple, intuitive widespread metric transaction cost-adjusted Sharpe ratio defined Equation (12.4). backtest, let us call \\(SR_{TC}^B\\) corresponding value benchmark, like define equally-weighted portfolio assets trading universe (dataset, roughly one thousand US equities). \\(SR_{TC}^P\\) best strategy \\(2\\times SR_{TC}^B\\), probably glitch somewhere backtest.criterion holds two assumptions:sufficiently long enough --sample period andlong-portfolios.unlikely realistic strategy can outperform solid benchmark wide margin long term. able improve benchmark’s annualized return 150 basis points (comparable volatility) already great achievement. Backtests deliver returns 5% benchmark dubious.","code":""},{"path":"backtest.html","id":"implication-of-non-stationarity-forecasting-is-hard","chapter":"12 Portfolio backtesting","heading":"12.5 Implication of non-stationarity: forecasting is hard","text":"subsection split two parts: first, discuss reason makes forecasting difficult task second present important theoretical result originally developed towards machine learning sheds light discipline confronted --sample tests. interesting contribution related topic study Farmer, Schmidt, Timmermann (2019). authors assess predictive fit linear models time: show fit strongly varying: sometimes model performs well, sometimes, much. reason case ML algorithms well.","code":""},{"path":"backtest.html","id":"general-comments","chapter":"12 Portfolio backtesting","heading":"12.5.1 General comments","text":"careful reader must noticed throughout Chapters 5 11, performance ML engines underwhelming. disappointing results purpose highlight crucial truth machine learning panacea, magic wand, philosopher’s stone can transform data golden predictions. ML-based forecasts fail. fact true enhanced sophisticated techniques, also simpler econometric approaches (Dichtl et al. (2020)), underlines need replicate results challenge validity.One reason datasets full noise extracting slightest amount signal tough challenge (recommend careful reading introduction Timmermann (2018) details topic). One rationale ever time-varying nature factor analysis equity space. factors can perform well one year poorly next year reversals can costly context fully automated data-based allocation processes.fact, one major difference many fields ML made huge advances. image recognition, numbers always shape, cats, buses, etc. Likewise, verb always verb syntaxes languages change. invariance, though sometimes hard grasp,26 nonetheless key great improvement computer vision natural language processing.factor investing, seem invariance (see Cornell (2020)). factor (possibly nonlinear) combination factors can explain accurately forecast returns long periods several decades.27 academic literature yet find model; even , simple arbitrage reasoning logically invalidate conclusions future datasets.","code":""},{"path":"backtest.html","id":"the-no-free-lunch-theorem","chapter":"12 Portfolio backtesting","heading":"12.5.2 The no free lunch theorem","text":"\nstart underlying free lunch theorem machine learning nothing asset pricing condition name (see, e.g., Delbaen Schachermayer (1994), , recently, Cuchiero, Klein, Teichmann (2016)). original formulation given Wolpert (1992a) also recommend look recent reference Y.-C. Ho Pepyne (2002). fact several theorems two can found Wolpert Macready (1997).statement theorem abstract requires notational conventions. assume training sample \\(S=(\\{\\textbf{x}_1,y_1\\}, \\dots, \\{\\textbf{x}_I,y_I\\})\\) exists oracle function \\(f\\) perfectly maps features labels: \\(y_i=f(\\textbf{x}_i)\\). oracle function \\(f\\) belongs large set functions \\(\\mathcal{F}\\). addition, write \\(\\mathcal{H}\\) set functions forecaster resort approximate \\(f\\). instance, \\(\\mathcal{H}\\) can space feed-forward neural networks, space decision trees, reunion . Elements \\(\\mathcal{H}\\) written \\(h\\) \\(\\mathbb{P}[h|S]\\) stands (largely unknown) distribution \\(h\\) knowing sample \\(S\\). Similarly, \\(\\mathbb{P}[f|S]\\) distribution oracle functions knowing \\(S\\). Finally, features given law, \\(\\mathbb{P}[\\textbf{x}]\\).Let us now consider two models, say \\(h_1\\) \\(h_2\\). statement theorem usually formulated respect classification task. Knowing \\(S\\), error choosing \\(h_k\\) induced samples outside training sample \\(S\\) can quantified :\n\\[\\begin{equation}\n\\tag{12.6}\nE_k(S)= \\int_{f,h}\\int_{\\textbf{x}\\notin S} \\underbrace{ (1-\\delta(f(\\textbf{x}),h_k(\\textbf{x})))}_{\\text{error term}} \\underbrace{\\mathbb{P}[f|S]\\mathbb{P}[h|S]\\mathbb{P}[\\textbf{x}]}_{\\text{distributional terms}},\n\\end{equation}\\]\n\\(\\delta(\\cdot,\\cdot)\\) delta Kronecker function:\n\\[\\begin{equation}\n\\tag{12.7}\n\\delta(x,y)=\\left\\{\\begin{array}{ll} 0 & \\text{} x\\neq y \\\\ 1 & \\text{} x = y \\end{array} .\\right.\n\\end{equation}\\]\nOne free lunch theorems states \\(E_1(S)=E_2(S)\\), , sole knowledge \\(S\\), can superior algorithm, average. order build performing algorithm, analyst econometrician must prior views structure relationship \\(y\\) \\(\\textbf{x}\\) integrate views construction model. Unfortunately, can also yield underperforming models views incorrect.","code":""},{"path":"backtest.html","id":"first-example-a-complete-backtest","chapter":"12 Portfolio backtesting","heading":"12.6 First example: a complete backtest","text":"\nfinally propose full detailed example one implementation ML-based strategy run careful backtest.\nfollows generalization content Section 5.2.2. spirit, split backtest four parts:creation/initialization variables;definition strategies one main function;backtesting loop ;performance indicators.Accordingly, start initializations.first step crucial, lays groundwork core backtest. consider two strategies: one ML-based EW (1/N) benchmark. main (weighting) function consist two components, define sophisticated one dedicated wrapper. ML-based weights derived XGBoost predictions 80 trees, learning rate 0.3 maximum tree depth 4. makes model complex exceedingly . predictions obtained, weighting scheme simple: EW portfolio best half stocks (median prediction).function , parameters (e.g., learning rate, eta number trees nrounds) hard-coded. can easily passed arguments next data inputs. One important detail contrast rest book, label 12-month future return. main reason rooted discussion Section 4.6. Also, speed computations, remove bulk distribution labels keep top 20% bottom 20%, advised Coqueret Guida (2020). filtering levels also passed arguments.Compared structure proposed Section 6.4.6, differences label based long-term returns, also relies volatility component. Even though denominator label exponential quantile volatility, seems fair say inspired Sharpe ratio model seeks explain forecast risk-adjusted return instead raw return. stock low volatility return unchanged label, stock high volatility see return divided factor close three (exp(1)=2.718).function embedded global weighting function wraps two schemes: EW benchmark ML-based policy.Equipped function, can turn main backtesting loop. Given fact use large-scale model, computation time loop large (possibly hours slow machine CPU). Resorting functional programming can speed loop (see exercise end chapter). Also, simple benchmark equally weighted portfolio can coded tidyverse functions .two important comments made code. first comment pertains two parameters defined first lines. refer size training sample (5 years) length buffer period shown Figure 12.2. buffer period imperative label based long-term (12-month) return. lag compulsory avoid forward-looking bias backtest., create function computes turnover (variation weights). requires weight values well returns assets weights just rebalancing depend weights assigned previous period, well returns assets altered original weights holding period.turnover defined, embed function computes several key indicators.Lastly, build function loops various strategies.Given weights returns portfolios, remains compute returns assets plug aggregate metrics function.ML-based strategy performs finally well! gain mostly obtained average return, volatility higher benchmark. net effect Sharpe ratio improved compared benchmark. augmentation breathtaking, (hence?) seems reasonable. noteworthy underline turnover substantially higher sophisticated strategy. Removing costs numerator (say, 0.005 times turnover, Goto Xu (2015), conservative figure) mildly reduces superiority Sharpe ratio ML-based strategy.Finally, always tempting plot corresponding portfolio values display two related graphs Figure 12.3.\nFIGURE 12.3: Graphical representation performance portfolios.\n12 years backtest, advanced strategy outperforms benchmark 10 years. less hurtful two four years aggregate losses (2015 2018). satisfactory improvement EW benchmark tough beat!","code":"\nsep_oos <- as.Date(\"2007-01-01\")                            # Starting point for backtest\nticks <- data_ml$stock_id %>%                               # List of all asset ids\n    as.factor() %>%\n    levels()\nN <- length(ticks)                                          # Max number of assets\nt_oos <- returns$date[returns$date > sep_oos] %>%           # Out-of-sample dates \n    unique() %>%                                            # Remove duplicates\n    as.Date(origin = \"1970-01-01\")                          # Transform in date format\nTt <- length(t_oos)                                         # Nb of dates, avoid T = TRUE\nnb_port <- 2                                                # Nb of portfolios/stragegies\nportf_weights <- array(0, dim = c(Tt, nb_port, N))          # Initialize portfolio weights\nportf_returns <- matrix(0, nrow = Tt, ncol = nb_port)       # Initialize portfolio returns \nweights_xgb <- function(train_data, test_data, features){ \n    train_features <- train_data %>% dplyr::select(features) %>% as.matrix()  # Indep. variable\n    train_label <- train_data$R12M_Usd / exp(train_data$Vol1Y_Usd)            # Dep. variable\n    ind <- which(train_label < quantile(train_label,0.2)|                     # Filter\n                   train_label > quantile(train_label, 0.8))\n    train_features <- train_features[ind, ]                                   # Filt'd features\n    train_label <- train_label[ind]                                           # Filtered label\n    train_matrix <- xgb.DMatrix(data = train_features, label = train_label)   # XGB format\n    fit <- train_matrix %>% \n        xgb.train(data = .,                       # Data source (pipe input)\n                  eta = 0.3,                      # Learning rate\n                  objective = \"reg:squarederror\", # Number of random trees\n                  max_depth = 4,                  # Maximum depth of trees\n                  nrounds = 80,                   # Number of trees used\n                  verbose = 0                     # No comments\n        )\n    xgb_test <- test_data %>%                     # Test sample => XGB format\n        dplyr::select(features) %>% \n        as.matrix() %>%\n        xgb.DMatrix()\n    \n    pred <- predict(fit, xgb_test)                # Single prediction\n    w <- pred > median(pred)                      # Keep only the 50% best predictions\n    w$weights <- w / sum(w)\n    w$names <- unique(test_data$stock_id)\n    return(w)                                     # Best predictions, equally-weighted\n}\nportf_compo <- function(train_data, test_data, features, j){ \n    if(j == 1){                                 # This is the benchmark\n        N <- test_data$stock_id %>%             # Test data dictates allocation\n            factor() %>% nlevels()\n        w <- 1/N                                # EW portfolio\n        w$weights <- rep(w,N)\n        w$names <- unique(test_data$stock_id)   # Asset names\n        return(w)\n    }\n    if(j == 2){                                 # This is the ML strategy.\n        return(weights_xgb(train_data, test_data, features))\n    }\n}\nm_offset <- 12                                          # Offset in months for buffer period\ntrain_size <- 5                                         # Size of training set in years\nfor(t in 1:(length(t_oos)-1)){                          # Stop before last date: no fwd ret.!\n    if(t%%12==0){print(t_oos[t])}                       # Just checking the date status\n    train_data <- data_ml %>% filter(date < t_oos[t] - m_offset * 30,   # Roll window w. buffer\n                                    date > t_oos[t] - m_offset * 30 - 365 * train_size)    \n    test_data <- data_ml %>% filter(date == t_oos[t])   # Test sample  \n    realized_returns <- test_data %>%                   # Computing returns via:\n        dplyr::select(R1M_Usd)                          # 1M holding period!\n    for(j in 1:nb_port){    \n        temp_weights <- portf_compo(train_data, test_data, features, j) # Weights\n        ind <- match(temp_weights$names, ticks) %>% na.omit()           # Index: test vs all\n        portf_weights[t,j,ind] <- temp_weights$weights                  # Allocate weights \n        portf_returns[t,j] <- sum(temp_weights$weights * realized_returns) # Compute returns\n    } \n}    ## [1] \"2007-12-31\"\n## [1] \"2008-12-31\"\n## [1] \"2009-12-31\"\n## [1] \"2010-12-31\"\n## [1] \"2011-12-31\"\n## [1] \"2012-12-31\"\n## [1] \"2013-12-31\"\n## [1] \"2014-12-31\"\n## [1] \"2015-12-31\"\n## [1] \"2016-12-31\"\n## [1] \"2017-12-31\"\nturnover <- function(weights, asset_returns, t_oos){ \n    turn <- 0\n    for(t in 2:length(t_oos)){\n        realised_returns <- returns %>% filter(date == t_oos[t]) %>% dplyr::select(-date)\n        prior_weights <- weights[t-1,] * (1 + realised_returns) # Before rebalancing\n        turn <- turn + apply(abs(weights[t,] - prior_weights/sum(prior_weights)),1,sum)\n    }\n    return(turn/(length(t_oos)-1))\n}\nperf_met <- function(portf_returns, weights, asset_returns, t_oos){ \n    avg_ret <- mean(portf_returns, na.rm = T)                     # Arithmetic mean \n    vol <- sd(portf_returns, na.rm = T)                           # Volatility\n    Sharpe_ratio <- avg_ret / vol                                 # Sharpe ratio\n    VaR_5 <- quantile(portf_returns, 0.05)                        # Value-at-risk\n    turn <- 0                                                     # Initialisation of turnover\n    for(t in 2:dim(weights)[1]){\n        realized_returns <- asset_returns %>% filter(date == t_oos[t]) %>% dplyr::select(-date)\n        prior_weights <- weights[t-1,] * (1 + realized_returns)\n        turn <- turn + apply(abs(weights[t,] - prior_weights/sum(prior_weights)),1,sum)\n    }\n    turn <- turn/(length(t_oos)-1)                                # Average over time\n    met <- data.frame(avg_ret, vol, Sharpe_ratio, VaR_5, turn)    # Aggregation of all of this\n    rownames(met) <- \"metrics\"\n    return(met)\n}\nperf_met_multi <- function(portf_returns, weights, asset_returns, t_oos, strat_name){\n    J <- dim(weights)[2]              # Number of strategies \n    met <- c()                        # Initialization of metrics\n    for(j in 1:J){                    # One very ugly loop\n        temp_met <- perf_met(portf_returns[, j], weights[, j, ], asset_returns, t_oos)\n        met <- rbind(met, temp_met)\n    }\n    row.names(met) <- strat_name      # Stores the name of the strat\n    return(met)\n}\nasset_returns <- data_ml %>%                          # Compute return matrix: start from data\n    dplyr::select(date, stock_id, R1M_Usd) %>%        # Keep 3 attributes \n    spread(key = stock_id, value = R1M_Usd)           # Shape in matrix format\nasset_returns[is.na(asset_returns)] <- 0              # Zero returns for missing points\n\nmet <- perf_met_multi(portf_returns = portf_returns,  # Computes performance metrics\n                      weights = portf_weights, \n                      asset_returns = asset_returns,\n                      t_oos = t_oos,\n                      strat_name = c(\"EW\", \"XGB_SR\"))\nmet                                                   # Displays perf metrics##            avg_ret        vol Sharpe_ratio       VaR_5      turn\n## EW     0.009697248 0.05642917    0.1718481 -0.07712509 0.0714512\n## XGB_SR 0.012602882 0.06376845    0.1976351 -0.08335864 0.5679932\nlibrary(lubridate) # Date management\nlibrary(cowplot)   # Plot grid management\ng1 <- tibble(date = t_oos,  \n      benchmark = cumprod(1+portf_returns[,1]),\n      ml_based = cumprod(1+portf_returns[,2])) %>%\n    gather(key = strat, value = value, -date) %>%\n    ggplot(aes(x = date, y = value, color = strat)) + geom_line() +theme_grey()\ng2 <- tibble(year = lubridate::year(t_oos),  \n             benchmark = portf_returns[,1],\n             ml_based = portf_returns[,2]) %>%\n    gather(key = strat, value = value, -year) %>%\n    group_by(year, strat) %>%\n    summarise(avg_return = mean(value)) %>%\n    ggplot(aes(x = year, y = avg_return, fill = strat)) + \n  geom_col(position = \"dodge\") + theme_grey()\nplot_grid(g1,g2, nrow = 2)"},{"path":"backtest.html","id":"second-example-backtest-overfitting","chapter":"12 Portfolio backtesting","heading":"12.7 Second example: backtest overfitting","text":"\nend chapter, quantify concepts Section 12.4.2. First, build function able generate performance metrics simple strategies can evaluated batches. strategies pure factor bets depend three inputs: chosen characteristic (e.g., market capitalization), threshold level (quantile characteristic) direction (long position top bottom distribution)., test function triplet arguments. pick price--book (Pb) ratio. position positive threshold 0.3, means strategy buys stocks Pb value 0.3 quantile distribution.output keeps three quantities useful compute statistic (12.5). must now generate indicators many strategies. start creating grid parameters.makes 84 strategies total. can proceed see fare. plot corresponding Sharpe ratios Figure 12.4. top plot shows strategies invest bottoms distributions characteristics bottom plot pertains portfolios long lower parts distributions.\nFIGURE 12.4: Sharpe ratios backtested strategies.\nlast step compute statistic (12.5). code :remains evaluate arguments function. “best” strategy one top left corner Figure 12.4 based market capitalization.value 0.6676416 high enough (reach 90% 95% threshold) make strategy significantly superior ones considered batch tests. ","code":"\nstrat <- function(data, feature, thresh, direction){\n    data_tmp <- dplyr::select(data, feature, date, R1M_Usd)       # Data\n    colnames(data_tmp)[1] <- \"feature\"                            # Colname\n    data_tmp %>% \n        mutate(decision = direction * feature > direction * thresh) %>% # Investment decision\n        group_by(date) %>%                                          # Date-by-date  analysis    \n        mutate(nb = sum(decision),                                  # Nb assets in portfolio\n               w = decision / nb,                                   # Weights of assets\n               return = w * R1M_Usd) %>%                            # Asset contribution\n        summarise(p_return = sum(return)) %>%                       # Portfolio return\n        summarise(avg = mean(p_return), sd = sd(p_return), SR = avg/sd) %>% # Perf. metrics\n        return()\n}\nstrat(data_ml, \"Pb\", 0.3, 1)   # Large cap## # A tibble: 1 × 3\n##      avg     sd    SR\n##    <dbl>  <dbl> <dbl>\n## 1 0.0102 0.0496 0.207\nfeature <- c(\"Div_Yld\", \"Ebit_Bv\", \"Mkt_Cap_6M_Usd\", \"Mom_11M_Usd\", \"Pb\", \"Vol1Y_Usd\")  \nthresh <- seq(0.2,0.8, by = 0.1)                                # Threshold values values\ndirection <- c(1,-1)                                            # Decision direction\npars <- expand.grid(feature, thresh, direction)                 # The grid\nfeature <- pars[,1] %>% as.character()                          # re-features\nthresh <- pars[,2]                                              # re-thresholds\ndirection <- pars[,3]                                           # re-directions\ngrd <- pmap(list(feature, thresh, direction),      # Parameters for the grid search\n            strat,                                 # Function on which to apply the grid search\n            data = data_ml                         # Data source/input\n) %>% \n    unlist() %>%\n    matrix(ncol = 3, byrow = T)\ngrd <- data.frame(feature, thresh, direction, grd)              # Gather & reformat results \ncolnames(grd)[4:6] <- c(\"mean\", \"sd\", \"SR\")                     # Change colnames\ngrd <- grd %>% mutate_at(vars(direction), as.factor)            # Change type: factor (for plot)\ngrd %>% ggplot(aes(x = thresh, y = SR, color = feature)) +      # Plot!\n    geom_point() + geom_line() + facet_grid(direction~.) \nDSR <- function(SR, Tt, M, g3, g4, SR_m, SR_v){ # First, we build the function\n    gamma <- -digamma(1)                        # Euler-Mascheroni constant\n    SR_star <- SR_m + sqrt(SR_v)*((1-gamma)*qnorm(1-1/M) + gamma*qnorm(1-1/M/exp(1))) # SR*\n    num <- (SR-SR_star) * sqrt(Tt-1)            # Numerator\n    den <- sqrt(1 - g3*SR + (g4-1)/4*SR^2)      # Denominator\n    return(pnorm(num/den))\n}\nM <- nrow(pars)             # Number of strategies we tested\nSR <- max(grd$SR)           # The SR we want to test\nSR_m <- mean(grd$SR)        # Average SR across all strategies\nSR_v <- var(grd$SR)         # Std dev of SR\n# Below, we compute the returns of the strategy by recycling the code of the strat() function\ndata_tmp <- dplyr::select(data_ml, \"Mkt_Cap_6M_Usd\", date, R1M_Usd) # feature = Mkt_Cap  \ncolnames(data_tmp)[1] <- \"feature\"\nreturns_DSR <-  data_tmp %>% \n        mutate(decision = feature < 0.2) %>% # Investment decision: 0.2 is the best threshold\n        group_by(date) %>%                   # Date-by-date computations\n        mutate(nb = sum(decision),           # Nb assets in portfolio\n               w = decision / nb,            # Portfolio weights\n               return = w * R1M_Usd) %>%     # Asset contribution to return\n        summarise(p_return = sum(return))    # Portfolio return\ng3 <- skewness(returns_DSR$p_return)         # Function from the e1071 package\ng4 <- kurtosis(returns_DSR$p_return) + 3     # Function from the e1071 package\nTt <- nrow(returns_DSR)                      # Number of dates\nDSR(SR, Tt, M, g3, g4, SR_m, SR_v)           # The sought value!## [1] 0.6676416"},{"path":"backtest.html","id":"coding-exercises-5","chapter":"12 Portfolio backtesting","heading":"12.8 Coding exercises","text":"Code returns EW portfolio tidyverse functions (loop).Code advanced weighting function defined Equation (12.3).Test small backtest check sensitivity parameters.Using functional programming package purrr, avoid loop backtest.","code":""},{"path":"interp.html","id":"interp","chapter":"13 Interpretability","heading":"13 Interpretability","text":"\nchapter dedicated techniques help understand way models process inputs outputs. Two recent books (Molnar (2019) available https://christophm.github.io/interpretable-ml-book/, Biecek Burzykowski (2021), available https://ema.drwhy.ai) entirely devoted topic highly recommend look . survey Belle Papantonis (2020) also worthwhile. Another introductory less technical reference Patrick Hall Gill (2019).\nObviously, chapter, adopt tone factor-investing orientated discuss examples related ML models trained financial dataset.Quantitative tools aim interpretability ML models required satisfy two simple conditions:provide information model.highly comprehensible.Often, tools generate graphical outputs easy read yield immediate conclusions.attempts white-box complex machine learning models, one dichotomy stands :Global models seek determine relative role features construction predictions model trained. done global level, patterns shown interpretation hold average whole training set.Local models aim characterize model behaves around one particular instance considering small variations around instance. way variations processed original model allows simplify approximating , e.g., linear fashion. approximation can example determine sign magnitude impact relevant feature vicinity original instance.Molnar (2019) proposes another classification interpretability solutions splitting interpretations depend one particular model (e.g., linear regression decision tree) versus interpretations can obtained kind model. sequel, present methods according global versus local dichotomy.Beyond traditional approaches present , wish highlight two methods: Sirus (Bénard et al. (2021)) Rulefit (J. H. Friedman Popescu (2008)). implemented R.","code":""},{"path":"interp.html","id":"global-interpretations","chapter":"13 Interpretability","heading":"13.1 Global interpretations","text":"","code":""},{"path":"interp.html","id":"surr","chapter":"13 Interpretability","heading":"13.1.1 Simple models as surrogates","text":"\nLet us start simplest example . linear model,\n\\[y_i=\\alpha+\\sum_{k=1}^K\\beta_kx_i^k+\\epsilon_i,\\]\nfollowing elements usually extracted estimation \\(\\beta_k\\):\\(R^2\\), appreciates global fit model (possibly penalized prevent overfitting many regressors). \\(R^2\\) usually computed -sample;sign estimates \\(\\hat{\\beta}_k\\), indicates direction impact feature \\(x^k\\) \\(y\\);\\(t\\)-statistics \\(t_{\\hat{\\beta_k}}\\), evaluate magnitude impact: regardless direction, large statistics absolute value reveal prominent variables. Often, \\(t\\)-statistics translated \\(p\\)-values computed suitable distributional assumptions.last two indicators useful inform user features matter sign effect predictor. gives simplified view model processes features output. tools aim explain black boxes follow principles.Decision trees, easy picture, also great models interpretability. Thanks favorable feature, target benchmarks simple models. Recently, Vidal, Pacheco, Schiffer (2020) propose method reduce ensemble trees unique tree. aim propose simpler model behaves exactly like complex one.generally, intuitive idea resort simple models proxy complex algorithms. One simple way build -called surrogate models. process simple: train original model \\(f\\) features \\(\\textbf{X}\\) labels \\(\\textbf{y}\\);train simpler model \\(g\\) explain predictions trained model \\(\\hat{f}\\) given features \\(\\textbf{X}\\):\n\\[\\hat{f}(\\textbf{X})=g(\\textbf{X})+\\textbf{error}\\]estimated model \\(\\hat{g}\\) explains initial model \\(\\hat{f}\\) maps features labels. illustrate , use iml package (see Molnar, Casalicchio, Bischl (2018)). simpler model tree depth two.\nFIGURE 13.1: Example surrogate tree.\nrepresentation tree different, compared seen Chapter 6. Indeed, four possible outcomes (determined conditions top lines) longer yield simple value (average label), information given, form box plot (including interquartile range outliers). representation, top right cluster seems highest rewards, especially many upward outliers. cluster consists small firms volatile past returns.","code":"\nlibrary(iml)\nmod <- Predictor$new(fit_RF, \n                     data = training_sample %>% dplyr::select(features)) \ndt <- TreeSurrogate$new(mod, maxdepth = 2)\nplot(dt)"},{"path":"interp.html","id":"variable-importance","chapter":"13 Interpretability","heading":"13.1.2 Variable importance (tree-based)","text":"\nOne incredibly favorable feature simple decision trees interpretability. visual representation clear straightforward. Just like regressions (another building block ML), simple trees easy comprehend suffer black-box rebuke often associated sophisticated tools.Indeed, random forests boosted trees fail provide perfectly accurate accounts happening inside engine. contrast, possible compute aggregate share (importance) feature determination structure tree trained.training, possible compute, node \\(n\\) gain \\(G(n)\\) obtained subsequent split , .e., node terminal leaf. also easy determine variable chosen perform split, hence write \\(\\mathcal{N}_k\\) set nodes feature \\(k\\) chosen partition. , global importance feature given \n\\[(k)=\\sum_{n\\\\mathcal{N}_k}G(n),\\]\noften rescaled sum \\((k)\\) across \\(k\\) equal one. case, \\((k)\\) measures relative contribution feature \\(k\\) reduction loss training. variable high importance greater impact predictions. Generally, variables located close root tree., take look results obtained tree-based models trained Chapter 6. start recycling output three regression models used. Notice fitted output structure importance vectors different names.\nFIGURE 13.2: Variable importance tree-based models.\ncode, tibbles like dataframes (v2.0 dataframes, speak).\nGiven way graph coded, Figure 13.2 fact misleading. Indeed, construction, simple tree model small number features nonzero importance: graph, 3: capitalization, price--book volatility. contrast, random forest boosted trees much complex, give importance many predictors. graph shows variables related simple tree model . scale reasons, normalization performed subset features chosen. preferred limit number features shown graph obvious readability concerns.differences way models rely features. instance, important feature changes model : simple tree model gives importance price--book ratio, random forest bets volatility boosted trees give weight capitalization.One defining property random forests give chance features. Indeed, randomizing choice predictors, individual exogenous variable shot explaining label. Along boosted trees, allocation importance balanced across predictors, compared simple tree puts eggs just baskets.","code":"\ntree_VI <- fit_tree$variable.importance  %>%                        # VI from tree model\n    as_tibble(rownames = NA) %>%                                    # Transform in tibble \n    rownames_to_column(\"Feature\")                                   # Add feature column\nRF_VI <- fit_RF$importance  %>%                                     # VI from random forest\n    as_tibble(rownames = NA) %>%                                    # Transform in tibble \n    rownames_to_column(\"Feature\")                                   # Add feature column\nXGB_VI <- xgb.importance(model = fit_xgb)[,1:2]                     # VI from boosted trees\nVI_trees <- tree_VI %>% left_join(RF_VI) %>% left_join(XGB_VI)      # Aggregate the VIs\ncolnames(VI_trees)[2:4] <- c(\"Tree\", \"RF\", \"XGB\")                   # New column names\nnorm_1 <- function(x){return(x / sum(x))}                           # Normalizing function\nVI_trees %>% na.omit %>% mutate_if(is.numeric,  norm_1) %>%         # Plotting sequence\n    gather(key = model, value = value, -Feature) %>%\n    ggplot(aes(x = Feature, y = value, fill = model)) + geom_col(position = \"dodge\") +\n    theme(axis.text.x = element_text(angle = 35, hjust = 1))"},{"path":"interp.html","id":"variable-importance-agnostic","chapter":"13 Interpretability","heading":"13.1.3 Variable importance (agnostic)","text":"\nidea quantifying importance feature learning process can extended nontree-based models. refer papers mentioned study Fisher, Rudin, Dominici (2019) information stream literature. premise : aim quantify extent one feature contributes learning process.One way track added value one particular feature look happens values inside training set entirely shuffled. original feature plays important role explanation dependent variable, shuffled version feature lead much higher loss.baseline method assess feature importance general case following:Train model original data compute associated loss \\(l^*\\).feature \\(k\\), create new training dataset feature’s values randomly permuted. , evaluate loss \\(l_k\\) model based altered sample.Rank variable importance feature, computed difference \\(\\text{VI}_k=l_k-l^*\\) ratio \\(\\text{VI}_k=l_k/l^*\\).Whether compute losses training set testing set open question remains appreciation analyst.\nprocedure course random can repeated importances averaged several trials: improves stability results. algorithm implemented FeatureImp() function iml R package developed author Molnar (2019). also recommend vip package, see Greenwell Boehmke (Forthcoming).\n, implement algorithm manually speak features appearing Figure 13.2. test approach ridge regressions recycle variables used Chapter 5. start first step: computing loss original training sample.Next, evaluate loss predictors sequentially shuffled. reduce computation time, make one round shuffling.Finally, plot results.\nFIGURE 13.3: Variable importance ridge regression model.\nresulting importances line thoses tree-based models: prominent variables volatility-based, market capitalization-based, price--book ratio; closely match variables Figure 13.2. Note cases (e.g., share turnover), score can even negative, means predictions accurate baseline model values predictor shuffled!","code":"\nfit_ridge_0 <- glmnet(x_penalized_train, y_penalized_train,                   # Trained model\n                      alpha = 0, lambda = 0.01) \nl_star <- mean((y_penalized_train-predict(fit_ridge_0, x_penalized_train))^2) # Loss\nl <- c()                                                             # Initialize\nfor(i in 1:nrow(VI_trees)){                                          # Loop on the features\n    feat_name <- as.character(VI_trees[i,1])\n    temp_data <- training_sample %>% dplyr::select(features)         # Temp feature matrix\n    temp_data[, which(colnames(temp_data) == feat_name)] <-          # Shuffles the values\n        sample(temp_data[, which(colnames(temp_data) == feat_name)]\n               %>% pull(1), replace = FALSE)\n    x_penalized_temp <- temp_data %>% as.matrix()                    # Predictors into matrix\n    l[i] <- mean((y_penalized_train-predict(fit_ridge_0, x_penalized_temp))^2) # = Loss\n}\ndata.frame(Feature = VI_trees[,1], loss = l - l_star) %>%\n    ggplot(aes(x = Feature, y = loss)) + geom_col() +\n    theme(axis.text.x = element_text(angle = 35, hjust = 1))"},{"path":"interp.html","id":"partial-dependence-plot","chapter":"13 Interpretability","heading":"13.1.4 Partial dependence plot","text":"\nPartial dependence plots (PDPs) aim showing relationship output model value feature (refer section 8.2 J. H. Friedman (2001) early treatment subject).Let us fix feature \\(k\\). want understand average impact \\(k\\) predictions trained model \\(\\hat{f}\\). order , assume feature space random split two: \\(k\\) versus \\(-k\\), stands features except \\(k\\). partial dependence plot defined \\[\\begin{equation}\n\\tag{13.1} \n\\bar{f}_k(x_k)=\\mathbb{E}[\\hat{f}(\\textbf{x}_{-k},x_k)]=\\int \\hat{f}(\\textbf{x}_{-k},x_k)d\\mathbb{P}_{-k}(\\textbf{x}_{-k}),\n\\end{equation}\\]\\(d\\mathbb{P}_{-k}(\\cdot)\\) (multivariate) distribution non-\\(k\\) features \\(\\textbf{x}_{-k}\\). function takes feature values \\(x_k\\) argument keeps features frozen via sample distributions: shows impact feature \\(k\\) solely. practice, average evaluated using Monte-Carlo simulations:\\[\\begin{equation}\n\\tag{13.2} \n\\bar{f}_k(x_k)\\approx \\frac{1}{M}\\sum_{m=1}^M\\hat{f}\\left(x_k,\\textbf{x}_{-k}^{(m)}\\right),\n\\end{equation}\\]\n\\(\\textbf{x}_{-k}^{(m)}\\) independent samples non-\\(k\\) features.Theoretically, PDPs computed one feature time. practice, possible two features (yielding 3D surface) computationally intense.illustrate concept , using dedicated package iml (interpretable machine learning); see also pdp package documented Greenwell (2017). model seek explain random forest built Section 6.2. recycle variables used therein. choose test impact price--book ratio outcome model.\nFIGURE 13.4: Partial dependence plot price--book ratio random forest model.\naverage impact price--book ratio predictions decreasing. somewhat expected, given conditional average dependent variable given price--book ratio. latter function depicted Figure 6.3 shows behavior comparable curve: strongly decreasing small value P/B relatively flat. price--book ratio low, firms undervalued. Hence, higher returns line value premium.Finally, refer Zhao Hastie (2020) theoretical discussion causality property PDPs. Indeed, deep look construction PDPs suggests interpreted causal representation feature model’s output.","code":"\nlibrary(iml)                                         # One package for interpretability\nmod_iml <- Predictor$new(fit_RF,                     # This line encapsulates the objects\n                         data = training_sample %>% dplyr::select(features))\npdp_PB = FeatureEffect$new(mod_iml, feature = \"Pb\")  # This line computes the PDP for p/b ratio\nplot(pdp_PB)                                         # Plot the partial dependence."},{"path":"interp.html","id":"local-interpretations","chapter":"13 Interpretability","heading":"13.2 Local interpretations","text":"Whereas global interpretations seek assess impact features output \\(overall\\), local methods try quantify behavior model particular instances neighborhood thereof. Local interpretability recently gained traction many papers published topic. , outline widespread methods.28","code":""},{"path":"interp.html","id":"lime","chapter":"13 Interpretability","heading":"13.2.1 LIME","text":"\nLIME (Local Interpretable Model-Agnostic Explanations) methodology originally proposed Ribeiro, Singh, Guestrin (2016). aim provide\nfaithful account model two constraints:simple interpretability, implies limited number variables visual textual representation. make sure human can easily understand outcome tool;local faithfulness: explanation holds vicinity instance.original (black-box) model \\(f\\) assume want approximate behavior around instance \\(x\\) interpretable model \\(g\\). simple function \\(g\\) belongs larger class \\(G\\). vicinity \\(x\\) denoted \\(\\pi_x\\) complexity \\(g\\) written \\(\\Omega(g)\\). LIME seeks interpretation form\n\\[\\xi(x)=\\underset{g \\G}{\\text{argmin}} \\, \\mathcal{L}(f,g,\\pi_x)+\\Omega(g),\\]\n\\(\\mathcal{L}(f,g,\\pi_x)\\) loss function (error/imprecision) induced \\(g\\) vicinity \\(\\pi_x\\) \\(x\\). penalization \\(\\Omega(g)\\) instance number leaves depth tree, number predictors linear regression.now remains define terms. vicinity \\(x\\) defined \\(\\pi_x(z)=e^{-D(x,z)^2/\\sigma^2},\\) \\(D\\) distance measure \\(\\sigma^2\\) scaling constant. underline function decreases \\(z\\) shifts away \\(x\\).tricky part loss function. order minimize , LIME generates artificial samples close \\(x\\) averages/sums error label simple representation makes. simplicity, assume scalar output \\(f\\), hence formulation following:\n\\[\\mathcal{L}(f,g,\\pi_x)=\\sum_z \\pi_x(z)(f(z)-g(z))^2\\]\nerrors weighted according distance initial instance \\(x\\): closest points get largest weights. basic implementation, set models \\(G\\) consists linear models.Figure 13.5, provide simplified diagram LIME works. \nFIGURE 13.5: Simplistic explanation LIME: explained instance surrounded red square. Five points generated (triangles) weighted linear model fitted accordingly (dashed grey line).\nexpositional clarity, work one dependent variable. original training sample shown black points. fitted (trained) model represented blue line (smoothed conditional average) want approximate model works around one particular instance highlighted red square around . order build approximation, sample 5 new points around instance (5 red triangles). triangle lies blue line (model predictions) weight proportional size: triangle closest instance bigger weight. Using weighted least-squares, build linear model fits 5 points (dashed grey line). outcome approximation. gives two parameters model: intercept slope. can evaluated standard statistical tests.sign slope important. fairly clear instance taken closer \\(x=0\\), slope probably almost flat hence predictor locally discarded. Another important detail number sample points. explanation, take five, practice, robust estimation usually requires around one thousand points . Indeed, neighbors sampled, estimation risk high approximation may rough.proceed example implementation. several steps:Fit model training data.Wrap everything using lime() function.Focus predictors see impact particular instances (via explain() function).start first step. time, work boosted tree model. , head steps two three. underlined , resort lime() explain() functions.graph (one graph corresponds explanation around one instance), two types information: sign impact magnitude impact. sign revealed color (positive blue, negative red) magnitude shown size rectangles.values left graphs show ranges features local approximations computed. Lastly, briefly discuss choice distance function chosen code. used evaluate discrepancy true instance simulated one give less weight prediction sampled instance. dataset comprises numerical data; hence, Euclidean distance natural choice:\\[\\text{Euclidean}(\\textbf{x}, \\textbf{y})=\\sqrt{\\sum_{n=1}^N(x_n-y_n)^2}.\\]\nAnother possible choice Manhattan distance:\n\\[\\text{Manhattan}(\\textbf{x}, \\textbf{y})=\\sum_{n=1}^N|x_n-y_n|.\\]problem two distances fail handle categorical variables. Gower distance steps (Gower (1971)). distance imposes different treatment features different types (classes versus numbers essentially, can also handle missing data!). categorical features, Gower distance applies binary treatment: value equal 1 features equal, zero (.e., \\(1_{\\{x_n=y_n\\}}\\)). numerical features, spread quantified \\(1-\\frac{|x_n-y_n|}{R_n}\\), \\(R_n\\) maximum absolute value feature can take. similarity measurements aggregated yield final score. Note case, logic reversed: \\(\\textbf{x}\\) \\(\\textbf{y}\\) close Gower distance close one, far away distance close zero.","code":"\nlibrary(lime)                              # Package for LIME interpretation\nparams_xgb <- list(                        # Parameters of the boosted tree\n    max_depth = 5,                         # Max depth of each tree\n    eta = 0.5,                             # Learning rate \n    gamma = 0.1,                           # Penalization\n    colsample_bytree = 1,                  # Proportion of predictors to be sampled (1 = all)\n    min_child_weight = 10,                 # Min number of instances in each node\n    subsample = 1)                         # Proportion of instance to be sampled (1 = all)\nxgb_model <- xgb.train(params_xgb,         # Training of the model\n                       train_matrix_xgb,   # Training data\n                       nrounds = 10)       # Number of trees\nexplainer <- lime(training_sample %>% dplyr::select(features_short), xgb_model) # Step 2.\nexplanation <- explain(x = training_sample %>%                                  # Step 3.\n                           dplyr::select(features_short) %>%\n                           dplyr::slice(1:2),           # First two instances in train_sample \n                       explainer = explainer,           # Explainer variable created above \n                       n_permutations = 900,            # Nb samples for loss function\n                       dist_fun = \"euclidean\",          # Dist.func. \"gower\" is one alternative\n                       n_features = 6                   # Nb of features shown (important ones)\n)\nplot_features(explanation, ncol = 1)                    # Visual display"},{"path":"interp.html","id":"shapley-values","chapter":"13 Interpretability","heading":"13.2.2 Shapley values","text":"\napproach Shapley values somewhat different compared LIME closer spirit PDPs. originates cooperative game theory (Shapley (1953)). rationale following. One way assess impact (usefulness) variable look happens remove variable dataset. detrimental quality model (.e., accuracy predictions), means variable substantially valuable.Shapley values used attribute risk performance portfolios Shalit (2020), Shalit (2020) Moehle, Boyd, Ang (2021).Numerically, simplest way proceed take variables remove one evaluate predictive ability. Shapley values computed larger scale consider possible combinations variables add target predictor. Formally, gives:\\[\\begin{equation}\n\\tag{13.3} \n\\phi_k=\\sum_{S \\subseteq \\{x_1,\\dots,x_K \\} \\backslash x_k}\\underbrace{\\frac{\\text{Card}(S)!(K-\\text{Card}(S)-1)!}{K!}}_{\\text{weight coalition}}\\underbrace{\\left(\\hat{f}_{S \\cup \\{x_k\\}}(S \\cup \\{x_k\\})-\\hat{f}_S(S)\\right)}_{\\text{gain adding } x_k}\n\\end{equation}\\]Obviously, Shapley values can take lot time compute number predictors large. refer J. Chen et al. (2018) discussion simplifying method reduces computation times case.\nExtensions Shapley values interpretability studied Lundberg Lee (2017).\nimplementation Shapley values permitted R via iml package. two restrictions compared LIME. First, features must filtered upfront features shown graph (becomes illegible beyond 20 features). code , use short list predictors (Section 1.2).\nSecond, instances analyzed one time.start fitting random forest model.can analyze behavior model around first instance training sample.\nFIGURE 13.6: Illustration Shapley method.\noutput shown Figure 13.6, obtain two crucial insights: sign impact feature relative importance (compared features).","code":"\nfit_RF_short <- randomForest(R1M_Usd ~.,    # Same formula as for simple trees!\n                 data = training_sample %>% dplyr::select(c(features_short), \"R1M_Usd\"),  \n                 sampsize = 10000,          # Size of (random) sample for each tree\n                 replace = FALSE,           # Is the sampling done with replacement?\n                 nodesize = 250,            # Minimum size of terminal cluster\n                 ntree = 40,                # Nb of random trees\n                 mtry = 4                   # Nb of predictive variables for each tree\n    )\npredictor <- Predictor$new(fit_RF_short,    # This wraps the model & data\n                          data = training_sample %>% dplyr::select(features_short), \n                          y = training_sample$R1M_Usd)\nshapley <- Shapley$new(predictor,                        # Compute the Shapley values...\n                       x.interest = training_sample %>% \n                           dplyr::select(features_short) %>%\n                           dplyr::slice(1))              # On the first instance\nplot(shapley) + coord_fixed(1500) +                      # Plot\n    theme(axis.text.x = element_text(angle = 35, hjust = 1)) + coord_flip()          "},{"path":"interp.html","id":"breakdown","chapter":"13 Interpretability","heading":"13.2.3 Breakdown","text":"\nBreakdown (see, e.g., Staniak Biecek (2018)) mixture ideas PDPs Shapley values. core breakdown -called relaxed model prediction defined Equation (13.4). close spirit Equation (13.1). difference working local level, .e., one particular observation, say \\(x^*\\). want measure impact set predictors prediction associated \\(x^*\\); hence, fix two sets \\(\\textbf{k}\\) (fixed features) \\(-\\textbf{k}\\) (free features) evaluate proxy average prediction estimated model \\(\\hat{f}\\) set \\(\\textbf{k}\\) predictors fixed values \\(x^*\\), , equal \\(x^*_{\\textbf{k}}\\) expression :\\[\\begin{equation}\n\\tag{13.4} \n\\tilde{f}_{\\textbf{k}}(x^*)=\\frac{1}{M}\\sum_{m=1}^M \\hat{f}\\left(x^{(m)}_{-\\textbf{k}},x^*_{\\textbf{k}} \\right).\n\\end{equation}\\]\\(x^{(m)}\\) expression either simulated values instances simply sampled values dataset. notation implies instance values replaced \\(x^*\\), namely correspond indices \\(\\textbf{k}\\). \\(\\textbf{k}\\) consists features, \\(\\tilde{f}_{\\textbf{k}}(x^*)\\) equal raw model prediction \\(\\hat{f}(x^*)\\) \\(\\textbf{k}\\) empty, equal average sample value label (constant prediction).quantity interest -called contribution feature \\(j\\notin \\textbf{k}\\) respect data point \\(x^*\\) set \\(\\textbf{k}\\):\\[\\phi_{\\textbf{k}}^j(x^*)=\\tilde{f}_{\\textbf{k} \\cup j}(x^*)-\\tilde{f}_{\\textbf{k}}(x^*).\\]Just Shapley values, indicator computes average impact augmenting set predictors feature \\(j\\). definition, depends set \\(\\textbf{k}\\), one notable difference Shapley values (span permutations). Staniak Biecek (2018), authors devise procedure incrementally increases decreases set \\(\\textbf{k}\\). greedy idea helps alleviate burden computing possible combinations features. Moreover, convenient property algorithm sum contributions equal predicted value:\n\\[\\sum_j \\phi_{\\textbf{k}}^j(x^*)=f(x^*).\\]visualization makes easy see (Figure 13.7 ).order illustrate one implementation breakdown, train random forest limited number features, shown . increase readability output breakdown.model trained, syntax breakdown predictions simple.\nFIGURE 13.7: Example breakdown output.\ngraphical output intuitively interpreted. grey bar prediction model chosen instance. Green bars signal positive contribution yellowish rectangles show variables negative impact. relative sizes indicate importance feature.","code":"\nformula_short <- paste(\"R1M_Usd ~\", paste(features_short, collapse = \" + \")) #  Model \nformula_short <- as.formula(formula_short)                                   #  Formula format\nfit_RF_short <- randomForest(formula_short, # Same formula as before\n                 data = dplyr::select(training_sample, c(features_short, \"R1M_Usd\")),  \n                 sampsize = 10000,          # Size of (random) sample for each tree\n                 replace = FALSE,           # Is the sampling done with replacement?\n                 nodesize = 250,            # Minimum size of terminal cluster\n                 ntree = 12,                # Nb of random trees\n                 mtry = 5                   # Nb of predictive variables for each tree\n    )\nlibrary(breakDown)\nexplain_break <- broken(fit_RF_short, \n                        data_ml[6,] %>% dplyr::select(features_short),\n                        data = data_ml %>% dplyr::select(features_short))\nplot(explain_break) "},{"path":"causality.html","id":"causality","chapter":"14 Two key concepts: causality and non-stationarity","heading":"14 Two key concepts: causality and non-stationarity","text":" \nprominent point criticism faced ML tools inability uncover causality relationships features labels mostly focused (design) capture correlations. Correlations much weaker causality characterize two-way relationship (\\(\\textbf{X}\\leftrightarrow \\textbf{y}\\)), causality specifies direction \\(\\textbf{X}\\rightarrow \\textbf{y}\\) \\(\\textbf{X}\\leftarrow \\textbf{y}\\). One fashionable example sentiment. Many academic articles seem find sentiment (irrespectively definition) significant driver future returns. high sentiment particular stock may increase demand stock push price (though contrarian reasonings may also apply: sentiment high, sign mean-reversion possibly happen). reverse causation also plausible: returns may well cause sentiment. stock experiences long period market growth, people become bullish stock sentiment increases (notably comes extrapolation, see Barberis et al. (2015) theoretical model). Coqueret (2020), found (opposition findings field), latter relationship (returns \\(\\rightarrow\\) sentiment) likely. result backed causality driven tests (see Section 14.1.1).Statistical causality large field refer Pearl (2009) deep dive topic. Recently, researchers sought link causality ML approaches (see, e.g., Peters, Janzing, Schölkopf (2017), Heinze-Deml, Peters, Meinshausen (2018), Arjovsky et al. (2019)). key notion work invariance. Often, data collected , different sources different moments. relationships found different sources change, others may remain . relationships invariant changing environments likely stem (signal) causality. One counter-example following (related Beery, Van Horn, Perona (2018)): training computer vision algorithm discriminate cows camels lead algorithm focus grass versus sand! camels pictured desert cows shown green fields grass. Thus, picture camel grass classified cow, cow sand labelled “camel.” pictures two animals different contexts (environments) learner end truly finding makes cow camel. camel remain camel matter pictured: recognized learner. , representation camel becomes invariant datasets learner discovered causality, .e., true attributes make camel camel (overall silhouette, shape back, face, color (possibly misleading!), etc.).search invariance makes sense many disciplines like computer vision natural language processing (cats always look like cats languages don’t change much). finance, obvious invariance may exist. Market conditions known time-varying relationships firm characteristics returns also change year year. One solution issue may simply embrace non-stationarity (see Section 1.1 definition stationarity). Chapter 12, advocate updating models frequently possible rolling training sets: allows predictions based recent trends. Section 14.2 , introduce theoretical practical options.","code":""},{"path":"causality.html","id":"causality-1","chapter":"14 Two key concepts: causality and non-stationarity","heading":"14.1 Causality","text":"\nTraditional machine learning models aim uncover relationships variables usually specify directions relationships. One typical example linear regression. write \\(y=+bx+\\epsilon\\), also true \\(x=b^{-1}(y--\\epsilon)\\), course also linear relationship (respect \\(y\\)). equations define causation whereby \\(x\\) clear determinant \\(y\\) (\\(x \\rightarrow y\\), opposite false).Recently, D’Acunto et al. (2021) investigated causal structure prominent equity factors. study, via VAR-LiNGAM technique Hyvärinen et al. (2010), finds risk factor interations continuously evolving.","code":""},{"path":"causality.html","id":"granger","chapter":"14 Two key concepts: causality and non-stationarity","heading":"14.1.1 Granger causality","text":"\nnotable tool first proposed Granger (1969) probably simplest. simplicity, consider two stationary processes, \\(X_t\\) \\(Y_t\\). strict definition causality following. \\(X\\) can said cause \\(Y\\), whenever, integer \\(k\\),\n\\[(Y_{t+1},\\dots,Y_{t+k})|(\\mathcal{F}_{Y,t}\\cup \\mathcal{F}_{X,t}) \\quad  \\overset{d}{\\neq} \\quad (Y_{t+1},\\dots,Y_{t+k})|\\mathcal{F}_{Y,t},\\]\n, distribution future values \\(Y_t\\), conditionally knowledge processes distribution sole knowledge filtration \\(\\mathcal{F}_{Y,t}\\). Hence \\(X\\) impact \\(Y\\) trajectory alters \\(Y\\).Now, formulation vague impossible handle numerically, thus simplify setting via linear formulation. keep notations section 5 original paper Granger (1969). test consists two regressions:\n\\[\\begin{align*}\nX_t&=\\sum_{j=1}^ma_jX_{t-j}+\\sum_{j=1}^mb_jY_{t-j} + \\epsilon_t \\\\\nY_t&=\\sum_{j=1}^mc_jX_{t-j}+\\sum_{j=1}^md_jY_{t-j} + \\nu_t\n\\end{align*}\\]\nsimplicity, assumed processes zero mean. usual assumptions apply: Gaussian noises \\(\\epsilon_t\\) \\(\\nu_t\\) uncorrelated every possible way (mutually time). test following: one \\(b_j\\) nonzero, said \\(Y\\) Granger-causes \\(X\\) one \\(c_j\\) nonzero, \\(X\\) Granger-causes \\(Y\\). two mutually exclusive widely accepted feedback loops can well occur.Statistically, null hypothesis, \\(b_1=\\dots=b_m=0\\) (resp. \\(c_1=\\dots=c_m=0\\)), can tested using usual Fischer distribution. Obviously, linear restriction can dismissed tests much complex. main financial article direction Hiemstra Jones (1994).many R packages embed Granger causality functionalities. One widespread lmtest, work . syntax incredibly simple. order maximum lag \\(m\\) equation. test market capitalization averaged past 6 months Granger-causes 1 month ahead returns one particular stock (first sample).test directional tests \\(X\\) Granger-causes \\(Y\\). order test reverse effect, required inverse arguments function. output , \\(p\\)-value low, hence probability observing samples similar knowing \\(H_0\\) holds negligible. Thus seems market capitalization Granger-cause one-month returns. nonetheless underline Granger causality arguably weaker one defined next subsection. process Granger-causes another one simply contains useful predictive information, proof causality strict sense. Moreover, test limited linear model including nonlinearities may alter conclusion. Lastly, including regressors (possibly omitted variables) also change results (see, e.g., Chow, Cotsomitis, Kwan (2002)).","code":"\nlibrary(lmtest)\nx_granger <- training_sample %>%                            # X variable =...\n    filter(stock_id ==1) %>%     # ... stock nb 1\n    pull(Mkt_Cap_6M_Usd)         # ... & Market cap\ny_granger <- training_sample %>%                            # Y variable = ...\n    filter(stock_id ==1) %>%     # ... stock nb 1\n    pull(R1M_Usd)                # ... & 1M return\nfit_granger <- grangertest(x_granger,                       # X variable\n                           y_granger,                       # Y variable\n                           order = 6,                       # Maximmum lag\n                           na.action = na.omit)             # What to do with missing data\nfit_granger## Granger causality test\n## \n## Model 1: y_granger ~ Lags(y_granger, 1:6) + Lags(x_granger, 1:6)\n## Model 2: y_granger ~ Lags(y_granger, 1:6)\n##   Res.Df Df     F    Pr(>F)    \n## 1    149                       \n## 2    155 -6 4.111 0.0007554 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"causality.html","id":"causal-additive-models","chapter":"14 Two key concepts: causality and non-stationarity","heading":"14.1.2 Causal additive models","text":"\nzoo causal model encompasses variety beasts (even BARTs Section 9.5 used purpose Hahn, Murray, Carvalho (2019)). interested reader can peek Pearl (2009), Peters, Janzing, Schölkopf (2017), Maathuis et al. (2018) Hünermund Bareinboim (2019) references therein. One central tool causal models -calculus developed Pearl. Whereas traditional probabilities \\(P[Y|X]\\) link odds \\(Y\\) conditionally observing \\(X\\) take value \\(x\\), (\\(\\cdot\\)) forces \\(X\\) take value \\(x\\). looking versus dichotomy. One classical example following. Observing barometer gives clue weather high pressures often associated sunny days:\n\\[P[\\text{sunny weather}|\\text{barometer says ``high''} ]>P[\\text{sunny weather}|\\text{barometer says ``low''} ],\\]\nhack barometer (force display value),\n\\[P[\\text{sunny weather}|\\text{barometer hacked ``high''} ]=P[\\text{sunny weather}|\\text{barometer hacked ``low''} ],\\]\nhacking barometer impact weather. short notation, intervention barometer, \\(P[\\text{weather}|\\text{(barometer)}]=P[\\text{weather}]\\). interesting example related causality. overarching variable pressure. Pressure impacts weather barometer joint effect called confounding. However, may true barometer impacts weather. interested reader wants dive deeper concepts closer look work Judea Pearl. -calculus powerful theoretical framework, easy apply situation dataset (see instance book review Aronow Sävje (2019)).formally present exhaustive tour theory behind causal inference, wish show practical implementations easy interpret. always hard single one type model particular choose one can explained simple mathematical tools. start simplest definition structural causal model (SCM), follow chapter 3 Peters, Janzing, Schölkopf (2017). idea behind models introduce hierarchy (.e., additional structure) model. Formally, gives\n\\[\\begin{align*}\nX&=\\epsilon_X \\\\ \nY&=f(X,\\epsilon_Y),\n\\end{align*}\\]\n\\(\\epsilon_X\\) \\(\\epsilon_Y\\) independent noise variables. Plainly, realization \\(X\\) drawn randomly impact realization \\(Y\\) via \\(f\\). Now scheme complex number observed variables larger. Imagine third variable comes \n\\[\\begin{align*}\nX&=\\epsilon_X \\\\ \nY&=f(X,\\epsilon_Y),\\\\\nZ&=g(Y,\\epsilon_Z)\n\\end{align*}\\]case, \\(X\\) causation effect \\(Y\\) \\(Y\\) causation effect \\(Z\\). thus following connections:\n\\[\\begin{array}{ccccccc} X & &&&\\\\\n&\\searrow & &&\\\\\n&&Y&\\rightarrow&Z. \\\\\n&\\nearrow &&\\nearrow& \\\\\n\\epsilon_Y & &\\epsilon_Z \n\\end{array}\\]\nrepresentation called graph graph theory nomenclature, briefly summarize. variables often referred vertices (nodes) arrows edges. arrows direction, called directed edges. two vertices connected via edge, called adjacent. sequence adjacent vertices called path, directed edges arrows. Within directed path, vertex comes first parent node one just child node.Graphs can summarized adjacency matrices. adjacency matrix \\(\\textbf{}=A_{ij}\\) matrix filled zeros ones. \\(A_{ij}=1\\) whenever edge vertex \\(\\) vertex \\(j\\). Usually, self-loops (\\(X \\rightarrow X\\)) prohibited adjacency matrices zeros diagonal. consider simplified version graph like \\(X \\rightarrow Y \\rightarrow Z\\), corresponding adjacency matrix \\[\\textbf{}=\\begin{bmatrix} \n0 & 1 & 0 \\\\\n0 & 0 & 1 \\\\\n0& 0&0\n\\end{bmatrix}.\\]letters \\(X\\), \\(Y\\), \\(Z\\) naturally ordered alphabetically. two arrows: \\(X\\) \\(Y\\) (first row, second column) \\(Y\\) \\(Z\\) (second row, third column).cycle particular type path creates loop, .e., first vertex also last. sequence \\(X \\rightarrow Y \\rightarrow Z \\rightarrow X\\) cycle. Technically, cycles pose problems. illustrate , consider simple sequence \\(X \\rightarrow Y \\rightarrow X\\). imply realization \\(X\\) causes \\(Y\\) turn cause realization \\(Y\\). Granger causality can viewed allowing kind connection, general causal models usually avoid cycles work directed acyclic graphs (DAGs). Formal graph manipulations (possibly linked -calculus) can computed via causaleffect package Tikka Karvanen (2017). Direct acyclic graphs can also created manipulated dagitty (Textor et al. (2016)) ggdag packages.Equipped tools, can explicitize general form models:\n\\[\\begin{equation}\n\\tag{14.1} \nX_j=f_j\\left(\\textbf{X}_{\\text{pa}_D(j)},\\epsilon_j  \\right),\n\\end{equation}\\]noise variables mutually independent. notation \\(\\text{pa}_D(j)\\) refers set parent nodes vertex \\(j\\) within graph structure \\(D\\). Hence, \\(X_j\\) function parents noise term \\(\\epsilon_j\\). additive causal model mild simplification specification:\\[\\begin{equation}\n\\tag{14.2} \nX_j=\\sum_{k\\\\text{pa}_D(j)}f_{j,k}\\left(\\textbf{X}_{k}  \\right)+\\epsilon_j,\n\\end{equation}\\]nonlinear effect variable cumulative, hence term ‘additive.’ Note time index . contrast Granger causality, natural ordering. models complex hard estimate. details can found Bühlmann et al. (2014). Fortunately, authors developed R package determines DAG \\(D\\)., build adjacency matrix pertaining small set predictor variables plus 1-month ahead return (training sample). original version book used CAM package simple syntax.29 , test recent InvariantCausalPrediction package.[[NOTE: remainder subsection revision.]]matrix sparse, means model uncovered many relationships variables within sample. Sadly, none direction interest prediction task seek. Indeed, first variable one want predict column empty. However, row full, indicates reverse effect: future returns cause predictor values, may seem rather counter-intuitive, given nature features.sake completeness, also provide implementation pcalg package (Kalisch et al. (2012)).30 , estimation via -called PC (named authors Peter Spirtes Clark Glymour) performed. details algorithm scope book, interested reader can look section 5.4 Spirtes et al. (2000) section 2 Kalisch et al. (2012) information subject. use Rgraphviz package available https://www.bioconductor.org/packages/release/bioc/html/Rgraphviz.html.\nFIGURE 14.1: Representation directed graph.\nbidirectional arrow shown model unable determine edge orientation. adjacency matrix different compared first model, still predictors seem clear causal effect dependent variable (first circle).","code":"\n# library(CAM)                # Activate the package\ndata_caus <- training_sample %>% dplyr::select(c(\"R1M_Usd\", features_short))\n# fit_cam <- CAM(data_caus)   # The main function\n# fit_cam$Adj                 # Showing the adjacency matrix\nlibrary(InvariantCausalPrediction)\nICP(X = training_sample %>% dplyr::select(all_of(features_short)) %>% as.matrix(),\n    Y = training_sample %>% dplyr::pull(\"R1M_Usd\"),\n    ExpInd = round(runif(nrow(training_sample))),\n    alpha = 0.05)## \n##  accepted empty set\n##  accepted set of variables \n##  accepted set of variables 1\n##  *** 2% complete: tested 2 of 128 sets of variables \n##  accepted set of variables 2\n##  accepted set of variables 3\n##  accepted set of variables 4\n##  accepted set of variables 5\n##  accepted set of variables 6\n##  accepted set of variables 7\n##  accepted set of variables 1,2\n##  accepted set of variables 1,3\n##  accepted set of variables 2,3\n##  accepted set of variables 1,4\n##  accepted set of variables 2,4\n##  accepted set of variables 3,4\n##  accepted set of variables 1,5\n##  accepted set of variables 2,5\n##  accepted set of variables 3,5\n##  accepted set of variables 4,5\n##  accepted set of variables 1,6\n##  accepted set of variables 2,6\n##  accepted set of variables 3,6\n##  accepted set of variables 4,6\n##  accepted set of variables 5,6\n##  accepted set of variables 1,7\n##  accepted set of variables 2,7\n##  accepted set of variables 3,7\n##  accepted set of variables 4,7\n##  accepted set of variables 5,7\n##  accepted set of variables 6,7\n##  accepted set of variables 1,2,3\n##  accepted set of variables 1,2,4\n##  accepted set of variables 1,3,4\n##  accepted set of variables 2,3,4\n##  accepted set of variables 1,2,5\n##  accepted set of variables 1,3,5\n##  accepted set of variables 2,3,5\n##  accepted set of variables 1,4,5\n##  accepted set of variables 2,4,5\n##  accepted set of variables 3,4,5\n##  accepted set of variables 1,2,6\n##  accepted set of variables 1,3,6\n##  accepted set of variables 2,3,6\n##  accepted set of variables 1,4,6\n##  accepted set of variables 2,4,6\n##  accepted set of variables 3,4,6\n##  accepted set of variables 1,5,6\n##  accepted set of variables 2,5,6\n##  accepted set of variables 3,5,6\n##  accepted set of variables 4,5,6\n##  accepted set of variables 1,2,7\n##  accepted set of variables 1,3,7\n##  accepted set of variables 2,3,7\n##  accepted set of variables 1,4,7\n##  accepted set of variables 2,4,7\n##  accepted set of variables 3,4,7\n##  accepted set of variables 1,5,7\n##  accepted set of variables 2,5,7\n##  accepted set of variables 3,5,7\n##  accepted set of variables 4,5,7\n##  accepted set of variables 1,6,7\n##  accepted set of variables 2,6,7\n##  accepted set of variables 3,6,7\n##  accepted set of variables 4,6,7\n##  accepted set of variables 5,6,7\n##  accepted set of variables 1,2,3,4\n##  accepted set of variables 1,2,3,5\n##  accepted set of variables 1,2,4,5\n##  accepted set of variables 1,3,4,5\n##  accepted set of variables 2,3,4,5\n##  accepted set of variables 1,2,3,6\n##  accepted set of variables 1,2,4,6\n##  accepted set of variables 1,3,4,6\n##  accepted set of variables 2,3,4,6\n##  accepted set of variables 1,2,5,6\n##  accepted set of variables 1,3,5,6\n##  accepted set of variables 2,3,5,6\n##  accepted set of variables 1,4,5,6\n##  accepted set of variables 2,4,5,6\n##  accepted set of variables 3,4,5,6\n##  accepted set of variables 1,2,3,7\n##  accepted set of variables 1,2,4,7\n##  accepted set of variables 1,3,4,7\n##  accepted set of variables 2,3,4,7\n##  accepted set of variables 1,2,5,7\n##  accepted set of variables 1,3,5,7\n##  accepted set of variables 2,3,5,7\n##  accepted set of variables 1,4,5,7\n##  accepted set of variables 2,4,5,7\n##  accepted set of variables 3,4,5,7\n##  accepted set of variables 1,2,6,7\n##  accepted set of variables 1,3,6,7\n##  accepted set of variables 2,3,6,7\n##  accepted set of variables 1,4,6,7\n##  accepted set of variables 2,4,6,7\n##  accepted set of variables 3,4,6,7\n##  accepted set of variables 1,5,6,7\n##  accepted set of variables 2,5,6,7\n##  accepted set of variables 3,5,6,7\n##  accepted set of variables 4,5,6,7\n##  accepted set of variables 1,2,3,4,5\n##  accepted set of variables 1,2,3,4,6\n##  accepted set of variables 1,2,3,5,6\n##  accepted set of variables 1,2,4,5,6\n##  accepted set of variables 1,3,4,5,6\n##  accepted set of variables 2,3,4,5,6\n##  accepted set of variables 1,2,3,4,7\n##  accepted set of variables 1,2,3,5,7\n##  accepted set of variables 1,2,4,5,7\n##  accepted set of variables 1,3,4,5,7\n##  accepted set of variables 2,3,4,5,7\n##  accepted set of variables 1,2,3,6,7\n##  accepted set of variables 1,2,4,6,7\n##  accepted set of variables 1,3,4,6,7\n##  accepted set of variables 2,3,4,6,7\n##  accepted set of variables 1,2,5,6,7\n##  accepted set of variables 1,3,5,6,7\n##  accepted set of variables 2,3,5,6,7\n##  accepted set of variables 1,4,5,6,7\n##  accepted set of variables 2,4,5,6,7\n##  accepted set of variables 3,4,5,6,7\n##  accepted set of variables 1,2,3,4,5,6\n##  accepted set of variables 1,2,3,4,5,7\n##  accepted set of variables 1,2,3,4,6,7\n##  accepted set of variables 1,2,3,5,6,7\n##  accepted set of variables 1,2,4,5,6,7\n##  accepted set of variables 1,3,4,5,6,7\n##  accepted set of variables 2,3,4,5,6,7\n##  accepted set of variables 1,2,3,4,5,6,7## \n##  Invariant Linear Causal Regression at level 0.05 (including multiplicity correction for the number of variables)\n##  \n##                   LOWER BOUND  UPPER BOUND  MAXIMIN EFFECT  P-VALUE\n## Div_Yld                -0.01         0.01            0.00     0.35\n## Eps                    -0.02         0.00            0.00     0.35\n## Mkt_Cap_12M_Usd        -0.04         0.00            0.00     0.34\n## Mom_11M_Usd            -0.02         0.00            0.00     0.34\n## Ocf                    -0.02         0.03            0.00     0.34\n## Pb                     -0.02         0.00            0.00     0.35\n## Vol1Y_Usd               0.00         0.02            0.00     0.35\nlibrary(pcalg)                                             # Load packages\nlibrary(Rgraphviz)\nest_caus <- list(C = cor(data_caus),  n = nrow(data_caus)) # Compute correlations\npc.fit <- pc(est_caus, indepTest = gaussCItest,            # Estimate model\n             p = ncol(data_caus),alpha = 0.01)\niplotPC(pc.fit)                                            # Plot model"},{"path":"causality.html","id":"structural-time-series-models","chapter":"14 Two key concepts: causality and non-stationarity","heading":"14.1.3 Structural time series models","text":"\nend topic causality mentioning particular type structural models: structural time series. illustrate relevance particular kind causal inference, closely follow notations Brodersen et al. (2015). model driven two equations:\\[\\begin{align*}\ny_t&=\\textbf{Z}_t'\\boldsymbol{\\alpha}_t+\\epsilon_t \\\\\n\\boldsymbol{\\alpha}_{t+1}& =\\textbf{T}_t\\boldsymbol{\\alpha}_{t}+\\textbf{R}_t\\boldsymbol{\\eta}_t.\n\\end{align*}\\]dependent variable expressed linear function state variables \\(\\boldsymbol{\\alpha}_t\\) plus error term. variables turn linear functions past values plus another error term can complex structure (’s product matrix \\(\\textbf{R}_t\\) centered Gaussian term \\(\\boldsymbol{\\eta}_t\\)). specification nests many models special cases, like ARIMA instance.goal Brodersen et al. (2015) detect causal impacts via regime changes. estimate model given training period predict model’s response test set. aggregate (summed/integrated) error realized versus predicted values significant (based statistical test), authors conclude breaking point relevant. Originally, aim approach quantify effect intervention looking model trained intervention behaves intervention., test 100\\(^{th}\\) date point sample (April 2008) turning point. Arguably, date belongs time span subprime financial crisis. use CausalImpact package uses bsts library (Bayesian structural time series).time series associated model shown Figure 14.2.\nFIGURE 14.2: Output causal impact study.\n, copy paste report generated function (obtained commented line code). conclusions support marked effect crisis model probably signs error post period constantly change sign.post-intervention period, response variable average value approx. 0.016. absence intervention, expected average response 0.031. 95% interval counterfactual prediction [-0.0059, 0.063]. Subtracting prediction observed response yields estimate causal effect intervention response variable. effect -0.015 95% interval [-0.047, 0.022].Summing individual data points post-intervention period (can sometimes meaningfully interpreted), response variable overall value 1.64. intervention taken place, expected sum 3.09. 95% interval prediction [-0.59, 6.34]. results given terms absolute numbers. relative terms, response variable showed decrease -47%. 95% interval percentage [-152%, +72%].means , although may look though intervention exerted negative effect response variable considering intervention period whole, effect statistically significant, meaningfully interpreted. apparent effect result random fluctuations unrelated intervention. often case intervention period long includes much time effect already worn . can also case intervention period short distinguish signal noise. Finally, failing find significant effect can happen enough control variables variables correlate well response variable learning period.probability obtaining effect chance p = 0.199. means effect may spurious generally considered statistically significant.","code":"\nlibrary(CausalImpact)\nstock1_data <- data_ml %>% filter(stock_id == 1)          # Data of first stock\nstruct_data <- data.frame(y = stock1_data$R1M_Usd) %>%    # Combine label...\n    cbind(stock1_data %>% dplyr::select(features_short))  # ... and features\npre.period <- c(1,100)                                    # Pre-break period (pre-2008)\npost.period <- c(101,200)                                 # Post-break period\nimpact <- CausalImpact(zoo(struct_data), pre.period, post.period)\nsummary(impact)## Posterior inference {CausalImpact}\n## \n##                          Average            Cumulative      \n## Actual                   0.016              1.638           \n## Prediction (s.d.)        0.03 (0.017)       3.05 (1.734)    \n## 95% CI                   [-0.0037, 0.065]   [-0.3720, 6.518]\n##                                                             \n## Absolute effect (s.d.)   -0.014 (0.017)     -1.410 (1.734)  \n## 95% CI                   [-0.049, 0.02]     [-4.880, 2.01]  \n##                                                             \n## Relative effect (s.d.)   -46% (57%)         -46% (57%)      \n## 95% CI                   [-160%, 66%]       [-160%, 66%]    \n## \n## Posterior tail-area probability p:   0.186\n## Posterior prob. of a causal effect:  81%\n## \n## For more details, type: summary(impact, \"report\")\n#summary(impact, \"report\")                                # Get the full report (see below)\nplot(impact)"},{"path":"causality.html","id":"nonstat","chapter":"14 Two key concepts: causality and non-stationarity","heading":"14.2 Dealing with changing environments","text":"common assumption machine learning contributions samples studied ..d. realizations phenomenon trying characterize. constraint natural relationship \\(X\\) \\(y\\) always changes, hard infer anything observations. One major problem Finance often case: markets, behaviors, policies, etc., evolve time. least partly related notion absence arbitrage: trading strategy worked time, agents eventually adopt via herding, annihilate corresponding gains.31 strategy kept private, holder become infinitely rich, obviously never happened.several ways define changes environments. denote \\(\\mathbb{P}_{XY}\\) multivariate distribution variables (features label), \\(\\mathbb{P}_{XY}=\\mathbb{P}_{X}\\mathbb{P}_{Y|X}\\), two simple changes possible:covariate shift: \\(\\mathbb{P}_{X}\\) changes \\(\\mathbb{P}_{Y|X}\\) : features fluctuating distribution, relationship \\(Y\\) holds still;concept drift: \\(\\mathbb{P}_{Y|X}\\) changes \\(\\mathbb{P}_{X}\\) : feature distributions stable, relation \\(Y\\) altered.Obviously, omit case items change, complex handle. factor investing, feature engineering process (see Section 4.4) partly designed bypass risk covariate shift. Uniformization guarantees marginals stay correlations features may course change. main issue probably concept drift way features explain label changes time. Cornuejols, Miclet, Barra (2018),32 authors distinguish four types drifts, reproduce Figure 14.3. factor models, changes presumably combination four types: can abrupt crashes, time progressive (gradual incremental) never-ending (continuously recurring).\nFIGURE 14.3: Different flavors concept change.\nNaturally, aknowledge environment changes, appears logical adapt models accordingly, .e., dynamically. gives rise -called stability-plasticity dilemma. dilemma trade-model reactiveness (new instances important impact updates) versus stability (instances may representative slower trend may thus shift model suboptimal direction).Practically, two ways shift cursor respect dilemma: alter chronological depth training sample (e.g., go back time) , ’s possible, allocate weight recent instances. discuss first option Section 12.1 second mentioned Section 6.3 (though purpose Adaboost precisely let algorithm handle weights). neural networks, possible, generality introduce instance-based weights computation loss function, though option (yet) available Keras (best knowledge: framework evolves rapidly). simple regressions, idea known weighted least squares wherein errors weighted inside loss:\n\\[L=\\sum_{=1}^Iw_i(y_i-\\textbf{x}_i\\textbf{b})^2.\\]\nmatrix terms, \\(L=(\\textbf{y}-\\textbf{Xb})'\\textbf{W}(\\textbf{y}-\\textbf{Xb})\\), \\(\\textbf{W}\\) diagonal matrix weights. gradient respect \\(\\textbf{b}\\) equal \\(2\\textbf{X}'\\textbf{WX}\\textbf{b}-2\\textbf{X}'\\textbf{Wy}\\) loss minimized \\(\\textbf{b}^*=(\\textbf{X}'\\textbf{WX})^{-1}\\textbf{X}'\\textbf{Wy}\\). standard least-square solution recovered \\(\\textbf{W}=\\textbf{}\\). order fine-tune reactiveness model, weights must function decreases instances become older sample.course perfect solution changing financial environements. , mention two routes taken ML literature overcome problem non-stationarity data generating process. first, propose yet another clear verification markets experience time-varying distributions.","code":""},{"path":"causality.html","id":"non-stationarity-yet-another-illustration","chapter":"14 Two key concepts: causality and non-stationarity","heading":"14.2.1 Non-stationarity: yet another illustration","text":"One basic practices (financial) econometrics work returns (relative price changes). simple reason returns seem behave consistently time (monthly returns bounded, usually lie -1 +1). Prices hand shift , often, prices never come back past values. makes prices harder study.Stationarity key notion financial econometrics: much easier characterize phenomenon distributional properties remain time (makes possible capture). Sadly, distribution returns stationary: mean variance returns change along cycles., Figure 14.4, illustrate fact computing average monthly return calendar years whole dataset.\nFIGURE 14.4: Average monthly return yearly basis.\nchanges mean also accompanied variations second moment (variance/volatility). effect, known volatility clustering, widely documented ever since theoretical breakthrough Engle (1982) (even well ). refer instance Cont (2007) details topic. computation realized volatility R, strongly recommend chapter 4 Regenstein (2018).terms machine learning models, also true. , estimate pure characteristic regression one predictor, market capitalization averaged past 6-months (\\(r_{t+1,n}=\\alpha+\\beta x_{t,n}^{\\text{cap}}+\\epsilon_{t+1,n}\\)). label 6-month forward return estimation performed every calendar year.\nFIGURE 14.5: Variations betas respect 6-month market capitalization.\nbars Figure 14.5 highlight concept drift: overall, relationship capitalization returns negative (size effect ). Sometimes markedly negative, sometimes, much. ability capitalization explain returns time-varying models must adapt accordingly.","code":"\ndata_ml %>% \n    mutate(year = year(date)) %>%          # Create a year variable\n    group_by(year) %>%                     # Group by year\n    summarize(avg_ret = mean(R1M_Usd)) %>% # Compute average return\n    ggplot(aes(x = year, y = avg_ret)) + geom_col() + theme_grey()\ndata_ml %>%\n    mutate(year = year(date)) %>%                           # Create a year variable\n    group_by(year) %>%                                      # Group by year\n    summarize(beta_cap = lm(R6M_Usd ~ Mkt_Cap_6M_Usd) %>%   # Perform regression\n                  coef() %>%                                # Extract coefs\n                  t() %>%                                   # Transpose\n                  data.frame() %>%                          # Format into df\n                  pull(Mkt_Cap_6M_Usd)) %>%                 # Pull coef (remove intercept)\n    ggplot(aes(x = year, y = beta_cap)) + geom_col() +      # Plot\n    theme_grey()"},{"path":"causality.html","id":"online-learning","chapter":"14 Two key concepts: causality and non-stationarity","heading":"14.2.2 Online learning","text":"\nOnline learning refers subset machine learning new information arrives progressively integration flow performed iteratively (term ‘online’ linked internet). order take latest data updates account, imperative update model (stating obvious). clearly case finance topic closely related discussion learning windows Section 12.1.problem 2019 model trained data 2010 2019, (dynamic) 2020 model re-trained whole dataset including latest points 2020. can heavy including just latest points learning process substantially decrease computational cost. neural networks, sequential batch updating weights can allow progressive change model. Nonetheless, typically impossible decision trees splits decided . One notable exception Basak (2004), , case, construction trees differs strongly original algorithm.simplest example online learning Widrow-Hodd algorithm (originally Widrow Hoff (1960)). Originally, idea comes -called ADALINE (ADAptive LInear NEuron) model neural network one hidden layer linear activation function (.e., like perceptron, different activation).Suppose model linear, \\(\\textbf{y}=\\textbf{Xb}+\\textbf{e}\\) (constant can added list predictors) amount data massive coming high frequency updating model full sample proscribed technically intractable. simple heuristic way update values \\(\\textbf{b}\\) compute\n\\[\\textbf{b}_{t+1} \\longleftarrow \\textbf{b}_t-\\eta (\\textbf{x}_t\\textbf{b}-y_t)\\textbf{x}_t',\\]\n\\(\\textbf{x}_t\\) row vector instance \\(t\\). justification simple. quadratic error \\((\\textbf{x}_t\\textbf{b}-y_t)^2\\) gradient respect \\(\\textbf{b}\\) equal \\(2(\\textbf{x}_t\\textbf{b}-y_t)\\textbf{x}_t'\\); therefore, update simple example gradient descent. \\(\\eta\\) must course quite small: , new point considerably alter \\(\\textbf{b}\\), thereby resulting volatile model.exhaustive review techniques pertaining online learning presented Hoi et al. (2018) (section 4.11 even dedicated portfolio selection). book Hazan et al. (2016) covers online convex optimization close domain large overlap online learning. presentation adapted second third parts first survey.Datasets indexed time: write \\(\\textbf{X}_t\\) \\(\\textbf{y}_t\\) features labels (usual column index (\\(k\\)) row index (\\(\\)) used section). Time bounded horizon \\(T\\). machine learning model depends parameters \\(\\boldsymbol{\\theta}\\) denote \\(f_{\\boldsymbol{\\theta}}\\). time \\(t\\) (dataset (\\(\\textbf{X}_t\\), \\(\\textbf{y}_t\\)) gathered), loss function \\(L\\) trained model naturally depends data (\\(\\textbf{X}_t\\), \\(\\textbf{y}_t\\)) model via \\(\\boldsymbol{\\theta}_t\\) parameter values fitted time-\\(t\\) data. notational simplicity, henceforth write \\(L_t(\\boldsymbol{\\theta}_t)=L(\\textbf{X}_t,\\textbf{y}_t,\\boldsymbol{\\theta}_t )\\). key quantity online learning regret whole time sequence:\n\\[\\begin{equation}\n\\tag{14.3} \nR_T=\\sum_{t=1}^TL_t(\\boldsymbol{\\theta}_t)-\\underset{\\boldsymbol{\\theta}^*\\\\boldsymbol{\\Theta}}{\\inf} \\ \\sum_{t=1}^TL_t(\\boldsymbol{\\theta}^*).\n\\end{equation}\\]regret total loss incurred models \\(\\boldsymbol{\\theta}_t\\) minus minimal loss obtained full knowledge data sequence (hence computed hindsight). basic methods online learning fact quite similar batch-training neural networks. updating parameter based \n\\[\\begin{equation}\n\\tag{14.4} \n\\textbf{z}_{t+1}=\\boldsymbol{\\theta}_t-\\eta_t\\nabla L_t(\\boldsymbol{\\theta}_t),\n\\end{equation}\\]\n\\(\\nabla L_t(\\boldsymbol{\\theta}_t)\\) denotes gradient current loss \\(L_t\\). One problem can arise \\(\\textbf{z}_{t+1}\\) falls bounds prescribed \\(\\boldsymbol{\\theta}_t\\). Thus, candidate vector new parameters, \\(\\textbf{z}_{t+1}\\), projected onto feasible domain call \\(S\\) :\n\\[\\begin{equation}\n\\tag{14.5} \n\\boldsymbol{\\theta}_{t+1}=\\Pi_S(\\textbf{z}_{t+1}), \\quad \\text{} \\quad \\Pi_S(\\textbf{u}) = \\underset{\\boldsymbol{\\theta}\\S}{\\text{argmin}} \\ ||\\boldsymbol{\\theta}-\\textbf{u}||_2.\n\\end{equation}\\]\nHence \\(\\boldsymbol{\\theta}_{t+1}\\) close possible intermediate choice \\(\\textbf{z}_{t+1}\\). Hazan, Agarwal, Kale (2007), shown suitable assumptions (e.g., \\(L_t\\) strictly convex bounded gradient \\(\\left|\\left|\\underset{\\boldsymbol{\\theta}}{\\sup} \\, \\nabla L_t(\\boldsymbol{\\theta})\\right|\\right|\\le G\\)), regret \\(R_T\\) satisfies\n\\[R_T \\le \\frac{G^2}{2H}(1+\\log(T)),\\]\n\\(H\\) scaling factor learning rate (also called step sizes): \\(\\eta_t=(Ht)^{-1}\\).sophisticated online algorithms generalize (14.4) (14.5) integrating Hessian matrix \\(\\nabla^2 L_t(\\boldsymbol{\\theta}):=[\\nabla^2 L_t]_{,j}=\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_i \\partial \\boldsymbol{\\theta}_j}L_t( \\boldsymbol{\\theta})\\) /including penalizations reduce instability \\(\\boldsymbol{\\theta}_t\\). refer section 2 Hoi et al. (2018) details extensions.interesting stream parameter updating passive-aggressive algorithms (PAAs) formalized Crammer et al. (2006). base case involves classification tasks, stick regression setting (section 5 Crammer et al. (2006)). One strong limitation PAAs rely set parameters loss either zero negligible: \\(\\boldsymbol{\\Theta}^*_\\epsilon=\\{\\boldsymbol{\\theta}, L_t(\\boldsymbol{\\theta})< \\epsilon\\}\\). general loss functions learner \\(f\\), set largely inaccessible. Thus, algorithms Crammer et al. (2006) restricted particular case, namely linear \\(f\\) \\(\\epsilon\\)-insensitive hinge loss:\\[L_\\epsilon(\\boldsymbol{\\theta})=\\left\\{ \\begin{array}{ll}\n0 & \\text{} \\ |\\boldsymbol{\\theta}'\\textbf{x}-y|\\le \\epsilon \\quad (\\text{close enough prediction}) \\\\\n|\\boldsymbol{\\theta}'\\textbf{x}-y|- \\epsilon & \\text{} \\  |\\boldsymbol{\\theta}'\\textbf{x}-y| >  \\epsilon \\quad (\\text{prediction far})\n\\end{array}\\right.,\\]parameter \\(\\epsilon>0\\). weight \\(\\boldsymbol{\\theta}\\) model close enough true value, loss zero; , equal absolute value error minus \\(\\epsilon\\). PAA, update parameter given \n\\[\\boldsymbol{\\theta}_{t+1}= \\underset{\\boldsymbol{\\theta}}{\\text{argmin}} ||\\boldsymbol{\\theta}-\\boldsymbol{\\theta}_t||_2^2, \\quad \\text{subject } \\quad L_\\epsilon(\\boldsymbol{\\theta})=0,\\]\nhence new parameter values chosen two conditions satisfied:\n- loss zero (definition loss, means model close enough true value);\n- , parameter close possible previous parameter values.construction, model good enough, model move (passive phase), , rapidly shifted towards values yield satisfactory results (aggressive phase).end section historical note. ideas online learning stem financial literature concept universal portfolios originally coined Cover (1991) particular. setting following. function \\(f\\) assumed linear \\(f(\\textbf{x}_t)=\\boldsymbol{\\theta}'\\textbf{x}_t\\) data \\(\\textbf{x}_t\\) consists asset returns, thus, values portfolio returns long \\(\\boldsymbol{\\theta}'\\textbf{1}_N=1\\) (budget constraint). loss functions \\(L_t\\) correspond concave utility function (e.g., logarithmic) regret reversed:\n\\[R_T=\\underset{\\boldsymbol{\\theta}^*\\\\boldsymbol{\\Theta}}{\\sup} \\ \\sum_{t=1}^TL_t(\\textbf{r}_t'\\boldsymbol{\\theta}^*)-\\sum_{t=1}^TL_t(\\textbf{r}_t'\\boldsymbol{\\theta}_t),\\]\n\\(\\textbf{r}_t'\\) returns. Thus, program transformed maximize concave function. Several articles (often Computer Science ML communities) proposed solutions type problems: Blum Kalai (1999), Agarwal et al. (2006) Hazan, Agarwal, Kale (2007). contributions work price data , notable exception Cover Ordentlich (1996), mentions external data (‘side information’). latter article, proven constantly rebalanced portfolios distributed according two random distributions achieve growth rates close unattainable optimal rates. two distributions uniform law (equally weighting, ) Dirichlet distribution constant parameters equal 1/2. universal distribution, Cover Ordentlich (1996) show wealth obtained bounded :\n\\[\\text{wealth universal} \\ge \\frac{\\text{wealth optimal strategy}}{2(n+1)^{(m-1)/2}}, \\]\n\\(m\\) number assets \\(n\\) number periods.literature online portfolio allocation reviewed B. Li Hoi (2014) outlined details B. Li Hoi (2018). Online learning, combined early stopping neural networks, applied factor investing Wong et al. (2020). Finally, online learning associated clustering methods portfolio choice Khedmati Azin (2020).","code":""},{"path":"causality.html","id":"homogeneous-transfer-learning","chapter":"14 Two key concepts: causality and non-stationarity","heading":"14.2.3 Homogeneous transfer learning","text":"\nsubsection mostly conceptual illustrated coded applications. ideas behind transfer learning can valuable can foster novel ideas, briefly present .Transfer learning surveyed numerous times. One classical reference Pan Yang (2009), Weiss, Khoshgoftaar, Wang (2016) recent exhaustive. Suppose given two datasets \\(D_S\\) (source) \\(D_T\\) (target). dataset features \\(\\textbf{X}^S\\) \\(\\textbf{X}^T\\) labels \\(\\textbf{y}^S\\) \\(\\textbf{y}^T\\). classical supervised learning, patterns target set learned \\(\\textbf{X}^T\\) \\(\\textbf{y}^T\\). Transfer learning proposes improve function \\(f^T\\) (obtained minimizing fit \\(y_i^T=f^T(\\textbf{x}_i^T)+\\epsilon^T_i\\) target data) via function \\(f^S\\) (\\(y_i^S=f^S(\\textbf{x}_i^S)+\\varepsilon^S_i\\) source data). Homogeneous transfer learning feature space change, case setting. asset management, may always case instance new predictors included (e.g., based alternative data like sentiment, satellite imagery, credit card logs, etc.).many subcategories transfer learning depending changes source \\(S\\) target \\(T\\): feature space, distribution labels, /relationship two? questions Section 14.2. latter case interest finance link non-stationarity evident: model \\(f\\) \\(\\textbf{y}=f(\\textbf{X})\\) changes time. transfer learning jargon, written \\(P[\\textbf{y}^S|\\textbf{X}^S]\\neq P[\\textbf{y}^T|\\textbf{X}^T]\\): conditional law label knowing features switching source target. Often, term ‘domain adaptation’ used synonym transfer learning. data shift, must adapt model increase accuracy. topics reviewed series chapters collection Quionero-Candela et al. (2009).important elegant result theory proven Ben-David et al. (2010) case binary classification. state . consider \\(f\\) \\(h\\) two classifiers values \\(\\{0,1 \\}\\). average error two domain \\(S\\) defined \n\\[\\epsilon_S(f,h)=\\mathbb{E}_S[|f(\\textbf{x})-h(\\textbf{x})|].\\]\n,\n\\[\\begin{equation}\n\\small\n\\epsilon_T(f_T,h)\\le \\epsilon_S(f_S,h)+\\underbrace{2 \\sup_B|P_S(B)-P_T(B)|}_{\\text{ difference domains }} + \\underbrace{ \\min\\left(\\mathbb{E}_S[|f_S(\\textbf{x})-f_T(\\textbf{x})|],\\mathbb{E}_T[|f_S(\\textbf{x})-f_T(\\textbf{x})|]\\right)}_{\\text{difference two learning tasks}}, \\nonumber\n\\end{equation}\\]\\(P_S\\) \\(P_T\\) denote distribution two domains. inequality bound generalization performance \\(h\\). take \\(f_S\\) best possible classifier \\(S\\) \\(f_T\\) best \\(T\\), error generated \\(h\\) \\(T\\) smaller sum three components:\n- error \\(S\\) space;\n- distance two domains (much data space shifted);\n- distance two best models (generators).One solution often mentioned transfer learning instance weighting. present general setting. machine learning, seek minimize\n\\[\\begin{align*}\n\\epsilon_T(f)=\\mathbb{E}_T\\left[L(\\text{y},f(\\textbf{X})) \\right],\n\\end{align*}\\]\n\\(L\\) loss function depends task (regression versus classification). can arranged\n\\[\\begin{align*}\n\\epsilon_T(f)&=\\mathbb{E}_T \\left[\\frac{P_S(\\textbf{y},\\textbf{X})}{P_S(\\textbf{y},\\textbf{X})} L(\\text{y},f(\\textbf{X})) \\right]  \\\\\n&=\\sum_{\\textbf{y},\\textbf{X}}P_T(\\textbf{y},\\textbf{X})\\frac{P_S(\\textbf{y},\\textbf{X})}{P_S(\\textbf{y},\\textbf{X})} L(\\text{y},f(\\textbf{X})) \\\\\n&=\\mathbb{E}_S \\left[\\frac{P_T(\\textbf{y},\\textbf{X})}{P_S(\\textbf{y},\\textbf{X})} L(\\text{y},f(\\textbf{X})) \\right]\n\\end{align*}\\]key quantity thus transition ratio \\(\\frac{P_T(\\textbf{y},\\textbf{X})}{P_S(\\textbf{y},\\textbf{X})}\\) (Radon–Nikodym derivative assumptions). course ratio largely inaccessible practice, possible find weighting scheme (instances) yields improvements error target space. weighting scheme, just Coqueret Guida (2020), can binary, thereby simply excluding observations computation error. Simply removing observations training sample can beneficial effects.\ngenerally, expression can viewed theoretical invitation user-specified instance weighting (Section 6.4.7). asset allocation parlance, can viewed introducing views observations interesting, e.g., value stocks can allowed larger weight computation loss user believes carry relevant information. Naturally, always remains minimize loss.close topic mentioning practical application transfer learning developed Koshiyama et al. (2020). authors propose neural network architecture allows share learning process different strategies across several markets. method , among things, aimed alleviating backtest overfitting problem.","code":""},{"path":"unsup.html","id":"unsup","chapter":"15 Unsupervised learning","heading":"15 Unsupervised learning","text":"algorithms presented Chapters 5 9 belong larger class supervised learning tools. tools seek unveil mapping predictors \\(\\textbf{X}\\) label \\(\\textbf{Z}\\). supervision comes fact asked data tries explain particular variable \\(\\textbf{Z}\\). Another important part machine learning consists unsupervised tasks, , \\(\\textbf{Z}\\) specified algorithm tries make sense \\(\\textbf{X}\\) . Often, relationships components \\(\\textbf{X}\\) identified. field much vast summarized one book, let alone one chapter. purpose briefly explain ways unsupervised learning can used, especially data pre-processing phase.","code":""},{"path":"unsup.html","id":"corpred","chapter":"15 Unsupervised learning","heading":"15.1 The problem with correlated predictors","text":"Often, tempting supply predictors ML-fueled predictive engine. may good idea predictors highly correlated. illustrate , simplest example regression two variables zero mean covariance precisions matrices:\n\\[\\boldsymbol{\\Sigma}=\\textbf{X}'\\textbf{X}=\\begin{bmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{bmatrix},  \\quad \\boldsymbol{\\Sigma}^{-1}=\\frac{1}{1-\\rho^2}\\begin{bmatrix} 1 & -\\rho \\\\ -\\rho & 1 \\end{bmatrix}.\\]\ncovariance/correlation \\(\\rho\\) increase towards 1 (two variables co-linear), scaling denominator \\(\\boldsymbol{\\Sigma}^{-1}\\) goes zero formula \\(\\hat{\\boldsymbol{\\beta}}=\\boldsymbol{\\Sigma}^{-1}\\textbf{X}'\\textbf{Z}\\) implies one coefficient highly positive one highly negative. regression creates spurious arbitrage two variables. course, inefficient yields disastrous results --sample.illustrate happens many variables used regression (Table 15.1). One elucidation aforementioned phenomenon comes variables Mkt_Cap_12M_Usd Mkt_Cap_6M_Usd, correlation 99.6% training sample. singled highly significant signs contradictory. Moreover, magnitude coefficients close (0.21 versus 0.18) net effect cancels . Naturally, providing regression one two inputs wiser.\nTABLE 15.1: Significant predictors training sample.\nfact, several indicators market capitalization maybe one suffice, obvious tell one best choice.depict correlation issues, compute correlation matrix predictors (training sample). dimension, show graphically. many labels, remove .\nFIGURE 15.1: Correlation matrix predictors.\ngraph Figure 15.1 reveals several blue squares around diagonal. instance, biggest square around first third features relates accounting ratios based free cash flows. common term calculation, features naturally highly correlated. local correlation patterns occur several times dataset explain good idea use simple regression set features.full disclosure, multicollinearity (predictors correlated) can much less problem ML tools pure statistical inference. statistics, one central goal study properties \\(\\beta\\) coefficients. Collinearity perturbs kind analysis. machine learning, aim maximize --sample accuracy. many predictors can helpful, . One simple example can help clarify matter. building regression tree, many predictors give options splits. features make sense, can useful. reasoning applies random forests boosted trees. matter large spectrum features helps improve generalization ability model. collinearity irrelevant.remainder chapter, present two approaches help reduce number predictors:first one aims creating new variables uncorrelated . Low correlation favorable algorithmic point view, new variables lack interpretability;second one gathers predictors homogeneous clusters one feature chosen cluster. rationale reversed: interpretability favored statistical properties resulting set features may still include high correlations, albeit lesser point compared original one.","code":"\nlibrary(broom)                                  # Package for clean regression output \ntraining_sample %>%    \n    dplyr::select(c(features,  \"R1M_Usd\")) %>%  # List of variables\n    lm(R1M_Usd ~ . , data = .) %>%              # Model: predict R1M_Usd\n    tidy() %>%                                  # Put output in clean format\n    filter(abs(statistic) > 3)  %>%             # Keep significant predictors only\n    knitr::kable(booktabs = TRUE,\n                 caption = \"Significant predictors in the training sample.\") \nlibrary(corrplot)              # Package for plots of correlation matrices\nC <- cor(training_sample %>% dplyr::select(features)) # Correlation matrix\ncorrplot(C, tl.pos='n')        # Plot"},{"path":"unsup.html","id":"principal-component-analysis-and-autoencoders","chapter":"15 Unsupervised learning","heading":"15.2 Principal component analysis and autoencoders","text":"first method cornerstone dimensionality reduction. seeks determine smaller number factors (\\(K'<K\\)) :\n- ) level explanatory power remains high possible;\n- ii) resulting factors linear combinations original variables;\n- iii) resulting factors orthogonal.","code":""},{"path":"unsup.html","id":"a-bit-of-algebra","chapter":"15 Unsupervised learning","heading":"15.2.1 A bit of algebra","text":" \nshort subsection, define key concepts required fully understand derivation principal component analysis (PCA). Henceforth, work matrices (bold fonts). \\(\\times K\\) matrix \\(\\textbf{X}\\) orthonormal \\(> K\\) \\(\\textbf{X}'\\textbf{X}=\\textbf{}_K\\). \\(=K\\), (square) matrix called orthogonal \\(\\textbf{X}'\\textbf{X}=\\textbf{X}\\textbf{X}'=\\textbf{}_K\\), .e., \\(\\textbf{X}^{-1}=\\textbf{X}'\\).One foundational result matrix theory Singular Value Decomposition (SVD, see, e.g., chapter 5 Meyer (2000)). SVD formulated follows: \\(\\times K\\) matrix \\(\\textbf{X}\\) can decomposed \n\\[\\begin{equation}\n\\tag{15.1}\n\\textbf{X}=\\textbf{U} \\boldsymbol{\\Delta} \\textbf{V}',\n\\end{equation}\\]\n\\(\\textbf{U}\\) (\\(\\times \\)) \\(\\textbf{V}\\) (\\(K \\times K\\)) orthogonal \\(\\boldsymbol{\\Delta}\\) (dimensions \\(\\times K\\)) diagonal, .e., \\(\\Delta_{,k}=0\\) whenever \\(\\neq k\\). addition, \\(\\Delta_{,}\\ge 0\\): diagonal terms \\(\\boldsymbol{\\Delta}\\) nonnegative.simplicity, assume \\(\\textbf{1}_I'\\textbf{X}=\\textbf{0}_K'\\), .e., columns zero sum (hence zero mean).33 allows write covariance matrix equal sample estimate \\(\\boldsymbol{\\Sigma}_X= \\frac{1}{-1}\\textbf{X}'\\textbf{X}\\).One crucial feature covariance matrices symmetry. Indeed, real-valued symmetric (square) matrices enjoy SVD much powerful: \\(\\textbf{X}\\) symmetric, exist orthogonal matrix \\(\\textbf{Q}\\) diagonal matrix \\(\\textbf{D}\\) \n\\[\\begin{equation}\n\\tag{15.2} \n\\textbf{X}=\\textbf{Q}\\textbf{DQ}'.\n\\end{equation}\\]\nprocess called diagonalization (see chapter 7 Meyer (2000)) conveniently applies covariance matrices.","code":""},{"path":"unsup.html","id":"pca","chapter":"15 Unsupervised learning","heading":"15.2.2 PCA","text":" \ngoal PCA build dataset \\(\\tilde{\\textbf{X}}\\) fewer columns keeps much information possible compressing original one, \\(\\textbf{X}\\). key notion change base, linear transformation \\(\\textbf{X}\\) \\(\\textbf{Z}\\), matrix identical dimension, via\n\\[\\begin{equation}\n\\tag{15.3}\n\\textbf{Z}=\\textbf{XP},\n\\end{equation}\\]\n\\(\\textbf{P}\\) \\(K \\times K\\) matrix. course infinite number ways transform \\(\\textbf{X}\\) \\(\\textbf{Z}\\), two fundamental constraints help reduce possibilities. first constraint columns \\(\\textbf{Z}\\) uncorrelated. uncorrelated features desirable tell different stories zero redundancy. second constraint variance columns \\(\\textbf{Z}\\) highly concentrated. means factors (columns) capture explanatory power (signal), (others) consist predominantly noise. coded covariance matrix \\(\\textbf{Z}\\):first condition imposes covariance matrix diagonal;second condition imposes diagonal elements, ranked decreasing magnitude, see value decline (sharply possible).covariance matrix \\(\\textbf{Z}\\) \n\\[\\begin{equation}\n\\tag{15.4} \n\\boldsymbol{\\Sigma}_Z=\\frac{1}{-1}\\textbf{Z}'\\textbf{Z}=\\frac{1}{-1}\\textbf{P}'\\textbf{X}'\\textbf{XP}=\\frac{1}{-1}\\textbf{P}'\\boldsymbol{\\Sigma}_X\\textbf{P}.\n\\end{equation}\\]expression, plug decomposition (15.2) \\(\\boldsymbol{\\Sigma}_X\\):\n\\[\\boldsymbol{\\Sigma}_Z=\\frac{1}{-1}\\textbf{P}'\\textbf{Q}\\textbf{DQ}'\\textbf{P},\\]\nthus picking \\(\\textbf{P}=\\textbf{Q}\\), get, orthogonality, \\(\\boldsymbol{\\Sigma}_Z=\\frac{1}{-1}\\textbf{D}\\), , diagonal covariance matrix \\(\\textbf{Z}\\). columns \\(\\textbf{Z}\\) can re-shuffled decreasing order variance diagonal elements \\(\\boldsymbol{\\Sigma}_Z\\) progressively shrink. useful helps locate factors informational content (first factors). limit, constant vector (zero variance) carries signal.matrix \\(\\textbf{Z}\\) linear transformation \\(\\textbf{X}\\), thus, expected carry information, even though information coded differently. Since columns ordered according relative importance, simple omit . new set features \\(\\tilde{\\textbf{X}}\\) consists first \\(K'\\) (\\(K'<K\\)) columns \\(\\textbf{Z}\\)., show perform PCA visualize output factoextra package. ease readability, use smaller sample predictors.rotation gives matrix \\(\\textbf{P}\\): ’s tool changes base. first row output indicates standard deviation new factor (column). factor indicated via PC index (principal component). Often, first PC (first column PC1 output) loads positively initial features: convex weighted average predictors expected carry lot information. example, almost case, exception volatility, negative coefficient first PC. second PC arbitrage price--book (long) dividend yield (short). third PC contrarian, loads heavily negatively momentum. principal components easy interpret.Sometimes, can useful visualize way principal components built. Figure 15.2, show one popular representation used two factors (usually first two).  \nFIGURE 15.2: Visual representation PCA two dimensions.\nplot shows initial factor negative signs first two principal components. Volatility negative first one earnings per share dividend yield negative second. numbers indicated along axes proportion explained variance PC. Compared figures first line output, numbers squared divided total sum squares.rotation known, possible select subsample transformed data. original 7 features, easy pick just 4.4 factors can used orthogonal features ML engine. fact features uncorrelated undoubtedly asset. price convenience high: features longer immediately interpretable. De-correlating predictors adds yet another layer “blackbox-ing” algorithm.  PCA can also used estimate factor models. Equation (15.3), suffices replace \\(\\textbf{Z}\\) returns, \\(\\textbf{X}\\) factor values \\(\\textbf{P}\\) factor loadings (see, e.g., Connor Korajczyk (1988) early reference). recently, Lettau Pelger (2020a) Lettau Pelger (2020b) propose thorough analysis PCA estimation techniques. notably argue first moments returns important included objective function, alongside optimization second moments.end subsection technical note. Usually, PCA performed covariance matrix returns. Sometimes, may preferable decompose correlation matrix. result may adjust substantially variables different variances (really case equity space). investment universe encompasses several asset classes, correlation-based PCA reduce importance volatile class. case, returns scaled respective volatilities.","code":"\npca <- training_sample %>% \n    dplyr::select(features_short) %>%    # Smaller number of predictors\n    prcomp()                             # Performs PCA\npca                                      # Show the result## Standard deviations (1, .., p=7):\n## [1] 0.4536601 0.3344080 0.2994393 0.2452000 0.2352087 0.2010782 0.1140988\n## \n## Rotation (n x k) = (7 x 7):\n##                         PC1         PC2         PC3         PC4         PC5          PC6\n## Div_Yld          0.27159946 -0.57909866  0.04572501 -0.52895604 -0.22662581 -0.506566090\n## Eps              0.42040708 -0.15008243 -0.02476659  0.33737265  0.77137719 -0.301883295\n## Mkt_Cap_12M_Usd  0.52386846  0.34323935  0.17228893  0.06249528 -0.25278113 -0.002987057\n## Mom_11M_Usd      0.04723846  0.05771359 -0.89715955  0.24101481 -0.25055884 -0.258476580\n## Ocf              0.53294744  0.19588990  0.18503939  0.23437100 -0.35759553 -0.049015486\n## Pb               0.15241340  0.58080620 -0.22104807 -0.68213576  0.30866476 -0.038674594\n## Vol1Y_Usd       -0.40688963  0.38113933  0.28216181  0.15541056 -0.06157461 -0.762587677\n##                          PC7\n## Div_Yld          0.032011635\n## Eps              0.011965041\n## Mkt_Cap_12M_Usd  0.714319417\n## Mom_11M_Usd      0.043178747\n## Ocf             -0.676866120\n## Pb              -0.168799297\n## Vol1Y_Usd        0.008632062\nlibrary(factoextra)                      # Package for PCA visualization\nfviz_pca_var(pca,                        # Source of PCA decomposition\n             col.var=\"contrib\",          \n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE                # Avoid text overlapping\n)\ntraining_sample %>%                                  # Start from large sample\n    dplyr::select(features_short) %>%                # Keep only 7 features\n    as.matrix() %>%                                  # Transform in matrix\n    multiply_by_matrix(pca$rotation[,1:4]) %>%       # Rotate via PCA (first 4 columns of P)\n    `colnames<-`(c(\"PC1\", \"PC2\", \"PC3\", \"PC4\")) %>%  # Change column names\n    head()                                           # Show first 6 lines##            PC1       PC2         PC3       PC4\n## [1,] 0.3989674 0.7578132 -0.13915223 0.3132578\n## [2,] 0.4284697 0.7587274 -0.40164338 0.3745255\n## [3,] 0.5215295 0.5679119 -0.10533870 0.2574949\n## [4,] 0.5445359 0.5335619 -0.08833864 0.2281793\n## [5,] 0.5672644 0.5339749 -0.06092424 0.2320938\n## [6,] 0.5871306 0.6420126 -0.44566482 0.3075399"},{"path":"unsup.html","id":"ae","chapter":"15 Unsupervised learning","heading":"15.2.3 Autoencoders","text":"PCA, coding \\(\\textbf{X}\\) \\(\\textbf{Z}\\) straightfoward, linear works ways:\n\\[\\textbf{Z}=\\textbf{X}\\textbf{P} \\quad \\text{} \\quad \\textbf{X}=\\textbf{ZP}',\\]\nrecover \\(\\textbf{X}\\) \\(\\textbf{Z}\\). can writen differently:\n\\[\\begin{equation}\n\\tag{15.5}\n\\textbf{X} \\quad \\overset{\\text{encode via }\\textbf{P}}{\\longrightarrow} \\quad \\textbf{Z} \\quad \\overset{\\text{decode via } \\textbf{P}'}{\\longrightarrow} \\quad \\textbf{X}\n\\end{equation}\\]take truncated version seek smaller output (\\(K'\\) columns), gives:\\[\\begin{equation}\n\\tag{15.6}\n\\textbf{X}, \\ (\\times K) \\quad \\overset{\\text{encode via }\\textbf{P}_{K'}}{\\longrightarrow} \\quad \\tilde{\\textbf{X}}, \\ (\\times K') \\quad \\overset{\\text{decode via } \\textbf{P}'_{K'}}{\\longrightarrow} \\quad \\breve{\\textbf{X}},\\ (\\times K),\n\\end{equation}\\]\\(\\textbf{P}_{K'}\\) restriction \\(\\textbf{P}\\) \\(K'\\) columns correspond factors largest variances. dimensions matrices indicated inside brackets. case, recoding recover \\(\\textbf{X}\\) exactly approximation, write \\(\\breve{\\textbf{X}}\\). approximation coded less information, hence new data \\(\\breve{\\textbf{X}}\\) compressed provides parsimonious representation original sample \\(\\textbf{X}\\).autoencodeur generalizes concept nonlinear coding functions. Simple linear autoencoders linked latent factor models (see Proposition 1 Gu, Kelly, Xiu (2020a) case single layer autoencoders.) scheme following\n\\[\\begin{equation}\n\\tag{15.7}\n\\textbf{X},\\ (\\times K) \\quad \\overset{\\text{encode via } N} {\\longrightarrow} \\quad \\tilde{\\textbf{X}}=N(\\textbf{X}), \\ (\\times K') \\quad \\overset{\\text{decode via } N'}{\\longrightarrow} \\quad \\breve{\\textbf{X}}=N'(\\tilde{\\textbf{X}}), \\ (\\times K),\n\\end{equation}\\]encoding decoding functions \\(N\\) \\(N'\\) often taken neural networks. term autoencoder comes fact target output, often write \\(\\textbf{Z}\\) original sample \\(\\textbf{X}\\). Thus, algorithm seeks determine function \\(N\\) minimizes distance (defined) \\(\\textbf{X}\\) output value \\(\\breve{\\textbf{X}}\\). encoder generates alternative representation \\(\\textbf{X}\\), whereas decoder tries recode back original values. Naturally, intermediate (coded) version \\(\\tilde{\\textbf{X}}\\) targeted smaller dimension compared \\(\\textbf{X}\\).","code":""},{"path":"unsup.html","id":"application","chapter":"15 Unsupervised learning","heading":"15.2.4 Application","text":"\nAutoencoders easy code Keras (see Chapter 7 details Keras). underline power framework, resort another way coding NN: -called functional API. simplicity, work small number predictors (7). structure network consists two symmetric networks one intermediate layer containing 32 units. activation function sigmoid; makes sense since input values unit interval.training part, optimize MSE use Adam update weights (see Section 7.2.3).Finally, ready train data onto ! evolution loss training testing samples depicted Figure 15.3. decreasing pattern shows progress quality compression.\nFIGURE 15.3: Output training autoencoder.\norder get details weights biases, syntax following.Retrieving encoder processing data compressed format just matter matrix manipulation. practice, possible build submodel loading weights encoder (see exercise ).","code":"\ninput_layer <- layer_input(shape = c(7))    # features_short has 7 columns \n\nencoder <- input_layer %>%       # First, encode\n    layer_dense(units = 32, activation = \"sigmoid\") %>% \n    layer_dense(units = 4)       # 4 dimensions for the output layer (same as PCA example)\n\ndecoder <- encoder %>%           # Then, from encoder, decode\n    layer_dense(units = 32, activation = \"sigmoid\") %>% \n    layer_dense(units = 7)       # the original sample has 7 features\nae_model <- keras_model(inputs = input_layer, outputs = decoder) # Builds the model\n\nae_model %>% compile(                # Learning parameters\n    loss = 'mean_squared_error',\n    optimizer = 'adam',\n    metrics = c('mean_absolute_error')\n)\nfit_ae <- ae_model %>% \n    fit(training_sample %>% dplyr::select(features_short) %>% as.matrix(),  # Input\n        training_sample %>% dplyr::select(features_short) %>% as.matrix(),  # Output\n        epochs = 15, batch_size = 512,\n        validation_data = list(testing_sample %>% dplyr::select(features_short) %>% as.matrix(), \n                               testing_sample %>% dplyr::select(features_short) %>% as.matrix())\n    )\nplot(fit_ae) + theme_grey()\nae_weights <- ae_model %>% get_weights()"},{"path":"unsup.html","id":"clustering-via-k-means","chapter":"15 Unsupervised learning","heading":"15.3 Clustering via k-means","text":" \nsecond family unsupervised tools pertains clustering. Features grouped homogeneous families predictors. possible single one among group (create synthetic average ). Mechanically, number predictors reduced.principle simple: among group variables (reasoning observations dimension) \\(\\textbf{x}_{\\{1 \\le j \\le J\\}}\\), find combination \\(k<J\\) groups minimize\n\\[\\begin{equation}\n\\tag{15.8}\n\\sum_{=1}^k\\sum_{\\textbf{x}\\S_i}||\\textbf{x}-\\textbf{m}_i||^2,\n\\end{equation}\\]\n\\(||\\cdot ||\\) norm usually taken Euclidean \\(l^2\\)-norm. \\(S_i\\) groups minimization run whole set groups \\(\\textbf{S}\\). \\(\\textbf{m}_i\\) group means (also called centroids barycenters): \\(\\textbf{m}_i=(\\text{card}(S_i))^{-1}\\sum_{\\textbf{x}\\S_i}\\textbf{x}\\).order ensure optimality, possible arrangements must tested, prohibitively long \\(k\\) \\(J\\) large. Therefore, problem usually solved greedy algorithms seek (find) solutions optimal ‘good enough.’One heuristic way proceed following:Start (possibly random) partition \\(k\\) clusters.cluster, compute optimal mean values \\(\\textbf{m}_i^*\\) minimizes expression (15.8). simple quadratic program.Given optimal centers \\(\\textbf{m}_i^*\\), reassign points \\(\\textbf{x}_i\\) closest center.Repeat steps 1. 2. points change cluster step 2., illustrate process example. 93 features, build 10 clusters.\nsingle fourth cluster composed mainly accounting ratios related profitability firms. Given 10 clusters, can build much smaller group features can fed predictive engines described Chapters 5 9. representative cluster can member closest center, simply center . pre-processing step can nonetheless cause problems forecasting phase. Typically, requires training data also clustered. extension testing data straightforward (clusters may ).","code":"\nset.seed(42)                               # Setting the random seed (the optim. is random)\nk_means <- training_sample %>%             # Performs the k-means clustering\n    dplyr::select(features) %>%\n    as.matrix() %>%\n    t() %>%\n    kmeans(10)\nclusters <- tibble(factor = names(k_means$cluster),   # Organize the cluster data\n                   cluster = k_means$cluster) %>%\n    arrange(cluster)\nclusters %>% filter(cluster == 4)                     # Shows one particular group## # A tibble: 4 × 2\n##   factor                         cluster\n##   <chr>                            <int>\n## 1 Asset_Turnover                       4\n## 2 Bb_Yld                               4\n## 3 Recurring_Earning_Total_Assets       4\n## 4 Sales_Ps                             4"},{"path":"unsup.html","id":"nearest-neighbors","chapter":"15 Unsupervised learning","heading":"15.4 Nearest neighbors","text":"\nbest knowledge, nearest neighbors used large-scale portfolio choice applications. reason simple: computational cost. Nonetheless, concept neighbors widespread unsupervised learning can used locally complement interpretability tools. Theoretical results k-NN relating bounds error rates classification tasks can found section 6.2 Ripley (2007). rationale following. :training sample able accurately span distribution \\((\\textbf{y}, \\textbf{X})\\); andthe testing sample follows distribution training sample (close enough);neighborhood one instance \\(\\textbf{x}_i\\) testing features computed training sample yield valuable information \\(y_i\\).follows, thus seek find neighbors one particular instance \\(\\textbf{x}_i\\) (\\(K\\)-dimensional row vector). Note major difference previous section: clustering intended observation level (row) predictor level (column).Given dataset (corresponding) columns \\(\\textbf{X}_{,k}\\), neighbors defined via similarity measure (distance)\n\\[\\begin{equation}\n\\tag{15.9}\nD(\\textbf{x}_j,\\textbf{x}_i)=\\sum_{k=1}^Kc_k d_k(x_{j,k},x_{,k}),\n\\end{equation}\\]\ndistance functions \\(d_k\\) can operate various data types (numerical, categorical, etc.). numerical values, \\(d_k(x_{j,k},x_{,k})=(x_{j,k}-x_{,k})^2\\) \\(d_k(x_{j,k},x_{,k})=|x_{j,k}-x_{,k}|\\). categorical values, refer exhaustive survey Boriah, Chandola, Kumar (2008) lists 14 possible measures. Finally \\(c_k\\) Equation (15.9) allow flexbility weighting features. useful raw values (\\(x_{,k}\\) versus \\(x_{,k'}\\)) measure outputs (\\(d_k\\) versus \\(d_{k'}\\)) can different scales.distances computed whole sample, ranked using indices \\(l_1^, \\dots, l_I^\\):\n\\[D\\left(\\textbf{x}_{l_1^},\\textbf{x}_i\\right) \\le D\\left(\\textbf{x}_{l_2^},\\textbf{x}_i\\right) \\le \\dots, \\le D\\left(\\textbf{x}_{l_I^},\\textbf{x}_i\\right)\\]nearest neighbors indexed \\(l_m^\\) \\(m=1,\\dots,k\\). leave case problematic equalities type \\(D\\left(\\textbf{x}_{l_m^},\\textbf{x}_i\\right)=D\\left(\\textbf{x}_{l_{m+1}^},\\textbf{x}_i\\right)\\) sake simplicity rarely occur practice long sufficiently many numerical predictors.Given neighbors, now possible build prediction label side \\(y_i\\). rationale straightforward: \\(\\textbf{x}_i\\) close instances \\(\\textbf{x}_j\\), label value \\(y_i\\) also close \\(y_j\\) (assumption features carry predictive information label \\(y\\)).intuitive prediction \\(y_i\\) following weighted average:\n\\[\\hat{y}_i=\\frac{\\sum_{j\\neq } h(D(\\textbf{x}_j,\\textbf{x}_i)) y_j}{\\sum_{j\\neq } h(D(\\textbf{x}_j,\\textbf{x}_i))},\\]\n\\(h\\) decreasing function. Thus, \\(\\textbf{x}_j\\) \\(\\textbf{x}_i\\), smaller weight average. typical choice \\(h\\) \\(h(z)=e^{-az}\\) parameter \\(>0\\) determines penalizing distance \\(D(\\textbf{x}_j,\\textbf{x}_i)\\) . course, average can taken set \\(k\\) nearest neighbors, case \\(h\\) equal zero beyond particular distance threshold:\n\\[\\hat{y}_i=\\frac{\\sum_{j \\text{ neighbor}} h(D(\\textbf{x}_j,\\textbf{x}_i)) y_j}{\\sum_{j \\text{ neighbor}} h(D(\\textbf{x}_j,\\textbf{x}_i))}.\\]agnostic rule take \\(h:=1\\) set neighbors case, neighbors weight (see old discussion T. Bailey Jain (1978) case classification). classification tasks, procedure involves voting rule whereby class votes wins contest, possible tie-breaking methods. interested reader can look short survey Bhatia et al. (2010).choice optimal \\(k\\), several complicated techniques criteria exist (see, e.g., . K. Ghosh (2006) Peter Hall et al. (2008)). Heuristic values often job pretty well. rule thumb \\(k=\\sqrt{}\\) (\\(\\) total number instances) far optimal value, unless \\(\\) exceedingly large. , illustrate concept. pick one date (31th December 2006) single one asset (stock_id equal 13). seek find \\(k=30\\) stocks closest asset particular date. resort FNN package proposes efficient computation Euclidean distances (ordering).neighbors distances known, can compute prediction return target stock. use function \\(h(z)=e^{-z}\\) weighting instances (via distances).prediction neither good, bad (sign correct!). However, note example used predictive purposes use data 2006-12-31 predict return date. order avoid forward-looking bias, knn_sample variable chosen prior point time.computations fast (handful seconds ), hold one asset. \\(k\\)-NN exercise, stock gets customed prediction set neighbors must re-assessed time. \\(N\\) assets, \\(N(N-1)/2\\) distances must evaluated. particularly costly backtest, especially several parameters can tested (number neighbors, \\(k\\), \\(\\) weighting function \\(h(z)=e^{-az}\\)). investment universe small (trading indices instance), k-NN methods become computationally attractive (see instance Y. Chen Hao (2017)).","code":"\nlibrary(FNN)     # Package for Fast Nearest Neighbors detection\nknn_data <- filter(data_ml, date == \"2006-12-31\")    # Dataset for k-NN exercise\nknn_target <- filter(knn_data, stock_id == 13) %>%   # Target observation\n              dplyr::select(features)\nknn_sample <- filter(knn_data, stock_id != 13) %>%   # All other observations\n              dplyr::select(features)\nneighbors <- get.knnx(data = knn_sample, query = knn_target, k = 30) \nneighbors$nn.index                                   # Indices of the k nearest neighbors##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15]\n## [1,]  905  876  730  548 1036  501  335  117  789    54   618   130   342   360   673\n##      [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] [,28] [,29]\n## [1,]   153   265   858   830   286  1150   166   946   192   340   162   951   376   785\n##      [,30]\n## [1,]     2\nknn_labels <- knn_data[as.vector(neighbors$nn.index),] %>%                # y values for neighb.\n    dplyr::select(R1M_Usd)    \nsum(knn_labels * exp(-neighbors$nn.dist) / sum(exp(-neighbors$nn.dist)))  # Pred w. k(z)=e^(-z)## [1] 0.003042282\nfilter(knn_data, stock_id == 13) %>%                                      # True y \n              dplyr::select(R1M_Usd)## # A tibble: 1 × 1\n##   R1M_Usd\n##     <dbl>\n## 1   0.089"},{"path":"unsup.html","id":"coding-exercise-1","chapter":"15 Unsupervised learning","heading":"15.5 Coding exercise","text":"Code compressed version data (narrow training sample) via encoder part autoencoder.","code":""},{"path":"RL.html","id":"RL","chapter":"16 Reinforcement learning","heading":"16 Reinforcement learning","text":"Due increasing popularity within Machine Learning community, dedicate chapter reinforcement learning (RL). 2019 , 25 papers dedicated RL submitted (updated ) arXiv q:fin (quantitative finance) classification. Applications trading include Xiong et al. (2018) Théate Ernst (2020). Market microstructure focal framework (H. Wei et al. (2019), Ferreira (2020), Karpe et al. (2020)).\nMoreover, early survey RL-based portfolios compiled Sato (2019) (see also Z. Zhang, Zohren, Roberts (2020)) general financial applications discussed Kolm Ritter (2019b), Meng Khushi (2019), Charpentier, Elie, Remlinger (2020) Mosavi et al. (2020). shows RL recently gained traction among quantitative finance community.34While RL framework much particular algorithm, efficient application portfolio management straightforward, show. discussion generalization ability RL algorithms, refer Packer et al. (2018) D. Ghosh et al. (2021).","code":""},{"path":"RL.html","id":"theoretical-layout","chapter":"16 Reinforcement learning","heading":"16.1 Theoretical layout","text":"","code":""},{"path":"RL.html","id":"general-framework","chapter":"16 Reinforcement learning","heading":"16.1.1 General framework","text":"section, introduce core concepts RL follow relatively closely notations (layout) \nSutton Barto (2018), widely considered solid reference field, along Bertsekas (2017). One central tool field called Markov Decision Process (MDP, see Chapter 3 Sutton Barto (2018)). MDPs, like RL frameworks, involve interaction agent (e.g., trader portfolio manager) environment (e.g., financial market). agent performs actions may alter state environment gets reward (possibly negative) action. short sequence can repeated arbitrary number times, shown Figure 16.1.\nFIGURE 16.1: Scheme Markov Decision Process. R, S stand reward, state action, respectively.\nGiven initialized values state environment (\\(S_0\\)) reward (usually \\(R_0=0\\)), agent performs action (e.g., invests assets). generates reward \\(R_1\\) (e.g., returns, profits, Sharpe ratio) also future state environment (\\(S_1\\)). Based , agent performs new action sequence continues. sets states, actions rewards finite, MDP logically called finite. financial framework, somewhat unrealistic discuss issue later . nevertheless hard think simplified discretized financial problems. instance, reward can binary: win money versus lose money. case one asset, action can also dual: investing versus investing. number assets sufficiently small, possible set fixed proportions lead reasonable number combinations portfolio choices, etc.pursue exposé finite MDPs; common literature formal treatment simpler. relative simplicity MDPs helps grasp concepts common RL techniques. often case Markovian objects, key notion transition probability:\\[\\begin{equation}\n\\tag{16.1}\np(s',r|s,)=\\mathbb{P}\\left[S_t=s',R_t=r | S_{t-1}=s,A_{t-1}=\\right],\n\\end{equation}\\]probability reaching state \\(s'\\) reward \\(r\\) time \\(t\\), conditionally state \\(s\\) performing action \\(\\) time \\(t-1\\). finite sets states actions denoted \\(\\mathcal{S}\\) \\(\\mathcal{}\\) henceforth.\nSometimes, probability averaged set rewards gives following decomposition:\n\\[\\begin{align}\nG_t&=\\sum_{k=0}^T\\gamma^kR_{t+k+1} \\nonumber \\\\   \\tag{16.3}\n&=R_{t+1} +\\gamma G_{t+1},\n\\end{align}\\].e., discounted version reward, discount factor \\(\\gamma \\(0,1]\\). horizon \\(T\\) may infinite, \\(\\gamma\\) originally introduced. Assuming rewards bounded, infinite sum may diverge \\(\\gamma=1\\). case rewards don’t decrease time reason .\n\\(\\gamma <1\\) rewards bounded, convergence assured. \\(T\\) finite, task called episodic , otherwise, said continuous.RL, focal unknown optimized learned policy \\(\\pi\\), drives actions agent. precisely, \\(\\pi(,s)=\\mathbb{P}[A_t=|S_t=s]\\), , \\(\\pi\\) equals probability taking action \\(\\) state environment \\(s\\). means actions subject randomness, just like mixed strategies game theory. may seem disappointing investor want sure take best action, also good reminder best way face random outcomes may well randomize actions well. Finally, order try determine best policy, one key indicator -called value function:\n\\[\\begin{equation}\n\\tag{16.4}\nv_\\pi(s)=\\mathbb{E}_\\pi\\left[ G_t | S_t=s \\right],\n\\end{equation}\\]time index \\(t\\) relevant omitted notation function. index \\(\\pi\\) expectation operator \\(\\mathbb{E}[\\cdot]\\) simply indicates average taken policy \\(\\pi\\) enforced. value function simply equal average gain conditionally state equal \\(s\\). financial terms, equivalent average profit agent takes actions driven \\(\\pi\\) market environment \\(s\\). generally, also possible condition state, also action taken. thus introduce \\(q_\\pi\\) action-value function:\n\\[\\begin{equation}\n\\tag{16.5}\nq_\\pi(s,)=\\mathbb{E}_\\pi\\left[ G_t | S_t=s, \\ A_t=\\right].\n\\end{equation}\\]\\(q_\\pi\\) function highly important gives average gain state action fixed. Hence, current state known, one obvious choice select action \\(q_\\pi(s,\\cdot)\\) highest. course, best solution optimal value \\(q_\\pi\\) known, always case practice. value function can easily accessed via \\(q_\\pi\\): \\(v_\\pi(s)=\\sum_a \\pi(,s)q_\\pi(s,)\\).optimal \\(v_\\pi\\) \\(q_\\pi\\) straightforwardly defined \n\\[v_*(s)=\\underset{\\pi}{\\max} \\, v_\\pi(s), \\ \\forall s\\\\mathcal{S}, \\quad \\text{ } \\quad q_*(s,) =\\underset{\\pi}{\\max} \\, q_\\pi(s,), \\ \\forall (s,)\\\\mathcal{S}\\times \\mathcal{}.\\]\\(v_*(s)\\) known, agent must span set actions find yield maximum value given state \\(s\\).Finding optimal values complicated task many articles dedicated solving challenge. One reason finding best \\(q_\\pi(s,)\\) difficult depends two elements (\\(s\\) \\(\\)) one side \\(\\pi\\) . Usually, fixed policy \\(\\pi\\), can time consuming evaluate \\(q_\\pi(s,)\\) given stream actions, states rewards. \\(q_\\pi(s,)\\) estimated, new policy \\(\\pi'\\) must tested evaluated determine better original one.\nThus, iterative search good policy can take long. details policy improvement value function updating, recommend chapter 4 Sutton Barto (2018) dedicated dynamic programming.","code":""},{"path":"RL.html","id":"q-learning","chapter":"16 Reinforcement learning","heading":"16.1.2 Q-learning","text":"\ninteresting shortcut problem finding \\(v_*(s)\\) \\(q_*(s,)\\) remove dependence policy. Consequently, course need iteratively improve . central relationship required -called Bellman equation satisfied \\(q_\\pi(s,)\\). detail derivation . First , recall \n\\[\\begin{align*}\nq_\\pi(s,) &= \\mathbb{E}_\\pi[G_t|S_t=s,A_t=] \\\\\n&= \\mathbb{E}_\\pi[R_{t+1}+ \\gamma G_{t+1}|S_t=s,A_t=],\n\\end{align*}\\]\nsecond equality stems (16.3). expression \\(\\mathbb{E}_\\pi[R_{t+1}|S_t=s,A_t=]\\) can decomposed. Since expectation runs \\(\\pi\\), need sum possible actions \\('\\) states \\(s'\\) resort \\(\\pi(',s')\\). addition, sum \\(s'\\) \\(r\\) arguments probability \\(p(s',r|s,)=\\mathbb{P}\\left[S_{t+1}=s',R_{t+1}=r | S_t=s,A_t=\\right]\\) gives access distribution random couple \\((S_{t+1},R_{t+1})\\) end \\(\\mathbb{E}_\\pi[R_{t+1}|S_t=s,A_t=]=\\sum_{', r,s'}\\pi(',s')p(s',r|s,) r\\). similar reasoning applies second portion \\(q_\\pi\\) :\n\\[\\begin{align}\nq_\\pi(s,) &=\\sum_{',r, s'}\\pi(',s')p(s',r|s,) \\left[ r+\\gamma \\mathbb{E}_\\pi[ G_{t+1}|S_t=s',A_t=']\\right] \\nonumber \\\\  \\tag{16.6}\n&=\\sum_{',r,s'}\\pi(',s')p(s',r|s,) \\left[ r+\\gamma q_\\pi(s',')\\right].\n\\end{align}\\]equation links \\(q_\\pi(s,)\\) future \\(q_\\pi(s',')\\) states actions \\((s',')\\) accessible \\((s,)\\).Notably, Equation (16.6) also true optimal action-value function \\(q_*=\\underset{\\pi}{\\max} \\, q_\\pi(s,)\\):\\[\\begin{align}\nq_*(s,) &= \\underset{'}{\\max} \\sum_{r,s'}p(s',r|s,) \\left[ r+\\gamma q_*(s',')\\right], \\\\ \n&= \\mathbb{E}_{\\pi^*}[r|s,]+ \\gamma \\, \\sum_{r,s'}p(s',r|s,) \\left(  \\underset{'}{\\max}  q_*(s',') \\right)  \\tag{16.7}\n\\end{align}\\]one optimal policy one maximizes \\(q_\\pi(s,)\\), given state \\(s\\) possible actions \\(\\). expression central cornerstone algorithm reinforcement learning called \\(Q\\)-learning (formal proof convergence outlined Watkins Dayan (1992)). \\(Q\\)-learning, state-action function longer depends policy written capital \\(Q\\). process following:Initialize values \\(Q(s,)\\) states \\(s\\) actions \\(\\). episode:\\[ (\\textbf{QL}) \\quad \\left\\{\n\\begin{array}{l}\n\\text{0. Initialize state } S_0 \\text{ iteration } \\text{ end episode;}   \\\\\n\\text{1. observe state } s_i;    \\\\\n\\text{2. perform action } a_i \\text{(depending } Q);   \\\\\n\\text{3. receive reward }r_{+1} \\text{ observe state } s_{+1};  \\\\\n\\text{4. Update } Q \\text{ follows: }\n\\end{array} \\right.\\]\\[\\begin{equation}\n\\tag{16.8}\nQ_{+1}(s_i,a_i) \\longleftarrow Q_i(s_i,a_i) + \\eta  \\left(\\underbrace{r_{+1}+\\gamma \\, \\underset{}{\\max} \\, Q_i(s_{+1},)}_{\\text{echo Bellman eq.}}-Q_i(s_i,a_i) \\right)\n\\end{equation}\\]underlying reason update rule works can linked fixed point theorems contraction mappings. function \\(f\\) satisfies \\(|f(x)-f(y)|< \\delta |x-y|\\) (Lipshitz continuity), fixed point \\(z\\) satisfying \\(f(z)=z\\) can iteratively obtained via \\(z \\leftarrow f(z)\\). updating rule converges fixed point. Equation (16.7) can solved using similar principle, except learning rate \\(\\eta\\) slows learning process also technically ensures convergence technical assumptions.generally, (16.8) form widespread reinforcement learning summarized Equation (2.4) Sutton Barto (2018):\n\\[\\begin{equation}\n\\tag{16.9}\n\\text{New estimate} \\leftarrow \\text{Old estimate + Step size (}.e., \\text{ learning rate)} \\times (\\text{Target - Old estimate}),\n\\end{equation}\\]last part can viewed error term. Starting old estimate, new estimate therefore goes ‘right’ (sought) direction, modulo discount term makes sure magnitude direction large. update rule (16.8) often referred ‘temporal difference’ learning driven improvement yielded estimates known time \\(t+1\\) (target) versus known time \\(t\\). \nOne important step Q-learning sequence (QL) second one action \\(a_i\\) picked. RL, best algorithms combine two features: exploitation exploration. Exploitation machine uses current information disposal choose next action. case, given state \\(s_i\\), chooses action \\(a_i\\) maximizes expected reward \\(Q_i(s_i,a_i)\\). obvious, choice optimal current function \\(Q_i\\) relatively far true \\(Q\\). Repeating locally optimal strategy likely favor limited number actions, narrowly improve accuracy \\(Q\\) function.order gather new information stemming actions tested much (can potentially generate higher rewards), exploration needed. action \\(a_i\\) chosen randomly. common way combine two concepts called \\(\\epsilon\\)-greedy exploration. action \\(a_i\\) assigned according :\\[\\begin{equation}\n\\tag{16.10}\na_i=\\left\\{ \\begin{array}{c l}\n\\underset{}{\\text{argmax}} \\ Q_i(s_i,) & \\text{ probability } 1-\\epsilon \\\\\n\\text{randomly (uniformly) } \\mathcal{} & \\text{ probability } \\epsilon\n\\end{array}\\right. .\n\\end{equation}\\]Thus, probability \\(\\epsilon\\), algorithm explores probability \\(1-\\epsilon\\), exploits current knowledge expected reward picks best action. actions non-zero probability chosen, policy called “soft.” Indeed, best action probability selection equal \\(1-\\epsilon(1-\\text{card}(\\mathcal{})^{-1})\\), actions picked probability \\(\\epsilon/\\text{card}(\\mathcal{})\\).","code":""},{"path":"RL.html","id":"sarsa","chapter":"16 Reinforcement learning","heading":"16.1.3 SARSA","text":"\n\\(Q\\)-learning, algorithm seeks find action-value function optimal policy. Thus, policy followed pick actions different one learned (via \\(Q\\)). algorithms called -policy. -policy algorithms seek improve estimation action-value function \\(q_\\pi\\) continuously acting according policy \\(\\pi\\). One canonical example -policy learning SARSA method requires two consecutive states actions SARSA. way quintuple \\((S_t,A_t,R_{t+1}, S_{t+1}, A_{t+1})\\) processed presented .main difference \\(Q\\) learning SARSA update rule. SARSA, given \n\\[\\begin{equation}\n\\tag{16.11}\nQ_{+1}(s_i,a_i) \\longleftarrow Q_i(s_i,a_i) + \\eta  \\left(r_{+1}+\\gamma \\, Q_i(s_{+1},a_{+1})-Q_i(s_i,a_i) \\right)\n\\end{equation}\\]improvement comes local point \\(Q_i(s_{+1},a_{+1})\\) based new states actions (\\(s_{+1},a_{+1}\\)), whereas \\(Q\\)-learning, comes possible actions best retained \\(\\underset{}{\\max} \\, Q_i(s_{+1},)\\).robust also computationally demanding version SARSA expected SARSA target \\(Q\\) function averaged actions:\n\\[\\begin{equation}\n\\tag{16.12}\nQ_{+1}(s_i,a_i) \\longleftarrow Q_i(s_i,a_i) + \\eta  \\left(r_{+1}+\\gamma \\, \\sum_a \\pi(,s_{+1}) Q_i(s_{+1},) -Q_i(s_i,a_i) \\right)\n\\end{equation}\\]Expected SARSA less volatile SARSA latter strongly impacted random choice \\(a_{+1}\\). expected SARSA, average smoothes learning process.","code":""},{"path":"RL.html","id":"the-curse-of-dimensionality","chapter":"16 Reinforcement learning","heading":"16.2 The curse of dimensionality","text":"Let us first recall reinforcement learning framework linked particular algorithm. fact, different tools can well co-exist RL task (AlphaGo combined tree methods neural networks, see Silver et al. (2016)). Nonetheless, RL attempt always rely three key concepts: states, actions rewards. factor investing, fairly easy identify, though always room interpretation. Actions evidently defined portfolio compositions. states can viewed current values describe economy: first-order approximation, can assumed feature levels fulfill role (possibly conditioned complemented macro-economic data). rewards even straightforward. Returns relevant performance metric35 can account rewards.major problem lies dimensionality states actions. Assuming absence leverage (negative weights), actions take values simplex\n\\[\\begin{equation}\n\\tag{16.13}\n\\mathbb{S}_N=\\left\\{ \\mathbf{x} \\\\mathbb{R}^N\\left|\\sum_{n=1}^Nx_n=1, \\ x_n\\ge 0, \\ \\forall n=1,\\dots,N \\right.\\right\\}\n\\end{equation}\\]\nassuming features uniformized, space \\([0,1]^{NK}\\). Needless say, dimensions spaces numerically impractical.simple solution problem discretization: space divided small number categories. authors take route. S. Y. Yang, Yu, Almahdi (2018), state space discretized three values depending volatility, actions also split three categories. Bertoluzzo Corazza (2012), Xiong et al. (2018) Taghian, Asadi, Safabakhsh (2020) also choose three possible actions (buy, hold, sell). Almahdi Yang (2019), learner expected yield binary signals buying shorting. Garcı́-Galicia, Carsteanu, Clempner (2019) consider larger state space (8 elements) restrict action set 3 options.36 terms state space, articles assume state economy determined prices (returns).One strong limitation approaches marked simplification imply. Realistic discretizations numerically intractable investing multiple assets. Indeed, splitting unit interval \\(h\\) points yields \\(h^{NK}\\) possibilities feature values. number options weight combinations exponentially increasing \\(N\\). example: just 10 possible values 10 features 10 stocks yield \\(10^{100}\\) permutations.problems mentioned course restricted portfolio construction. Many solutions proposed solve Markov Decision Processes continuous spaces. refer instance Section 4 Powell Ma (2011) review early methods (outside finance).curse dimensionality accompanied fundamental question training data. Two options conceivable: market data versus simulations. given controlled generator samples, hard imagine algorithm beat solution maximizes given utility function. anything, converge towards static optimal solution stationary data generating process (see, e.g., Chaouki et al. (2020) trading tasks), way strong modelling assumption.leaves market data preferred solution even large datasets, little chance cover (actions, states) combinations mentioned . Characteristics-based datasets depths run decades monthly data, means several hundreds time-stamps . far limited allow reliable learning process. always possible generate synthetic data (Yu et al. (2019)), unclear solidly improve performance algorithm.","code":""},{"path":"RL.html","id":"policy-gradient","chapter":"16 Reinforcement learning","heading":"16.3 Policy gradient","text":"","code":""},{"path":"RL.html","id":"principle-2","chapter":"16 Reinforcement learning","heading":"16.3.1 Principle","text":"\nBeyond discretization action state spaces, powerful trick parametrization. \\(\\) \\(s\\) can take discrete values, action-value functions must computed pairs \\((,s)\\), can prohibitively cumbersome. elegant way circumvent problem assume policy driven relatively modest number parameters. learning process focused optimizing set parameters \\(\\boldsymbol{\\theta}\\). write \\(\\pi_{\\boldsymbol{\\theta}}(,s)\\) probability choosing action \\(\\) state \\(s\\). One intuitive way define \\(\\pi_{\\boldsymbol{\\theta}}(,s)\\) resort soft-max form:\n\\[\\begin{equation}\n\\tag{16.14}\n\\pi_{\\boldsymbol{\\theta}}(,s) = \\frac{e^{\\boldsymbol{\\theta}'\\textbf{h}(,s)}}{\\sum_{b}e^{\\boldsymbol{\\theta}'\\textbf{h}(b,s)}},\n\\end{equation}\\]\noutput function \\(\\textbf{h}(,s)\\), dimension \\(\\boldsymbol{\\theta}\\) called feature vector representing pair \\((,s)\\). Typically, \\(\\textbf{h}\\) can well simple neural network two input units output dimension equal length \\(\\boldsymbol{\\theta}\\).One desired property \\(\\pi_{\\boldsymbol{\\theta}}\\) differentiable respect \\(\\boldsymbol{\\theta}\\) \\(\\boldsymbol{\\theta}\\) can improved via gradient method. simple intuitive results policy gradients known case episodic tasks (finite horizon) sought maximize average gain \\(\\mathbb{E}_{\\boldsymbol{\\theta}}[G_t]\\) gain defined Equation (16.3). expectation computed according particular policy depends \\(\\boldsymbol{\\theta}\\), use simple subscript. One central result -called policy gradient theorem states \\[\\begin{equation}\n\\tag{16.15}\n\\nabla \\mathbb{E}_{\\boldsymbol{\\theta}}[G_t]=\\mathbb{E}_{\\boldsymbol{\\theta}} \\left[G_t\\frac{\\nabla \\pi_{\\boldsymbol{\\theta}}}{\\pi_{\\boldsymbol{\\theta}}} \\right].\n\\end{equation}\\]result can used gradient ascent: seeking maximize quantity, parameter change must go upward direction:\\[\\begin{equation}\n\\tag{16.16}\n\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\eta \\nabla \\mathbb{E}_{\\boldsymbol{\\theta}}[G_t].\n\\end{equation}\\]\nsimple update rule known REINFORCE algorithm. One improvement simple idea add baseline, refer section 13.4 Sutton Barto (2018) detailed account topic.","code":""},{"path":"RL.html","id":"extensions-2","chapter":"16 Reinforcement learning","heading":"16.3.2 Extensions","text":"popular extension REINFORCE -called actor-critic (AC) method combines policy gradient \\(Q\\)- \\(v\\)-learning. AC algorithm can viewed kind mix policy gradient SARSA. central requirement state-value function \\(v(\\cdot)\\) differentiable function parameter vector \\(\\textbf{w}\\) (often taken neural network). update rule \\[\\begin{equation}\n\\tag{16.17}\n\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\eta \\left(R_{t+1}+\\gamma v(S_{t+1},\\textbf{w})-v(S_t,\\textbf{w}) \\right)\\frac{\\nabla \\pi_{\\boldsymbol{\\theta}}}{\\pi_{\\boldsymbol{\\theta}}},\n\\end{equation}\\]\ntrick vector \\(\\textbf{w}\\) must also updated. actor policy side drives decision making. critic side value function evaluates actor’s performance. learning progresses (time sets parameters updated), sides improve. exact algorithmic formulation bit long refer Section 13.5 Sutton Barto (2018) precise sequence steps AC.Another interesting application parametric policies outlined Aboussalah Lee (2020). article, authors define trading policy based recurrent neural network. Thus, parameter \\(\\boldsymbol{\\theta}\\) case encompasses weights biases network.Another favorable feature parametric policies compatible continuous sets actions. Beyond form (16.14), ways shape \\(\\pi_{\\boldsymbol{\\theta}}\\). \\(\\mathcal{}\\) subset \\(\\mathbb{R}\\), \\(f_{\\boldsymbol{\\Omega}}\\) density function parameters \\(\\boldsymbol{\\Omega}\\), candidate form \\(\\pi_{\\boldsymbol{\\theta}}\\) \\[\\begin{equation}\n\\tag{16.18}\n\\pi_{\\boldsymbol{\\theta}} = f_{\\boldsymbol{\\Omega}(s,\\boldsymbol{\\theta})}(),\n\\end{equation}\\]\nparameters \\(\\boldsymbol{\\Omega}\\) turn functions states underlying (second order) parameters \\(\\boldsymbol{\\theta}\\).Gaussian distribution (see section 13.7 Sutton Barto (2018)) often preferred choice, require processing lie inside unit interval. One easy way obtain values apply normal cumulative distribution function output. H. Wang Zhou (2019), multivariate Gaussian policy theoretically explored, assumes constraint weights.natural parametric distributions emerge alternatives. one asset traded, Bernoulli distribution can used determine whether buy asset. riskless asset available, beta distribution offers flexibility values proportion invested risky asset span whole interval; remainder can invested safe asset. many assets traded, things become complicated budget constraint. One ideal candidate Dirichlet distribution defined simplex (see Equation (16.13)):\n\\[f_{\\boldsymbol{\\alpha}}(w_1,\\dots,w_n)=\\frac{1}{B(\\boldsymbol{\\alpha})}\\prod_{n=1}^Nw_n^{\\alpha_n-1},\\]\n\\(B(\\boldsymbol{\\alpha})\\) multinomial beta function:\n\\[B(\\boldsymbol{\\alpha})=\\frac{\\prod_{n=1}^N\\Gamma(\\alpha_n)}{\\Gamma\\left(\\sum_{n=1}^N\\alpha_n \\right)}.\\]set \\(\\pi=\\pi_{\\boldsymbol{\\alpha}}=f_{\\boldsymbol{\\alpha}}\\), link factors characteristics can coded \\({\\boldsymbol{\\alpha}}\\) via linear form:\n\\[\\begin{equation}\n(\\textbf{F1}) \\quad  \\alpha_{n,t}=\\theta_{0,t} + \\sum_{k=1}^K \\theta_{t}^{(k)}x_{t,n}^{(k)},\n\\end{equation}\\]\nhighly tractable, may violate condition \\(\\alpha_{n,t}>0\\) values \\(\\theta_{k,t}\\). Indeed, learning process, update \\(\\boldsymbol{\\theta}\\) might yield values feasible set \\(\\boldsymbol{\\alpha}_t\\). case, possible resort trick widely used online learning (see, e.g., section 2.3.1 Hoi et al. (2018)). idea simply find acceptable solution closest suggestion algorithm. call \\(\\boldsymbol{\\theta}^*\\) result update rule given algorithm, closest feasible vector \n\\[\\begin{equation}\n\\boldsymbol{\\theta}= \\underset{\\textbf{z} \\\\Theta(\\textbf{x}_t)}{\\min} ||\\boldsymbol{\\theta}^*-\\textbf{z}||^2,\n\\end{equation}\\]\n\\(||\\cdot||\\) Euclidean norm \\(\\Theta(\\textbf{x}_t)\\) feasible set, , set vectors \\(\\boldsymbol{\\theta}\\) \\(\\alpha_{n,t}=\\theta_{0,t} + \\sum_{k=1}^K \\theta_{t}^{(k)}x_{t,n}^{(k)}\\) non-negative.second option form policy, \\(\\pi^2_{\\boldsymbol{\\theta}_t}\\), slightly complex remains always valid (.e., positive \\(\\alpha_{n,t}\\) values):\n\\[\\begin{equation}\n(\\textbf{F2}) \\quad  \\alpha_{n,t}=\\exp \\left(\\theta_{0,t} + \\sum_{k=1}^K \\theta_{t}^{(k)}x_{t,n}^{(k)}\\right),\n\\end{equation}\\]\nsimply exponential first version. algebra, possible derive policy gradients. policies \\(\\pi^j_{\\boldsymbol{\\theta}_t}\\) defined Equations \\((\\textbf{Fj})\\) . Let \\(\\digamma\\) denote digamma function. Let \\(\\textbf{1}\\) denote \\(\\mathbb{R}^N\\) vector ones. \n\\[\\begin{align*}\n\\frac{\\nabla_{\\boldsymbol{\\theta}_t} \\pi^1_{\\boldsymbol{\\theta}_t}}{\\pi^1_{\\boldsymbol{\\theta}_t}}&= \\sum_{n=1}^N \\left( \\digamma \\left( \\textbf{1}'\\textbf{X}_t\\boldsymbol{\\theta}_t \\right) - \\digamma(\\textbf{x}_{t,n}\\boldsymbol{\\theta}_t) + \\ln w_n \\right) \\textbf{x}_{t,n}' \\\\\n\\frac{\\nabla_{\\boldsymbol{\\theta}_t} \\pi^2_{\\boldsymbol{\\theta}_t}}{\\pi^2_{\\boldsymbol{\\theta}_t}}&= \\sum_{n=1}^N \\left( \\digamma \\left( \\textbf{1}'e^{\\textbf{X}_{t}\\boldsymbol{\\theta}_t} \\right) - \\digamma(e^{\\textbf{x}_{t,n}\\boldsymbol{\\theta}_t}) + \\ln w_n \\right) e^{\\textbf{x}_{t,n}\\boldsymbol{\\theta}_t} \\textbf{x}_{t,n}' \n\\end{align*}\\]\n\\(e^{\\textbf{X}}\\) element-wise exponential matrix \\(\\textbf{X}\\).allocation can either made direct sampling, using mean distribution \\((\\textbf{1}'\\boldsymbol{\\alpha})^{-1}\\boldsymbol{\\alpha}\\). Lastly, technical note: Dirichlet distributions can used small portfolios scaling constant density becomes numerically intractable large values \\(N\\) (e.g., 50). details idea laid André Coqueret (2020).","code":""},{"path":"RL.html","id":"simple-examples","chapter":"16 Reinforcement learning","heading":"16.4 Simple examples","text":"","code":""},{"path":"RL.html","id":"q-learning-with-simulations","chapter":"16 Reinforcement learning","heading":"16.4.1 Q-learning with simulations","text":"\nillustrate gist problems mentioned , propose two implementations \\(Q\\)-learning. simplicity, first one based simulations. helps understand learning process simplified framework. consider two assets: one risky one riskless, return equal zero. returns risky process follow autoregressive model order one (AR(1)): \\(r_{t+1}=+\\rho r_t+\\epsilon_{t+1}\\) \\(|\\rho|<1\\) \\(\\epsilon\\) following standard white noise variance \\(\\sigma^2\\). practice, individual (monthly) returns seldom autocorrelated, adjusting autocorrelation helps understand algorithm learns correctly (see exercise ).environment consists observing past return \\(r_t\\). Since seek estimate \\(Q\\) function, need discretize state variable. simplest choice resort binary variable: equal -1 (negative) \\(r_t<0\\) +1 (positive) \\(r_t\\ge 0\\). actions summarized quantity invested risky asset. can take 5 values: 0 (risk-free portfolio), 0.25, 0.5, 0.75 1 (fully invested risky asset). instance choice Pendharkar Cusatis (2018).landscape R libraries RL surprisingly sparse. resort package ReinforcementLearning intuitive implementation \\(Q\\)-learning (another option reinforcelearn package). requires dataset usual inputs: state, action, reward subsequent state. start simulating returns: drive states rewards (portfolio returns). actions sampled randomly. Technically, main function package requires states actions character type. data built chunk .3 parameters implementation Q-learning algorithm:\\(\\eta\\), learning rate updating Equation (16.8). ReinforcementLearning, coded alpha;\\(\\gamma\\), discounting rate rewards (also shown Equation (16.8));\\(\\epsilon\\), controls rate exploration versus exploitation (see Equation (16.10)).output shows Q function, depends naturally states actions. state negative, large risky positions (action equal 0.75 1.00) associated smallest average rewards, whereas small positions yield highest average rewards. state positive, average rewards highest largest allocations. rewards cases almost monotonic function proportion invested risky asset. Thus, recommendation algorithm (.e., policy) fully invested positive state refrain investing negative state. Given positive autocorrelation underlying process, make sense.Basically, algorithm simply learned positive (resp. negative) returns likely follow positive (resp. negative) returns. somewhat reassuring, means impressive, much simpler tools yield similar conclusions guidance.","code":"\nlibrary(ReinforcementLearning)                              # Package for RL\nset.seed(42)                                                # Fixing the random seed\nn_sample <- 10^5                                            # Number of samples to be generated\nrho <- 0.8                                                  # Autoregressive parameter\nsd <- 0.4                                                   # Std. dev. of noise\na <- 0.06 * rho                                             # Scaled mean of returns\ndata_RL <- tibble(returns = a/rho + arima.sim(n = n_sample, # Returns via AR(1) simulation\n                                      list(ar = rho),       \n                                      sd = sd),\n                  action = round(runif(n_sample)*4)/4) %>%  # Random action (portfolio)\n    mutate(new_state = if_else(returns < 0, \"neg\", \"pos\"),  # Coding of state\n           reward = returns * action,                       # Reward = portfolio return\n           state = lag(new_state),                          # Next state\n           action = as.character(action)) %>% \n    na.omit()                                               # Remove one missing state\ndata_RL %>% head()                                          # Show first lines## # A tibble: 6 × 5\n##   returns action new_state  reward state\n##     <dbl> <chr>  <chr>       <dbl> <chr>\n## 1  -0.474 0.5    neg       -0.237  neg  \n## 2  -0.185 0.25   neg       -0.0463 neg  \n## 3   0.146 0.25   pos        0.0364 neg  \n## 4   0.543 0.75   pos        0.407  pos  \n## 5   0.202 0.75   pos        0.152  pos  \n## 6   0.376 0.25   pos        0.0940 pos\ncontrol <- list(alpha = 0.1,                       # Learning rate\n                gamma = 0.7,                       # Discount factor for rewards\n                epsilon = 0.1)                     # Exploration rate\n\nfit_RL <- ReinforcementLearning(data_RL,           # Main RL function\n                               s = \"state\", \n                               a = \"action\", \n                               r = \"reward\", \n                               s_new = \"new_state\", \n                               control = control)\nprint(fit_RL)   # Show the output## State-Action function Q\n##          0.25         0         1      0.75      0.5\n## neg 0.2473169 0.4216894 0.1509653 0.1734538 0.229004\n## pos 1.0721669 0.7561417 1.4739050 1.1214795 1.045047\n## \n## Policy\n## neg pos \n## \"0\" \"1\" \n## \n## Reward (last iteration)\n## [1] 2588.659"},{"path":"RL.html","id":"RLemp2","chapter":"16 Reinforcement learning","heading":"16.4.2 Q-learning with market data","text":"second application based financial dataset. reduce dimensionality problem, assume :\n- one feature (price--book ratio) captures state environment. feature processed limited number possible values;\n- actions take values discrete set consisting three positions: +1 (buy market), -1 (sell market) 0 (hold risky positions);\n- two assets traded: stock_id equal 3 4 - 245 days trading data.construction dataset unelegantly coded .Actions states merged yield possible combinations. simplify states, round 5 times price--book ratios.keep hyperparameters previous example. Columns stand actions: first (\\(resp.\\) second) number notes position first (\\(resp.\\) second) asset. rows correspond states. scaled P/B ratios separated point (e.g., “X2.3” means first (\\(resp.\\) second) asset scaled P/B 2 (\\(resp.\\) 3).output shows many combinations states actions spanned data: basically, \\(Q\\) function zero likely combination explored. states seem often represented (“X1.1,” “X1.2” “X2.1”), others, less (“X3.1” “X3.2”). hard make sense recommendations. states close “X0.1” “X1.1” outcomes related different (buy short versus hold buy). Moreover, coherence monotonicity actions respect individual state values: low values states can associated different actions.One reason conclusions appear trustworthy pertains data size. 200+ time points 99 state-action pairs (11 times 9), yields average two data points compute \\(Q\\) function. improved testing random actions, limits sample size eventually (rapidly) reached anyway. left exercise (see ).","code":"\nreturn_3 <- data_ml %>% filter(stock_id == 3) %>% pull(R1M_Usd)  # Return of asset 3\nreturn_4 <- data_ml %>% filter(stock_id == 4) %>% pull(R1M_Usd)  # Return of asset 4\npb_3 <- data_ml %>% filter(stock_id == 3) %>% pull(Pb)           # P/B ratio of asset 3\npb_4 <- data_ml %>% filter(stock_id == 4) %>% pull(Pb)           # P/B ratio of asset 4\naction_3 <- floor(runif(length(pb_3))*3) - 1                     # Action for asset 3 (random)\naction_4 <- floor(runif(length(pb_4))*3) - 1                     # Action for asset 4 (random)\n\nRL_data <- tibble(return_3, return_4,                            # Building the dataset\n                  pb_3, pb_4,\n                  action_3, action_4) %>%\n    mutate(action = paste(action_3, action_4),                   # Uniting actions\n           pb_3 = round(5 * pb_3),                               # Simplifying states (P/B)\n           pb_4 = round(5 * pb_4),                               # Simplifying states (P/B)\n           state = paste(pb_3, pb_4),                            # Uniting states\n           reward = action_3*return_3 + action_4*return_4,       # Computing rewards\n           new_state = lead(state)) %>%                          # Infer new state\n    dplyr::select(-pb_3, -pb_4, -action_3,                       # Remove superfluous vars.\n                  -action_4, -return_3, -return_4) \nhead(RL_data)                                                    # Showing the result## # A tibble: 6 × 4\n##   action state reward new_state\n##   <chr>  <chr>  <dbl> <chr>    \n## 1 -1 -1  1 1   -0.061 1 1      \n## 2 0 1    1 1    0     1 1      \n## 3 -1 0   1 1   -0.018 1 1      \n## 4 0 -1   1 1    0.011 1 1      \n## 5 -1 1   1 1   -0.036 1 1      \n## 6 -1 -1  1 1   -0.056 1 1\nfit_RL2 <- ReinforcementLearning(RL_data,           # Main RL function\n                               s = \"state\", \n                               a = \"action\", \n                               r = \"reward\", \n                               s_new = \"new_state\", \n                               control = control)\nfit_RL2$Q <- round(fit_RL2$Q, 3) # Round the Q-matrix\nprint(fit_RL2)                   # Show the output ## State-Action function Q\n##       0 0    0 1   0 -1  -1 -1   -1 0   -1 1   1 -1    1 0    1 1\n## 0 2 0.000  0.000  0.000 -0.017  0.000  0.000  0.000  0.002  0.000\n## 0 3 0.000  0.000  0.003  0.000  0.000  0.000  0.030  0.000  0.000\n## 3 1 0.002  0.000  0.005  0.000 -0.002  0.000  0.000  0.000  0.000\n## 2 1 0.005  0.018  0.009 -0.028  0.010 -0.003  0.021  0.008 -0.004\n## 2 2 0.000  0.010  0.000  0.014  0.000  0.000 -0.013  0.006  0.000\n## 2 3 0.000  0.000  0.000  0.000  0.000  0.020  0.000 -0.034  0.000\n## 1 1 0.002 -0.005 -0.022 -0.011 -0.002 -0.009 -0.020 -0.014 -0.023\n## 1 2 0.006  0.016  0.006  0.028 -0.001  0.001  0.020  0.020 -0.001\n## 1 3 0.001  0.004  0.004 -0.011  0.000  0.003  0.005  0.003  0.010\n## \n## Policy\n##     0 2     0 3     3 1     2 1     2 2     2 3     1 1     1 2     1 3 \n##   \"1 0\"  \"1 -1\"  \"0 -1\"  \"1 -1\" \"-1 -1\"  \"-1 1\"   \"0 0\" \"-1 -1\"   \"1 1\" \n## \n## Reward (last iteration)\n## [1] -1.296"},{"path":"RL.html","id":"concluding-remarks","chapter":"16 Reinforcement learning","heading":"16.5 Concluding remarks","text":"Reinforcement learning applied financial problems long time. Early contributions late 1990s include Neuneier (1996), Moody Wu (1997), Moody et al. (1998) Neuneier (1998). Since , many researchers computer science field sought apply RL techniques portfolio problems. advent massive datasets increase dimensionality make hard RL tools adapt well rich environments encountered factor investing.Recently, approaches seek adapt RL continuous action spaces (H. Wang Zhou (2019), Aboussalah Lee (2020)) high-dimensional state spaces. spaces required factor investing firms yield hundreds data points characterizing economic situation. addition, applications RL financial frameworks particularity compared many typical RL tasks: financial markets, actions agents impact environment (unless agent able perform massive trades, rare ill-advised pushes prices wrong direction). lack impact actions may possibly mitigate efficiency traditional RL approaches.challenges need solved order RL become competitive alternative (supervised) methods. Nevertheless, progressive (online-like) way RL works seems suitable non-stationary environments: algorithm slowly shifts paradigms new data arrives. stationary environments, shown RL manages converge optimal solutions (Kong et al. (2019), Chaouki et al. (2020)). Therefore, non-stationary markets, RL recourse build dynamic predictions adapt changing macroeconomic conditions. research needs carried field large dimensional datasets.end chapter underlining reinforcement learning also used estimate complex theoretical models (Halperin Feldshteyn (2018), Garcı́-Galicia, Carsteanu, Clempner (2019)). research field incredibly diversified orientated towards many directions. likely captivating work published near future.","code":""},{"path":"RL.html","id":"exercises","chapter":"16 Reinforcement learning","heading":"16.6 Exercises","text":"Test happens process generating returns negative autocorrelation. impact \\(Q\\) function policy?Test happens process generating returns negative autocorrelation. impact \\(Q\\) function policy?Keeping 2 assets Section 16.4.2, increases size RL_data testing possible action combinations original data point. Re-run \\(Q\\)-learning function see happens.Keeping 2 assets Section 16.4.2, increases size RL_data testing possible action combinations original data point. Re-run \\(Q\\)-learning function see happens.","code":""},{"path":"data-description.html","id":"data-description","chapter":"17 Data description","heading":"17 Data description","text":"TABLE 17.1:  List variables (features labels) dataset","code":""},{"path":"python.html","id":"python","chapter":"18 Python notebooks","heading":"18 Python notebooks","text":"page hosts Jupyter notebooks make Python version monograph (first edition).\n, official notebooks naturally split chapters.\nalso provide independent implementation Zheyuan Shen, hosted \nGoogle Drive.Chapter 1: Notations & dataChapter 2: IntroductionChapter 3: Factor investing asset pricing anomaliesChapter 4: Data pre-processing","code":""},{"path":"solutions-to-exercises.html","id":"solutions-to-exercises","chapter":"19 Solutions to exercises","heading":"19 Solutions to exercises","text":"","code":""},{"path":"solutions-to-exercises.html","id":"chapter-3","chapter":"19 Solutions to exercises","heading":"19.1 Chapter 3","text":"annual values, see 19.1:\n\nFIGURE 19.1: value factor: annual returns.\nmonthly values, see 19.2:\n\nFIGURE 19.2: value factor: portfolio values.\nPortfolios based quartiles, using tidyverse . rely heavily fact features uniformized, .e., distribution uniform given date. Overall, small firms outperform heavily (see Figure 19.3).\nFIGURE 19.3: value factor: portfolio values.\n","code":"\ndata_ml %>%\n    group_by(date) %>%                                            \n    mutate(growth = Pb > median(Pb)) %>%            # Creates the sort\n    ungroup() %>%                                   # Ungroup\n    mutate(year = lubridate::year(date)) %>%        # Creates a year variable\n    group_by(year, growth) %>%                      # Analyze by year & sort\n    summarize(ret = mean(R1M_Usd)) %>%              # Compute average return\n    ggplot(aes(x = year, y = ret, fill = growth)) + geom_col(position = \"dodge\") + # Plot!\n    theme(legend.position = c(0.7, 0.8))\nreturns_m <- data_ml %>%\n    group_by(date) %>%                                            \n    mutate(growth = Pb > median(Pb)) %>%                         # Creates the sort\n    group_by(date, growth) %>%                                   # Analyze by date & sort\n    summarize(ret = mean(R1M_Usd)) %>%                           # Compute average return\n    spread(key = growth, value = ret) %>%                        # Pivot to wide matrix format\n    ungroup()\ncolnames(returns_m)[2:3] <- c(\"value\", \"growth\")                 # Changing column names\nreturns_m %>%\n    mutate(value = cumprod(1 + value),                           # From returns to portf. values\n           growth = cumprod(1 + growth)) %>%\n    gather(key = portfolio, value = value, -date) %>%            # Back in tidy format\n    ggplot(aes(x = date, y = value, color = portfolio)) + geom_line() +     # Plot!  \n    theme(legend.position = c(0.7, 0.8))\ndata_ml %>%\n    mutate(small = Mkt_Cap_6M_Usd <= 0.25,                        # Small firms...\n           medium = Mkt_Cap_6M_Usd > 0.25 & Mkt_Cap_6M_Usd <= 0.5, \n           large = Mkt_Cap_6M_Usd > 0.5 & Mkt_Cap_6M_Usd <= 0.75,\n           xl = Mkt_Cap_6M_Usd > 0.75,                            # ...Xlarge firms\n           year = year(date)) %>%                        \n    group_by(year) %>%\n    summarize(small = mean(small * R1M_Usd),                      # Compute avg returns\n              medium = mean(medium * R1M_Usd),\n              large = mean(large * R1M_Usd),\n              xl = mean(xl * R1M_Usd)) %>%\n    gather(key = size, value = return, -year) %>%\n    ggplot(aes(x = year, y = return, fill = size)) + geom_col(position = \"dodge\")"},{"path":"solutions-to-exercises.html","id":"chapter-4","chapter":"19 Solutions to exercises","heading":"19.2 Chapter 4","text":", import credit spread supplied Bank America. symbol/ticker “BAMLC0A0CM.” apply data expansion small number predictors save memory space. One important trick overlooked uniformization step product (4.3) computed. Indeed, want new features properties old ones. skip step, distributions altered, show one example .start data extraction joining. ’s important join early keep highest data frequency (daily) order replace missing points close values. Joining monthly data replacing creates unnecessary lags.creation augmented dataset requires manipulation. Features longer uniform shown Figure 19.4.\nFIGURE 19.4: Distribution Eps conditioning.\nprevent issue, uniformization required verified Figure 19.5. \nFIGURE 19.5: Distribution uniformized conditioned feature values.\nsecond question naturally requires downloading VIX series first joining original data.can proceed categorization. create vector label new (smaller) dataset attached large data_ml variable. Also, check balance labels evolution time (see Figure 19.6).\nFIGURE 19.6: Evolution categories time.\nFinally, switch outliers (Figure 19.7). \nFIGURE 19.7: Outliers dependent variable.\nReturns 50 indeed rare.largest return comes stock #683. Let’s look stream monthly returns 2009.returns high. annual value plausible. addition, quick glance Vol1Y values shows stock volatile dataset.","code":"\ngetSymbols.FRED(\"BAMLC0A0CM\",                                    # Extract data\n                env = \".GlobalEnv\", \n                return.class = \"xts\")## [1] \"BAMLC0A0CM\"\ncred_spread <- fortify(BAMLC0A0CM)                               # Transform to dataframe\ncolnames(cred_spread) <- c(\"date\", \"spread\")                     # Change column name\ncred_spread <- cred_spread %>%                                   # Take extraction and...\n    full_join(data_ml %>% dplyr::select(date), by = \"date\") %>%  # Join!\n    mutate(spread = na.locf(spread))                             # Replace NA by previous\ncred_spread <- cred_spread[!duplicated(cred_spread),]            # Remove duplicates\ndata_cond <- data_ml %>%                                    # Create new dataset\n    dplyr::select(c(\"stock_id\", \"date\", features_short))\nnames_cred_spread <- paste0(features_short, \"_cred_spread\") # New column names\nfeat_cred_spread <- data_cond %>%                           # Old values\n    dplyr::select(features_short)\ncred_spread <- data_ml %>%                                  # Create vector of spreads\n    dplyr::select(date) %>%\n    left_join(cred_spread, by = \"date\") \nfeat_cred_spread <- feat_cred_spread *                      # This product creates...\n    matrix(cred_spread$spread,                              # the new values...\n           length(cred_spread$spread),                      # using duplicated...\n           length(features_short))                          # columns\ncolnames(feat_cred_spread) <- names_cred_spread             # New column names\ndata_cond <- bind_cols(data_cond, feat_cred_spread)         # Aggregate old & new\ndata_cond %>% ggplot(aes(x = Eps_cred_spread)) + geom_histogram() # Plot example\ndata_cond <- data_cond %>%                   # From new dataset\n    group_by(date) %>%                       # Group by date and...\n    mutate_at(names_cred_spread, norm_unif)  # Uniformize the new features\ndata_cond %>% ggplot(aes(x = Eps_cred_spread)) + geom_histogram(bins = 100) # Verification\ngetSymbols.FRED(\"VIXCLS\",                           # Extract data\n                env = \".GlobalEnv\", \n                return.class = \"xts\")## [1] \"VIXCLS\"\nvix <- fortify(VIXCLS)                              # Transform to dataframe\ncolnames(vix) <- c(\"date\", \"vix\")                   # Change column name\nvix <- vix %>%                                      # Take extraction and...\n    full_join(data_ml %>% dplyr::select(date), by = \"date\") %>%    # Join! \n    mutate(vix = na.locf(vix))                      # Replace NA by previous\nvix <- vix[!duplicated(vix),]                       # Remove duplicates\nvix <- data_ml %>%                                  # Keep original data format\n    dplyr::select(date) %>%                         # ...\n    left_join(vix, by = \"date\")                     # Via left_join()\ndelta <- 0.5                                       # Magnitude of vix correction\nvix_bar <- median(vix$vix)                         # Median of vix\ndata_vix <- data_ml %>%                            # Smaller dataset\n    dplyr::select(stock_id, date, R1M_Usd) %>%\n    mutate(r_minus = (-0.02) * exp(-delta*(vix$vix-vix_bar)),  # r_-\n           r_plus = 0.02 * exp(delta*(vix$vix-vix_bar)))       # r_+\ndata_vix <- data_vix %>% \n    mutate(R1M_Usd_Cvix = if_else(R1M_Usd < r_minus, -1,       # New label!\n                                  if_else(R1M_Usd > r_plus, 1,0)),\n           R1M_Usd_Cvix = as.factor(R1M_Usd_Cvix))\ndata_vix %>% \n    mutate(year = year(date)) %>%\n    group_by(year, R1M_Usd_Cvix) %>%\n    summarize(nb = n()) %>%\n    ggplot(aes(x = year, y = nb, fill = R1M_Usd_Cvix)) + geom_col()\ndata_ml %>%\n    ggplot(aes(x = R12M_Usd)) + geom_histogram()\ndata_ml %>% filter(R12M_Usd > 50) %>% dplyr::select(stock_id, date, R12M_Usd)## # A tibble: 8 × 3\n##   stock_id date       R12M_Usd\n##      <int> <date>        <dbl>\n## 1      212 2000-12-31     53.0\n## 2      221 2008-12-31     53.5\n## 3      221 2009-01-31     55.2\n## 4      221 2009-02-28     54.8\n## 5      296 2002-06-30     72.2\n## 6      683 2009-02-28     96.0\n## 7      683 2009-03-31     64.8\n## 8      862 2009-02-28     58.0\ndata_ml %>% \n    filter(stock_id == 683, year(date) == 2009) %>% \n    dplyr::select(date, R1M_Usd)## # A tibble: 12 × 2\n##    date       R1M_Usd\n##    <date>       <dbl>\n##  1 2009-01-31  -0.625\n##  2 2009-02-28   0.472\n##  3 2009-03-31   1.44 \n##  4 2009-04-30   0.139\n##  5 2009-05-31   0.086\n##  6 2009-06-30   0.185\n##  7 2009-07-31   0.363\n##  8 2009-08-31   0.103\n##  9 2009-09-30   9.91 \n## 10 2009-10-31   0.101\n## 11 2009-11-30   0.202\n## 12 2009-12-31  -0.251"},{"path":"solutions-to-exercises.html","id":"chapter-5","chapter":"19 Solutions to exercises","heading":"19.3 Chapter 5","text":"recycle training testing data variables created chapter (coding section notably). addition, create dedicated function resort map2() function purrr package.\nFIGURE 19.8: Performance elasticnet across parameter values.\noutlined Figure 19.8, parameters marginal impact. Maybe model good fit task.","code":"\nalpha_seq <- (0:10)/10                     # Sequence of alpha values\nlambda_seq <- 0.1^(0:5)                    # Sequence of lambda values\npars <- expand.grid(alpha_seq, lambda_seq) # Exploring all combinations!\nalpha_seq <- pars[,1]\nlambda_seq <- pars[,2]\nlasso_sens <- function(alpha, lambda, x_train, y_train, x_test, y_test){ # Function\n    fit_temp <- glmnet(x_train, y_train,                                 # Model\n                       alpha = alpha, lambda = lambda)\n    return(sqrt(mean((predict(fit_temp, x_test) - y_test)^2)))           # Output\n}\nrmse_elas <- map2(alpha_seq, lambda_seq, lasso_sens,                     # Automation\n                  x_train = x_penalized_train, y_train = y_penalized_train,\n                  x_test = x_penalized_test, y_test = testing_sample$R1M_Usd)\n\nbind_cols(alpha = alpha_seq, lambda = as.factor(lambda_seq), rmse = unlist(rmse_elas)) %>%\n    ggplot(aes(x = alpha, y = rmse, fill = lambda)) + geom_col() + facet_grid(lambda ~.) +\n    coord_cartesian(ylim = c(0.19,0.193))"},{"path":"solutions-to-exercises.html","id":"chapter-6","chapter":"19 Solutions to exercises","heading":"19.4 Chapter 6","text":"\n\nFIGURE 19.9: Sample (complex) tree.\nfirst model (Figure 19.9) precise: going details training sample translate good performance --sample. second, simpler model, yields better results.Trees definition random results can vary test test. Overall, large numbers trees preferable reason new tree tells new story diversifies risk whole forest. technical details may case outlined original paper Breiman (2001).last exercises, recycle formula used Chapter 6. \nFIGURE 19.10: Tree 2008.\nfirst splitting criterion Figure 19.10 enterprise value (EV). EV indicator adjusts market capitalization substracting debt adding cash. faithful account true value company. 2008, companies fared least poorly highest EV (.e., large, robust firms).\nFIGURE 19.11: Tree 2009.\n2009 (Figure 19.11), firms recovered fastest experienced high volatility past (likely, downwards volatility). Momentum also important: firms lowest past returns rebound fastest. typical example momentum crash phenomenon studied Barroso Santa-Clara (2015) K. Daniel Moskowitz (2016). rationale following: market downturn, stocks potential growth suffered largest losses. Consequently, negative (short) leg momentum factor performs well, often better long leg. indeed, long momentum factor 2009 generated negative profits.","code":"\nfit1 <- rpart(formula, \n              data = training_sample,     # Data source: full sample\n              cp = 0.001)                 # Precision: smaller = more leaves\nmean((predict(fit1, testing_sample) - testing_sample$R1M_Usd)^2) ## [1] 0.04018973\nfit2 <- rpart(formula,\n              data = training_sample,     # Data source: full sample\n              cp = 0.01)                  # Precision: smaller = more leaves\nmean((predict(fit2, testing_sample) - testing_sample$R1M_Usd)^2) # Test!## [1] 0.03699696\nrpart.plot(fit1)                         # Plot the first tree\nn_trees <- c(10, 20, 40, 80, 160)\nmse_RF <- 0\nfor(j in 1:length(n_trees)){       # No need for functional programming here...\n    fit_temp <- randomForest(\n        as.formula(paste(\"R1M_Usd ~\", paste(features_short, collapse = \" + \"))),  # New formula!\n        data = training_sample,    # Data source: training sample\n        sampsize = 30000,          # Size of (random) sample for each tree\n        replace = TRUE,            # Is the sampling done with replacement?\n        ntree = n_trees[j],        # Nb of random trees\n        mtry = 5)                  # Nb of predictors for each tree\n    mse_RF[j] <- mean((predict(fit_temp, testing_sample) - testing_sample$R1M_Usd)^2)\n}\nmse_RF## [1] 0.03967754 0.03885924 0.03766900 0.03696370 0.03699772\ntree_2008 <- rpart(formula,\n                   data = data_ml %>% filter(year(date) == 2008), # Data source: 2008\n                   cp = 0.001,\n                   maxdepth = 2) \nrpart.plot(tree_2008)\ntree_2009 <- rpart(formula,\n                   data = data_ml %>% filter(year(date) == 2009), # Data source: 2009\n                   cp = 0.001,\n                   maxdepth = 2) \nrpart.plot(tree_2009)"},{"path":"solutions-to-exercises.html","id":"chapter-7-the-autoencoder-model-universal-approximation","chapter":"19 Solutions to exercises","heading":"19.5 Chapter 7: the autoencoder model & universal approximation","text":"\nFirst, imperative format inputs properly. avoid issues, work perfectly rectangular data hence restrict investment set stocks missing points. Dimensions must also correct order.Next, turn specification network, using functional API form.Finally, ask structure model, train .second exercise, use simple architecture. activation function, number epochs batch size may matter…full disclosure, improve fit, also increase sample size. show improvement figure .\nFIGURE 19.12: Case 128 units. sine function light blue approximation black.\n","code":"\ndata_short <- data_ml %>%         # Shorter dataset\n    filter(stock_id %in% stock_ids_short) %>%\n    dplyr::select(c(\"stock_id\", \"date\",features_short, \"R1M_Usd\"))\ndates <- unique(data_short$date)  # Vector of dates\n\nN <- length(stock_ids_short)      # Dimension for assets\nTt <- length(dates)               # Dimension for dates\nK <- length(features_short)       # Dimension for features\n\nfactor_data <- data_short %>%  # Factor side date\n    dplyr::select(date, stock_id, R1M_Usd) %>%\n    spread(key = stock_id, value = R1M_Usd) %>%\n    dplyr::select(-date) %>%\n    as.matrix()\n\nbeta_data <- array(unlist(data_short %>%  # Beta side data: beware the permutation below!\n                              dplyr::select(-stock_id, -date, -R1M_Usd)), \n                   dim = c(N, Tt, K))\nbeta_data <- aperm(beta_data, c(2,1,3))   # Permutation\nmain_input <- layer_input(shape = c(N), name = \"main_input\")  # Main input: returns      \nfactor_network <- main_input %>%                              # Def of factor side network\n    layer_dense(units = 8, activation = \"relu\", name = \"layer_1_r\") %>%\n    layer_dense(units = 4, activation = \"tanh\", name = \"layer_2_r\") \n\naux_input <- layer_input(shape = c(N,K), name = \"aux_input\")  # Aux input: characteristics\nbeta_network <- aux_input %>%                                 # Def of beta side network\n    layer_dense(units = 8, activation = \"relu\", name = \"layer_1_l\") %>%\n    layer_dense(units = 4, activation = \"tanh\", name = \"layer_2_l\") %>%\n    layer_permute(dims = c(2,1), name = \"layer_3_l\")          # Permutation!\n\nmain_output <- layer_dot(c(beta_network, factor_network),     # Product of 2 networks\n                         axes = 1, name = \"main_output\") \n\nmodel_ae <- keras_model(                                      # AE Model specs\n    inputs = c(main_input, aux_input),\n    outputs = c(main_output)\n)\nsummary(model_ae)                      # See model details / architecture## Model: \"model_5\"\n## __________________________________________________________________________________________\n## Layer (type)                 Output Shape        Param #    Connected to                  \n## ==========================================================================================\n## aux_input (InputLayer)       [(None, 793, 7)]    0                                        \n## __________________________________________________________________________________________\n## layer_1_l (Dense)            (None, 793, 8)      64         aux_input[0][0]               \n## __________________________________________________________________________________________\n## main_input (InputLayer)      [(None, 793)]       0                                        \n## __________________________________________________________________________________________\n## layer_2_l (Dense)            (None, 793, 4)      36         layer_1_l[0][0]               \n## __________________________________________________________________________________________\n## layer_1_r (Dense)            (None, 8)           6352       main_input[0][0]              \n## __________________________________________________________________________________________\n## layer_3_l (Permute)          (None, 4, 793)      0          layer_2_l[0][0]               \n## __________________________________________________________________________________________\n## layer_2_r (Dense)            (None, 4)           36         layer_1_r[0][0]               \n## __________________________________________________________________________________________\n## main_output (Dot)            (None, 793)         0          layer_3_l[0][0]               \n##                                                             layer_2_r[0][0]               \n## ==========================================================================================\n## Total params: 6,488\n## Trainable params: 6,488\n## Non-trainable params: 0\n## __________________________________________________________________________________________\nmodel_ae %>% compile(                  # Learning parameters\n    optimizer = \"rmsprop\",\n    loss = \"mse\"\n)\n\nmodel_ae %>% fit(                      # Learning function\n    x = list(main_input = factor_data, aux_input = beta_data),\n    y = list(main_output = factor_data),\n    epochs = 20,                      # Nb rounds\n    batch_size = 49                   # Nb obs. per round\n)\nmodel_ua <- keras_model_sequential()\nmodel_ua %>%   # This defines the structure of the network, i.e. how layers are organized\n    layer_dense(units = 16, activation = 'sigmoid', input_shape = 1) %>%\n    layer_dense(units = 1) # \nmodel_ua %>% compile(                             # Model specification\n    loss = 'mean_squared_error',                  # Loss function\n    optimizer = optimizer_rmsprop(),              # Optimisation method (weight updating)\n    metrics = c('mean_absolute_error')            # Output metric\n)\nsummary(model_ua)                                 # A simple model!## Model: \"sequential_31\"\n## __________________________________________________________________________________________\n## Layer (type)                            Output Shape                        Param #       \n## ==========================================================================================\n## dense_83 (Dense)                        (None, 16)                          32            \n## __________________________________________________________________________________________\n## dense_82 (Dense)                        (None, 1)                           17            \n## ==========================================================================================\n## Total params: 49\n## Trainable params: 49\n## Non-trainable params: 0\n## __________________________________________________________________________________________\nfit_ua <- model_ua %>% \n    fit(seq(0, 6, by = 0.001) %>% matrix(ncol = 1),              # Training data = x\n        sin(seq(0, 6, by = 0.001)) %>% matrix(ncol = 1),         # Training label = y\n        epochs = 30, batch_size = 64                             # Training parameters\n) \nmodel_ua2 <- keras_model_sequential()\nmodel_ua2 %>%   # This defines the structure of the network, i.e. how layers are organized\n    layer_dense(units = 128, activation = 'sigmoid', input_shape = 1) %>%\n    layer_dense(units = 1) # \nmodel_ua2 %>% compile(                             # Model specification\n    loss = 'mean_squared_error',                  # Loss function\n    optimizer = optimizer_rmsprop(),              # Optimisation method (weight updating)\n    metrics = c('mean_absolute_error')            # Output metric\n)\nsummary(model_ua2)                                 # A simple model!## Model: \"sequential_18\"\n## __________________________________________________________________________________________\n## Layer (type)                            Output Shape                        Param #       \n## ==========================================================================================\n## dense_46 (Dense)                        (None, 128)                         256           \n## __________________________________________________________________________________________\n## dense_45 (Dense)                        (None, 1)                           129           \n## ==========================================================================================\n## Total params: 385\n## Trainable params: 385\n## Non-trainable params: 0\n## __________________________________________________________________________________________\nfit_ua2 <- model_ua2 %>% \n    fit(seq(0, 6, by = 0.0002) %>% matrix(ncol = 1),            # Training data = x\n        sin(seq(0, 6, by = 0.0002)) %>% matrix(ncol = 1),       # Training label = y\n        epochs = 60, batch_size = 64                            # Training parameters\n) \ntibble(x = x) %>%\n  ggplot() + \n  geom_line(aes(x = x, y = predict(model_ua, x), color = \"Small model\")) +\n  geom_line(aes(x = x, y = predict(model_ua2, x), color = \"Large model\")) +\n  stat_function(fun = sin, aes(color = \"sin(x) function\")) + \n  scale_color_manual(values = c(\"#9999FF\", \"#333399\", \"#000000\"))"},{"path":"solutions-to-exercises.html","id":"chapter-8","chapter":"19 Solutions to exercises","heading":"19.6 Chapter 8","text":"Since going reproduce similar analysis several times, let’s simplify task 2 tips. First, using default parameter values passed common arguments svm function. Second, creating custom function computes MSE. Third, resorting functional calculus via map function purrr package. , recycle datasets created Chapter 6. first two kernels yield best fit, last one avoided. Note apart linear kernel, options require parameters. used default ones, may explain poor performance nonlinear kernels., train SVM model training sample observations limited 7 major predictors. Even smaller number features, training time consuming.figure low. , test simple form boosted trees, comparison purposes.forecasts slightly better, computation time lower. Two reasons models perform poorly:enough predictors;models static: adjust dynamically macro-conditions.","code":"\nmse <- function(fit, features, label){             # MSE function\n    return(mean((predict(fit, features)-label)^2))\n}\npar_list <- list(y = train_label_xgb[1:10000],     # From Tree chapter\n                 x = train_features_xgb[1:10000,],\n                 type = \"eps-regression\",\n                 epsilon = 0.1,                    # Width of strip for errors\n                 gamma = 0.5,                      # Constant in the radial kernel \n                 cost = 0.1)\nsvm_par <- function(kernel, par_list){             # Function for SVM fit automation\n    require(e1071)\n    return(do.call(svm, c(kernel = kernel, par_list))) \n}\nkernels <- c(\"linear\", \"radial\", \"polynomial\", \"sigmoid\") # Kernels\nfit_svm_par <- map(kernels, svm_par, par_list = par_list) # SVM models\nmap(fit_svm_par, mse,                                     # MSEs\n    features = test_feat_short,                           # From SVM chapter \n    label = testing_sample$R1M_Usd)## [[1]]\n## [1] 0.03849786\n## \n## [[2]]\n## [1] 0.03924576\n## \n## [[3]]\n## [1] 0.03951328\n## \n## [[4]]\n## [1] 334.8173\nsvm_full <- svm(y = train_label_xgb,      # Train label\n                x = train_features_xgb,   # Training features\n                type = \"eps-regression\",  # SVM task type (see LIBSVM documentation)\n                kernel = \"linear\",        # SVM kernel \n                epsilon = 0.1,            # Width of strip for errors\n                cost = 0.1)               # Slack variable penalisation\ntest_feat_short <- dplyr::select(testing_sample,features_short)       # Test set\nmean(predict(svm_full, test_feat_short) * testing_sample$R1M_Usd > 0) # Hit ratio## [1] 0.490343\nxgb_full <- xgb.train(data = train_matrix_xgb,    # Data source \n                      eta = 0.3,                          # Learning rate\n                      objective = \"reg:linear\",           # Objective function\n                      max_depth = 4,                      # Maximum depth of trees\n                      nrounds = 60                        # Number of trees used (bit low here)\n)## [14:44:45] WARNING: amalgamation/../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\nmean(predict(xgb_full, xgb_test) * testing_sample$R1M_Usd > 0) # Hit ratio## [1] 0.5017377"},{"path":"solutions-to-exercises.html","id":"chapter-11-ensemble-neural-network","chapter":"19 Solutions to exercises","heading":"19.7 Chapter 11: ensemble neural network","text":"First, create three feature sets. first one gets multiples 3 3 93. second one gets indices, minus one, third one, initial indices minus two., specify network structure. First, 3 independent networks, aggregation.Lastly, can train evaluate (see Figure 19.13).\nFIGURE 19.13: Learning integrated ensemble.\n","code":"\nfeat_train_1 <- training_sample %>% dplyr::select(features[3*(1:31)]) %>%   # First set of feats\n    as.matrix() \nfeat_train_2 <- training_sample %>% dplyr::select(features[3*(1:31)-1]) %>% # Second set of feats\n    as.matrix() \nfeat_train_3 <- training_sample %>% dplyr::select(features[3*(1:31)-2]) %>% # Third set of feats\n    as.matrix() \nfeat_test_1 <- testing_sample %>% dplyr::select(features[3*(1:31)]) %>%     # Test features 1\n    as.matrix() \nfeat_test_2 <- testing_sample %>% dplyr::select(features[3*(1:31)-1]) %>%   # Test features 2\n    as.matrix() \nfeat_test_3 <- testing_sample %>% dplyr::select(features[3*(1:31)-2]) %>%   # Test features 3\n    as.matrix() \nfirst_input <- layer_input(shape = c(31), name = \"first_input\")   # First input      \nfirst_network <- first_input %>%                                  # Def of 1st network\n    layer_dense(units = 8, activation = \"relu\", name = \"layer_1\") %>%\n    layer_dense(units = 2, activation = 'softmax')                # Softmax for categ. output\nsecond_input <- layer_input(shape = c(31), name = \"second_input\") # Second input      \nsecond_network <- second_input %>%                                # Def of 2nd network\n    layer_dense(units = 8, activation = \"relu\", name = \"layer_2\") %>%\n    layer_dense(units = 2, activation = 'softmax')                # Softmax for categ. output\nthird_input <- layer_input(shape = c(31), name = \"third_input\")  # Third input      \nthird_network <- third_input %>%                                  # Def of 3rd network\n    layer_dense(units = 8, activation = \"relu\", name = \"layer_3\") %>%\n    layer_dense(units = 2, activation = 'softmax')                # Softmax for categ. output\n\nmain_output <- layer_concatenate(c(first_network, \n                                   second_network,\n                                   third_network)) %>%            # Combination\n    layer_dense(units = 2, activation = 'softmax', name = 'main_output')\n\nmodel_ens <- keras_model(                                          # Agg. Model specs\n    inputs = c(first_input, second_input, third_input),\n    outputs = c(main_output)\n)\nsummary(model_ens)                      # See model details / architecture## Model: \"model_6\"\n## __________________________________________________________________________________________\n## Layer (type)                 Output Shape        Param #    Connected to                  \n## ==========================================================================================\n## first_input (InputLayer)     [(None, 31)]        0                                        \n## __________________________________________________________________________________________\n## second_input (InputLayer)    [(None, 31)]        0                                        \n## __________________________________________________________________________________________\n## third_input (InputLayer)     [(None, 31)]        0                                        \n## __________________________________________________________________________________________\n## layer_1 (Dense)              (None, 8)           256        first_input[0][0]             \n## __________________________________________________________________________________________\n## layer_2 (Dense)              (None, 8)           256        second_input[0][0]            \n## __________________________________________________________________________________________\n## layer_3 (Dense)              (None, 8)           256        third_input[0][0]             \n## __________________________________________________________________________________________\n## dense_84 (Dense)             (None, 2)           18         layer_1[0][0]                 \n## __________________________________________________________________________________________\n## dense_85 (Dense)             (None, 2)           18         layer_2[0][0]                 \n## __________________________________________________________________________________________\n## dense_86 (Dense)             (None, 2)           18         layer_3[0][0]                 \n## __________________________________________________________________________________________\n## concatenate_1 (Concatenate)  (None, 6)           0          dense_84[0][0]                \n##                                                             dense_85[0][0]                \n##                                                             dense_86[0][0]                \n## __________________________________________________________________________________________\n## main_output (Dense)          (None, 2)           14         concatenate_1[0][0]           \n## ==========================================================================================\n## Total params: 836\n## Trainable params: 836\n## Non-trainable params: 0\n## __________________________________________________________________________________________\nmodel_ens %>% compile(                  # Learning parameters\n    optimizer = optimizer_adam(),\n    loss = \"binary_crossentropy\",\n    metrics = \"categorical_accuracy\"\n)\n\nfit_NN_ens <- model_ens %>% fit(               # Learning function\n    x = list(first_input = feat_train_1, \n             second_input = feat_train_2,\n             third_input = feat_train_3),\n    y = list(main_output = NN_train_labels_C), # Recycled from NN Chapter\n    epochs = 12,                               # Nb rounds\n    batch_size = 512,                          # Nb obs. per round\n    validation_data = list(list(feat_test_1, feat_test_2, feat_test_3),\n                           NN_test_labels_C)\n)\nplot(fit_NN_ens)"},{"path":"solutions-to-exercises.html","id":"chapter-12","chapter":"19 Solutions to exercises","heading":"19.8 Chapter 12","text":"","code":""},{"path":"solutions-to-exercises.html","id":"ew-portfolios-with-the-tidyverse","chapter":"19 Solutions to exercises","heading":"19.8.1 EW portfolios with the tidyverse","text":"one incredibly easy; ’s simpler compact close spirit code generates Figure 3.1. returns plotted Figure 19.14.\n\nFIGURE 19.14: Time series returns.\n","code":"\ndata_ml %>%\n  group_by(date) %>%                     # Group by date\n  summarize(return = mean(R1M_Usd)) %>%  # Compute return\n  ggplot(aes(x = date, y = return)) + geom_point() + geom_line() # Plot"},{"path":"solutions-to-exercises.html","id":"advanced-weighting-function","chapter":"19 Solutions to exercises","heading":"19.8.2 Advanced weighting function","text":"First, code function inputs.Second, test random dataset. use returns created end Chapter 1 used Lasso allocation Section 5.2.2. \\(\\boldsymbol{\\mu}\\), use sample average, rarely good idea practice. serves illustration .weights can course negative. Finally, use map2() function test sensitivity. examine 3 key indicators:\n- diversification, measure via inverse sum squared weights (inverse Hirschman-Herfindhal index);\n- leverage, assess via absolute sum negative weights;\n- -sample volatility, compute \\(\\textbf{w}' \\boldsymbol{\\Sigma} \\textbf{x}\\), create dedicated function .Instead using baseline map2 function, rely version thereof concatenates results dataframe directly.\nFIGURE 19.15: Indicators related portfolio weights.\nFigure 19.15, panel displays indicator. first panel, see diversification increases \\(k_D\\): indeed, number increases, portfolio converges uniform (EW) values. parameter \\(\\lambda\\) minor impact. second panel naturally shows inverse effect leverage: diversification increases \\(k_D\\), leverage (.e., total negative positions - shortsales) decreases. Finally, last panel shows -sample volatility however largely driven risk aversion parameter. \\(\\lambda\\) increases, volatility logically decreases. small values \\(\\lambda\\), \\(k_D\\) negatively related volatility pattern reverses large values \\(\\lambda\\). equally weighted portfolio less risky leveraged mean-variance policies, risky minimum-variance portfolio.","code":"\nweights <- function(Sigma, mu, Lambda, lambda, k_D, k_R, w_old){\n    N <- nrow(Sigma)\n    M <- solve(lambda*Sigma + 2*k_R*Lambda + 2*k_D*diag(N)) # Inverse matrix\n    num <- 1-sum(M %*% (mu + 2*k_R*Lambda %*% w_old))       # eta numerator\n    den <- sum(M %*% rep(1,N))                              # eta denominator\n    eta <- num / den                                        # eta\n    vec <- mu + eta * rep(1,N) + 2*k_R*Lambda %*% w_old     # Vector in weight\n    return(M %*% vec)\n}\nSigma <- returns %>% dplyr::select(-date) %>% as.matrix() %>% cov()  # Covariance matrix\nmu <- returns %>% dplyr::select(-date) %>% apply(2,mean)             # Vector of exp. returns\nLambda <- diag(nrow(Sigma))                                          # Trans. Cost matrix\nlambda <- 1                                                          # Risk aversion\nk_D <- 1\nk_R <- 1\nw_old <- rep(1, nrow(Sigma)) / nrow(Sigma)                           # Prev. weights: EW\nweights(Sigma, mu, Lambda, lambda, k_D, k_R, w_old) %>% head()       # First weights##             [,1]\n## 1   0.0031339308\n## 3  -0.0003243527\n## 4   0.0011944677\n## 7   0.0014194215\n## 9   0.0015086240\n## 11 -0.0005015207\nsensi <- function(lambda, k_D, Sigma, mu, Lambda, k_R, w_old){\n    w <- weights(Sigma, mu, Lambda, lambda, k_D, k_R, w_old)\n    out <- c()\n    out$div <- 1/sum(w^2)             # Diversification\n    out$lev <- sum(abs(w[w<0]))       # Leverage\n    out$vol <- t(w) %*% Sigma %*% w   # In-sample vol\n    return(out)\n}\nlambda <- 10^(-3:2)              # parameter values\nk_D <- 2*10^(-3:2)               # parameter values\npars <- expand_grid(lambda, k_D) # parameter grid\nlambda <- pars$lambda\nk_D <- pars$k_D\n\nres <- map2_dfr(lambda, k_D, sensi, \n                Sigma = Sigma, mu = mu, Lambda = Lambda, k_R = k_R, w_old = w_old)\n\nbind_cols(lambda = as.factor(lambda), k_D = as.factor(k_D), res) %>%\n    gather(key = indicator, value = value, -lambda, -k_D) %>%\n    ggplot(aes(x = lambda, y = value, fill = k_D)) + geom_col(position = \"dodge\") +\n    facet_grid(indicator ~. , scales = \"free\")"},{"path":"solutions-to-exercises.html","id":"functional-programming-in-the-backtest","chapter":"19 Solutions to exercises","heading":"19.8.3 Functional programming in the backtest","text":"\nOften, programmers prefer avoid loops. order avoid loop backtest, need code happens one given date. encapsulated following function. simplicity, code one strategy. Also, function assume structure data known, columns (features & labels) also passed arguments. recycle function weights_xgb Chapter 12.Next, combine function map(). test first 6 dates: reduces computation times.element backtest list two components: portfolio weights returns. access data easily, functions like melt package reshape2 useful.","code":"\nportf_map <- function(t, data_ml, ticks, t_oos, m_offset, train_size, weight_func){\n    train_data <- data_ml %>% filter(date < t_oos[t] - m_offset * 30,   # Roll. window w. buffer\n                                     date > t_oos[t] - m_offset * 30 - 365 * train_size)\n    test_data <- data_ml %>% filter(date == t_oos[t])                   # Test set  \n    realized_returns <- test_data %>%                                   # Computing returns via:\n        dplyr::select(R1M_Usd)                                          # 1M holding period!\n    temp_weights <- weight_func(train_data, test_data, features)        # Weights = > recycled!\n    ind <- match(temp_weights$names, ticks) %>% na.omit()               # Index of test assets\n    x <- c() \n    x$weights <- rep(0, length(ticks))                           # Empty weights\n    x$weights[ind] <- temp_weights$weights                       # Locate weights correctly\n    x$returns <- sum(temp_weights$weights * realized_returns)    # Compute returns\n    return(x)\n}\nback_test <- 1:3 %>%             # Test on the first 100 out-of-sample dates\n    map(portf_map, data_ml = data_ml, ticks = ticks, t_oos = t_oos,\n        m_offset = 1, train_size = 5, weight_func = weights_xgb)\nhead(back_test[[1]]$weights)     # Sample weights## [1] 0.001675042 0.000000000 0.000000000 0.001675042 0.000000000 0.001675042\nback_test[[1]]$returns           # Return of first period## [1] 0.0189129"},{"path":"solutions-to-exercises.html","id":"chapter-15","chapter":"19 Solutions to exercises","heading":"19.9 Chapter 15","text":"recycle AE model trained Chapter 15. Strangely, building smaller models (encoder) larger ones (AE) requires save reload weights. creates external file, call “ae_weights.” can check output 4 columns (compressed) instead 7 (original data).\n","code":"\nsave_model_weights_hdf5(object = ae_model,filepath =\"ae_weights.hdf5\", overwrite = TRUE)\nencoder_model <- keras_model(inputs = input_layer, outputs = encoder)\nencoder_model %>% \n    load_model_weights_hdf5(filepath = \"ae_weights.hdf5\",skip_mismatch = TRUE,by_name = TRUE)\nencoder_model %>% compile(\n    loss = 'mean_squared_error',\n    optimizer = 'adam',\n    metrics = c('mean_absolute_error')\n)\nencoder_model %>% \n  keras::predict_on_batch(x = training_sample %>% \n                              dplyr::select(features_short) %>% \n                              as.matrix()) %>%\n    head(5)##            [,1]      [,2]        [,3]      [,4]\n## [1,] -0.4481973 0.6415710 -0.08774725 -1.083881\n## [2,] -0.4586810 0.6319650 -0.07966632 -1.051239\n## [3,] -0.4436134 0.6245905 -0.07436219 -1.116247\n## [4,] -0.4438604 0.6197044 -0.07135797 -1.128985\n## [5,] -0.4508429 0.6114001 -0.07056579 -1.150953"},{"path":"solutions-to-exercises.html","id":"chapter-16","chapter":"19 Solutions to exercises","heading":"19.10 Chapter 16","text":"need change rho coefficient code Chapter 16. learning can proceed.case, constantly switching feature return process changes outcome. negative state associated large profits portfolio fully invested, positive state best average reward agent refrains investing.second exercise, trick define possible actions, combinations (+1,0-1) two assets dates. recycle data Chapter 16.can plug data RL function.matrix less sparse compared one Chapter 16; covered much ground! policy recommendations changed compared smaller sample, ! change occurs states points available first trial. data, decision altered.","code":"\nset.seed(42)                                                 # Fixing the random seed\nn_sample <- 10^5                                             # Number of samples generated\nrho <- (-0.8)                                                # Autoregressive parameter\nsd <- 0.4                                                    # Std. dev. of noise\na <- 0.06 * rho                                              # Scaled mean of returns\ndata_RL3 <- tibble(returns = a/rho + arima.sim(n = n_sample, # Returns via AR(1) simulation\n                                               list(ar = rho),       \n                                               sd = sd),\n                   action = round(runif(n_sample)*4)/4) %>%   # Random action (portfolio)\n    mutate(new_state = if_else(returns < 0, \"neg\", \"pos\"),   # Coding of state\n           reward = returns * action,                        # Reward = portfolio return\n           state = lag(new_state),                           # Next state\n           action = as.character(action)) %>% \n    na.omit()                                                # Remove one missing state\ncontrol <- list(alpha = 0.1,                        # Learning rate\n                gamma = 0.7,                        # Discount factor for rewards\n                epsilon = 0.1)                      # Exploration rate\nfit_RL3 <- ReinforcementLearning(data_RL3,          # Main RL function\n                                 s = \"state\", \n                                 a = \"action\", \n                                 r = \"reward\", \n                                 s_new = \"new_state\", \n                                 control = control)\nprint(fit_RL3)   # Show the output## State-Action function Q\n##          0.25         0         1      0.75       0.5\n## neg 0.7107268 0.5971710 1.4662416 0.9535698 0.8069591\n## pos 0.7730842 0.7869229 0.4734467 0.4258593 0.6257039\n## \n## Policy\n## neg pos \n## \"1\" \"0\" \n## \n## Reward (last iteration)\n## [1] 3013.162\npos_3 <- c(-1,0,1)                              # Possible alloc. to asset 1\npos_4 <- c(-1,0,1)                              # Possible alloc. to asset 3\npos <- expand_grid(pos_3, pos_4)                # All combinations\npos <- bind_cols(pos, id = 1:nrow(pos))         # Adding combination id\n\nret_pb_RL <- bind_cols(r3 = return_3, r4 = return_4, # Returns & P/B dataframe\n                       pb3 = pb_3, pb4 = pb_4) \ndata_RL4 <- sapply(ret_pb_RL,                        # Combining return & positions\n                   rep.int, \n                   times = nrow(pos)) %>%\n    data.frame() %>%\n    bind_cols(id = rep(1:nrow(pos), 1, each = length(return_3))) %>%\n    left_join(pos) %>% dplyr::select(-id) %>%\n    mutate(action = paste(pos_3, pos_4),            # Uniting actions\n           pb3 = round(5 * pb3),                    # Simplifying states\n           pb4 = round(5 * pb4),                    # Simplifying states\n           state = paste(pb3, pb4),                 # Uniting states\n           reward = pos_3*r3 + pos_4*r4,            # Computing rewards\n           new_state = lead(state)) %>%             # Infer new state\n    dplyr::select(-pb3, -pb4, -pos_3,          # Remove superfluous vars.\n                  -pos_4, -r3, -r4) \nfit_RL4 <- ReinforcementLearning(data_RL4,           # Main RL function\n                                 s = \"state\", \n                                 a = \"action\", \n                                 r = \"reward\", \n                                 s_new = \"new_state\", \n                                 control = control)\nfit_RL4$Q <- round(fit_RL4$Q, 3) # Round the Q-matrix\nprint(fit_RL4)                   # Show the output ## State-Action function Q\n##       0 0    0 1  0 -1  -1 -1   -1 0   -1 1   1 -1    1 0    1 1\n## 0 2 0.000  0.000 0.002 -0.017 -0.018 -0.020  0.023  0.025  0.024\n## 0 3 0.001 -0.005 0.007 -0.013 -0.019 -0.026  0.031  0.027  0.021\n## 3 1 0.003  0.003 0.003  0.002  0.002  0.003  0.002  0.002  0.003\n## 2 1 0.027  0.038 0.020  0.004  0.015  0.039  0.013  0.021  0.041\n## 2 2 0.021  0.014 0.027  0.038  0.047  0.045 -0.004 -0.011 -0.016\n## 2 3 0.007  0.006 0.008  0.054  0.057  0.056 -0.041 -0.041 -0.041\n## 1 1 0.027  0.054 0.005 -0.031 -0.005  0.041  0.025  0.046  0.072\n## 1 2 0.019  0.020 0.020  0.015  0.023  0.029  0.012  0.014  0.023\n## 1 3 0.008  0.019 0.000 -0.036 -0.027 -0.016  0.042  0.053  0.060\n## \n## Policy\n##    0 2    0 3    3 1    2 1    2 2    2 3    1 1    1 2    1 3 \n##  \"1 0\" \"1 -1\" \"0 -1\"  \"1 1\" \"-1 0\" \"-1 0\"  \"1 1\" \"-1 1\"  \"1 1\" \n## \n## Reward (last iteration)\n## [1] 0"}]
